A couple of videos ago, I made the statement that the rank of a matrix A is equal to the rank of its transpose. And I made a bit of a hand wavy argument. It was at the end of the video. And I was tired. It was actually at the end of the day. And I thought it would be worthwhile to maybe flush this out a little bit, because it's an important takeaway. And it'll help us understand everything we've learned a little bit better. So let's just understand what the, actually, I'm going to start with the rank of A transpose. The rank of A transpose. The rank of A transpose is equal to the dimension of the column space of A transpose. That's the definition of the rank. And what is it? The dimension of the column space of A transpose is the number of basis vectors for the column space of A transpose. That's what dimension is. For any subspace, you figure out how many basis vectors you need in that subspace. And you count them, and that's your dimension. So it's the number of basis vectors for the column space of A transpose, which is, of course, the same thing. This thing, we've seen multiple times, is the same thing as the row space of A. The columns of A transpose are the same thing as the rows of A, just because you switch the rows and the columns. Now, how can we figure out the number of basis vectors we need for the column space of A transpose, or the row space of A? So let's just think about what the column space of A transpose is telling us. So it's equivalent to, so let's say, let me draw A like this. Let me draw A. I have some matrix A. Let's say it's an m by n matrix. And let me just write it as a bunch of row vectors. I could also write it as a bunch of column vectors. But right now, let's just stick to the row vectors. So we'd have row 1, the transpose of column vectors. We can just write that's row 1. And we're going to have row 2. And we're going to go all the way down to row m. It's an m by n matrix. Each of these vectors are members of Rn, because they're going to have n entries in them, because we have n columns. So that's what A is going to look like. A is going to look like that. And then A transpose, all of these rows are going to become columns. A transpose is going to look like this. R1, R2, all the way to Rm. And this is, of course, going to be an n by m matrix. You swap these out. So all these rows are going to be columns. And obviously, the column space, or maybe not so obviously, the column space of A transpose is equal to the span of R1, R2, all the way to Rm. It's equal to the span of these things. Or you could equivalently call it, it's equal to the span of the rows of A. That's why it's called the row space. So this is equal to the span of the rows of A. These two things are equivalent. Now, these are the span. That means this is some subspace. It's all of the linear combinations of these columns, or all the linear combinations of these rows. If we want the basis for it, we want to find a minimum set of linearly independent vectors that we could use to construct any of these columns, or that we could use to construct any of these rows right here. Now, what happens when we put A into reduced row echelon form? So we do a bunch of row operations to put it into reduced row echelon form. You do a bunch of row operations, and you eventually you'll get something like this. You'll get the reduced row echelon form of A. The reduced row echelon form of A is going to look something like this. You're going to have some pivot rows, some rows that have pivot entries. Let's say that's one of them. Let's say that's one of them. This will all have zeros all the way down. This one will have zeros. Your pivot entry has to be the only non-zero entry in its column, and everything to the left of it also has to be zero. Let's say that this one isn't. These are some non-zero values. These are zero. See, we have another pivot entry over here. Everything else is zero. And let's say everything else are non-pivot entries. So you come here, and you add a certain number of pivot rows, or a certain number of pivot entries. And you got there by performing linear row operations on these guys. So those linear row operations, I take 3 times row 2, and I add it to row 1, and that's going to become my new row 2. And you keep doing that, and you get these things here. So these things here are linear combinations of those guys. Or another way to do it, you could reverse those row operations. I could start with these guys right here, and I could just as easily perform the reverse row operations. Any linear operation, you could perform the reverse of it. We've seen that multiple times. You could perform row operations with these guys to get all of these guys. Or another way to view it is, these vectors here, these row vectors right here, they span all of these, or all of these row vectors, can be represented as linear combinations of your pivot rows right here. Obviously, your non-pivot rows are going to be all zeros. And those are useless. But your pivot rows, if you take linear combinations of them, you can clearly do reverse row echelon form and get back to your matrix. So all of these guys can be represented as linear combinations of them. And all of these pivot entries are by definition, well, almost by definition, they're linearly independent. Because I've got a 1 here, no one else has a 1 there, so this guy can definitely not be represented as a linear combination of the other guys. So why am I going through this whole exercise? Well, we started off saying we wanted a basis for the row space. We wanted some minimum set of linearly independent vectors that spans everything that these guys can span. Well, if all of these guys can be represented as linear combinations of these row vectors in reduced row echelon form, or these pivot rows in reduced row echelon form, and these guys are all linearly independent, then they are a reasonable basis. So these pivot rows right here, that's one of them. This is the second one. This is the third one. Maybe they're the only three. This is just my particular example. That would be a suitable basis for the row space. So let me write this down. The pivot rows in reduced row echelon form of A are A basis for the row space of A. And the row space of A is the same thing, or the column space of A transpose. Row space of A is the same thing as the column space of A transpose. We've seen that multiple times. Now, so if we want to know the dimension of your column space, will you just count the number of pivot rows you have? So you just count the number of pivot rows. So the dimension of your row space, which is the same thing as the column space of A transpose, is going to be the number of pivot rows you have in reduced row echelon form. Or, even simpler, the number of pivot entries you have, because every pivot entry has a pivot row. So we can say, we can write that the rank of A transpose is equal to the number of pivot entries in reduced row echelon form of A. Because every pivot entry corresponds to a pivot row. Those pivot rows are a suitable basis for the entire row space, because every row can be made with a linear combination of these guys. And since all of these can be, then anything that these guys can construct, these guys can construct. Fair enough. Now, what is the rank of A? This is the rank of A transpose that we've been dealing with so far. The rank of A is equal to the dimension of the column space of A. Or, you could say, it's the number of vectors in the basis for the column space of A. So if we take that same matrix A that we used above, and instead we write it as a bunch of column vectors. So C1, C2, all the way to Cn. We have n columns right there. The column space is essentially the subspace that's spanned by all of these characters right here. So the column space of A is equal to the span of C1, C2, all the way to Cn. That's the definition of it. But we want to know the number of basis vectors. And we've seen before, we've done this multiple times, the basis vectors, suitable basis vectors could be, if you put this into reduced row echelon form, and you have some pivot entries, and they're corresponding pivot columns. So some pivot entries with their corresponding pivot columns, just like that. Maybe that's like that. And then maybe this one isn't one, and then this one is. So you have a certain number of pivot columns. Let me do them in another color right here. When you put A into reduced row echelon form, we learned that the basis vectors, or the basis columns that form a basis for your column space, are the columns that correspond to the pivot columns. So the first column here is a pivot column, so this guy could be a basis vector. The second column is, so this guy could be a pivot vector. And maybe the fourth one right here, so this guy could be a pivot vector. So in general, you just say, hey, if you want to count the number of basis vectors, because we only have to know what they are to figure out the rank, we just have to know the number they are. Well, you say, well, for every pivot column here, we have a basis vector over there. So we could just count the number of pivot columns. But the number of pivot columns is equivalent to just the number of pivot entries we have, because every pivot entry gets its own column. So we could say that the rank of A is equal to the number of pivot entries in the reduced row echelon form of A. And as you can see very clearly, that's the exact same thing that we deduced was equivalent to the rank of A transpose, or the dimension of the column space of A transpose, or the dimension of the row space of A. So we can now write our conclusion. The rank of A is definitely the same thing as the rank of A transpose.