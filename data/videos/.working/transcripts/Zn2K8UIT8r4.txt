Let's say I've got some set A of the vectors a1, a2, all the way to an. And I know for a fact that it's a basis for the subspace V. What I want to show you in this video is that if this guy has n elements right here, that any set that spans V has to have at least n elements. So any spanning set must have at least n elements, n elements, or n members, or cardinality of n. There's all just a ways of saying you've got n vectors in this set. So let's see if we could, if we could, if we have, if I'm saying that every set that spans V must have at least n elements, if the sum basis set has n elements for V, let's see if we can kind of run with a set that has less than n elements and see if we reach any contradictions. So let's say that I have some set B here, and it's equal to the vectors B1, B2, all the way to BM. And M is less than n, so I have some set of vectors here that have fewer elements than my set A. And let's say that B spans, you come to me one day and you say, look, I found you this set of vectors right here. And not only does it have fewer elements than A, but it spans V. And I look at you very suspiciously because I always thought that this green statement was true. So we start a little bit of a thought experiment. And I say, OK, you claim that your set spans V, so let's do something. Let me define a new set. Let me call this new set B1 prime, and you'll see why I'm doing this kind of strange notation. What's essentially going to be is the set B plus my vector A1. So it's A1, and then I have all of my elements of B. So B1, B2, all the way to BM. Now, I think you and I could both agree that this set is linearly dependent. How do I know that? Linear dependence means that at least one of the elements of the set can be represented as a linear combination of the others. Well, we know that A1, it's one of the basis vectors for V, for this definition of a basis. But all of the basis vectors are members of V. If this set is a basis for V, then this means that this set spans V, or that every member of V can be represented as a linear combination of these guys. Or in other ways, every linear combination of these guys is in V. And one of the linear combinations of these guys is you just set the coefficient on A1 to be 0, and the coefficient on A1 to be 1, and the coefficients on everyone else to be 0. So obviously, A1 is also in the set. So if A1 is in V, and all of these guys span V, by definition, if these guys span V, some linear combination of these guys can be used to construct any member of V. So you can take some linear combination of these guys to construct A1. So you could say A1 is equal to, maybe it's D1, where the D's are the constants, D1, B1 plus D2, B2, all the way to DM, BM. And at least one of these have to be non-zero. We know that A is a non-zero vector. If it was a zero vector, this couldn't be a basis, because it wouldn't be linearly independent, because you can always represent a zero vector as really just a zero times any other vector. So this won't be a zero vector. So at least one of these are non-zero. So let's just say, for the sake of argument, that DJ, so the coefficient on BJ, is non-zero. So DJ does not equal zero. So what we could actually do is we could solve for that term. So over here, someplace you have the term DJBJ, and it's plus a bunch of other stuff. We can solve for this term. So if we subtract it from both sides of the equation, and then divide both sides by minus DJ, and put this minus A1 on the other side, what do we get? I know there's a lot of operations, but that's just straight up algebra. I think you can say that we could rewrite this right here. We can solve for BJ. We could solve for our BJ term, and say that should be equal to minus 1 over its coefficient times, and if we subtract the A1 from both sides, minus A1, and then plus all of these guys, plus D1, B1, plus all the way, you're going to have a little bit of a gap here. I'll just draw it like that. It's very unconventional notation where this guy sat, all the way to DM, BM. And I'm doing all of this just to show you that by definition, you can write A1 as a linear combination of these other guys, but you can just rearrange things. You can rearrange it so that you can write one of the other guys as a linear combination of the rest of the other guys, and A1. And you say, you know what? This guy is now redundant. I don't need this guy any longer to continue to span V. Clearly, this set still spanned V. I mean, I added an extra vector here, but I can remove this guy right here. I can remove him from my set B1 prime, and still span V. And how do I know that? Because I can achieve him. By removing him, I don't lose anything. Because if I needed this vector to create some other vector, I can construct him with a linear combination of the rest of the Bs plus my A1. So let's get rid of him, and let's call that set B1. And actually, just for the sake of notation, let me just change his name. Let me just say, this is a little unconventional. You won't see it done like this in any textbook, but I think it's a little bit easier instead of having to keep talking about these guys that are embedded someplace in the middle of the stream. I mean, these names, B1, B2, BM, they're arbitrary names. So let me just rename. Let me swap the labels. Let me just say that BJ is equal to B1, and that B1 is equal to BJ. I'm just swapping their names. So I'm essentially just going to remove, I took that guy, I renamed him B1, I renamed B1 BJ so that I could swap them. So I'm essentially just going to remove B1 from the vector, just to make my notation easier. You could just keep saying, oh, I'm going to remove this BJ from the middle, but it becomes very confusing then. So let me call my new set after removing the BJ that I've renamed as B1. Let me just call that straight up B1. So my straight up set B1 is equal to A1, A1. And then remember, I removed the BJ, and I renamed that as B1, and then I renamed B1 as BJ. So now my set looks like this. Let me go to the other color. B2. And for all we know, BJ might have been B1. We don't know. And there's probably multiple of these that are non-zero, so we could have picked any of those to be our BJ. So we took our BJ, renamed it B1, and removed the B1. And so now our set looks like this. B3 all the way to BM. And this will still span. This set still spans V. And we know that because the guy we removed can be constructed with any linear combination of these guys, so we haven't lost our ability to construct all of the vectors in V. Now let me create another vector. Let me create the vector B. Let me do a new color. Let's say I have the vector B2 prime. And what I'm going to do here is now I'm going to take another element from our spanning, from our basis of V. I'll take the second element. I'll take A2. I'll take A2 and throw it on this guy. So now we have the set. Let me write it this way. B2 prime is equal to, I'm just going to add A2 to this guy. So you have A1, A2, and then you have all the rest of these guys. B2, B3, all the way to BM. And of course, this still spans V. I just added something here. But this is definitely linearly dependent. Remember, I didn't say in the beginning whether this was linear dependent or not. It may or may not be. But when you add this other vector that's in V, you definitely know that you're linear dependent, because these guys can construct that guy. Similarly, we know that this vector, B1, this spans V. So when we add this new element here, we know that it can be written as a linear combination of the other ones. So we know that this right here is linearly dependent. And we could say that A2 is equal to some constant times C1 times A1 plus, let me put some constants, plus D2. Actually, let me just write it this way. Since plus C2, B2, plus C3, B3, all the way to CM, BM. Now, what I'm going to claim is that at least one of these coefficients is non-zero. So at least one of the CIs does not equal to 0. And I'll make the further claim that there's at least one that's outside of this one. There's at least one that's outside of that one. That at least one of the coefficients on these Bs, on these B terms, has to be non-zero. And the way you can kind of think about it is, what if all of these guys were 0? If all of these guys were 0, then that means that A2 is a linear combination of A1. All of these guys would cancel out and you'd have A2 is equal to some non-zero constant times A1. We know that's not the case, because these two guys come from the same linearly independent set. They both come from that spanning basis. The fact that they are a basis, the word spanning basis, I shouldn't say it like that, because it's redundant. A basis is a spanning set that is linearly independent. If they're linearly independent, we know that A2 cannot be represented as some linear combination of the rest of these guys. So we know that one of the coefficients on the B terms has to be non-zero. And once again, let's just say that it's the coefficient someplace you're going to have a Cj, Bj. This is a different one than we had before. And we know that this guy, one of them, at least one of them has to be non-zero. Because if all of these guys were non-zero, then you wouldn't be able to say that this vector and that vector are linearly independent, because they would be scalar multiples of each other. So we're going to do the same exercise. This guy right here, that's someplace Cj, Bj right here. Obviously, this coefficient is non-zero. So we can solve for our Bj. Once again, we can say that Bj is equal to minus 1 over Cj times, now it's minus A2 plus C1, A1, all the way to Cm, Bm. So we have some Bj here that can be represented as a linear combination of the rest of the people, including our new A2. And so, just like we did before, let's remove him. Let's take him out of the set. And before I take him out of the set, I'm going to rename him solely for the purpose of notational simplicity. I'm just going to rename our Bj, B2, and our B2 is equal to Bj, so I'm just rearranging the names. And I'm going to remove our B2. Or I'm going to remove what I now call our B2. It was whatever was out here that could be represented as a linear combination of everything else, including our new A2. So let me call that set. When I remove that one of those terms right here, and now I renamed it B2, I call this set B2, and now it's equal to A1, A2, and now I have the leftovers of my Bs. So I have B3, B4, all the way to BM. I still notice I still have exactly M elements, and this still spans, so this spans V. It spans V because the element that I took out of it can be represented as a linear combination of these guys. So if I ever want to construct anything that needed that, I can construct that vector with some combination of these guys so it wasn't necessary. So it still spans V. So this process I'm doing, I can just keep repeating it. I can add an A3. I can define B3 prime as I can just add A3 to this set right here, A2, A3, and then I have my B3, B4, all the way to BM. And I'll say, oh, this is linearly dependent because this guy spans V. So everything but this guy spans V. So obviously, you can construct this guy with a linear combination of the rest of them. So you could say A3 is equal to some A1 plus some A2 plus C3, B3, all the way to CMBM. And we know that at least one of the coefficients on the B terms has to be non-zero. Because if all of those were 0, then you would be saying that A3 could be a linear combination of the A terms. And we know that A3 can't be represented as a linear combination of the A terms because all these A terms come from a linearly independent set. So you do the same operation. You find you can solve, let's say that CJ, some term right here, the CJ is non-zero. Then you can solve for that BJ. And then I do that little renaming little thing I do, where I rename the BJ B3 and rename B3 BJ. And then I remove B3. And I get the set B3 is equal to A1, A2, A3. And then I have B4 all the way to BM. And this still spans V. And I keep doing it. So what's going to happen eventually? If I keep doing this process over and over and over again, eventually I'll essentially replace all of the BM's, or I'll replace all of the N terms. So eventually I'll have a set that looks like this. I'll have a set that looks BM. Well, I will replace each of these guys with an A, where I would have replaced each of these guys with an A. So I'll have A1, A2, A3, all the way to AM. You can always do this by definition if you started with that initial set B that is a spanning set. And once you do this process, you'll get the same result that this also spans V. Now, let me write this. This is the result we got by starting off with a spanning set B that has M elements, where we said that M is less than N. So we always have enough A elements to do this, because we have more A elements than there were B elements to begin with. And we get a result that this spans V. But we already said, we already said that the set A, which is equal to A1, A2, all the way to AM, and then AM plus 1. I don't know how many more terms there are between M and N, but then you go all the way to AN. Remember, we said that N is greater than M. Or when we defined B, we said that M is less than N. Same thing, that this was a smaller set. Now, we're saying that this spans V. But at the same time, we said that this was a basis. This was just our starting fact, that this is a basis for V. Basis means two things. It means it spans V. And it means it's linearly independent. Now, we just got this result by assuming that we had some set B that's smaller than this set here that spans V. We were able to construct this by saying that A1 through AM also spans V. The result we got is that this spans V. But if this subset of A spans V, then A becomes linearly independent. Because if this subset spans V, that means that AN can be represented as some linear combination of these guys, which would imply that you're linearly dependent, which is a contradiction with our original statement that set A is a basis for V, because that means that it's linearly independent. If you're able to do this, then this means that this is, if there is some smaller spanning set, you get the result that A has to be linearly dependent, even though we said it was linearly independent. So we now know, we get our contradiction, we say that there cannot be. So this leads us to, there cannot be a set A spanning set B that has fewer elements than A. And this is a pretty neat outcome. Because now if anyone tells you that, if I come up to you and I say, hey, I found some set X, so set X spans the subspace, subspace, I don't know, let's just call that V again, then you know that an X has five elements. You now know that no set that spans the subspace V can have fewer than five elements. Even better, if I told you that X is a basis, X is a basis for V, and it has five elements, and Y is a basis for V, Y is another basis, my handwriting's degrading, Y is, let me write it a little nicer, Y is also a basis for V. You know that Y also has to have exactly five elements. How do I know that? How do I know that, well, if Y is a basis, then that means that it spans V. And we know it can't have anything less than five elements, we just proved that. So one way we know that Y has to have greater than or equal to five elements. But on the other hand, we know if Y is a basis, we know that Y is a basis for V, and X is a basis, X also spans V. So we know that X has to have fewer elements than Y. So we know that Y has to have greater than X, or let me just call it Y's elements, have to be greater than X's elements. Because any spanning set has to have more elements, or at least as many elements as a basis set, X's elements. And then since X is a spanning set, X's elements have to be greater than or equal to Y's elements, because Y is a basis. Y's elements, I know this is, you can't read that. But if this guy's elements are less than this guy's elements, but it's also greater than or equal to, we know that X, the number of elements that X has, so X's elements, or the cardinality, or the number of elements in it, is equal to Y's elements. And so now that we know that any basis for a vector space, so let's say that X, though let me just go back to our set A, A is equal to A1, A2, all the way to An. We can now say that any basis for some vector, for some sub space V, they all have the same number of elements. And so we can define a new term called the dimension. Sometimes it's written just dimension of V, is equal to the number of elements, sometimes called the cardinality, of any basis of V. And I went through great pranes in this video to show that any basis of V all has the same number of elements, so this is well defined. You can't have one basis that has five elements and one that has six. By definition, they would either both have to have five, or they would both have to have six. And so we can define our dimensionality.