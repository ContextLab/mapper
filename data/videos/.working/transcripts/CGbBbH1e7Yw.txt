So just as a reminder of where we are, we've got this very nonlinear transformation, and we showed that if you zoom in on a specific point while that transformation is happening, it looks a lot like something linear. And we reasoned that you can figure out what linear transformation that looks like by taking the partial derivatives of your given function, the one that I defined up here, and then turning that into a matrix. And what I want to do here is basically just finish up what I was talking about by computing all of those partial derivatives. So first of all, let me just rewrite the function back on the screen so we have it in a convenient place to look at. The first component is x plus sine of y, sine of y, and then y plus sine of x was the second component. So what I want to do here is just compute all of those partial derivatives to show what kind of thing this looks like. So let's go ahead and get rid of this word. Then I'll go ahead and kind of redraw the matrix here. So for that upper left component, we're taking the partial derivative with respect to x of the first component. So we look up at this first component, and the partial derivative with respect to x is just 1, since there's 1 times x plus something that has nothing to do with x. And then below that, we take the partial derivative of the second component with respect to x down here. And that guy, the y, well, that looks like a constant, so nothing happens. And the derivative of sine of x becomes cosine of x. And then up here, we're taking the partial derivative with respect to y of the first component, that upper one here. And for that, partial derivative of x with respect to y is 0, and partial derivative of sine of y with respect to y is cosine of y. And then finally, the partial derivative of the second component with respect to y looks like 1, because it's just 1 times y plus some constant. And this is the general Jacobian as a function of x and y. But if we want to understand what happens around the specific point that started off at, well, I think I recorded it here, at negative 2, 1, we plug that into each one of these values. So when we plug in negative 2, 1, so go ahead and just kind of, again, rewrite it to remember, we're plugging in negative 2, 1 as our specific point. That matrix as a function, kind of a matrix-valued function, becomes 1. And then next, we have cosine. But we're plugging in negative 2 for x, cosine of negative 2. And if you're curious, that is approximately equal to, I calculated this earlier, negative 0.42. You just want to think in terms of a number there. Then for the upper right, we have cosine again. But now we're plugging in the value for y, which is 1. And cosine of 1 is approximately equal to 0.54. And then bottom right, that's just another constant, 1. So that is the matrix, just as a matrix full of numbers. And just as kind of a gut check, we can take a look at the linear transformation this was supposed to look like. And notice how the first basis vector, the thing it got turned into, which is this vector here, does look like it has coordinates 1 and negative 0.42, right? It's got this rightward component that's about as long as the vector itself started. And then this downward component, which I think that's pretty believable, that that's negative 0.42. And then likewise, this second column is telling us what happened to that second basis vector, which is the one that looks like this. And again, its y component is about as long as how it started, right? A length of 1. And then the rightward component is around half of that. And we actually see that in the diagram. But this is something you compute. Again, it's pretty straightforward. You just take all of the possible partial derivatives, and you organize them into a grid like this. So with that, I'll see you guys next video.