Let's say I have a line that goes through the origin. I'll draw it in R2, but this can be extended to an arbitrary Rn. Let me draw my axes. Those are my axes right there. Not perfectly drawn, but I think you get the idea. Let me draw a line that goes through the origin here. So that is my line there. And we know that a line in any Rn, we're doing it in R2, can be defined as just all of the possible scalar multiples of some vector. So let's say that this is some vector right here that's on the line. We can define our line. We could say L is equal to the set of all the scalar multiples. Let me say that this is vector. Let's say that that is V right there. So it's all the possible scalar multiples of our vector V, where the scalar multiples, by definition, they're just any real number. So obviously, if you take all of the possible multiples of V, both positive multiples and negative multiples and less than one multiples, fraction multiples, you'll have a set of vectors that will essentially define, or I guess specify, every point on that line that goes through the origin. We know, of course, if this wasn't a line that went through the origin, you would have to shift it by some vector. It would have to be some other vector plus Cv. But anyway, we're starting off with this line definition that goes through the origin. What I want to do in this video is to define the idea of a projection onto L of some other vector x. So let me draw some other vector x. Let's say that this right here is my other vector x. Now, a projection, I'm going to give you just a sense of it, and then we'll define it a little bit more precisely. A projection, I always imagine, is if you had some light source that were perpendicular somehow or orthogonal to our line. So let's say our light source, the light was shining down like this, and I'm doing that direction because that is perpendicular to my line. I imagine the projection of x onto this line is kind of the shadow of x. So if this light was coming down, I would just draw a perpendicular like that. And the shadow of x onto L would be that vector right there. So we can kind of view it as the shadow of x on our line L. That's one way to think of it. Another way to think of it, and you can think of it however you like, is how much of x goes in the L direction. But the technique would be the same. You draw perpendicular from x to L, and you say, OK, then how much of L do I have to go in that direction to get to my perpendicular? Either of those are how I think of the idea of a projection. I think the shadow is part of the motivation for why it's even called a projection. When you project something, you're kind of beaming light and seeing where the light hits on a wall, and you're kind of doing that here. You're beaming light, and you're seeing where that light hits on a line in this case. But you can't do anything with this definition. This is just kind of an intuitive sense of what a projection is. So we need to figure out some way to calculate this, or a more mathematically precise definition. And one thing we can do is, when I created this projection, let me actually draw another projection of another line, or another vector, just so you get the idea. If I had some other vector over here that looked like that, the projection of this onto the line would look something like this. You just draw perpendicular, and this projection would be like that. So I don't want to draw, for just this case, I want to give you the sense that it's the shadow of any vector onto this line. So how can we think about it with our original example? Well, in every case, no matter how I perceive it, I dropped a perpendicular down here. And so if we can construct a vector right here, we could say, hey, that vector is always going to be perpendicular to the line. And we can do that. I would have been talking about it if we couldn't. So let me define this vector. I'm not even going to define it. What is this vector going to be? If this vector, let me not use all these this's, let me say that this vector, we know we want to somehow get to this blue vector. Yeah, let me keep it in blue. That blue vector is the projection of x onto L. That's what we want to get to. Now, one thing we can look at is this pink vector right there. What is that pink vector? That pink vector that I just drew, this is x minus the projection minus this blue vector over here, minus the projection of x onto L. If you add the projection to the pink vector, you get x. So if you add this blue projection of x to x minus the projection of x, you're of course going to get x. And we also know that this pink vector is orthogonal to the line itself, which means it's orthogonal to every vector on the line, which also means that its dot product is going to be 0. So let me define the projection this way. The projection, this is going to be my slightly more mathematical definition. The projection onto L of some vector x is going to be some vector that's in L. I drew it right here, this blue vector. I'll trace it with white right here. Some vector in L where, and this might be a little bit unintuitive, where x minus the projection vector, x minus the projection onto L of x, is orthogonal to my line. So I'm saying this is my definition. I'm defining the projection of x onto L to some vector in L where x minus that projection is orthogonal to L. This is my definition. And that is a little bit more precise, and I think it makes a bit of sense why it connects to the idea of the shadow or projection. But how can we deal with this? This is still just in words. How can I actually calculate the projection of x onto L? Well, the key clue here is this notion that x minus the projection of x is orthogonal to L. So let's see if we can use that somehow. So the first thing we need to realize is by definition, because the projection of x onto L is some vector in L, that means that some scalar multiple of V, some scalar multiple of our defining vector of our V right there. So we could also say, we could say, hey, look, we could rewrite our projection of x onto L. We could write it as some scalar multiple times our vector V. We can say that. This is equivalent to our projection. Now we also know that x minus our projection is orthogonal to L. So we also know that x minus our projection, and I just said that I could rewrite my projection as some multiple of this vector right there. You could see it the way I drew it here. It almost looks like it's 2 times this vector. So we know that x minus our projection, this is our projection right here, is orthogonal to L. Orthogonality by definition means it's dot product with any vector in L is 0. So let's dot it with some vector in L. Well, we could dot it with this vector V. That's what we used to define L. So let's dot it with V. And we know that that must be equal to 0. We're taking this vector right here, dotting it with V, and we know that this has to be equal to 0. That has to be equal to 0. So let's use our properties of dot products to see if we can calculate a particular value of C. Because once we know a particular value of C, then we could just always multiply that times the vector V, which we are given, and we will have our projection. And then I'll show it to you with some actual numbers. So let's see if we can calculate a C. So if we distribute the V, we know the dot product exhibits the distributive property. This expression can be rewritten as x dot V, right? x dot V minus C times v dot V. I rearrange things. We know that the scalar, we know that C minus Cv dot V is the same thing we could write it as minus C times v dot V. And all of this, of course, is equal to 0. And then if we want to solve for C, let's add Cv dot V to both sides of the equation. And you get x dot V is equal to C times v dot V. Solving for C, let's divide both sides of this equation by v dot V. You get, do it in a different color, C is equal to this x dot V divided by v dot V. Now what was C? C was, we're saying the projection of x, let me write it here, the projection of x onto L is equal to some scalar multiple, right? We know it's in the line. So it's some scalar multiple of this defining vector, some scalar multiple of the vector V. And we just figured out what that scalar multiple's going to be. It's going to be x dot V over v dot V. And this, of course, is just going to be a number, right? This is a scalar still. Even though we have all these vectors here, when you take their dot products, you just end up with a number. And you multiply that number times v. You just kind of scale v, and you get your projection. So in this case, the way I drew it up here, my dot product should end up with some scaling factor that's maybe close to 2. So that if I start with a v and I scale it up by 2, this value would be 2, and I'd get a projection that looks something like that. Now this looks a little abstract to you. So let's do it with some real vectors, and I think it'll make a little bit more sense. And nothing I did here only applies to R2. Everything I did here can be extended to an arbitrarily high dimension. So even though we're doing an R2, and R2 and R3 is where we tend to deal with projections the most, this could apply to Rn. So let me do it in this particular case. Let me define my line L to be the set of all scalar multiples of the vector, I don't know, let's say the vector 2, 1, such that all of them are, the c is any real number. So let me draw my axes here. That's my vertical axes. This is my horizontal axis right there. And so my line is all the scalar multiples of the vector 2.1. And actually let me just call my vector 2.1, let me call that right there, the vector v. So let me draw that. So I go 1, 2, go up 1. That right there is my vector v. Vector v right there. And the line is all of the possible scalar multiples of that. So let me draw that. So all the possible scalar multiples of that, you just keep going in that direction, or you keep going backwards in that direction, or anything in between. That's what my line is. All of the scalar multiples of my vector v. Now let's say I have another vector x. Let's say I have a vector x. And let's say that x is equal to 2, 3. Let me draw x. x is 2, and then you go 1, 2, 3. So x will look like this. Vector x will look like that. Let me draw a little bit better than that. Vector x will look like that. That is vector x. What we want to do is figure out the projection of x onto l. We can use this definition right here. So let me write it down. The projection of x onto l is equal to what? It's equal to x dot v, where v is kind of the defining vector for our line. So it's equal to x, which is 2, 3, dot v, which is 2, 1. All of that over v dot v. So all of that over 2, 1, dot 2, 1, times our original defining vector v. So what's our original defining vector? It's this one right here, 2, 1. So times the vector 2, 1. And what is this equal? See, when you take these two dotted each other, you have 2 times 2 plus 3 times 1. So 4 plus 3, so you get 7. This all simplified to 7. And then this you get 2 times 2 plus 1 times 1. So 4 plus 1 is 5. So you get 7 fifths. That all simplified to 5. That was a very fast simplification. You might have been daunted by this kind of strange looking expression, but when you take dot products, they actually tend to simplify very quickly. And then you just multiply that times your defining vector for the line. So we're scaling it up by a factor of 7 fifths. So multiply it times the vector 2, 1. And what do you get? You get the vector, we did a new color. You get the vector 14 over 5 and the vector 7 over 5. And just so we can visualize this or plot it a little better, let me write it as decimals. 14 over 5 is 2 and 4 fifths, which is 2.8. And this is 1 and 2 fifths, which is 1.4. And so the projection of x onto L is 2.8, 1.4. So let's see, 1, 2, 2.8 is right about there. And I go 1.4 is right about there. So the vector is going to be right about there. I haven't even drawn this too precisely, but you get the idea. This is the projection. Our computation shows us that this is the projection of x onto L. And if we draw a perpendicular right there, we see that it's consistent with our idea of this being the shadow of x onto our line L. Well now we actually can calculate projections. In the next video, I'll actually show you how to figure out a matrix representation for this, which is essentially a transformation.