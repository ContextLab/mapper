Let's say I have some matrix A. If I'm trying to determine the null space of A, I'm essentially just asking, look, if we set up the equation Ax is equal to the 0 vector, the null space of A is all the x's that satisfy this equation. So it's all the x's that satisfy that equation. Ax is equal to the 0 vector. You could call it the system. And the way you would solve it, and we've done this many times, this was many videos ago, you would make an augmented matrix with this. So the augmented matrix would look like that. You'd have the 0 vector on the right-hand side. And then you'd perform a bunch of row operations to put the left-hand side into reduced row echelon form. So you would do a bunch of operations. The left-hand side would go into reduced row echelon form. Let's call that reduced row echelon form of A. And then the right-hand side is just going to stay 0, because you perform the same row operations. But when you perform those row operations on 0, you just get the 0 vector right here. And then when you create the system back from this right here, because these two systems are equivalent, you're essentially going to have your solution set look something like this. You're going to have your solution set is going to be equal to some scalar multiple. Let's say that of your free variables, your free variables are going to be the scalar multiples. And you've seen this multiple times, so I'll see it stay fairly general. There's going to be some multiple times, let's say, vector 1 plus some other scalar times vector 2. These scalars tend to be your free variables times vector 2 all the way to, I don't know, whatever, c times your nth vector. I'm just trying to say general. We haven't seen any examples that had more than two or three vectors here. But this is what, essentially, your null space is spanned by these vectors right there. You get an equation, you get a solution set that looks something like that. And you call that your null space. We've done that multiple times. Your null space is that, so it's all the linear combinations, or it's the span of these little vectors that you get here. And 1, and 2, all the way to nn. This is nothing new. I'm just restating something that we've seen multiple, multiple times. We've actually did this in the previous video. I just maybe never wrote it exactly like this. But what about the case when you're solving the inhomogeneous equation? So the inhomogeneous equation looks like this. So if I want to solve Ax is equal to b, I would do something very similar to this. I will create an augmented matrix. I have a on the left-hand side, and I'd put b on the right-hand side. And I'll perform a bunch of row operations to put a into reduced row echelon form. So let me do that. So this left-hand side will be the reduced row echelon form of a. And then the right-hand side, whatever operations I did on a I have to do on the entire row. So I'll also be doing them to b. So I'll have some new vector here. Maybe I'll call that the vector b prime. It's going to be different than b, but let's just call it b prime. And so when you go out of the augmented matrix world and rewrite it as a system, and you solve for it, and we did this in the last video, you'll get your solution set that satisfies this. x is going to be equal to this b prime, whatever this new vector is, this b prime plus something that looks exactly like this. That looks exactly like that. In fact, I'll copy and paste it. It'll look exactly like this. Let me see if I did copy and paste it. Edit, copy, and let me paste it. So it'll look something that looks exactly like that. And we said in the last video that that, given this, you can kind of think of the solution set to the inhomogeneous equation is equivalent to some particular solution, is equal to some particular solution, let's call that some particular solution, plus some member of your null space. So you could say it's plus some homogeneous solution. So if you just pick particular values for a, b, and see all of the different multiples of the vector that span your null space, you'll get some particular homogeneous solution. So what I implied in the last video, and I didn't show it to you rigorously, is that any solution to the inhomogeneous system, let me write it this way, any solution, and do it in white, any solution to the inhomogeneous system, to inhomogeneous system, Ax is equal to b. This is a claim I made. We'll take the form. Some particular solution, that was this right here, maybe I should do it in green. This is this right here. When you do the reduced row echelon form, it becomes that b prime vector, plus some homogeneous solution. So some member of the null space. Now I didn't prove it to you, but I implied that this is the case. What I want to do in this video is actually do a little bit of a more rigorous proof, but it's actually fairly straightforward. So let's first of all verify that this is a solution. So let's just put this into our original equation. So remember, our original equation was Ax is equal to b. So let's verify. So is, let me write it as a question, is that particular solution plus some homogeneous solution, a solution, to Ax is equal to b. Well to do that, you just put that in the place of x. So let's try it out. So a times this guy right here, times some particular solution, plus some homogeneous solution, is going to be equal to a times the particular solution, plus a times some member of my null space. And what is this equal to? That is going to be equal to b. We're saying that this is a particular solution to this equation. That is going to be equal to b. And that this is going to be equal to the 0 vector, because this is a solution to our homogeneous equation. So this is going to be equal to b plus 0, or it's equal to b. So a times this vector right here is indeed equal to b. So this is a solution. Yes. Now the next question is, does every solution to the inhomogeneous system, or does any solution to the inhomogeneous system take this form? So does any solution x to Ax equal to b take the form x is equal to some particular solution plus a member of our null space, or plus a homogeneous solution? So to do that, let's test out what happens when we multiply the vector a times x. Let me write it this way. Let's say that x is any solution to Ax is equal to b. Let's start off with that. And let's see what happens when we take a times x minus some particular solution to this. So when we distribute the matrix vector product, you get a times our any solution minus a times our particular solution. Now what is this going to be equal to? We're saying that this is a solution to Ax equal to b. So this is going to be equal to b. And of course, any particular solution to this when we multiply it by a is also going to be equal to b. So it's going to be b minus b. So that's going to be equal to the 0 vector. Or another way to think about it is the vector x minus our particular solution is a solution to a times x is equal to 0. Think about this. If you take this in parentheses right here and you put it right there, when you multiply it times a, you get the 0 vector. We just did that. You get the 0 vector because when you multiply each of these guys by a, you get b. And then you get b minus b. And so you get 0. So you can say that x minus, so our any solution x minus the particular solution of x is a member of our null space. By definition, your null space is all of the x's that satisfy this equation. And let's say, since it's a member of our null space, we can say that it is equal to, so our any solution minus our particular solution is equal to some member of our null space. We could say that it's equal to a homogeneous solution. There might be more than one. A homogeneous solution. Now, if we just add our particular solution to both sides of this, we get that any solution. Remember, we assume that x is any solution to this. That any solution is equal to our homogeneous solution, is equal to a homogeneous solution, plus our particular solution. So we've proven it both ways. This is a solution to our inhomogeneous equation, and that any solution to our inhomogeneous equation takes this form right here. Now, why am I so concerned with this? I've been kind of fixated on this inhomogeneous equation for some time. But we've been talking about the notion of a transformation being one to one. That was one of the two conditions for a transformation to be invertible. Now, to be one to one, so let me draw a transformation here. So let's say this is my domain, x. And this is my codomain right here, y. And I have a transformation that maps from x to y. In order for t to be one to one, that means for any b that you pick here, for any b that is a member of our codomain, there's at most one solution to a times x. And I'm assuming that a is our transformation matrix. So we can write our transformation t as being equal to some matrix times our vector in our domain. So this would be ax if this is x right here. So t would map from that to that right there. So in order for our transformation to be one to one, that means you pick any b here, there has to be at most one solution to ax is equal to b. Or another way to say that is that there is at most one guy that maps into that element of our codomain. There might be none. So there could be no solutions to this, but there has to be at most one solution. Now, we just said that any solution to an inhomogeneous, so we just said that any solution takes the form. If there is a solution, so if there isn't a solution, that's fine, that'll still satisfy one to one. So but if there is a solution, any solution is going to take the form x particular plus a member of your null space. Plus this guy right here is a member of the null space. This thing right here just applies to that guy right here. If there are no solutions, that's fine. You can still be one to one. But if you do have a solution, you can have at most one person that maps to it, and any solution will take this form. I just showed you that. Now, in order to be one to one, this can only be one solution, the solution set can only be one solution. This can only be one solution. We can only have one solution here, which means, what does that mean? That means that this guy right here cannot be more than one vector. It just has to be one vector. There's only one particular solution right there, but this guy right here has to be, well, for any solution set depending on how you define it, there's only one particular vector there. But this guy, the only way that you're only going to have one solution is if your null space, the only way you're going to have one solution is if your null space is trivial, if it only contains the zero vector. Your null space will always, at minimum, contain the zero vector. In the last video, I think I just off the cuff said, oh, your null space has to be empty. But no, your null space will always, by definition, by the fact that it is a subspace, it will always contain a zero vector. You can always multiply a times zero to get zero. So your null space will always contain that. But in order to have only one solution, your null space can only have the zero vector, so that this can only be zero. And so that your only solution is going to be the particular solution that you found, depending on how you got there, but it's only going to be your particular solution. So let me put this this way. So one to one, in order to be one to one, your null space of your transformation matrix has to be trivial. It has to contain only the zero vector. Now, we've covered this many, many videos ago. What does it mean if your null space only contains the trivial vector? Let me make this clear. So if your transformation vector looks like this, a1, a2, all the way to an, and you're multiplying it times x1, x2, all the way to xn, and the null space is all of the x's that satisfy this equation, zero, and you're going to have m zeros right there. So if your null space is trivial, and we're saying that that is a condition for you to be one to one, for your transformation to be one to one, the transformation that's specified by this matrix. If your null space is trivial, what does that mean? That means that the only solution to another way of writing this is x1 times a1 plus x2 times a2, all the way to xn times an is equal to the zero vector. These are equivalent statements right here. I just multiply each of these terms times these respective column vectors. These are the same thing. Now, if you say that your null space has to be equal to zero, you're saying that the only solution to this equation right here, the only scalars that satisfy this equation, sorry, these aren't me actually, because I wrote the scalars as vectors. This statement right here is equivalent to x1 times a1 plus x2 times a2 plus all the way to xn times an is equal to the zero vector, where the x1's through xn's are scalars. Now, if we say the null space is zero, we're saying the only way that this is satisfied is if your x1 all the way to xn is equal to zero. And this means, this is our definition actually, of linear independence. That means that a1, so the null space being zero, also means that your column vectors of a, your column vectors, let me write it this way, it also means that a1, a2, all the way through an are linearly independent. Now, what does that mean? If all of these guys are linearly independent, what is going to be the basis for your column space? Remember, the column space is the span. The column space of a is equal to the span of a1, a2, all the way to an. Well, we just said, if we're dealing with a one to one, or one of the conditions, or the condition to be one to one, is that your null space has to be zero, or only contain the zero vector. If your null space contains a zero vector, then all of your columns are linearly independent. If all of these columns span your column space, and they're linearly independent, then they form a basis. So that means that a1, a2, all the way to an, are a basis for our column space. And then that means, if all of our column vectors here are linearly independent, they obviously span our column space by definition, and they all are linearly independent, they form the basis. So the dimension of our column space, that's essentially the number of vectors you need to form the basis, is going to be equal to n. We have n columns. So it's going to be equal to n. Or another way to say it is that the rank of your matrix is going to be equal to n. So now we have a condition for something to be one to one. Something is going to be one to one if and only if the rank of your matrix is equal to n. And you could go both ways. If you assume something is one to one, then that means that its null space here has to only have the zero vector, so it only has one solution. If its null space only has the zero vector, then that means its columns are linearly independent, which means that they all are part of the basis, which means that you have n basis vectors or you have a rank of n. Go the other way. If you have a rank of n, that means that all of these guys are linearly independent. If all of these guys are linearly independent, then the null space is just the zero vector. And then if the null space is just the zero vector, this part of your solution disappears, and then you're only left with one solution. So you're one to one. If and only if the rank of your transformation matrix is equal to n.