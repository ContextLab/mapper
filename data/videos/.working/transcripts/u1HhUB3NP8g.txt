All right, so where we left off, we had simplified our algebraic expression for the squared error to the line from the n data points. And we kind of visualized. This expression right here would be a surface in, I guess you could view it as a surface in three dimensions, where for any m and b is going to be a point on that surface that represents the squared error for that line. And our goal is to find the m and the b, which would define an actual line, to find the m and b that minimize the squared error. And the way that we do that is we find a point where the partial derivative of the squared error with respect to m is 0, and the partial derivative with respect to b is also equal to 0. So it's flat with respect to m. So that means that the slope in this direction is going to be flat. Let me do it in the same color. So the slope in this direction, that's the partial derivative with respect to m, is going to be flat. It's not going to change in that direction. And the partial derivative with respect to b is going to be flat. So it will be a flat point right over there. The slope at that point in that direction will also be 0, and that is our minimum point. So let's figure out the m and b's that give us this. So if I were to take the partial derivative of this expression with respect to m, so the partial derivative of this expression with respect to m, well this first term has no m terms in it, so it's a constant from the point of view of m. And just as a reminder, partial derivatives, it's just like taking a regular derivative, and you're just assuming that everything but the variable that you're taking the partial derivative with respect to, you're assuming everything else is a constant. So in this expression, all the x's, the y's, the b's, the n's, those are all constants. The only variable when we take the partial derivative with respect to m that matters is the m. So this is a constant. There's no m here. This term right over here, we're taking with respect to m. So the derivative of this with respect to m is negative 2, it's kind of the coefficients on the m. So negative 2 times n times the mean of the xy's, that's the partial of this with respect to m. And then this term right here has no m's in it, so it's constant with respect to m, so its partial derivative with respect to m is 0. Then this term here, you have n times the mean of the x squared times m squared. So this is going to be, we're taking the partial derivative with respect to m, so it's going to be 2 times, so it's going to be plus 2 times n times the mean of the x squared times m. Right? The derivative of m squared is 2m, and then you just have this coefficient there as well. Now this term, you also have an m over there. So let's see. Everything else is just kind of a coefficient on this m, so the derivative with respect to m is 2bn times the mean of the x's. If I took the derivative of 3m, the derivative is just 3, it's just the coefficient on it. And then finally, this is a constant with respect to m, so we don't see it. And so this is the partial derivative with respect to m, that's that right over there, and we want to set this equal to 0. Now let's do the same thing with respect to b. This term, once again, is a constant from the perspective of b. There's no b here, there's no b over here, so the partial derivative of either of these with respect to b is 0. Then over here, you have a negative 2n times the mean of y's as a coefficient on a b. So the partial derivative with respect to b is going to be minus 2n, or negative 2n, times the mean of the y's. And then there's no b over here, and we do have a b over here, so it's plus 2mn times the mean of the x's, plus 2mn times the mean of the x's. This is essentially the coefficient on the b over here. It was written in a mixed order, but all of these are constants from the point of view of b. They're the coefficient in front of the b. The partial derivative of that with respect to b is just going to be the coefficient. And then finally, the partial derivative of this with respect to b is going to be 2nb, or 2nb to the first, you could even say, 2bn, or 2nb is the partial derivative of that with respect to b. And we want to set this equal to 0. So it looks very complicated, but remember, we're just trying to solve for the m's and the b's. And we have two equations with two unknowns here. We have the m's, we have the m's, and then we have the b's. And to simplify this, both of these equations, actually the top one and the bottom one, both sides are divisible by 2n. I mean, 0 is divisible by anything. It'll be just 0. So let's divide the top equation by 2n and see what we get. If we divide the top equation by 2n, we can even see it here. This will become just 1. That goes away, and then those go away. And you would just be left with negative times the negative mean of the xy's plus m times the mean of the x squareds plus b times the mean of the x's is equal to 0. That's this first expression when you divide both sides by negative 2n. And the second expression will be, this is when you divide it by 2n. I don't want to say negative 2n. That's when you divide it by 2n, you get this. And we divide this by 2n, that'll go away, that will go away, and then those will go away. And you're just left with the negative mean of the y's plus m times the mean of the x's plus b is equal to 0. So if we find the m and the b values that satisfy the system of equations, we have minimized the squared error. And we could just solve it in a traditional way, but I want to rewrite this, because I think it's kind of interesting to see what these really represent. So let's add this mean of the xy's to both sides of this top equation, and then we're going to have, so if we add the mean of the xy's to both sides of this top equation, what do we get? We get m times the mean of the x squareds plus b times the mean of the x's is equal to, these are going to cancel out, is equal to the mean of the xy's. That's that top equation. This bottom equation right here, let's add the mean of y to both sides of this equation. And I do that so that cancels out. And then we're left with m, do that in the blue color, show you the same equation, we have m times the mean of the x's plus b is equal to the mean of the y's. Now I actually want to get both of these into mx plus b form. This is actually already there. You can see that if our line, if our best fitting line is going to be y is equal to mx plus b, we still have to find the m and the b, but we see on that best fitting line, because the m and the b that satisfy both of these equations are going to be the m and the b on that best fitting line. So that best fitting line actually contains the point, and we get this from the second equation right here, it contains the point, or the point, I should write it this way, the coordinate, mean of x, mean of y, lies on this point. And you can see it right over here. If you put the mean of x in this for the optimal m and b, you're going to get the mean of the y's. So that's interesting. This optimal line, let's never forget what we're even trying to do. This optimal line is going to contain some point on it, let me do that in a new color, it's going to contain some point on it right here that is the mean of all of the x values, and the mean of all the y values. That's just interesting. It kind of makes intuitive sense. Now, this other thing, just to kind of get it in the same point of view, and then it'll actually become kind of an easier way to solve the system. You could solve this a million different ways, but just to give us an intuition of what even is going on here, what's another point that's on that line? Because if you have two points on the line, you know what the equation of the line is going to be. Well, the other point, we want this to be an mx plus b form, so let's divide both sides of this equation by this term right here, by the mean of the x's. And if we do that, we get m times the mean of the x squareds divided by the mean of the x's plus b is equal to the mean of the xy's divided by the mean of the x's. And so when you write it in this form, this is the exact same equation as that, I just divided both sides by the mean of the x's, you get another interesting point that will lie on this optimal fitting line, at least from the point of view of the squared distances. So another point that will lie on it is going to be the point, the x value is going to be this, so it's going to be the coordinate, the mean of the x squareds divided by the mean of the x's, and then the y value is going to be the mean of the xy's divided by the mean of the x's. And I'll let you think about that a little bit more, but already this is actually the two points that lie on the line, so both of these on the best fitting line based on how we're measuring a good fit, which is the square distance. These are on the line that minimize that square distance. What I'm going to do in the next video, this is turning into like a six or seven video saga on trying to prove the best fitting line or finding the formula for the best fitting line, but it's interesting. There's all sorts of neat little mathematical things to ponder over here, but in the next video we can actually use this information, we could have just solved the system straight up, but we can actually use this information right here to solve for our M and B's, maybe we'll do it both ways depending on my mood.