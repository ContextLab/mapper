This right here is a simulation that was created by Peter Colingridge using the Khan Academy Computer Science Scratch Pad to better understand why we divide by n minus 1 when we calculate an unbiased sample variance, when we are in an unbiased way trying to estimate the true population variance. So what this simulation does is at first it constructs a population distribution, a random one. And every time you go to it, it'll be a different population distribution. This one has a population of 383. And then it calculates the parameters for that population directly from it. The mean is 10.9. The variance is 25.5. And then it uses that population and samples from it. And it does samples of size 2, 3, 4, 5, all the way up to 10. And it keeps sampling from it. Calculates the statistics for those samples. So the sample mean and the sample variance, in particular, the biased sample variance. And it starts telling us some things about us that give us some intuition. And you can actually click on each of these and zoom in to really be able to study these graphs in detail. So I've already taken a screenshot of this and put it on my little doodle pad so it can really delve into some of the math and the intuition of what this is actually showing us. So here I took a screenshot. And you see for this case right over here, the population was 529. Population mean was 10.6. And down here in this chart, he plots the population mean right here at 10.6, right over there. And you see that the population variance is at 36.8. And right here, he plots that right over here, 36.8. So this first chart on the bottom left tells us a couple of interesting things. And just to be clear, this is the biased sample variance that he's calculating. This is the biased sample variance. So he's calculating it. That is being calculated for each of our data points. So starting with our first data point in each of our samples, going to our nth data point in the sample, you're taking that data point, subtracting out the sample mean, squaring it, and then dividing the whole thing, not by n minus 1, but by lowercase n. And this tells us several interesting things. The first thing it shows us is that the cases where we are significantly underestimating the sample variance, when we're getting sample variances close to 0, these are also the cases, or they're disproportionately the cases, where the means for those samples are way far off from the true sample mean. Or you could view that the other way around. The cases where the mean is way far off from the sample mean, it seems like you're much more likely to underestimate the sample variance in those situations. The other thing that might pop out at you is the realization that the pinker dots are the ones for smaller sample size, while the bluer dots are the ones of a larger sample size. And you see here, these two little, I guess, the tails, so to speak, of this hump, that at these ends, you disproportionately, it's more of a reddish color. That most of the bluish or the purplish dots are focused right in the middle, right over here, that they are giving us a better estimate. There are some red ones here, and that's why it gives us that purplish color. But out here on these tails, it's almost purely some of these red. Every now and then, by happenstance, you get a little blue one. But this is disproportionately far more red, which really makes sense. When you have a smaller sample size, you're more likely to get a sample mean that is a bad estimate of the population mean, that's far from the population mean. And you're more likely to significantly underestimate the sample variance. Now, this next chart really gets to the meat of the issue. Because what it's telling us is that for each of these sample sizes, so this right over here, for sample size 2, if we keep taking sample size 2 and we keep calculating the by sample variances and dividing that by the population variance and finding the mean over all of those, you see that over many, many, many trials, many, many samples of size 2, that by sample variance over population variance, it's approaching half of the true population variance. When sample size is 3, it's approaching 2 thirds, 66.6% of the true population variance. When sample size is 4, it's approaching 3 fourths of the true population variance. And so we can come up with a general theme that's happening. When we use the biased estimate, we're not approaching the population variance. Let me write this down. We're approaching n minus 1 over n times the population variance. When n was 2, this approached 1 half. When n is 3, this is 2 thirds. When n is 4, this is 3 fourths. So this is giving us a biased estimate. So how would we unbiased this? Well, if we really want to get our best estimate of the true population variance, not n minus 1 over n times the population variance, we would want to multiply. Let me do this in a color I haven't used yet. We would want to multiply times n over n minus 1. We would want to multiply n over n minus 1. To get an unbiased estimate. Here, these cancel out, and you are just left with your population variance. That's what we want to estimate. And over here, you are left with our unbiased estimate of population variance, or our unbiased sample variance, which is equal to, and this is what we saw in the last several videos, what you see in statistics books. Sometimes it's confusing why. Hopefully Peter's simulation gives you a good idea of why. Or it at least convinces you that it is the case. So you would want to divide by n minus 1.