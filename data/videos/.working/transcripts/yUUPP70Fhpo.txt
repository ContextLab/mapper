In the last video, we started to explore the notion of an error function, not to be confused with expected value because it really does look like the same notation. But here, e is for error. And we could also sometimes see it referred to as a remainder function. And we saw it's really just the difference between the function and our approximation of the function. So for example, this distance right over here, that is our error at x is equal to b. And what we really care about is the absolute value of it. Because at some points, f of x might be larger than the polynomial. Sometimes the polynomial might be larger than f of x. But what we care is the absolute distance between them. And so what I want to do in this video is try to bound our error at some b. Try to bound our error. So say it's less than or equal to some constant value. Try to bound it at b for some b is greater than a. We're just going to assume that b is greater than a. And we got to a bit of a tantalizing result that seems like we might be able to bound it in the last video. We saw that the n plus 1th derivative of our error function is equal to the n plus 1th derivative of our function. Or that their absolute values would also be equal to it. So if we can somehow bound the n plus 1th derivative of our function over some interval, an interval that matters to us, an interval that maybe has b in it, then we can at least bound the n plus 1th derivative of our error function. And then maybe we can do a little bit of integration to bound the error itself at some value b. So let's see if we can do that. Well, let's just assume that we're in a reality where we do know something about the n plus 1th derivative of f of x. Let's say we do know that this, we do it in a color that I haven't used yet. I'll do it in white. So let's say that thing right over there looks something like that. So that is f the n plus 1th derivative. And I only care about it over this interval right over here. Who cares what it does later? I just want to bound it over the interval, because at the end of the day, I just want to bound b right over here. So let's say that the absolute value of this, let's say that we know. Let me write it over here. Let's say that we know that the absolute value of the n plus 1th derivative, the n plus 1th, and I apologize. I actually switched between the capital n and the lower case. And I did that in the last video. I shouldn't have. But now that you know that I did that, hopefully it doesn't confuse you. n plus 1th. So let's say we know that the n plus 1th derivative of f of x, the absolute value of it, let's say it's bounded. Let's say it's less than or equal to some m over the interval, because we only care about the interval. It might not be bounded in general, but all we care is that it takes some maximum value over this interval. So over the interval x, I could write it this way, over the interval x is a member between a and b. And this includes both of them. It's a closed interval. x could be a, x could be b, or x could be anything in between. And we can say this generally, that this derivative will have some maximum value. So this is the absolute value's maximum value, max value, m for max. We know that it will have a maximum value if this thing is continuous. So once again, we're going to assume that it is continuous, that it has some maximum value over this interval right over here. Well, this thing right over here, we know is the same thing as the n plus 1th derivative of the error function. So then we know, so then that implies that the, that's a new color. Let me do that blue, or that green. That implies that the n plus 1th derivative of the error function, the absolute value of it, because either the same thing is also bounded by m. So that's a little bit of an interesting result, but it gets us nowhere near there. It might look similar, but this is the n plus 1th derivative of the error function. And we'll have to think about how we can get an m in the future. We're assuming that we somehow know it, and maybe we'll do some example problems where we figure that out. But this is the n plus 1th derivative. We bounded its absolute value, but we really want to bound the actual error function, the 0th derivative, you could say, the actual function itself. Well, we could try to integrate both sides of this and see if we can eventually get to e of x, to get to our error function or our remainder function. So let's do that. Let's take the integral of both sides of this. Now, the integral on this left-hand side, it's a little interesting. We could take the integral of the absolute value. It would be easier if we were taking the absolute value of the integral. And lucky for us, the way it's set up, so let me just write a little aside here, we know generally that if I take, and it's something for you to think about, so if I have two options, this option versus, and I know they look the same right now. So over here, I'm going to have the integral of the absolute value. And over here, I'm going to have the absolute value of the integral. Which of these can be larger? Well, you just have to think about the scenarios. So if f of x is always positive over the interval that you're taking the integration, then they're going to be the same thing. So you're going to get positive values, take the absolute value of a positive value. It doesn't make a difference. What matters is if f of x is negative. If f of x is negative the entire time, so if this is our x-axis, that is our y-axis, if f of x is, well, we saw if it's positive the entire time, you're taking the absolute value of a positive, it's not going to matter. These two things are going to be equal. If f of x is negative the whole time, then this integral is going to evaluate to a negative value, but then you're going to take the absolute value of it. And then over here, the integral is going to evaluate to a positive value, but it's still going to be the same thing. The interesting case is when f of x is both positive and negative. So you can imagine a situation like this. If f of x looks something like that, then this right over here, the integral, you'd have positive. This would be positive, and then this would be negative right over here. And so they would cancel each other out. So this would be a smaller value than if you took the integral of the absolute value. So the absolute value of f would look something like this. So all of the areas are going to be, if you view this would be a definite integral. All of the areas would be positive. So if you're going to get a bigger value when you take the integral of the absolute value, then you will, especially when f of x goes both positive and negative over the interval, then you would if you took the integral first and then the absolute value. Because once again, if you took the integral first for something like this, you would get a low value. Because this stuff would cancel out with this stuff right over here, and then you would take the absolute value of just a lower magnitude number. And so in general, the absolute value of the integral is going to be less than or equal to the integral of the absolute value. So this right here is the integral of the absolute value, which is going to be greater than or equal. What we have written over here is just this. That's going to be greater than or equal to, and I think you'll see why I'm doing this in a second, greater than or equal to the absolute value of the integral of the n plus 1th derivative of x dx. And the reason why this is useful is that we can still keep the inequality that this is less than or equal to this, but now this is a pretty straightforward integral to evaluate. The anti-derivative of the n plus 1th derivative is going to be the nth derivative. So this business right over here is just going to be the absolute value of the nth derivative of our error function. Did I say expected value? I shouldn't. See, it even confuses me. This is the error function. I should have used r, r for remainder, but this is all error. There's nothing about probability or expected value in this video. This is e for error. So anyway, this is going to be the nth derivative of our error function, which is going to be less than or equal to this, which is less than or equal to the anti-derivative of m. Well, that's a constant. So that's going to be mx. And since we're just taking indefinite integrals, we can't forget the idea that we have a constant over here. And in general, when you're trying to create an upper bound, you want as low of an upper bound as possible. So we want to minimize what this constant is. And lucky for us, we do know what value this function takes on at a point. We know that the nth derivative of our error function at a is equal to 0. I think we wrote it over here. The nth derivative at a is equal to 0. And that's because the nth derivative of the function and the approximation at a are going to be the same exact thing. And so if we evaluate both sides of this at a, and I'll do it over here on the side, we know that the absolute value of the nth derivative at a, we know that this thing is going to be equal to the absolute value of 0, which is 0, which needs to be less than or equal to when you evaluate this thing at a, which is less than or equal to ma plus c. And so if you look at this part of the inequality, you subtract ma from both sides, you get negative ma is less than or equal to c. So our constant here, based on that little condition that we were able to get in the last video, our constant is going to be greater than or equal to negative ma. So if we want to minimize the constant, if we want to get this as low of a bound as possible, we would want to pick c is equal to negative ma. That is the lowest possible c that will meet these constraints that we know are true. So we will actually pick c to be negative ma. And then we can rewrite this whole thing as the absolute value of the nth derivative of the error function, not the expected value. I have a strange suspicion I might have said expected value. But this is the error function. The absolute value of the nth derivative of the error function is less than or equal to m times x minus a. And once again, all of the constraints hold. This is for x as part of the interval, the closed interval, between a and b. But it looks like we're making progress. We at least went from the n plus 1th derivative to the nth derivative. Let's see if we can keep going. So same general idea. If we know this, then we know that we can take the integral of both sides of this. So we could take the integral of both sides of this, the antiderivative of both sides. And we know from what we figured out up here that something that's even smaller than this right over here is the absolute value of the integral of the expected value, see I said it, of the error function, not the expected value of the error function. The nth derivative of the error function of x, the nth derivative of the error function of x dx. So we know that this is less than or equal to, based on the exact same logic there. And this is useful because this is just going to be the n minus 1th derivative of our error function of x. And of course, we have the absolute value outside of it. And now this is going to be less than or equal to this, which is less than or equal to this right over here. The antiderivative of this right over here is going to be m times x minus a squared over 2. You could do u substitution if you want. Or you could just say, hey, look, I have a little expression here. Its derivative is 1, so it's implicitly there. So I can just treat it as kind of a u. So raise it to an exponent and then divide that exponent. But once again, I'm taking indefinite integrals. So I'm going to say a plus c over here. But let's use that same exact logic. If we evaluate this at a, you're going to have it. If we evaluate this whole, let's evaluate both sides of this at a. The left side evaluated at a we know is going to be 0. We figured that out up here in the last video. So you get, I'll do it on the right over here, you get 0 when you evaluate the left side at a. The right side of a, if the right side evaluated at a, you get m times a minus a squared over 2. So you're going to get 0 plus c. So you're going to get 0 is less than or equal to c. Once again, we want to minimize our constant. We want to minimize our upper bound over here. So we want to pick the lowest possible c that meets our constraints. So the lowest possible c that meets our constraint is 0. And so the general idea here is that we can keep doing this. We can keep doing exactly what we're doing all the way, all the way, all the way until you, so we keep integrating it the exact same way that I've done it, all the way that we get, and using this exact same property here, all the way until we get the bound on the error function of x. So you could view this as the 0th derivative. We're going all the way to the 0th derivative, which is really just the error function. The bound on the error function of x is going to be less than or equal to. And what's it going to be? And you can already see the pattern here, is that it's going to be m times x minus a. And the exponent, the one way to think about it, this exponent plus this derivative is going to be equal to n plus 1. Now this derivative is 0, so this exponent's going to be n plus 1. And whatever that exponent is, you're going to have n plus 1 factorial over here. And if you say, wait, where does this n plus 1 factorial come from? I just had a 2 here. Well, think about what happens when we integrate this again. You're going to raise this to the third power and then divide by 3. So your denominator's going to have 2 times 3. Then when you integrate it again, you're going to raise it to the fourth power and then divide by 4. So then your denominator's going to be 2 times 3 times 4, 4 factorial. So whatever power you're raising to, the denominator's going to be that power factorial. But what's really interesting now is if we are able to figure out that maximum value of our function, if we're able to figure out that maximum value of our function right there, we now have a way of bounding our error function over that interval, over that interval between a and b. So for example, the error function at b, we can now bound it if we know what an m is. We can say the error function at b is going to be less than or equal to m times b minus a to the n plus 1th power over n plus 1 factorial. So that gets us a really powerful, I guess you could call it, result, kind of the math behind it. Now we can show some examples where this could actually be applied.