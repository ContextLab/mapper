So I have the matrix A over here, and A has M rows and N columns. So we could call this an M by N matrix. And what I want to do in this video is relate the linear independence, or linear dependence, of the column vectors of A to the null space of A. So first of all, what am I talking about as column vectors? Well as you can see, there's N columns here, and we can view each of those as an M dimensional vector. And so, let me do it this way. So you could view this one right over here. We could write that as V1, V1, this next one over here, this would be V2, V2, and you would have N of these, because we have N columns. And so this one right over here would be VN. V, V sub N. And so we could rewrite A, we could rewrite the matrix A, the M by N matrix A, I'm bolding it to show that that's a matrix. We could rewrite it as, so let me do it the same way. So, I'll draw my little brackets there. We can write it, just express it, in terms of its column vectors. And so we could just say, well this is going to be V1 for that column, V1 for that column, V2 for this column, all the way, we're gonna have N columns, so you're gonna have VN for the Nth column. And remember, each of these are going to have M terms, or I should say M components in them. These are M dimensional column vectors. Now what I wanna do, I said I wanna relate the linear independence of these vectors to the null space of A. So let's remind ourselves what the null space of A even is. So the null space of A, the null space of A is equal to, or I could say it's equal to the set, it's the set of all vectors X that are members of RN, and I'm gonna double down on why I'm saying RN in a second, such that, such that if I take my matrix A, if I take my matrix A and multiply it by one of those Xs, by one of those Xs, I am going to get, I am going to get the zero vector. So why does X have to be a member of RN? Well just for the matrix multiplication to work, for this to be, if this is M by N, let me write this down, if this is M by N, well in order to just make the matrix multiplication work, or you could say the matrix vector multiplication, this has to be an N by one, an N by one vector. And so it's going to have N components, so it's going to be a member of RN. If this was M by A, or let me use a different letter, if this was M by, I don't know, seven, then this would be R seven that we would be dealing with. So that is the null space. So another way of thinking about it is, well if I take my matrix A and I multiply it by some vector X that's member of this null space, I'm going to get the zero vector. So if I take my matrix A, which I've expressed here in terms of its column vectors, multiply it by some vector X, so some vector X, and actually let me make it clear that it doesn't have to have the same, so some vector X right over here. Let me draw the other bracket. So this is a vector X, and so it's going to have, it's a member of RN, so it's going to have N components, so you're going to have X one as the first component, X two, and go all the way to XN. If you multiply, so if we say that this X is a member of the null space of A, then this whole thing is going to be equal to the zero vector. Is going to be equal to the zero vector, and once again the zero vector, this is going to be an M by one vector. So it's going to look, actually let me write it like this. I'm going to have the same number of rows as A, so I'll try to make it, the bracket's roughly the same length, so, and there we go. Try and draw my brackets neatly, so you're going to have M of these one, two, and then go all the way to the Mth zero. So let's actually just multiply this out using what we know of matrix multiplication, and by the definition of matrix multiplication, one way to view this, if you were to multiply our matrix A times our vector X here, you're going to get the first column vector, V one, V one, times the first component here, X one, X one, plus the second component times the second column vector, X two times V two, V two, and we're going to do that N times, so plus dot dot dot X sub N times V sub N, V sub N, and these all, when you add them together, are going to be equal to the zero vector. Now this should be, this is going to be equal to the zero vector, and now this should start ringing a bell to you. When we looked at linear independence, we saw something like this. In fact, we saw that these vectors V, V sub one, V sub two, these N vectors are linearly independent if and only if any linear, if and only if the solution to this, or I guess you could say the weights on these vectors, the only way to get this to be true is if X one, X two, X N are all equal zero. So let me write this down. So V sub one, V sub two, all the way to V sub N are linearly independent, linearly independent if and only if, if and only if, only solution, so let me, only solution, or you could say weights on these vectors to this equation, the only solution is X one, X two, all the way to X N are equal to zero. So if the only solution here, if the only way to get this sum to be equal to the zero vector is if X one, X two, all the way through X N are equal to zero, well that means that our vectors, V one, V two, all the way to V N are linearly independent or vice versa. If they are linearly independent, the only solution to this, if we're solving for the weights on those vectors, is if for X one, X two, and X N to be equal to zero. Remember, linear independence, if you want to say it's still mathematical, but in a little bit more common language is if these vectors are linearly independent, that means that none of these vectors can be constructed by linear combinations of the other vectors. Or, looking at it this way, this right over here is a, this is a linear combination of all of the vectors, that the only way to get this linear combination of all the vectors to be equal to zero is if X one, X two, all the way through X N are equal to zero. And we proved that in other videos on linear independence. Well, if the only solution to this is all of the X ones through X N's is equal to zero, that means that the null space, this is only going to be true, you could say if and only if, the null space of A, the null space of A, let me make sure it looks like a matrix, I'm gonna bold it, the null space of A only contains one vector. It only contains the zero vector. Remember, this is, if all of these are going to be zero, well, then the only solution here is going to be the zero vector, is going to be, is going to be the zero vector. So the result that we're showing here is if the column vectors of a matrix are linearly independent, then the null space of that matrix is only going to consist of the zero vector. Or you could go the other way. If the null space of a matrix only contains the zero vector, well, that means that the columns of that matrix are linearly independent.