{"domain":{"id":"artificial-intelligence-ml","name":"AI and Machine Learning","parent_id":"computer-science","level":"sub","region":{"x_min":0.508002,"x_max":0.665108,"y_min":0.461562,"y_max":0.705055},"grid_size":70},"questions":[{"id":"b821bce3987019e2","question_text":"Artificial intelligence was formally founded as an academic discipline at a conference held at which institution in 1956?","options":{"A":"Carnegie Mellon University","B":"Massachusetts Institute of Technology","C":"Dartmouth College","D":"Stanford University"},"correct_answer":"C","difficulty":1,"source_article":"Artificial intelligence","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["artificial intelligence"],"x":0.618632,"y":0.663685},{"id":"6d7d99d5a9dd0c83","question_text":"The term 'machine learning' was coined in 1959 by which IBM researcher, who developed a program that learned to play checkers?","options":{"A":"Marvin Minsky","B":"Frank Rosenblatt","C":"John McCarthy","D":"Arthur Samuel"},"correct_answer":"D","difficulty":1,"source_article":"Machine learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["machine learning"],"x":0.787207,"y":0.762855},{"id":"472e3b153bcc1d53","question_text":"In a neural network, the output of each artificial neuron is computed by applying what type of function to the weighted sum of its inputs?","options":{"A":"A logarithmic scaling function","B":"A nonlinear activation function","C":"A stochastic sampling function","D":"A linear transformation function"},"correct_answer":"B","difficulty":1,"source_article":"Neural network (machine learning)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["neural network"],"x":0.839279,"y":0.748883},{"id":"c651a94650f3131f","question_text":"In deep learning, the adjective 'deep' refers to what characteristic of the neural network architecture?","options":{"A":"The high dimensionality of input features","B":"The use of multiple layers in the network","C":"The large size of the training dataset","D":"The extensive duration of the training process"},"correct_answer":"B","difficulty":1,"source_article":"Deep learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["deep learning"],"x":0.771805,"y":0.723412},{"id":"5691a2bd831492d6","question_text":"The word 'algorithm' derives from the Latinized name of which 9th-century Persian mathematician?","options":{"A":"Ibn al-Haytham","B":"Al-Khwarizmi","C":"Al-Kindi","D":"Omar Khayyam"},"correct_answer":"B","difficulty":1,"source_article":"Algorithm","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["algorithm"],"x":0.789164,"y":0.820271},{"id":"ede15d7227444161","question_text":"In machine learning, data is typically split into three subsets: a training set, a test set, and which third set used for tuning hyperparameters?","options":{"A":"A holdout control set","B":"A validation set","C":"A reference set","D":"A calibration set"},"correct_answer":"B","difficulty":1,"source_article":"Training, validation, and test data sets","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["training data"],"x":0.760139,"y":0.719487},{"id":"20ba126bce1690bd","question_text":"Supervised learning requires training data in which each example is paired with what kind of information?","options":{"A":"A cluster membership assignment","B":"A reward signal from the environment","C":"A known correct output label","D":"An unlabeled feature vector only"},"correct_answer":"C","difficulty":1,"source_article":"Supervised learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["supervised learning"],"x":0.749667,"y":0.71183},{"id":"2c649110c47d22f8","question_text":"What distinguishes unsupervised learning from supervised learning in terms of the data it uses?","options":{"A":"It learns patterns only from synthetically generated data","B":"It learns patterns exclusively from unlabeled data","C":"It learns patterns from data with explicit output labels","D":"It learns patterns from data with reward signals"},"correct_answer":"B","difficulty":1,"source_article":"Unsupervised learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["unsupervised learning"],"x":0.755054,"y":0.714616},{"id":"9ffd3967c418364c","question_text":"In machine learning, classification is the task of assigning an input to one of a set of discrete categories. What are the two main subtypes of classification?","options":{"A":"Binary classification and multiclass classification","B":"Parametric classification and nonparametric classification","C":"Linear classification and polynomial classification","D":"Deterministic classification and probabilistic classification"},"correct_answer":"A","difficulty":1,"source_article":"Statistical classification","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["classification"],"x":0.779242,"y":0.728447},{"id":"2ebf77a319d990c3","question_text":"Regression analysis estimates the relationship between a dependent variable and one or more independent variables. What is the most common form of regression?","options":{"A":"Polynomial regression","B":"Ridge regression","C":"Linear regression","D":"Logistic regression"},"correct_answer":"C","difficulty":1,"source_article":"Regression analysis","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["regression"],"x":0.837527,"y":0.79065},{"id":"6bdb0981013dc4c0","question_text":"The word 'robot' was introduced in Karel Capek's 1920 play R.U.R. From which Czech word, meaning forced labor or serfdom, was it derived?","options":{"A":"Robitel, meaning autonomous thinking machine","B":"Robotnik, meaning skilled craftsman or artisan","C":"Robota, meaning forced labor or compulsory service","D":"Rabota, meaning voluntary mechanical work"},"correct_answer":"C","difficulty":1,"source_article":"Robot","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["robot"],"x":0.696099,"y":0.828907},{"id":"43a0037ff7669234","question_text":"Natural language processing (NLP) is a subfield of computer science and AI. What two broad categories of tasks does NLP primarily encompass?","options":{"A":"Natural language indexing and natural language compression","B":"Natural language encoding and natural language transmission","C":"Natural language compilation and natural language execution","D":"Natural language understanding and natural language generation"},"correct_answer":"D","difficulty":1,"source_article":"Natural language processing","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["natural language processing"],"x":0.811788,"y":0.760741},{"id":"b09f9b5553bcdd11","question_text":"Computer vision is an interdisciplinary field that enables machines to interpret visual information. What type of high-level understanding does it extract from digital images or videos?","options":{"A":"Binary or hexadecimal information used for data compression and file storage","B":"Acoustic or frequency information used for sound reconstruction and audio synthesis","C":"Temporal or sequential information used for text generation and language models","D":"Numerical or symbolic information used for decisions and understanding of scenes"},"correct_answer":"D","difficulty":1,"source_article":"Computer vision","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["computer vision"],"x":0.778637,"y":0.724366},{"id":"814dec2fe8ea5a02","question_text":"Gradient descent is a first-order iterative optimization algorithm. In which direction does it repeatedly step to minimize a differentiable function?","options":{"A":"In the direction perpendicular to the gradient at the current point, along a contour line","B":"In a random direction sampled uniformly from the unit sphere at each iteration","C":"In the opposite direction of the gradient at the current point, the direction of steepest descent","D":"In the same direction as the gradient at the current point, the direction of steepest ascent"},"correct_answer":"C","difficulty":2,"source_article":"Gradient descent","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["gradient descent"],"x":0.740811,"y":0.712938},{"id":"0c3d4d3d7bec919e","question_text":"In machine learning, overfitting occurs when a model learns training data too closely, including noise. What happens to the model's performance on unseen data as overfitting increases?","options":{"A":"Performance on unseen data becomes worse even as training performance continues to improve","B":"Performance on unseen data improves proportionally as training performance continues to improve","C":"Performance on unseen data oscillates randomly while training performance steadily decreases","D":"Performance on unseen data remains constant while training performance stops changing"},"correct_answer":"A","difficulty":2,"source_article":"Overfitting","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["overfitting"],"x":0.781338,"y":0.732053},{"id":"d17330ed50ba1a20","question_text":"A convolutional neural network (CNN) uses a sliding window operation across input data. What does this operation compute between the kernel values and the input at each position?","options":{"A":"A cross product, producing a vector field of spatial orientations","B":"A bitwise XOR, producing a binary mask of edge boundaries","C":"An arithmetic mean, producing a smoothed map of average intensities","D":"A dot product, producing a feature map of detected features"},"correct_answer":"D","difficulty":2,"source_article":"Convolutional neural network","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["convolutional neural network"],"x":0.795387,"y":0.739008},{"id":"887026eeae32e120","question_text":"Recurrent neural networks (RNNs) differ from feedforward networks by using recurrent connections. What is fed back as additional input at each time step to capture temporal dependencies?","options":{"A":"The output weights from a random time step","B":"The hidden state from the previous time step","C":"The loss gradient from the final time step","D":"The raw input from the first time step"},"correct_answer":"B","difficulty":2,"source_article":"Recurrent neural network","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["recurrent neural network"],"x":0.824638,"y":0.754544},{"id":"4b41d37e50f19684","question_text":"Backpropagation efficiently computes the gradient of a loss function with respect to network weights. Which mathematical rule does it apply, iterating backward layer by layer?","options":{"A":"Bayes' rule of probability","B":"The chain rule of calculus","C":"L'Hopital's rule of limits","D":"The product rule of calculus"},"correct_answer":"B","difficulty":2,"source_article":"Backpropagation","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["backpropagation"],"x":0.749855,"y":0.711741},{"id":"4ee2da7f7f61db96","question_text":"Reinforcement learning trains an agent through interactions with an environment. What fundamental tradeoff must the agent balance between trying new actions and using known rewarding ones?","options":{"A":"The compression versus fidelity tradeoff","B":"The bias versus variance tradeoff","C":"The precision versus recall tradeoff","D":"The exploration versus exploitation tradeoff"},"correct_answer":"D","difficulty":2,"source_article":"Reinforcement learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["reinforcement learning"],"x":0.777256,"y":0.719818},{"id":"ce4ef91a1d2d7d10","question_text":"Decision tree learning builds a tree-structured predictive model through recursive partitioning. What do the leaf nodes of a classification decision tree represent?","options":{"A":"Class labels assigned to input instances","B":"Feature importance scores for each attribute","C":"Splitting thresholds for continuous variables","D":"Probability distributions over training samples"},"correct_answer":"A","difficulty":2,"source_article":"Decision tree learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["decision tree"],"x":0.71125,"y":0.688752},{"id":"5ce78a8caa2165cb","question_text":"In transfer learning, what is the common practice when adapting a pretrained deep neural network to a new task with limited data?","options":{"A":"Fine-tuning the later layers while keeping the early and middle layers frozen, since early layers capture general features reusable across tasks.","B":"Freezing the final classification layer and retraining only the first layer, since initial layers are most task-specific and need updating.","C":"Retraining all layers from scratch with random initialization, since pretrained weights introduce bias from the original task's data distribution.","D":"Removing all convolutional layers and replacing them with fully connected layers, since new tasks require fundamentally different feature extraction."},"correct_answer":"A","difficulty":2,"source_article":"Transfer learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["transfer learning"],"x":0.766133,"y":0.720202},{"id":"c25e7dd407abe938","question_text":"In a generative adversarial network (GAN), what are the roles of the two neural networks trained simultaneously?","options":{"A":"The generator creates synthetic data samples, while the discriminator tries to distinguish generated samples from real training data.","B":"The policy network selects actions in an environment, while the value network estimates expected cumulative rewards for each state.","C":"The teacher network produces soft probability targets, while the student network learns to replicate those targets with fewer parameters.","D":"The encoder compresses input data into a latent space, while the decoder reconstructs the original input from the compressed representation."},"correct_answer":"A","difficulty":2,"source_article":"Generative adversarial network","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["generative adversarial network"],"x":0.82328,"y":0.75201},{"id":"12a70cf0c1ea1929","question_text":"What key architectural innovation did the transformer introduce that allowed it to replace recurrent neural networks for sequence modeling?","options":{"A":"The memory-augmented cell, which lets the network store and retrieve information from an external differentiable memory matrix.","B":"The self-attention mechanism, which lets every position attend to all other positions in parallel rather than processing tokens sequentially.","C":"The convolutional filter bank, which lets the network extract local n-gram patterns from fixed-size windows across the sequence.","D":"The gating mechanism, which lets the network selectively forget irrelevant information from earlier positions in the sequence."},"correct_answer":"B","difficulty":2,"source_article":"Transformer (deep learning architecture)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["transformer"],"x":0.737992,"y":0.709012},{"id":"c27ffcb4e6efb5cc","question_text":"What underlying architecture do modern large language models such as GPT use, and how are they initially trained?","options":{"A":"They use deep convolutional networks and are pretrained with supervised classification on millions of manually labeled sentence pairs.","B":"They use memory-augmented autoencoders and are pretrained with contrastive learning on paired examples of similar and dissimilar texts.","C":"They use the transformer architecture and are pretrained with self-supervised learning on massive text corpora to predict upcoming tokens.","D":"They use stacked recurrent neural networks and are pretrained with reinforcement learning on curated question-answer dialogue datasets."},"correct_answer":"C","difficulty":2,"source_article":"Large language model","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["large language model"],"x":0.747173,"y":0.714862},{"id":"c3e7f1600a2cb656","question_text":"In the bias-variance tradeoff, what happens to bias and variance as model complexity increases?","options":{"A":"Both bias and variance decrease together because more parameters allow the model to generalize better and reduce all sources of error simultaneously.","B":"Bias increases because more parameters introduce systematic approximation errors, while variance decreases because the model averages over more learned features.","C":"Bias decreases because the model can fit training data more closely, while variance increases because the model becomes more sensitive to training set fluctuations.","D":"Bias remains constant regardless of complexity, while variance increases linearly with the number of parameters due to accumulated rounding errors."},"correct_answer":"C","difficulty":3,"source_article":"Bias\u2013variance tradeoff","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["bias-variance tradeoff"],"x":0.77866,"y":0.737292},{"id":"a82e1211de2e2989","question_text":"How does L1 regularization (Lasso) differ from L2 regularization (Ridge) in its effect on model weights?","options":{"A":"L1 penalizes only negative weights to enforce non-negativity constraints, while L2 penalizes only large positive weights to prevent unbounded parameter growth.","B":"L1 adds an absolute-value penalty that drives some weights exactly to zero, producing sparse models, while L2 shrinks all weights evenly without eliminating any.","C":"L1 multiplies each weight by a fixed decay factor after every training epoch, while L2 randomly zeroes a fraction of weights during each forward pass.","D":"L1 adds a squared penalty that distributes weight values uniformly across features, while L2 uses an absolute-value penalty concentrating weights on one dominant feature."},"correct_answer":"B","difficulty":3,"source_article":"Regularization (mathematics)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["regularization"],"x":0.740213,"y":0.714811},{"id":"c5ce8815bceefef7","question_text":"In k-fold cross-validation, how is the dataset used to estimate a model's generalization performance?","options":{"A":"Data is divided into k folds of increasing size; the model trains on progressively larger subsets and tests only on the final fold.","B":"Data is shuffled into k folds; the model trains on all folds simultaneously and tests on a separate held-out set outside the folds.","C":"Data is partitioned into k folds; the model trains on one fold and tests on the other k\u22121, rotating so every fold trains once.","D":"Data is partitioned into k folds; the model trains on k\u22121 folds and tests on the remaining one, rotating so every fold validates once."},"correct_answer":"D","difficulty":3,"source_article":"Cross-validation (statistics)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["cross-validation"],"x":0.77225,"y":0.730601},{"id":"510e459f46edc4f8","question_text":"What problem was batch normalization originally designed to address, and how does it operate during training?","options":{"A":"It was designed to eliminate vanishing gradients by scaling each layer's weights to have equal magnitude using the full training set statistics during training.","B":"It was designed to reduce internal covariate shift by normalizing each layer's inputs to have zero mean and unit variance across the mini-batch during training.","C":"It was designed to reduce overfitting by randomly permuting each layer's output activations within each training sample during each forward pass.","D":"It was designed to prevent gradient explosion by clipping each layer's activations to a fixed range across the entire training dataset during training."},"correct_answer":"B","difficulty":3,"source_article":"Batch normalization","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["batch normalization"],"x":0.848272,"y":0.769372},{"id":"03e463ea3be3f7d0","question_text":"In the self-attention mechanism used by transformers, how are the query, key, and value vectors used to compute attention weights?","options":{"A":"Element-wise products of query and value vectors are normalized, then passed through tanh to produce weights that scale each key vector's output contribution.","B":"Euclidean distances between query and key vectors are inverted, then passed through sigmoid to produce weights that gate each value vector's output contribution.","C":"Cosine similarities between key and value vectors are thresholded, then passed through ReLU to produce weights that filter each query vector's output contribution.","D":"Dot products between query and key vectors are scaled, then passed through softmax to produce weights that sum each value vector into the output."},"correct_answer":"D","difficulty":3,"source_article":"Attention (machine learning)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["attention mechanism"],"x":0.762799,"y":0.724704},{"id":"ecc4d02f194efbe7","question_text":"What notable property of Word2Vec embeddings demonstrated that word vectors capture semantic relationships through vector arithmetic?","options":{"A":"Vector analogies such as king minus man plus woman yielding a vector closest to queen showed that arithmetic on embeddings encodes semantic relationships.","B":"Clustering word vectors by their magnitude showed that words with similar frequencies in the corpus always share identical syntactic roles in sentences.","C":"Projecting word vectors onto two principal components showed that all synonyms occupy the exact same point in the reduced embedding space.","D":"Computing the determinant of the word vector matrix showed that semantically related words always produce integer values while unrelated words produce irrational values."},"correct_answer":"A","difficulty":3,"source_article":"Word embedding","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["word embedding"],"x":0.752216,"y":0.718846},{"id":"f82e4941109e8416","question_text":"In the attention mechanism used by transformers, what three vectors are computed from each input element to determine how much focus one position gives to another?","options":{"A":"Input, hidden, and output vectors, where the dot product of inputs and outputs produces attention weights used to compute a weighted sum of hidden states.","B":"Encoder, decoder, and context vectors, where the dot product of encoders and decoders produces attention weights used to compute a weighted sum of contexts.","C":"Query, key, and value vectors, where the dot product of queries and keys produces attention weights used to compute a weighted sum of values.","D":"Query, key, and value vectors, where the element-wise product of queries and values produces activation weights used to compute a weighted sum of keys."},"correct_answer":"C","difficulty":3,"source_article":"Attention_(machine_learning)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["attention mechanism"],"x":0.76948,"y":0.728287},{"id":"eb891d5b3d7ac730","question_text":"How do word embedding models like Word2Vec and GloVe represent words, and what geometric property encodes semantic similarity between words?","options":{"A":"They represent words as dense, low-dimensional vectors where semantically similar words are mapped to nearby points in the vector space.","B":"They represent words as dense, low-dimensional vectors where semantically similar words are mapped to distant points in the vector space.","C":"They represent words as dense, low-dimensional vectors where semantically similar words are mapped to orthogonal directions in the vector space.","D":"They represent words as sparse, high-dimensional one-hot vectors where semantically similar words are mapped to nearby points in the vector space."},"correct_answer":"A","difficulty":3,"source_article":"Word_embedding","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["word embedding"],"x":0.761694,"y":0.721468},{"id":"603caceee7ec130b","question_text":"A Markov decision process is defined by a tuple of five components. Which components formalize the sequential decision-making problem that underpins reinforcement learning?","options":{"A":"A set of states, a set of actions, transition probabilities, a reward function, and a discount factor governing future reward weighting.","B":"A set of states, a set of actions, transition probabilities, a loss function, and a learning rate governing parameter update magnitude.","C":"A set of inputs, a set of outputs, conditional probabilities, a reward function, and a discount factor governing future reward weighting.","D":"A set of states, a set of actions, prior probabilities, a reward function, and a momentum term governing convergence speed."},"correct_answer":"A","difficulty":3,"source_article":"Markov_decision_process","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["Markov decision process"],"x":0.804185,"y":0.740355},{"id":"7b45b6efb5eb7d15","question_text":"How does a random forest improve upon a single decision tree, and what additional source of randomness does it introduce beyond bootstrap sampling?","options":{"A":"It trains many decision trees on the full dataset and randomly selects a subset of features at each split, reducing variance through boosting.","B":"It trains many decision trees on bootstrap samples and randomly selects a subset of features at each split, reducing variance through ensemble averaging.","C":"It trains many decision trees on bootstrap samples and randomly selects a subset of features at each split, reducing bias through sequential correction.","D":"It trains many decision trees on bootstrap samples and randomly selects a subset of training examples at each split, reducing bias through ensemble averaging."},"correct_answer":"B","difficulty":3,"source_article":"Random_forest","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["random forest"],"x":0.755005,"y":0.725733},{"id":"d23f3dc8f950dc9c","question_text":"In principal component analysis, what mathematical operation on the data's covariance matrix identifies the directions of maximum variance used for dimensionality reduction?","options":{"A":"Matrix inversion of the covariance matrix, where column vectors define the principal component directions and diagonal entries indicate the variance explained by each.","B":"Eigendecomposition of the covariance matrix, where eigenvectors define the principal component directions and eigenvalues indicate the variance explained by each.","C":"Eigendecomposition of the correlation matrix, where eigenvectors define the principal component directions and eigenvalues indicate the mean explained by each.","D":"Eigendecomposition of the covariance matrix, where eigenvalues define the principal component directions and eigenvectors indicate the variance explained by each."},"correct_answer":"B","difficulty":3,"source_article":"Principal_component_analysis","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["principal component analysis"],"x":0.841251,"y":0.794754},{"id":"a10bf2eab26a2deb","question_text":"What causes the vanishing gradient problem in deep neural networks, and which widely adopted activation function was introduced to mitigate it?","options":{"A":"Saturating activation functions like sigmoid cause gradients to shrink exponentially during backpropagation; softmax mitigates this by normalizing gradients across all neurons in each layer.","B":"Saturating activation functions like sigmoid cause gradients to shrink exponentially during backpropagation; ReLU mitigates this by maintaining a gradient of one for positive inputs.","C":"Saturating activation functions like sigmoid cause gradients to grow exponentially during backpropagation; ReLU mitigates this by clamping gradients to a maximum of one for all inputs.","D":"Non-saturating activation functions like ReLU cause gradients to shrink exponentially during backpropagation; sigmoid mitigates this by maintaining a gradient of one for positive inputs."},"correct_answer":"B","difficulty":3,"source_article":"Vanishing_gradient_problem","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["vanishing gradient problem"],"x":0.811673,"y":0.74947},{"id":"925ba426faa0aabf","question_text":"How does dropout regularize a neural network during training, and what happens to the dropout mechanism at inference time?","options":{"A":"During training, dropout randomly sets a fraction of neuron activations to zero to prevent co-adaptation; at inference time, dropout rate is doubled to improve robustness.","B":"During training, dropout randomly sets a fraction of neuron activations to zero to prevent co-adaptation; at inference time, dropout is disabled and all neurons are active.","C":"During training, dropout permanently removes a fraction of neurons from the network to reduce complexity; at inference time, the pruned architecture is used directly.","D":"During training, dropout randomly sets a fraction of neuron activations to zero to accelerate convergence; at inference time, dropout is disabled and weights are randomly reinitialized."},"correct_answer":"B","difficulty":3,"source_article":"Dilution_(neural_networks)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["dropout"],"x":0.824314,"y":0.755677},{"id":"ec6b7f158d35fd90","question_text":"What two pre-training objectives does BERT use to learn bidirectional language representations from unlabeled text?","options":{"A":"Masked language modeling, which predicts randomly masked tokens from context, and next sentence prediction, which determines whether two sentences are consecutive.","B":"Masked language modeling, which predicts randomly masked tokens from context, and sentence similarity scoring, which estimates the semantic overlap between two sentences.","C":"Causal language modeling, which predicts the next token from left context only, and next sentence prediction, which determines whether two sentences are consecutive.","D":"Masked language modeling, which predicts randomly masked tokens from context, and text classification, which assigns a categorical label to each input sentence."},"correct_answer":"A","difficulty":3,"source_article":"BERT_(language_model)","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["BERT"],"x":0.75126,"y":0.72073},{"id":"883137d4c58793e1","question_text":"In the PAC learning framework proposed by Leslie Valiant, what does it mean for a concept class to be 'probably approximately correctly' learnable?","options":{"A":"A learning algorithm can, with certainty, produce a hypothesis with zero generalization error after observing an exponential number of training samples.","B":"A learning algorithm can, with high probability, produce a hypothesis with low generalization error after observing a polynomial number of training samples.","C":"A learning algorithm can, with high probability, produce a hypothesis with low generalization error after observing a logarithmic number of training samples.","D":"A learning algorithm can, with high probability, produce a hypothesis with low training error after observing a polynomial number of validation samples."},"correct_answer":"B","difficulty":4,"source_article":"Probably_approximately_correct_learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["PAC learning"],"x":0.80912,"y":0.74841},{"id":"c513b84c0af4a97f","question_text":"What does the VC dimension of a hypothesis class measure, and how does it relate to the class's ability to generalize from training data?","options":{"A":"It measures the size of the largest set of points the class can shatter; an infinite VC dimension guarantees uniform convergence and bounds generalization error.","B":"It measures the number of parameters in the hypothesis class; a finite VC dimension guarantees uniform convergence and bounds generalization error.","C":"It measures the size of the largest set of points the class can shatter; a finite VC dimension guarantees convergence of training error to zero.","D":"It measures the size of the largest set of points the class can shatter; a finite VC dimension guarantees uniform convergence and bounds generalization error."},"correct_answer":"D","difficulty":4,"source_article":"Vapnik%E2%80%93Chervonenkis_dimension","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["VC dimension"],"x":0.772923,"y":0.739364},{"id":"9d65ff225c664a2e","question_text":"In a variational autoencoder, the reparameterization trick is essential for training. What problem does it solve, and how does it work?","options":{"A":"The KL divergence term is intractable for high-dimensional latents; the trick approximates it using a Monte Carlo estimate over decoder outputs.","B":"Backpropagation cannot flow through stochastic sampling nodes; the trick replaces sampling with the mean of the latent distribution during training.","C":"The decoder loss gradient vanishes for distant latent codes; the trick clips gradients to a fixed norm before updating encoder parameters.","D":"Backpropagation cannot flow through stochastic sampling nodes; the trick expresses latent samples as a deterministic function of learned parameters plus external noise."},"correct_answer":"D","difficulty":4,"source_article":"Variational autoencoder","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["variational autoencoder","reparameterization trick","ELBO","backpropagation"],"x":0.781512,"y":0.734025},{"id":"020e3c65a93cc41f","question_text":"The Expectation-Maximization algorithm finds maximum likelihood estimates when latent variables are present. What do the E-step and M-step each compute?","options":{"A":"The E-step samples latent variable values from the current model; the M-step finds parameters that maximize the marginal likelihood directly.","B":"The E-step computes the posterior over observed variables given latent ones; the M-step finds parameters that minimize the posterior entropy.","C":"The E-step computes the expected log-likelihood using current parameter estimates; the M-step finds parameters that maximize this expected log-likelihood.","D":"The E-step computes the gradient of the log-likelihood with respect to latent variables; the M-step updates latent variables by gradient ascent."},"correct_answer":"C","difficulty":4,"source_article":"Expectation\u2013maximization algorithm","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["expectation-maximization algorithm","latent variables","maximum likelihood estimation"],"x":0.763404,"y":0.728177},{"id":"7990fd55d27af9cc","question_text":"Q-learning is a model-free reinforcement learning algorithm. What makes it off-policy, and what key operation distinguishes its update rule from SARSA?","options":{"A":"It learns the optimal policy independent of the behavior policy; its update takes the Q-value of a randomly sampled next-state action instead of the one actually taken.","B":"It learns the optimal policy independent of the behavior policy; its update takes the average Q-value over next-state actions instead of the action actually taken.","C":"It requires a model of the environment's transition dynamics; its update takes the maximum Q-value over next-state actions instead of the action actually taken.","D":"It learns the optimal policy independent of the behavior policy; its update takes the maximum Q-value over next-state actions instead of the action actually taken."},"correct_answer":"D","difficulty":4,"source_article":"Q-learning","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["Q-learning","off-policy learning","temporal difference learning","Bellman optimality equation"],"x":0.800305,"y":0.736113},{"id":"c044e326e0e2d444","question_text":"Kernel methods allow linear algorithms to learn nonlinear decision boundaries. What does Mercer's theorem guarantee about a valid kernel function?","options":{"A":"A symmetric positive semi-definite kernel corresponds to a distance metric in some feature space, so the kernel trick can replace explicit high-dimensional mapping.","B":"A continuous bounded kernel corresponds to an inner product in a finite-dimensional feature space, so computation scales linearly with the number of samples.","C":"A symmetric positive definite kernel guarantees that the resulting optimization problem is convex, so any local minimum equals the global minimum.","D":"A symmetric positive semi-definite kernel corresponds to an inner product in some feature space, so the kernel trick can replace explicit high-dimensional mapping."},"correct_answer":"D","difficulty":4,"source_article":"Kernel method","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["kernel method","Mercer's theorem","kernel trick","support vector machine"],"x":0.78558,"y":0.748047},{"id":"f700b5217c44075b","question_text":"The information bottleneck method formalizes optimal data compression with respect to a relevant target variable. What tradeoff does its Lagrangian objective balance?","options":{"A":"It balances minimizing reconstruction error of the input from its compressed representation against maximizing the entropy of the target variable.","B":"It balances minimizing mutual information between the input and its compressed representation against maximizing mutual information between the representation and the target variable.","C":"It balances minimizing the KL divergence between input and compressed distributions against maximizing mutual information between the input and the target variable.","D":"It balances minimizing the dimensionality of the compressed representation against maximizing the classification accuracy on the target variable."},"correct_answer":"B","difficulty":4,"source_article":"Information bottleneck method","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["information bottleneck","mutual information","rate-distortion tradeoff","data compression"],"x":0.763194,"y":0.72737},{"id":"7a55c996a6b92fb8","question_text":"Neural architecture search automates the design of neural network architectures. What are its three core components, and which early NAS approach used a recurrent network as a controller?","options":{"A":"The three components are search space, search strategy, and performance estimation; Zoph and Le's 2017 approach used a convolutional controller trained with evolutionary algorithms.","B":"The three components are search space, search strategy, and performance estimation; Real et al.'s 2017 approach used an RNN controller trained with reinforcement learning.","C":"The three components are search space, search strategy, and performance estimation; Zoph and Le's 2017 approach used an RNN controller trained with reinforcement learning.","D":"The three components are hyperparameter space, gradient strategy, and cross-validation estimation; Zoph and Le's 2017 approach used an RNN controller trained with reinforcement learning."},"correct_answer":"C","difficulty":4,"source_article":"Neural architecture search","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["neural architecture search","search space","reinforcement learning","automated machine learning"],"x":0.82922,"y":0.754686},{"id":"f3b7bc0634d8e6b7","question_text":"Normalizing flows construct complex probability distributions by composing invertible transformations. Why must each transformation be invertible, and what computational cost does this impose?","options":{"A":"Invertibility enables exact posterior inference via Bayes' theorem, but requires computing the log-determinant of each transformation's Jacobian matrix.","B":"Invertibility enables exact likelihood computation via the change-of-variables formula, but requires computing the eigenvalues of each transformation's Hessian matrix.","C":"Invertibility ensures the latent space has the same dimensionality as the data space, but requires computing the trace of each transformation's Jacobian matrix.","D":"Invertibility enables exact likelihood computation via the change-of-variables formula, but requires computing the log-determinant of each transformation's Jacobian matrix."},"correct_answer":"D","difficulty":4,"source_article":"Flow-based generative model","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["normalizing flow","change of variables","Jacobian determinant","exact likelihood"],"x":0.790413,"y":0.751145},{"id":"93468e44467385bf","question_text":"Proximal Policy Optimization (PPO) is a policy gradient method that improves training stability over TRPO. How does the PPO-Clip variant prevent destructively large policy updates?","options":{"A":"It clips the gradient norm of the policy network to a fixed maximum value, preventing any single parameter from changing excessively per step.","B":"It clips the probability ratio between new and old policies to a narrow range around 1, preventing large destabilizing updates to the policy.","C":"It adds a hard KL divergence constraint between new and old policies, using second-order optimization to keep updates within a trust region.","D":"It clips the advantage estimates to a narrow range around zero, preventing updates driven by high-variance or noisy reward signals."},"correct_answer":"B","difficulty":4,"source_article":"Proximal Policy Optimization","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["proximal policy optimization","policy gradient","clipping","trust region policy optimization"],"x":0.773321,"y":0.731612},{"id":"cffd6ebd47c64da3","question_text":"Graph neural networks operate on graph-structured data using message passing. What fundamental expressiveness limit do standard message-passing GNNs face, as characterized by a classical graph theory test?","options":{"A":"They cannot distinguish graph structures that differ only in edge weights, since message passing aggregates neighbor features without considering edge attributes.","B":"They cannot learn representations for graphs with more than a fixed number of nodes, since the receptive field grows linearly with network depth.","C":"They cannot distinguish graph structures that the chromatic number test also fails to distinguish, bounding their discriminative power to graph coloring equivalence.","D":"They cannot distinguish graph structures that the 1-dimensional Weisfeiler-Leman isomorphism test also fails to distinguish, bounding their discriminative power."},"correct_answer":"D","difficulty":4,"source_article":"Graph neural network","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["graph neural network","message passing","Weisfeiler-Leman test","expressiveness"],"x":0.78054,"y":0.733586},{"id":"1cbc1cbf17079a1b","question_text":"Diffusion models generate data by learning to reverse a gradual noising process. What does the forward process do, and what does the neural network learn to predict during training?","options":{"A":"The forward process compresses data into a low-dimensional latent code; the network learns to predict and remove the quantization error at each decoding step.","B":"The forward process incrementally adds Gaussian noise until data becomes pure noise; the network learns to predict and remove the noise added at each step.","C":"The forward process incrementally removes structure until data becomes uniform; the network learns to predict the original clean data from any noise level.","D":"The forward process incrementally adds Gaussian noise until data becomes pure noise; the network learns to predict the transition probabilities between successive noise levels."},"correct_answer":"B","difficulty":4,"source_article":"Diffusion model","domain_ids":["artificial-intelligence-ml"],"concepts_tested":["diffusion model","denoising","forward diffusion process","score matching"],"x":0.858759,"y":0.774183}],"labels":[],"articles":[]}