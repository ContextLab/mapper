[
  {
    "original_question": {
      "question": "In the computational theory of mind, why are representational structures and the computational procedures that operate on them considered the foundational mechanism for thinking?",
      "options": {
        "A": "Because discrete, combinatorial representations support the manipulation of novel combinations via general rules, enabling flexible, task-agnostic generalization.",
        "B": "Because cognition is fully determined by the specific neural hardware of the brain, so different tasks require no shared representations.",
        "C": "Because mental content is never abstracted; all thinking is just reactive responses to stimuli, so representations are unnecessary.",
        "D": "Because learning depends exclusively on external feedback loops without any internal representations or processing rules."
      },
      "correct_answer": "A",
      "source_article": "Cognitive science",
      "x": 1.2798595428466797,
      "y": 1.039600133895874,
      "concepts_tested": [
        "Concept 1: Representational structures and computational procedures as the foundational mechanism for thinking (computational theory of mind).",
        "Concept 2: Multidisciplinary, multi-level analysis of cognition (from neural circuitry to logic and planning; across psychology, philosophy, AI, neuroscience, linguistics, anthropology).",
        "Concept 3: Use of computational/metaphorical models (e.g., brain as a system, computer as a model/tool) to study and explain cognitive processes."
      ],
      "parent_concepts": [
        "Concept 3: Theoretical frameworks (content theories vs. process theories) offer different mechanisms for motivation, including examples like hierarchy of needs, expectancy/goal-setting/self-determination/reinforcement theories.",
        "Concept 3: The relationship and interaction between behaviorism and cognitive psychology, including how cognitive-behavioral therapies integrate principles from both approaches and apply them in real-world contexts (ABA, organizational behavior management).",
        "Mindset as a cognitive process that biases interpretation and decision-making",
        "Brain-behavior relationship: how injuries or illnesses of the brain affect cognitive and behavioral functions.",
        "Mind-brain integration: neuropsychology as a bridge linking brain pathology to cognitive processes and behavior, distinct from but related to neurology and psychology.",
        "Concept 1: Cognitive impairment affects multiple domains (memory, attention, planning, reasoning, language, executive function, visuospatial) and domain involvement can vary.",
        "Structuralist versus cognitive narratology: structure-focused study vs. studying how humans make sense of stories.",
        "Concept 1: Reaction time distributions (means, variance) index processing speed and the duration of mental operations.",
        "Embodiment as a mechanism: Cognition depends on the body and sensorimotor capacities, not just abstract brain processes.",
        "The idea that design ability is widespread and intrinsic to humans, framing design as a universal cognitive function that people engage in to alter situations.",
        "Concept 1: Multilingualism is associated with enhanced language learning abilities compared with monolingualism (a cause-effect/relationship principle that can be probed with why/how questions).",
        "Concept 2: Cognitive representations (schemas, attributions, stereotypes) as foundational elements that are activated and manipulated by processing to produce social judgments and biases.",
        "Concept 3: The link between cognitive processing and social/affective factors, and the resulting behavioral and interpersonal consequences across intrapersonal, interpersonal, and group contexts.",
        "Concept 3: Theoretical frameworks (psychological, cognitive, normative) that shape how decision-making is analyzed and understood, including normative logic and invariant choices.",
        "Concept 1: Framing as cognitive schemas/filters that shape interpretation and subsequent decisions or reactions.",
        "Concept 3: Grounded language learning via affordances in robotics, linking actions, perceptions, and effects to spoken words and enabling word-to-meaning mappings without requiring grammatical structure.",
        "Concept 1: Analogy as a cognitive transfer mechanism that maps information/meaning from a source domain to a target domain.",
        "Concept 3: Guiding principles such as statistical optimality and cognitive processing constraints (e.g., limited vs. unlimited capacity, serial vs. parallel processing) that shape model development and interpretation."
      ],
      "parent_articles": [
        "Motivation",
        "Behaviorism",
        "Mindset",
        "Neuropsychology",
        "Neuropsychology",
        "Cognitive impairment",
        "Narratology",
        "Mental chronometry",
        "Embodied cognition",
        "Design",
        "Multilingualism",
        "Social cognition",
        "Social cognition",
        "Decision-making",
        "Framing (social sciences)",
        "Computational linguistics",
        "Analogy",
        "Mathematical psychology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to the computational theory of mind, why are internal representational structures and the computational procedures that act on them taken to be the central mechanism of thinking?",
      "options": {
        "A": "Because discrete, combinatorial mental representations can be manipulated by general computational rules to produce novel combinations and flexible, task‑independent generalization.",
        "B": "Because cognition is entirely determined by the brain's specific neural hardware, so different tasks rely only on distinct circuits and shared abstract representations are unnecessary.",
        "C": "Because all mental activity is merely reactive stimulus–response behavior with no abstract internal representations or algorithmic processing.",
        "D": "Because learning depends solely on external feedback loops and sensory contingencies, without any internal representations or processing rules."
      },
      "correct_answer": "A",
      "simplification_notes": "Shortened and clarified the question while retaining technical terms (representations, computational procedures). Options were kept as plausible alternatives but made more concise; correct answer unchanged.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A cognitive scientist runs three parallel investigations of how adults remember 7-digit phone numbers: (1) a behavioral recall experiment measuring accuracy and reaction time, (2) an fMRI study identifying brain regions active during retention, and (3) two computational models — a symbolic program that stores digits in a buffer and applies rule-based rehearsal, and a connectionist network that learns to reproduce digit sequences via gradient descent. Which interpretation best exemplifies the computational theory of mind and the multi-level, multidisciplinary methodology central to cognitive science?",
      "options": {
        "A": "These results imply that memory is fully explained by a single neural circuit; therefore cognitive science should prioritize ever-higher-resolution neural recordings and discard symbolic and behavioral approaches as unnecessary.",
        "B": "The most appropriate interpretation is that remembering is the manipulation of internal representational structures by computational procedures: the behavioral task reveals the computational goal and performance constraints, fMRI points to hardware implementation, and the symbolic and connectionist models offer competing algorithm/representation-level hypotheses and useful computational tools; integrating psychology, neuroscience and AI exemplifies cognitive science.",
        "C": "Because the computer models can reproduce recall behavior, the brain must literally be a Von Neumann machine; cognitive science should therefore focus on implementing the brain in digital hardware rather than studying biology or behavior.",
        "D": "The divergence between symbolic and connectionist model predictions shows theoretical confusion; the field should avoid computational models and rely solely on behavioral measures to produce the most reliable accounts of memory."
      },
      "correct_answer": "B",
      "generation_notes": "Created a concrete three-part experimental vignette (behavioral, neuroimaging, computational models) and asked which interpretation maps to representational/ computational theory of mind and Marr-style multi-level analysis; distractors reflect common misunderstandings (reductionism, literal computer metaphor, rejection of levels).",
      "concepts_tested": [
        "Representational structures and computational procedures (computational theory of mind)",
        "Multi-level, multidisciplinary analysis of cognition (behavioral, algorithmic, implementation)",
        "Use of computational/metaphorical models (symbolic and connectionist models; computer as tool and metaphor)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.8_vs_16"
  },
  {
    "original_question": {
      "question": "How does the distinction between sustainability as a long-term goal and sustainable development as the set of processes and pathways to achieve it influence the design of policy and governance?",
      "options": {
        "A": "It implies policymakers can fix a single plan early and implement it without adjusting, since the end goal remains unchanged.",
        "B": "It encourages flexible, iterative policy design with feedback loops, stakeholder engagement, and adaptive instruments to respond to evolving knowledge, technology, and social conditions.",
        "C": "It suggests prioritizing immediate growth while ignoring present environmental constraints, because the goal is distant.",
        "D": "It asserts that development should be defined by maximizing short-term resource extraction efficiency."
      },
      "correct_answer": "B",
      "source_article": "Sustainable development",
      "x": 1.3628000020980835,
      "y": 0.8609886169433594,
      "concepts_tested": [
        "Concept 1: Intergenerational equity and the prioritization of the needs of the world’s poor within planetary limits (the Brundtland framing of needs vs technological/social constraints)",
        "Concept 2: The balance among economy, environment, and society (the triple bottom line) and the idea that development must harmonize these dimensions",
        "Concept 3: The distinction between sustainability as a long-term goal and sustainable development as the set of processes/pathways to achieve that goal (and the implications for policy and governance)"
      ],
      "parent_concepts": [
        "Concept 3: The importance of local context and investment in education, physical and social infrastructure, and locally produced development strategies; why/how tailored, locally driven strategies improve rural development outcomes.",
        "Concept 3: The relationship between infrastructure and sustainability/climate policy (guided by SDGs) and how policy shapes infrastructure development and transformation.",
        "Concept 2: The socio-economic–environmental dynamics of urbanization (the challenges and opportunities for sustainability, including resource scarcity, land use, quality of life) and how sustainable strategies can mitigate or leverage these effects.",
        "Concept 2: Environmental and social externalities of tourism and the principle of sustainable tourism to balance economic benefits with environmental and social responsibility.",
        "Concept 2: The shift toward sustainability and integrated transport policies, linking planning decisions to environmental goals, congestion reduction, and urban design.",
        "Distinguishing features (continuous transit use, pedestrian-friendly design, reduced parking) differentiate TOD from transit-proximate development and support sustainable urban growth.",
        "Concept 2: Protecting and designating specific land uses (flood plains, green belts, nuisance lands, transportation corridors) function as mechanisms to balance development with environmental and social objectives.",
        "Concept 3: Regulatory, financial, and governance barriers and incentives as key factors shaping the feasibility and outcomes of adaptive reuse (building codes, policies, incentives, information gaps).",
        "Concept 1: Integration of economic, social, and environmental concerns as the core principle guiding sustainable tourism (the triple bottom line).",
        "Global vs. local emissions: why local climate policies must align with global emission reductions to impact global warming.",
        "Concept 2: Energy policy is interdependent with climate policy and international targets; national decisions affect ability to meet commitments like Paris Agreement benchmarks.",
        "Concept 1: Directing growth to compact, walkable, mixed-use centers to avoid sprawl and reduce traffic congestion and environmental degradation.",
        "Concept 2: Long-range regional sustainability goals (transportation/housing choices, equity, preservation of resources, public health) as guiding principles for planning outcomes.",
        "The three base principles of the circular economy: designing out waste and pollution; keeping products and materials in use; regenerating natural systems.",
        "Mechanisms enabling circularity: circular business models (product-as-a-service, sharing platforms, product life extension) and the redesign of products/services toward long-life solutions.",
        "Systematic assessment of land/water potential, alternatives, and socio-economic conditions to guide decisions",
        "Concept 2: Externalities and trade-offs in transport (mobility benefits versus environmental, health, and social costs; short-term gains vs long-term sustainability).",
        "Concept 3: Rights-based governance of food security (the right to food, policy frameworks such as the World Food Summit declaration) and the role of agency in securing and sustaining food access, including why food should not be used as a political/economic tool.",
        "Concept 3: Relationships between resource scarcity, economic/political dynamics, and sustainability frameworks (e.g., circular economy, SDGs)",
        "Concept 1: Sustainability and balance between human activity and natural systems as the central aim of environmentalism.",
        "Concept 1: Design as the primary mechanism to reduce environmental impact and improve occupant health",
        "Concept 2: The environmental and social externalities of sprawl (environmental degradation, loss of countryside, segregation, and impacts on urban vitality).",
        "DRR is interconnected with climate change adaptation and broader development planning, requiring cross-sector integration and policy coordination.",
        "Holistic, adaptive management as a mechanism to sustain ecosystem function and services while meeting human needs (and its contrast with command-and-control approaches)",
        "Concept 3: Integrative approach linking cohesion policy with other EU objectives (climate change, energy, globalization) to achieve sustainable development and regional competitiveness",
        "Economic and environmental role of transport: enabling trade and growth while introducing pollution and land-use considerations, and the pursuit of sustainable transport options.",
        "Concept 1: Renewable energy reduces greenhouse gas emissions and air pollution, driving climate change mitigation and public health benefits.",
        "Concept 2: The relationship between resource extraction, environmental/human rights impacts, and governance frameworks (Sustainable Development Goals, circular economy) to mitigate negative outcomes.",
        "Environmental impact assessments (EIA) as a planning/enforcement mechanism: evaluating environmental consequences before projects proceed to integrate protection with development decisions.",
        "Concept 1: The triple bottom line as an integrated framework for evaluating performance across social, environmental, and economic dimensions (principle of multi-dimensional value).",
        "Integrated cross-sector decision-making that links natural, social, and economic systems to achieve sustainable coastal development.",
        "Balancing environmental protection with economic and social development, aiming to maintain functional integrity and environmental health.",
        "Concept 3: The relationship between appropriate technology and development paradigms (as an alternative to capital-intensive technology transfer; context-dependent differences between developing and developed countries; implications for equity and sustainability).",
        "Concept 3: Environmental and societal impacts shape policy and planning (how pollution, noise, climate vulnerability, and other effects drive mitigation and regulation).",
        "Concept 1: Parks serve multiple, sometimes competing functions (human recreation vs. wildlife/natural habitat protection) and the design aims to balance these objectives.",
        "Concept 2: Reinvestment of profits into sustainable development and services to align economic activity with social objectives.",
        "Energy ladder as a mechanism: increasing income leads households to shift from traditional biomass to cleaner, more efficient energy sources.",
        "Concept 1: Closure planning as a lifecycle process that integrates on-site environmental rehabilitation with off-site socio-economic impacts (e.g., livelihood loss and the use of offsets).",
        "Concept 1: Multi-objective management that balances conservation, utilization, and mixed goals within ecological, economic, and social/legal contexts.",
        "Concept 1: Multiple-use management as a framework that balances timber production with biodiversity, water quality, recreation, and other ecosystem services.",
        "Concept 1: Ecosystem-based fisheries management (EBFM) as a comprehensive, ecosystem-focused approach that balances ecological health, productivity, and human needs, contrasted with traditional single-species management.",
        "Self-sufficiency and mixed land use: housing, industry, and agriculture arranged within a single garden city to capture the benefits of both urban and rural environments."
      ],
      "parent_articles": [
        "Rural development",
        "Infrastructure",
        "Urbanization",
        "Tourism",
        "Transportation planning",
        "Transit-oriented development",
        "Regional planning",
        "Adaptive reuse",
        "Sustainable tourism",
        "Politics of climate change",
        "Energy policy",
        "Smart growth",
        "Smart growth",
        "Circular economy",
        "Circular economy",
        "Land-use planning",
        "Sustainable transport",
        "Food security",
        "Natural resource",
        "Environmentalism",
        "Sustainable design",
        "Urban sprawl",
        "Disaster risk reduction",
        "Ecosystem management",
        "Regional policy of the European Union",
        "Transport",
        "Renewable energy",
        "Natural resource",
        "Environmental law",
        "Triple bottom line",
        "Integrated coastal zone management",
        "Integrated coastal zone management",
        "Appropriate technology",
        "Airport",
        "Park",
        "Social economy",
        "Energy poverty",
        "Mine closure",
        "Forest management",
        "Forestry",
        "Fisheries management",
        "Garden city movement"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If we treat \"sustainability\" as the long-term objective and \"sustainable development\" as the suite of processes and pathways to reach that objective, how should this distinction shape the design of policy and governance?",
      "options": {
        "A": "It permits a single, fixed policy plan to be chosen early and executed without major revision, because the ultimate objective does not change.",
        "B": "It favors flexible, iterative policy design with monitoring and feedback loops, active stakeholder engagement, and adaptive instruments that respond to new knowledge, technologies, and social conditions.",
        "C": "It implies that immediate economic growth should be prioritized while current environmental limits can be ignored, since the sustainability goal is far in the future.",
        "D": "It requires defining development primarily by maximizing short-term efficiency of resource extraction to accelerate progress toward goals."
      },
      "correct_answer": "B",
      "simplification_notes": "Question was shortened and phrasing clarified for undergraduate readers; references to Brundtland and triple‑bottom‑line were condensed into the core distinction between goal (sustainability) and processes (sustainable development). Options were made concise but kept plausible distractors.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.4_vs_16",
    "pass_2_attempt": {
      "question": "The coastal developing state of Marima has an aquifer with natural recharge $R=100\\ \\text{Mm}^3/\\text{yr}$, while current extraction is $E=120\\ \\text{Mm}^3/\\text{yr}$; 30% of the population lives below the national poverty line. The government must adopt a policy package consistent with the Brundtland framing of sustainable development and with UNESCO's distinction that 'sustainability' is a long-term goal while 'sustainable development' comprises the processes to reach it. Which of the following policy packages best aligns with these principles (intergenerational equity and prioritising essential needs of the poor within planetary limits; balancing economy, environment and society; and treating sustainable development as iterative pathways toward the long-term goal)?",
      "options": {
        "A": "Implement a phased policy that (1) immediately guarantees basic water and food access for the poorest (rationing and subsidies to ensure essential needs), (2) sets a legally binding cap so net extraction does not exceed recharge within 10 years while permitting transitional use, (3) invests in water‑saving agricultural practices, decentralized renewables, education and social safety nets to diversify livelihoods, and (4) establishes participatory governance, measurable indicators and adaptive review cycles to iteratively adjust measures toward long‑term sustainability.",
        "B": "Prioritise rapid GDP growth by expanding export agriculture and industrial use of groundwater now, financed by foreign investment; promise future redistribution to the poor once growth raises national income, and rely on market forces to finance later environmental mitigation.",
        "C": "Immediately impose a strict extraction limit of $E\\leq 50\\ \\text{Mm}^3/\\text{yr}$ to protect the aquifer, with heavy penalties for violations, but do not create social support or transitional economic measures for affected communities; treat the limit as the sole policy goal.",
        "D": "Digitally optimise resource allocation by deploying smart meters, blockchain-based water trading and privatized water utilities to maximise allocative efficiency; rely on technological innovation and price signals to resolve distributional and ecological issues without explicit caps or guaranteed social protections."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete resource-management scenario with numeric recharge/extraction to force consideration of intergenerational equity, the triple bottom line, and the distinction between sustainability (goal) and sustainable development (processes). Options test trade-offs: inclusive integrated pathway (correct) versus growth-first, conservation-only, and techno-market approaches.",
      "concepts_tested": [
        "Intergenerational equity and prioritization of essential needs of the poor within planetary limits",
        "Balancing economy, environment, and society (triple bottom line)",
        "Distinction between sustainability as a long-term goal and sustainable development as the iterative processes/pathways to achieve it"
      ]
    },
    "pass_2_reason": "readability_too_high_22.3_vs_16"
  },
  {
    "original_question": {
      "question": "How does participatory democracy and collective action contribute to inclusive decision-making in community development, and why does this mechanism tend to improve both legitimacy and implementation of decisions?",
      "options": {
        "A": "It centralizes authority in a single expert to accelerate decisions, reducing the need for broad input.",
        "B": "It delays decisions to collect more data from external agencies, ensuring compliance with external standards.",
        "C": "It broadens the information base by including diverse stakeholders, creating negotiated decisions that communities are more likely to accept and implement.",
        "D": "It replaces community input with technical assessments to guarantee optimal outcomes without local opposition."
      },
      "correct_answer": "C",
      "source_article": "Community development",
      "x": 1.2571288347244263,
      "y": 0.9223065972328186,
      "concepts_tested": [
        "Concept 1: Empowerment as a mechanism for change (building skills, education, and social groups to enable individuals to influence their communities and institutions)",
        "Concept 2: Participatory democracy and collective action as core principles/mechanisms for inclusive decision-making in communities",
        "Concept 3: The relationship between grassroots action and larger social institutions (how community development engages with policy, organizations, and standards to effect systemic change)"
      ],
      "parent_concepts": [
        "Concept 3: The importance of local context and investment in education, physical and social infrastructure, and locally produced development strategies; why/how tailored, locally driven strategies improve rural development outcomes.",
        "Participatory, inside-out organization: citizens as active actors, decisions grounded in local conversations, broad leadership involvement, and local control over development processes.",
        "Relational capital and asset mapping as mechanism: importance of relationships, listening and asking for ideas, and tools like capacity/skill inventories to mobilize and coordinate community resources.",
        "Concept 1: Empowerment as an ongoing, community-centered process that increases access to and control over resources through mutual respect, critical reflection, caring, and group participation."
      ],
      "parent_articles": [
        "Rural development",
        "Asset-based community development",
        "Asset-based community development",
        "Empowerment"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do participatory democracy and collective action produce more inclusive decisions in community development, and why does this process tend to increase both the legitimacy of decisions and their likelihood of being implemented?",
      "options": {
        "A": "By concentrating decision authority in a single expert to accelerate choices, reducing the need for broad community input.",
        "B": "By delaying decisions to gather more data from external agencies, ensuring conformity with outside standards before acting.",
        "C": "By widening the information base through involvement of diverse local stakeholders, producing negotiated decisions that communities recognize as legitimate and are therefore more likely to carry out.",
        "D": "By replacing community input with technical assessments so expert solutions—assumed optimal—can be implemented without local engagement."
      },
      "correct_answer": "C",
      "simplification_notes": "Question reworded for clarity and concision; emphasized core ideas (participatory democracy, collective action, broader information base, negotiated decisions, legitimacy, implementation). Options kept plausible and aligned with the original concepts; correct answer unchanged.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.0_vs_16",
    "pass_2_attempt": {
      "question": "In the town of Riverford, a low-income riverside neighborhood suffers recurrent flooding, limited municipal services, and exclusion from local planning decisions. A group of residents proposes different strategies to improve resilience and influence municipal policy. Which strategy best exemplifies the principles of community development — using empowerment, participatory democracy/collective action, and productive engagement with larger social institutions to achieve systemic change?",
      "options": {
        "A": "Residents form neighborhood committees, run skills workshops on community mapping and budgeting, hold open deliberative planning forums where all households help set priorities, pilot small volunteer-led drainage projects, compile monitoring data, present evidence-based proposals to the municipal council, and partner with a local university and a national community development network to secure funding and align their plan with recognised practice standards.",
        "B": "A national NGO hires engineers to design and construct a high-capacity floodwall for the neighborhood, funded and managed entirely by the NGO; residents are informed after construction is complete and invited to a ribbon-cutting ceremony.",
        "C": "Individual residents send separate petitions to different municipal departments requesting infrastructure repairs and wait for departmental responses, without forming collective groups, training, or shared data to support their claims.",
        "D": "Residents organize repeated road blockades and media stunts to force immediate attention to flooding, rejecting any negotiations with municipal authorities or external institutions as co-optation, and demanding unilateral action from the city government."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a concrete town scenario requiring evaluation of actions against community development principles: empowerment (skills/workshops), participatory democracy (open forums, collective planning), and engagement with institutions (data-driven negotiation, partnerships, standards).",
      "concepts_tested": [
        "Empowerment through skills, education and social groups",
        "Participatory democracy and collective action for inclusive decision-making",
        "Relationship between grassroots action and larger social institutions/policy"
      ]
    },
    "pass_2_reason": "readability_too_high_20.3_vs_16"
  },
  {
    "original_question": {
      "question": "Which statement BEST explains how governance instruments (political, economic, military power, and diplomacy) interact to safeguard a state's security?",
      "options": {
        "A": "Military power alone is sufficient to deter threats, making other instruments unnecessary.",
        "B": "Diplomatic engagement, economic policy, and political legitimacy operate independently from military power, so there's no strategic interaction.",
        "C": "The instruments work together to shape incentives, reduce vulnerability, and address root causes; diplomacy aligns interests, economic policy builds resilience and interdependence, political legitimacy mobilizes support, and military power provides deterrence when necessary.",
        "D": "Security is primarily about offense and deterrence through force; governance tools mainly focus on internal administration."
      },
      "correct_answer": "C",
      "source_article": "National security",
      "x": 1.23271906375885,
      "y": 0.7966703176498413,
      "concepts_tested": [
        "Concept 1: Multidimensional nature of national security (military and non-military threats integrated into security policy)",
        "Concept 2: Use and interaction of governance instruments (political, economic, military power, diplomacy) to safeguard security",
        "Concept 3: Role of root causes and international/regional cooperation in security (reducing transnational causes like climate change, inequality, and proliferation)"
      ],
      "parent_concepts": [
        "Concept 1: Energy security is a function of resource availability and the unequal distribution of energy supplies, which creates national security vulnerabilities.",
        "Concept 1: Prevention and protection as core objectives of aviation security (why the aim is to prevent harm to aircraft, passengers, crew, and national security; how security serves these goals)",
        "Concept 2: The distinction and relationship between security intelligence (domestic threats) and foreign intelligence (information on foreign states) and how this separation shapes priorities and operations.",
        "Verification and obligation framework: background checks/vetting and legal obligations (Official Secrets Act) that bind cleared individuals and enforce compliance.",
        "Concept 2: Core mechanisms of CT (intelligence, surveillance, reconnaissance, and technology like facial recognition) and their relationship to effectiveness and civil liberties"
      ],
      "parent_articles": [
        "Energy security",
        "Airport security",
        "Intelligence agency",
        "Security clearance",
        "Counterterrorism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which statement BEST explains how political, economic, military, and diplomatic instruments interact to protect a state's national security?",
      "options": {
        "A": "Military power alone provides sufficient deterrence and defense, making diplomatic, economic, and political instruments unnecessary.",
        "B": "Diplomacy, economic policy, and political legitimacy operate largely independently of military power; there is no strategic interaction among these instruments.",
        "C": "The instruments are complementary: diplomacy aligns interests and reduces conflict, economic policy builds resilience and interdependence, political legitimacy mobilizes domestic support and reduces internal vulnerabilities, and military power deters or defeats direct threats when required.",
        "D": "National security is primarily about offensive capability and deterrence through force; governance tools mainly address internal administration and do not substantially shape external security."
      },
      "correct_answer": "C",
      "simplification_notes": "Condensed the original wording, clarified each instrument's role and interaction, kept the emphasis on military and non-military dimensions and on addressing root causes and cooperation.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.0_vs_16",
    "pass_2_attempt": {
      "question": "The nation of Norland faces a compound security crisis: periodic cross-border artillery strikes, frequent ransomware attacks against its electricity grid, a prolonged drought that has reduced crop yields and spurred internal migration, and rising youth unemployment. The Norland government must design a 5-year national security strategy that both mitigates immediate risks and reduces the structural drivers of insecurity. Which of the following policy packages best reflects a contemporary, multidimensional approach to national security that appropriately uses political, economic, military, and diplomatic instruments and recognises the importance of addressing root causes and regional cooperation?",
      "options": {
        "A": "Rapidly expand conventional ground forces and fortify borders with permanent barriers; allocate the cyber budget to offensive cyber operations targeting suspected external hackers; institute strict unilateral immigration controls to stop migrants; and prioritise defence procurement over social spending.",
        "B": "Maintain a credible, cost‑effective military deterrent for territorial defence; invest in cyber resilience of the electricity grid and incident response capabilities; launch an economic stimulus and job‑training programme in drought‑affected regions; finance water infrastructure and climate‑adaptation projects; and negotiate regional water‑sharing agreements and a multilateral resilience fund with neighbouring states.",
        "C": "Rely primarily on market mechanisms: privatise energy and water sectors to attract investment for infrastructure upgrades, cut corporate taxes to stimulate growth, reduce public sector employment programmes, and avoid new multilateral commitments so Norland can secure resources through bilateral commercial contracts.",
        "D": "Adopt an assertive preemption doctrine permitting cross‑border raids against hostile actors, expand internal surveillance powers and curtail civil liberties to prevent unrest, subcontract cyber defence entirely to foreign private firms, and suspend regional environmental negotiations to prioritise short‑term security actions."
      },
      "correct_answer": "B",
      "generation_notes": "Created a realistic multi‑risk scenario and offered four plausible strategic packages varying in emphasis on military, cyber, economic, environmental, and diplomatic instruments; correct option integrates multidimensional security, governance instruments, root‑cause mitigation, and regional cooperation.",
      "concepts_tested": [
        "Multidimensional nature of national security (military and non‑military threats)",
        "Use and interaction of governance instruments (political, economic, military, diplomacy)",
        "Addressing root causes and role of regional/international cooperation"
      ]
    },
    "pass_2_reason": "readability_too_high_22.6_vs_16"
  },
  {
    "original_question": {
      "question": "In a system with interdependent critical infrastructures, why can a disruption in natural gas distribution cascade into electricity production, transportation systems, and emergency services?",
      "options": {
        "A": "Gas and electricity systems operate independently; a gas disruption cannot affect power generation.",
        "B": "A significant portion of electricity is produced by gas-fired plants, so a gas disruption reduces electric generation, which then degrades computerized controls, communications, and the operation of transportation and emergency services.",
        "C": "Transportation and emergency services have complete redundant backups that ensure no cascading effects occur, regardless of gas supply.",
        "D": "Gas disruptions only affect heating and have no wider implications for other sectors."
      },
      "correct_answer": "B",
      "source_article": "U.S. critical infrastructure protection",
      "x": 1.3271887302398682,
      "y": 0.819746196269989,
      "concepts_tested": [
        "Interdependence and cascading effects: how a disruption in one infrastructure (e.g., gas distribution) propagates to power, transportation, and emergency services.",
        "Policy mechanism for CIP: identification, prioritization, and protection of critical infrastructure driven by directives (PDD-63, HSPD-7) and its rationale.",
        "Standardization for preparedness: use of standardized descriptions of critical infrastructure to facilitate monitoring, risk assessment, and protective measures."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In an interdependent critical infrastructure system, why can a disruption in natural gas distribution lead to cascading failures in electricity generation, computerized control and communications, transportation, and emergency services?",
      "options": {
        "A": "Because gas and electricity systems are independent, a gas supply disruption cannot affect power generation or other sectors.",
        "B": "Many electric generators are gas-fired, so loss of gas reduces electricity production; lower power availability then degrades computerized controls and communications, which impairs transportation systems and emergency services.",
        "C": "Transportation and emergency services have complete, fail-safe redundant backups that prevent any cascading effects from a gas supply disruption.",
        "D": "Natural gas disruptions only affect heating and have no significant downstream effects on other critical sectors."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording tightened to focus on interdependence and cascading effects; removed historical and policy context from stem while preserving the causal chain (gas → electricity → controls/communications → transport/emergency). Options rewritten to be concise and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_25.0_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized metropolitan region experiences a coordinated incident: malware compromises the SCADA controllers at a major natural gas compressor station that supplies a nearby combined-cycle power plant. The plant trips offline, causing rolling blackouts that disable railway signaling, degrade airport ground-communications, and interrupt hospital electronic health records. According to U.S. Critical Infrastructure Protection principles established by PDD-63, updated by HSPD-7, and operationalized through the NIPP model (sector lead agencies, Sector Coordinating Councils, and standardized sector plans), which of the following actions would best (a) ensure the compressor station was identified beforehand as a critical asset, (b) reduce the probability and impact of cascading failures across sectors, and (c) conform to the standardized, sector-based coordination mechanism envisioned by the directives?",
      "options": {
        "A": "Use a standardized sector criticality assessment (including interdependency matrices and a criticality index) coordinated by the designated lead agency and the Sector Coordinating Council to designate the compressor station as Tier 1; require remediation measures such as redundant feed paths and hardened SCADA segmentation; and run joint sector-wide exercises to validate mitigation and response plans.",
        "B": "Rely solely on the private utility owner’s internal security audits and incremental software patches for the SCADA system, reporting results voluntarily to DHS only after an incident occurs, while leaving interdependency analysis to each company.",
        "C": "Concentrate federal funding exclusively on hardening physical perimeter defenses (fencing, guards) at the compressor station, since physical attacks cause the most damage, and defer cyber protections and cross-sector exercises to later phases.",
        "D": "Eliminate public–private coordination by nationalizing regional energy assets under a single federal operator so the DoD can unilaterally identify and protect assets without sector councils or owner participation."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete multi-sector cascading-failure scenario and asked which policy-driven, standardized coordinated action (lead agency + SCC + interdependency analysis + remediation + exercises) best addresses identification, cascading risk reduction, and conformity with PDD-63/HSPD-7/NIPP.",
      "concepts_tested": [
        "Interdependence and cascading effects",
        "Policy mechanisms for CIP (PDD-63, HSPD-7, NIPP, sector coordination)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the Born–Oppenheimer approximation enable a meaningful factorization of the molecular wavefunction into an electronic part parameterized by fixed nuclear coordinates and a nuclear part, and how does this facilitate solving the Schrödinger equation for molecules?",
      "options": {
        "A": "Because electrons are fermions and nuclei are bosons; this separation emerges from symmetry and leads to exactly solvable equations for both subsystems.",
        "B": "Because nuclei are much heavier and move much more slowly than electrons, on the electronic timescale electrons respond to fixed nuclear positions; this yields an electronic Schrödinger equation at fixed nuclei, whose eigenvalues define a potential energy surface that governs nuclear motion.",
        "C": "Because the electronic wavefunction must be antisymmetric with respect to exchange, which decouples from nuclear motion; this ensures the electronic Hamiltonian commutes with nuclear coordinates operators.",
        "D": "Because the Born–Oppenheimer approximation is exact for all molecular systems, the total wavefunction is a simple product and no coupling remains."
      },
      "correct_answer": "B",
      "source_article": "Quantum chemistry",
      "x": 1.7933958768844604,
      "y": 1.083405613899231,
      "concepts_tested": [
        "Born–Oppenheimer approximation: why the electronic wave function can be parameterized by nuclear positions and how this separation simplifies solving the Schrödinger equation for molecules.",
        "Trade-offs among quantum chemistry methods: how semi-empirical methods, DFT, Hartree–Fock, QMC, and coupled-cluster approaches balance accuracy, cost, and applicability.",
        "Connection between electronic structure and observables: how quantum chemical calculations predict or interpret structures, spectra, and thermodynamic properties, linking theory to experimental data."
      ],
      "parent_concepts": [
        "Concept 1: Absorption of light leads to excited molecular states and subsequent photophysical or photochemical outcomes.",
        "Concept 1: Photoexcitation and excited-state pathways (S1, S0, S2, internal conversion, fluorescence, phosphorescence, intersystem crossing) and how energy states govern reaction outcomes."
      ],
      "parent_articles": [
        "Photobiology",
        "Photochemistry"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does the Born–Oppenheimer approximation allow the molecular wavefunction to be written approximately as a product, e.g. $\\Psi(\\mathbf{r},\\mathbf{R})\\approx\\psi_{\\mathrm{el}}(\\mathbf{r};\\mathbf{R})\\,\\chi(\\mathbf{R})$, and how does that make solving the molecular Schrödinger equation easier?",
      "options": {
        "A": "Because electrons are fermions and nuclei are bosons; symmetry differences let you separate the two subsystems and give exactly solvable equations for each.",
        "B": "Because nuclei are much heavier and therefore move much more slowly than electrons, so on the electronic timescale electrons see fixed nuclear positions; this permits solving an electronic Schrödinger equation at fixed nuclear coordinates whose eigenvalues define a potential energy surface that governs the slower nuclear motion.",
        "C": "Because the electronic wavefunction must be antisymmetric under electron exchange and this antisymmetry decouples electronic from nuclear motion; therefore the electronic Hamiltonian commutes with nuclear coordinate operators and can be solved independently.",
        "D": "Because the Born–Oppenheimer approximation is exact for all molecules, the total wavefunction factors as a simple product with no residual coupling between electrons and nuclei."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was made more concise and direct for undergraduates; an explicit factorization $\\Psi(\\mathbf{r},\\mathbf{R})\\approx\\psi_{\\mathrm{el}}(\\mathbf{r};\\mathbf{R})\\,\\chi(\\mathbf{R})$ was added; distractors were kept plausible but incorrect; core physical justification (mass/time-scale separation and resulting potential energy surface) was preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A researcher has three computational goals for different systems: (i) obtain the ground-state electronic energy and a reaction barrier accurate to about $1\\ \\text{kcal mol}^{-1}$ for a gas‑phase 5‑atom reaction; (ii) compute harmonic vibrational frequencies and an IR spectrum to help assign peaks for a 60‑atom organic molecule measured experimentally; (iii) estimate the probability of a nonadiabatic transition at an avoided crossing during a photochemical event. Which single choice below correctly pairs each task with the most appropriate computational strategy and correctly explains how the Born–Oppenheimer approximation and method trade‑offs justify those choices?",
      "options": {
        "A": "(i) Use a high‑level coupled‑cluster method such as CCSD(T) for the 5‑atom system because coupled‑cluster recovers dynamic correlation and is the ‘‘gold standard’’ often capable of sub‑kcal/mol barriers (though expensive, scaling roughly as $n^{7}$). (ii) Use Kohn–Sham DFT with a validated functional for the 60‑atom molecule because DFT typically scales about $n^{3}$ and gives reliable geometries and vibrational frequencies for large molecules at affordable cost. (iii) Treat the avoided crossing with an explicitly nonadiabatic approach (e.g., CASSCF or multireference dynamics or surface‑hopping including vibronic couplings) and/or use the Landau–Zener estimate because the Born–Oppenheimer approximation (electronic wavefunction parameterized by nuclear positions) breaks down near such couplings and single‑surface adiabatic dynamics is insufficient.",
        "B": "(i) Use Hartree–Fock for the 5‑atom reaction because it is mean‑field, inexpensive, and gives qualitatively correct barriers. (ii) Use a semi‑empirical method for the 60‑atom IR spectrum because parametrization ensures speed for large systems. (iii) Model the photochemical avoided crossing using pure molecular dynamics on a single Born–Oppenheimer surface because nonadiabatic effects are usually small and can be neglected.",
        "C": "(i) Use a semi‑empirical method fitted to hydrocarbons to get the $1\\ \\text{kcal mol}^{-1}$ barrier for the 5‑atom system because parametrized Hamiltonians are fast and accurate when parameters exist. (ii) Use quantum Monte Carlo (QMC) to compute IR frequencies for the 60‑atom molecule because QMC gives near‑exact energies and so will yield the most accurate vibrational spectrum. (iii) Use time‑independent single‑reference perturbation theory to estimate the crossing probability, since perturbation theory captures small nonadiabatic couplings.",
        "D": "(i) Use DFT for the 5‑atom high‑accuracy barrier because exchange–correlation functionals are systematic and always give chemical accuracy. (ii) Use Hartree–Fock for the 60‑atom IR spectrum because it provides the correct electronic structure without correlation. (iii) Rely on the Born–Oppenheimer approximation for the photochemical event and compute dynamics on one potential energy surface; nonadiabatic transitions are higher‑order effects and not relevant for estimating transition probabilities."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete multi‑task scenario comparing CCSD(T), DFT, semi‑empirical, HF, QMC, and nonadiabatic methods; tested BO validity near crossings and trade‑offs in scaling and accuracy (e.g., $n^{3}$ vs $n^{7}$) and connection of electronic structure to spectra and thermochemistry.",
      "concepts_tested": [
        "Born–Oppenheimer approximation and its breakdown in nonadiabatic regions",
        "Trade-offs among quantum chemistry methods (accuracy vs computational scaling)",
        "How electronic structure calculations predict observables: energies (thermochemistry) and vibrational spectra"
      ]
    },
    "pass_2_reason": "readability_too_high_26.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the practice of modeling and abstraction in mathematical biology help reveal the principles that govern the structure, development, and behavior of biological systems?",
      "options": {
        "A": "Abstraction isolates core components and interactions, revealing robust, invariant relationships that persist across different conditions or implementations.",
        "B": "Abstraction adds layers of detail that mimic every possible molecular process, ensuring the model captures all outcomes.",
        "C": "Abstraction eliminates the need for empirical data, allowing principles to be derived purely from theoretical reasoning.",
        "D": "Abstraction enforces linearity in dynamics, making problems easier to solve but always accurately reflecting real biology."
      },
      "correct_answer": "A",
      "source_article": "Mathematical and theoretical biology",
      "x": 1.7137258052825928,
      "y": 1.1157869100570679,
      "concepts_tested": [
        "Concept 1: Modeling and abstraction are used to uncover the principles governing the structure, development, and behavior of biological systems.",
        "Concept 2: Theoretical biology and mathematical biology overlap but emphasize different aspects (principles vs. tools), illustrating the relationship between theory and mathematics.",
        "Concept 3: Quantitative descriptions and models enable simulation and prediction of biological system behavior, linking abstraction to practical understanding."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does abstraction in mathematical biology help reveal the principles that govern the structure, development, and behavior of biological systems?",
      "options": {
        "A": "Abstraction isolates core components and interactions, revealing robust, invariant relationships that persist across different conditions or implementations.",
        "B": "Abstraction adds extensive mechanistic detail to model every molecular process, ensuring the model reproduces all possible biological outcomes.",
        "C": "Abstraction removes the need for empirical data, allowing governing principles to be derived solely by theoretical reasoning.",
        "D": "Abstraction enforces linear dynamics to simplify analysis, making problems easier to solve and therefore always accurately representing real biology."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording made more concise; kept original choices' intents but clarified language and removed redundant phrasing. Technical meaning and correct answer preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "A research team studies the irreversibility of eukaryotic cell‑cycle checkpoints in yeast. They construct a reduced network abstraction of cyclin–Cdk regulation, write a system of ordinary differential equations that include enzyme kinetics terms such as a Michaelis–Menten term $\\frac{V C}{K+C}$ and a Goldbeter–Koshland switch, perform bifurcation analysis to show a saddle‑node (or infinite‑period/Hopf) bifurcation at a critical cell mass, and then fit parameters to wild‑type data and simulate mutant perturbations (altered degradation rates) to predict phenotypes. Which of the following best explains how this project exemplifies the relationship between theoretical and mathematical biology and the role of quantitative abstraction?",
      "options": {
        "A": "This is primarily mathematical biology because it only applies mathematical tools (ODEs, bifurcation analysis) without addressing biological principles; the abstraction is a purely formal exercise and the simulations do not contribute to conceptual understanding.",
        "B": "This is a combined theoretical and mathematical biology project: theoretical biology is concerned with the underlying principle (bifurcation‑driven irreversibility) while mathematical biology provides the quantitative tools (ODEs, kinetics, parameter fitting and simulation) that allow abstraction to be tested and used to predict mutant phenotypes.",
        "C": "This falls outside theoretical or mathematical biology and is essentially experimental biology, because only direct laboratory experiments can establish irreversibility; models and simulations are merely illustrative and cannot generate reliable predictions about mutants.",
        "D": "This work is best classified as computational neuroscience since it uses dynamical systems and bifurcation theory; therefore its methods and conclusions are not relevant to mathematical or theoretical biology of the cell cycle."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete cell‑cycle modeling scenario referencing ODEs, Michaelis–Menten and Goldbeter–Koshland kinetics, bifurcation analysis and parameter fitting to test overlap of theoretical vs mathematical biology and the predictive role of quantitative models.",
      "concepts_tested": [
        "Role of abstraction and modeling in uncovering principles of biological systems",
        "Distinction and overlap between theoretical biology (principles) and mathematical biology (tools)",
        "Use of quantitative models to simulate and predict biological behavior"
      ]
    },
    "pass_2_reason": "readability_too_high_21.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the life sciences field act as an umbrella within the natural sciences, and how do its sub-disciplines illustrate the way biology organizes knowledge across levels and mechanisms?",
      "options": {
        "A": "Because living systems are governed by organizing principles that span chemistry, physics, and information processing, so biology provides an integrative framework that links organism-focused fields (zoology, botany) with mechanism-focused ones (genetics, biochemistry, cell biology) into a coherent whole.",
        "B": "Because physics explains all life directly, so the life sciences simply restate physical laws in biological terms without needing internal organization.",
        "C": "Because sub-disciplines within life sciences operate in complete isolation from one another, requiring the umbrella concept to keep them in a single category.",
        "D": "Because the natural sciences treat living and non-living matter identically, so biology has no unique organizing role."
      },
      "correct_answer": "A",
      "source_article": "List of life sciences",
      "x": 1.6935666799545288,
      "y": 1.032867670059204,
      "concepts_tested": [
        "Concept 1: The hierarchical relationship between life sciences and other natural sciences (biology as the overarching framework with sub-disciplines; distinction from physical science).",
        "Concept 2: The organization of life sciences by focus and scale (organism-specific branches vs aspects common to life, and micro-scale vs macro-scale fields).",
        "Concept 3: The connection between basic life-science discovery and real-world applications (impacts on health, agriculture, medicine, pharmaceuticals, and food science)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why are the life sciences described as an \"umbrella\" within the natural sciences, and how do their sub-disciplines demonstrate biology's organization of knowledge across scales (micro to macro) and mechanisms (structure, chemistry, information)?",
      "options": {
        "A": "Because living systems are governed by organizing principles that draw on chemistry, physics, and information processing, so biology provides an integrative framework linking organism-focused fields (e.g., zoology, botany) with mechanism-focused fields (e.g., genetics, biochemistry, cell biology) into a coherent whole.",
        "B": "Because physics alone explains life completely, so the life sciences merely restate physical laws in biological language and do not require an internal organizing framework.",
        "C": "Because sub-disciplines in the life sciences work largely independently from one another, the 'umbrella' is only a convenient taxonomic label rather than an integrative structure.",
        "D": "Because natural science treats living and non-living matter in the same way, biology does not have a unique organizing role and is therefore not an integrative umbrella."
      },
      "correct_answer": "A",
      "simplification_notes": "Condensed the original prompt into a single clear question; clarified 'organism-focused' vs 'mechanism-focused' examples; retained emphasis on cross-scale organization and links to chemistry/physics/information processing. Options rewritten to be concise and all plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.6_vs_16",
    "pass_2_attempt": {
      "question": "An interdisciplinary committee must design an introductory syllabus that reflects the conceptual structure of natural sciences and prepares students to move from basic discovery to application. Which of the following descriptions best matches (1) the hierarchical relationship between biology and other life sciences and its distinction from physical science, (2) the organization of life-science disciplines by organism-specific versus aspect-focused approaches and by biological scale (micro-scale versus macro-scale), and (3) the typical translational pathways from basic discovery to applied sectors such as health, agriculture, medicine, pharmaceuticals, and food science?",
      "options": {
        "A": "Natural science splits into physical sciences (non-living matter) and life sciences (study of life); biology is the overall natural science concerned with life and encompasses many subdisciplines (e.g., zoology, botany, genetics). Life-science fields are often organized by organism-specific study (zoology, botany) versus aspect-focused study that crosses taxa (anatomy, genetics), and by scale — micro-scale (molecular biology, biochemistry, microbiology) versus macro-scale (ecology, ethology, physiology). Basic discoveries in these fields commonly translate into applied domains such as health, agriculture, medicine, pharmaceuticals, and food science.",
        "B": "Life sciences are a sub-branch of the physical sciences and sit alongside biology as one among many subdisciplines; organism-specific fields (e.g., zoology) are treated as large-scale disciplines while molecular biology and biochemistry are generally considered large-scale as well; because of this separation, basic life-science discovery seldom informs sectors like agriculture or pharmaceuticals.",
        "C": "Biology is distinct from the life sciences (they are entirely separate categories); organism-specific disciplines (zoology, botany) should be categorized with macro-scale methods while ecology and ethology are micro-scale fields focused on cellular interactions; translational outcomes of basic life-science research are limited primarily to environmental management rather than health or food industries.",
        "D": "Natural science is divided by methodology rather than subject matter, so biology belongs within physical science; life-science subdisciplines are organized only by taxonomic groupings (e.g., plant vs animal) and not by shared aspects or scale, and thus basic laboratory discoveries rarely connect directly to applied areas like medicine or food production."
      },
      "correct_answer": "A",
      "generation_notes": "Created a realistic syllabus-design scenario requiring students to integrate the hierarchy of natural sciences (biology as overarching life science), classification of disciplines by organism-focus and scale (micro vs macro), and the link from basic discoveries to applied sectors; distractors contain common misclassifications.",
      "concepts_tested": [
        "Hierarchy of natural sciences and role of biology",
        "Organization of life-science disciplines by focus (organism-specific vs aspect-focused) and scale (micro vs macro)",
        "Translation of basic life-science discoveries into applied domains (health, agriculture, medicine, pharmaceuticals, food science)"
      ]
    },
    "pass_2_reason": "readability_too_high_27.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does viewing creativity as an iterative process—identifying problems, proposing solutions, testing hypotheses, and refining results—help explain how creative outputs become both novel and useful?",
      "options": {
        "A": "Because iteration ensures rapid convergence to a single pre-existing solution by preserving initial assumptions.",
        "B": "Because each cycle surfaces new constraints and gaps, guiding refinements that blend novel ideas with practical relevance.",
        "C": "Because repeating tests primarily adds random variation, guaranteeing originality regardless of usefulness.",
        "D": "Because this view eliminates the need for problem identification, allowing rapid, one-shot solutions."
      },
      "correct_answer": "B",
      "source_article": "Creativity",
      "x": 1.2792103290557861,
      "y": 0.9960055947303772,
      "concepts_tested": [
        "Concept 1: Creativity involves producing novel and useful products. This establishes a criterion for what counts as creative output and invites questions about how novelty and usefulness interact to constitute creativity.",
        "Concept 2: Creativity as a process with iterative problem identification and solution testing (as described in Torrance’s definition). This provides a mechanism to test how creative work unfolds over time and why each step matters.",
        "Concept 3: The relationship between creativity and originality (creativity can occur without being strictly original). This invites questions about how creative value can arise even when elements are not entirely novel."
      ],
      "parent_concepts": [
        "Concept 1",
        "Improvisation as a spontaneous, unscripted process that uses whatever can be found to produce new outcomes across domains.",
        "Improvisation as a problem-solving mechanism (stop-gap solutions and brainstorming) that fosters flexible thinking and idea generation.",
        "Cross-domain training and transfer of improvisational skills (how performing-arts improvisation techniques translate to other disciplines).",
        "Opportunity identification through resource recombination: identifying business opportunities by using existing or new resources in innovative ways to create value.",
        "Concept 1: Autonomy in algorithmic composition — when an algorithm can make creative choices during creation versus being used with human input or guidance.",
        "The idea that design ability is widespread and intrinsic to humans, framing design as a universal cognitive function that people engage in to alter situations.",
        "Concept 1",
        "Improvisation as extemporaneous creation guided by harmonic frameworks or chord progressions.",
        "Concept 1: Design thinking as an iterative, non-linear process with specific activities (context analysis, user testing, problem framing, ideation, prototyping, evaluation) that together shape problem solving.",
        "Concept 2: Mechanisms for triggering creativity and alignment (use of tools and broad participation across workers/users to achieve a common understanding and goals)",
        "Concept 1: Criteria for computational creativity (novelty, usefulness, rejection of prior ideas, persistence/motivation, and problem clarification) and how these criteria define “creative” outputs.",
        "Concept 2: Theoretical debates about machine creativity (e.g., Lovelace’s objection vs. counterarguments) and how definitions influence the assessment of computer-generated work."
      ],
      "parent_articles": [
        "Remix",
        "Improvisation",
        "Improvisation",
        "Improvisation",
        "Entrepreneurship",
        "Algorithmic composition",
        "Design",
        "Worldbuilding",
        "Musical improvisation",
        "Design thinking",
        "Innovation management",
        "Computational creativity",
        "Computational creativity"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does viewing creativity as an iterative cycle—identify problems, propose solutions, test hypotheses, and refine results—explain why creative outputs can be both novel and useful?",
      "options": {
        "A": "Because iteration forces rapid convergence on a single, pre-existing solution by preserving initial assumptions.",
        "B": "Because each cycle exposes new constraints and gaps, guiding refinements that integrate novel elements with practical relevance.",
        "C": "Because repeating tests mainly adds random variation, which guarantees originality regardless of usefulness.",
        "D": "Because this view removes the need to identify problems, enabling rapid one-shot solutions."
      },
      "correct_answer": "B",
      "simplification_notes": "Stem shortened and clarified into ‘iterative cycle’ phrasing; retained original sequence (identify→propose→test→refine). Options rewritten to be concise and plausible while preserving the original correct choice (B).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.2_vs_16",
    "pass_2_attempt": {
      "question": "Four project descriptions are given below. Using the criteria in the provided article (1) creativity requires producing products that are both novel and useful, (2) Torrance's process of creativity involves iterative problem sensitivity, hypothesis formation, testing and retesting, and (3) creativity can occur without strict originality of every element, which single project best exemplifies creativity as defined in the article?",
      "options": {
        "A": "A cognitive scientist writes a bold, previously unarticulated theoretical essay proposing a new model of mind. She publishes it without empirical work, arguing its elegance will inspire others.",
        "B": "A restaurant chef reproduces a century-old regional recipe exactly, plates it attractively, and markets it to tourists as an authentic experience.",
        "C": "An engineer adapts widely used motors, bearings and control modules into a new, low-cost mobility aid targeted to shorten commutes in narrow urban alleys. He began by noticing the community problem, sketched several conceptual solutions, built prototypes, ran iterative tests, modified the design after each trial, and finally released a working device that measurably reduced travel time.",
        "D": "A software developer reorders and documents an established open-source algorithm to make it easier to read; she runs basic unit tests to ensure it still produces identical outputs."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed four concrete scenarios contrasting novelty/usefulness, Torrance-style iterative process, and originality vs. recombination; selected the scenario that meets novel+useful, shows iterative hypothesis-testing, and uses recombined elements (not strictly wholly original).",
      "concepts_tested": [
        "Novelty and usefulness as joint criteria for creativity",
        "Torrance's iterative process of problem sensitivity, hypothesis testing, modification and communication",
        "Distinction between creativity and strict originality (creativity via recombination/improvement)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.5_vs_16"
  },
  {
    "original_question": {
      "question": "In a public safety system organized across national, regional, and local levels, with sub-sectors such as law enforcement, emergency services, and justice, why is formal coordination across levels and sectors essential for effective crisis response?",
      "options": {
        "A": "It enables a centralized, top-down command that dictates specific actions for every unit, ensuring uniform behavior regardless of local context.",
        "B": "It builds shared situational awareness and interoperable processes (common standards, joint protocols, mutual aid, and data sharing) that align objectives and enable rapid, efficient deployment of resources across levels and sub-sectors.",
        "C": "It ensures each level operates completely independently, which minimizes bureaucracy but creates risk during large-scale incidents.",
        "D": "It defers all decision-making to the private sector, reducing public sector constraints and accelerating responses through market competition."
      },
      "correct_answer": "B",
      "source_article": "Public security",
      "x": 1.2518806457519531,
      "y": 0.7722831964492798,
      "concepts_tested": [
        "Cross-sector collaboration and its link to political stability and economic prosperity",
        "Multi-level governance and the organized structure of public safety (national/regional/local, plus sub-sectors like law enforcement, emergency services, justice) and the coordination among them",
        "The evolving threat landscape and resource constraints (budgets, information systems) driving risk management and the role of information sharing"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a public safety system spanning national, regional, and local levels with sub-sectors such as law enforcement, emergency services, and justice, why is formal coordination across levels and sectors essential for effective crisis response?",
      "options": {
        "A": "It creates a centralized, top-down command that prescribes exact actions for every unit, producing uniform behavior regardless of local conditions.",
        "B": "It builds shared situational awareness and interoperable processes—common standards, joint protocols, mutual aid, and data sharing—that align objectives and allow rapid, efficient deployment of resources across levels and sub-sectors.",
        "C": "It guarantees each level operates entirely independently, reducing bureaucracy but increasing vulnerability during large-scale incidents.",
        "D": "It hands decision-making to the private sector, removing public-sector constraints and accelerating responses through market competition."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the stem; preserved the multi-level and multi-sector context; kept technical terms (situational awareness, interoperable processes) and the original rationale for coordination. Options were rephrased for concision but remain plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.3_vs_16",
    "pass_2_attempt": {
      "question": "Portville is a mid-sized coastal city hosting an upcoming international cultural festival. In the past year the city has experienced: (1) cross-border organized trafficking that exploits gaps between local and national border controls, (2) strain on emergency medical services during pandemic waves, and (3) credible threats of a mass-casualty attack during the festival. The city government faces chronically limited budgets and legacy information systems that impede situational awareness. Which of the following policy packages best addresses the need for cross-sector collaboration to sustain political stability and economic prosperity, multi-level governance coordination among national, regional, and local public safety actors, and improved information sharing under resource constraints?",
      "options": {
        "A": "A centralized national command that temporarily supersedes local authorities, deploying federal police and military to manage border control, festival security, and medical triage, financed by emergency national appropriations.",
        "B": "Establish a multi-agency fusion center that integrates national, regional, and local law enforcement, public health, EMS, and private-sector venue operators via formal MOUs; deploy a shared, low-cost interoperable data platform for real-time intelligence and resource-status reporting; and run joint exercises to standardize protocols.",
        "C": "Privatize festival security and emergency medical services to third-party firms contracted directly by organizers, while the city reallocates remaining funds to local police visibility patrols and public communications campaigns.",
        "D": "Implement strict border closures and long-term deployment of regional border patrols with separate information systems for each agency to preserve operational autonomy, and prioritize capital investment in a single large hospital expansion to absorb future medical surges."
      },
      "correct_answer": "B",
      "generation_notes": "Created a realistic urban scenario combining transnational organized crime, mass-event terrorism risk, and pandemic strain to test integrated concepts. Options contrast centralized control, multi-agency coordination with interoperable information sharing (correct), privatization, and siloed approaches.",
      "concepts_tested": [
        "Cross-sector collaboration between government and private actors and its link to political stability and economic prosperity",
        "Multi-level governance and coordination among national, regional, and local public safety organizations",
        "Evolving threat landscape, resource constraints, and the role of interoperable information sharing for risk management"
      ]
    },
    "pass_2_reason": "readability_too_high_20.7_vs_16"
  },
  {
    "original_question": {
      "question": "How does integrating multiple disciplines with quantitative methods enhance our understanding of environmental system behavior compared to a single-discipline perspective?",
      "options": {
        "A": "By enabling explicit coupling of physical, biological, and social processes, capturing cross-domain feedbacks, and using data to estimate parameters, it reveals emergent system behaviors that none of the single disciplines can predict alone.",
        "B": "By increasing the number of variables, which always improves predictive accuracy regardless of model structure.",
        "C": "By prioritizing qualitative narratives over quantitative data, ensuring policy relevance without numerical uncertainty.",
        "D": "By isolating environmental components into separate sectors so that simple cause-effect explanations become sufficient."
      },
      "correct_answer": "A",
      "source_article": "Environmental science",
      "x": 1.396980881690979,
      "y": 0.8786066770553589,
      "concepts_tested": [
        "Concept 1: Interdisciplinary, integrative, and quantitative analysis as the core approach to studying environmental systems.",
        "Concept 2: The relationships and distinctions between environmental science, ecology, environmental studies, and environmental engineering (scope, overlap, and how they inform each other).",
        "Concept 3: Historical drivers (policy, public awareness, and environmental incidents) as mechanisms that spur the development and direction of environmental science."
      ],
      "parent_concepts": [
        "Ecosystem services and biophysical feedbacks: ecosystems provide services (e.g., biomass production, climate regulation, water filtration) and include feedback mechanisms that moderate environmental processes.",
        "Concept 2: Site assessment and historical site use (Phase I ESA) determine the remediation plan, with attention to off-site contamination and nearby affected areas.",
        "Diverse forms of contaminants (chemical, physical, thermal) and their mechanisms of impacting water quality and aquatic life",
        "Concept 1: Water quality is defined and controlled by the intended use, with treatment and standards needed to ensure safety and suitability.",
        "Concept 1: Disturbances as drivers of ecosystem change and succession key to shifts in population sizes and species dominance over time.",
        "Concept 3: Environmental indicators and measurements (e.g., DO, COD, BOD, pH, nitrates, heavy metals, pesticides) as links between chemical processes and environmental health, reflecting underlying mechanisms.",
        "Concept 1: The cause-effect relationship between artificial light at night and ecological/health impacts, including how night-time contrast intensifies effects.",
        "Concept 3: Ecological and socio-economic consequences — how habitat destruction leads to biodiversity loss, soil erosion/desertification, local climate changes, and displacement of indigenous peoples.",
        "Concept 1: Human activity as a driver of environmental issues and pollution, leading to ecosystem disruption and climate-related impacts.",
        "Pollution and disturbance mechanisms: how emissions, noise, water pollution, and road dust near roads affect vegetation and animal health and behavior.",
        "Design-to-protect relationship: engineering design of water supply, wastewater treatment, and pollution control as a mechanism to prevent health hazards and improve environmental quality.",
        "Concept 2"
      ],
      "parent_articles": [
        "Ecology",
        "Environmental remediation",
        "Water pollution",
        "Water quality",
        "Disturbance (ecology)",
        "Environmental chemistry",
        "Light pollution",
        "Deforestation",
        "Environmental issues",
        "Road ecology",
        "Environmental engineering",
        "Water resources"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does combining multiple disciplines with quantitative methods improve our understanding and prediction of environmental system behavior compared with a single-discipline approach?",
      "options": {
        "A": "By explicitly coupling physical, biological, and social processes, capturing cross-domain feedbacks, and using data-driven parameter estimation, it reveals emergent system behaviors that single-discipline analyses typically miss.",
        "B": "By increasing the number of variables, which always improves predictive accuracy regardless of model structure.",
        "C": "By prioritizing qualitative narratives and stakeholder perspectives over quantitative data, making findings more policy-relevant without numerical uncertainty.",
        "D": "By separating environmental components into independent sectors so that simple cause–effect explanations are sufficient for prediction."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording condensed and clarified for undergraduates; retained core terms (coupling processes, feedbacks, quantitative parameter estimation, emergent behavior); options made concise and plausible while preserving original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.3_vs_16",
    "pass_2_attempt": {
      "question": "A regional planning authority commissions an Environmental Impact Assessment (EIA) for a proposed petrochemical plant beside an estuarine marsh that supports an endangered amphibian. The EIA must: (1) quantify multiphase fate and transport of a leaking volatile organic solvent in soil, groundwater, and the overlying air; (2) model population-level responses of the amphibian to contaminant exposure and habitat loss; (3) assess local stakeholders' perceptions and recommend policy instruments for mitigation; and (4) design a wastewater treatment and air emissions control system to meet regulatory standards. Which of the following best assigns these tasks to the appropriate disciplines and correctly explains the historical mechanism that most likely produced the legal requirement for the EIA?",
      "options": {
        "A": "Environmental chemists and hydrogeologists would perform the multiphase fate-and-transport modeling; ecologists would model population responses; environmental social scientists (environmental studies specialists) would assess stakeholder perceptions and policy instruments; and environmental engineers would design treatment and emissions controls. The legal requirement for the EIA most likely arose from a combination of high-profile environmental incidents and growing public pressure leading to legislation and agencies (e.g., Silent Spring, the 1969 Santa Barbara oil spill and Cuyahoga River fires, NEPA and the subsequent formation of regulatory bodies).",
        "B": "Ecologists would be primarily responsible for the fate-and-transport modeling and for designing the wastewater system because they study organism–environment interactions; environmental engineers would survey public perceptions and propose policy instruments; environmental science and ecology are functionally identical so any specialist can do all tasks. The EIA requirement is mainly the result of 21st-century computing advances enabling complex assessments.",
        "C": "Environmental engineers would do the multiphase contaminant transport modeling and also model amphibian population dynamics because engineering models are quantitative; environmental chemists would only provide laboratory analyses of solvent samples; sociologists would design the wastewater and emissions controls. The legal driver for the EIA is professional practice standards developed by engineering societies rather than public incidents or legislation.",
        "D": "Environmental social scientists would quantify the solvent transport using community-collected data; ecologists would handle stakeholder perceptions; environmental science is strictly the study of organisms so it would not contribute; the EIA obligation stems primarily from early taxonomic work (e.g., Linnaeus) and ancient legislation rather than modern environmental disasters or policy responses."
      },
      "correct_answer": "A",
      "generation_notes": "Created an applied EIA scenario requiring assignment of tasks to disciplines (chemistry/hydrogeology, ecology, social science, engineering) and linked the regulatory requirement to historical drivers (Silent Spring, 1969 incidents, NEPA/EPA). Distractors misassign roles or misattribute historical causes.",
      "concepts_tested": [
        "Interdisciplinary and quantitative approach to environmental systems",
        "Distinctions and overlaps among environmental science, ecology, environmental studies, and environmental engineering",
        "Historical drivers (public awareness, incidents, legislation) prompting environmental policy and EIA requirements"
      ]
    },
    "pass_2_reason": "readability_too_high_22.8_vs_16"
  },
  {
    "original_question": {
      "question": "How do constitutional constraints in liberal democracies contribute to legitimacy and rights protection?",
      "options": {
        "A": "They let the majority override minority rights whenever it is politically advantageous, speeding up policy.",
        "B": "They reduce accountability by removing public input from decisions.",
        "C": "They channel majority preferences through constitutional bounds and judicial review, which protects minority rights and creates stable, predictable rules, enhancing legitimacy.",
        "D": "They replace elections with technocratic rule to ensure consistent implementation."
      },
      "correct_answer": "C",
      "source_article": "Democracy",
      "x": 1.1574050188064575,
      "y": 0.8469097018241882,
      "concepts_tested": [
        "Direct democracy vs. representative democracy: how authority is exercised and decisions are made; implications for accountability.",
        "Liberal democracy and constitutional constraints: majority rule tempered by constitutions and courts to protect minority rights; why this matters for legitimacy and rights protection.",
        "Democracy and outcomes/legitimacy: relationships between democratic systems and health, education, and economic outcomes; mechanisms like rule of law and accountability that link governance to results."
      ],
      "parent_concepts": [
        "Concept 1: Regulation of electoral processes to preserve legitimacy and integrity of democracy (why regulation matters for fair elections)",
        "Concept 3: Electoral disputes and judicial oversight as mechanisms to remedy violations, increase public trust, and defend the electoral process (how courts and disputes support democratic outcomes)",
        "Concept 2: The relationship between electoral reforms and democratic quality/legitimacy (reforms can advance or backslide democracy; implications for stability and power transfers)",
        "Concept 3: The role of international standards and oversight in elections (how organizations like the UN and ISO influence safety, scrutiny, and legitimacy, and their limits)",
        "Concept 1: Public participation as a mechanism that grants rights and should influence decision-making, reflecting democratic governance and human-rights underpinnings.",
        "Concept 2: Public participation as a driver of governance legitimacy, trust, and social justice, addressing declines in public trust.",
        "Concept 1: Public space as a democratic space that enables political participation and vocalization of rights.",
        "How private fundraising mechanisms influence access to policymakers and potential policy outcomes (cause-and-effect relationship)",
        "Concept 1: The executive’s legitimacy and continuance depend on maintaining the confidence of a majority in the parliament (fusion of powers and accountability mechanism).",
        "Concept 1: The hybrid model of governance that combines direct citizen deliberation with representative decision-making.",
        "Concept 3: Relationship to democracy and social change - how advocacy groups contribute to or challenge democratic processes, their role in social movements, and the interaction with civil engagement and media.",
        "Concept 2: Relationship between party fragmentation, seat-votes proportionality, and barriers to entry, and how these shape governance and competition.",
        "Concept 3: The relationship and distinction between grassroots movements and participatory democracy within governance.",
        "Concept 3: Foundational principles such as transparency and aligning influence with those most affected by a decision",
        "Concept 2: Decentralization and civic engagement — decentralization has functional and civic value, increasing citizens’ participation in public affairs and providing a counterweight to centralized power.",
        "Concept 1: Mechanisms of direct democracy (referendums, citizen-initiated initiatives, recall, direct vs indirect initiatives) and how they translate public voting into policy or constitutional change.",
        "Concept 1: Institutional design influences voter turnout (e.g., ballot length, number of elections, multi-party systems) and explains cross-country differences.",
        "Concept 2: Turnout impacts democratic performance and long-term political outcomes (e.g., reduced regulatory capture, ability to implement reforms).",
        "Concept 2: The social contract and general will as mechanisms linking individual liberty to collective political authority.",
        "Concept 2: Mechanisms of inclusion/exclusion in suffrage (age, residency, citizenship status, felon disenfranchisement, guardianship, non-resident voting) and how these criteria affect political participation.",
        "Concept 3: Electoral reforms aim to improve fairness and maximize the meaningful use of votes in electing winners.",
        "The relationship between civil control, accountability, and democracy (rule of law, transparency, protection against abuse, and alignment with societal values).",
        "Concept 1: Parliamentary accountability as the mechanism by which the government remains in power (no-confidence → resignation or election).",
        "Concept 1: Reformist, gradualist, democratic approach to achieving social equality within capitalism.",
        "Concept 3: Jurisdictional and contextual variability (RONR vs. TSC, British vs. American usage) and how these differences shape what counts as a majority.",
        "Concept 1: Democratic organization of learning and governance that gives students an equal voice with teachers"
      ],
      "parent_articles": [
        "Election law",
        "Election law",
        "Electoral reform",
        "Electoral reform",
        "Public participation",
        "Public participation",
        "Public space",
        "Campaign finance",
        "Parliamentary system",
        "Participatory democracy",
        "Advocacy group",
        "Party system",
        "Grassroots",
        "Public participation (decision making)",
        "Subsidiarity",
        "Direct democracy",
        "Voter turnout",
        "Voter turnout",
        "Popular sovereignty",
        "Suffrage",
        "Voting",
        "Civil control of the military",
        "Responsible government",
        "Social democracy",
        "Majority",
        "Democratic education"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which statement best explains how constitutional constraints (for example, a constitution and judicial review) function in liberal democracies to support legitimacy and protect rights?",
      "options": {
        "A": "They permit majority coalitions to override minority protections whenever politically convenient, speeding policy implementation.",
        "B": "They diminish democratic accountability by removing public input from important decisions.",
        "C": "They limit majority power through constitutional rules and judicial review, protecting minority rights and creating stable, predictable rules that bolster legitimacy.",
        "D": "They replace electoral decision‑making with technocratic rule so policy is implemented consistently."
      },
      "correct_answer": "C",
      "simplification_notes": "Reworded the prompt to be concise and focused on the role of constitutions and judicial review; clarified each option to be plausible while preserving the original correct choice; removed extraneous historical detail.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.8_vs_16",
    "pass_2_attempt": {
      "question": "Consider two hypothetical states. State D employs a nationwide direct-democracy model: any law is enacted by a simple majority referendum (majority defined as $\\ge 50\\%$ of votes cast), referendums occur frequently, and there is no constitutional court to review laws or enshrine minority protections. State R is a representative liberal democracy: citizens elect legislators in competitive elections, a written constitution limits majority power, and an independent supreme court has judicial review. Empirically and theoretically—drawing on mechanisms discussed in the article (rule of law, protection of minority rights, incentives for long-term public goods, accountability)—which of the following conclusions is best supported about likely medium-to-long-run outcomes in these two states?",
      "options": {
        "A": "State D will systematically outperform State R in long-run health, education and economic indicators because direct voting aggregates citizens' information (per Condorcet-type logic) and direct responsiveness substitutes for institutions, so absence of courts accelerates effective policy.",
        "B": "Both states will exhibit similar medium-to-long-run outcomes because the mere presence of democratic participation suffices; the distinction between direct and representative mechanisms is secondary to whether elections or votes occur at all.",
        "C": "State R is more likely to secure sustained improvements in health, education and economic outcomes and to protect minority rights because constitutional constraints and an independent judiciary create rule-of-law incentives, limit majority tyranny, and provide stable property- and policy-rights that encourage public- and private investment.",
        "D": "State D will enjoy greater democratic legitimacy and better protection of minorities because laws passed by referendums express the direct will of the people, which normatively outweighs any institutional constraints and therefore produces more legitimate and protective outcomes."
      },
      "correct_answer": "C",
      "generation_notes": "Created a comparative scenario contrasting direct democracy without constitutional constraints and a representative liberal democracy with judicial review; options test mechanisms linking institutional design to policy outcomes, legitimacy, and minority protection.",
      "concepts_tested": [
        "Direct vs. representative democracy (decision-making and accountability)",
        "Liberal democracy and constitutional constraints (majority limitation, judicial review, minority rights)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does structuring urban planning as a sequence of research/analysis, public consultation, policy development, and implementation create a mechanism that links decisions to outcomes and allows adaptation to changing community needs?",
      "options": {
        "A": "It ensures all decisions are fully determined by researchers, making community input redundant.",
        "B": "It makes implementation unnecessary because policies are derived only from initial analysis.",
        "C": "It creates iterative feedback loops where each stage informs the next, so decisions reflect evidence and community values and implementation reveals outcomes for refinement.",
        "D": "It guarantees outcomes cannot be measured, so planners can avoid evaluating performance."
      },
      "correct_answer": "C",
      "source_article": "Urban planning",
      "x": 1.3686091899871826,
      "y": 0.8635537028312683,
      "concepts_tested": [
        "Concept 1: Public welfare as a core guiding principle in urban planning, including considerations of efficiency, sanitation, environmental protection, and sustainability.",
        "Concept 2: Planning processes as mechanisms linking decisions to outcomes, via research/analysis, public consultation, policy development, and implementation.",
        "Concept 3: Interdisciplinary and participatory nature of urban planning, integrating multiple fields and community engagement to shape livable, inclusive, and sustainable places."
      ],
      "parent_concepts": [
        "Concept 1: The collaborative, multi-stakeholder nature of transportation planning and how stakeholder input shapes policies, investments, and outcomes.",
        "Concept 2: The shift toward sustainability and integrated transport policies, linking planning decisions to environmental goals, congestion reduction, and urban design.",
        "Concept 3: Capacity and scale as design/economic factors. Some venues accommodate very large numbers of spectators, influencing design considerations and potential economic impact.",
        "Concept 3: The relationship between renewal practices (demolition, slum clearance, high-rise housing) and social outcomes (displacement, loss of historic fabric, alienation).",
        "Concept 3: Gentrification is a contested, multi-dimensional process involving perceived benefits (economic development, lower crime, value increases) and costs (demographic change, displacement) within urban politics and planning.",
        "Concept 1: Transport systems shape urban and regional development (cities and land use are influenced by the exchange and movement enabled by transport).",
        "Transit and climate/urban policy",
        "Public space as central: The design and management of public spaces (streets, plazas, parks) and how people use and experience them are core to urban design.",
        "Density, land-use mix, and walkability near transit drive higher transit ridership and lower private-car use.",
        "A defined walkable catchment (roughly 400–800 meters) around a central transit stop solves the last-mile problem and sets the effective scale of TOD.",
        "Distinguishing features (continuous transit use, pedestrian-friendly design, reduced parking) differentiate TOD from transit-proximate development and support sustainable urban growth.",
        "Concept 2: Protecting and designating specific land uses (flood plains, green belts, nuisance lands, transportation corridors) function as mechanisms to balance development with environmental and social objectives.",
        "Concept 3: Regulatory, financial, and governance barriers and incentives as key factors shaping the feasibility and outcomes of adaptive reuse (building codes, policies, incentives, information gaps).",
        "Concept 1: Directing growth to compact, walkable, mixed-use centers to avoid sprawl and reduce traffic congestion and environmental degradation.",
        "Concept 2: Long-range regional sustainability goals (transportation/housing choices, equity, preservation of resources, public health) as guiding principles for planning outcomes.",
        "Concept 3: Planning systems co-evolve with governance structures and vary across countries, expanding the focus from zoning/land use to managing the spatial relationships among activities (employment, housing, leisure) within an overall strategy.",
        "Suburbanization as a process driven by population and business relocation from urban cores to low-density peripheral areas, producing sprawl and land-use changes.",
        "Mechanisms shaping suburban growth, including postwar housing policy (GI Bill), discriminatory housing practices, and evolving transportation/infrastructure, which enable or constrain suburban expansion.",
        "Consequences and patterns resulting from suburbanization, such as the rise of commuter towns/minicities, shifts in economic activity, potential urban core decay, and environmental and social implications (e.g., segregation, work-home separation).",
        "Concept 1: The link between land-use patterns (low-density, single-use zoning) and transportation outcomes (car dependence, longer travel times, higher transport costs).",
        "Concept 2: The environmental and social externalities of sprawl (environmental degradation, loss of countryside, segregation, and impacts on urban vitality).",
        "Concept 1: Listing as a regulatory mechanism that restricts demolition, alteration, or extension and requires permission from planning authorities (with consultation of central agencies), including potential material-specific requirements.",
        "Concept 2: Design and infrastructure shape human movement and behavior (how buildings, streets, walkability, and transit influence movement patterns and safety)",
        "Concept 3: Multimodal integration and design options — grade separation accommodates multiple transport modes (roads, rail, canals, etc.) and can be implemented via bridges, tunnels, or combinations of both.",
        "Zoning regulations and their impact on what qualifies as commercial property and how it’s used",
        "End-to-end development process and sequencing",
        "Concept 2: The satellite-city network around a central city, connected by road and rail, acting as a “third magnet” to balance urban and rural benefits and mitigate social ills.",
        "Concept 1: Renewal as a mechanism for social reform through improved housing and urban design (linking housing quality to moral/economic uplift)",
        "Variations in metropolitan structure: single-centered vs. multi-centered metros and implications for regional planning and governance.",
        "Delimitation frameworks and policy implications: how MSAs, functional urban areas, and regiopolis concepts define and influence urban understanding and resource allocation.",
        "Transport as a system of infrastructure, vehicles, and operations, and the role of planning and governance in mobility and urban form.",
        "Concept 1: Contamination presence is central to brownfield status and redevelopment feasibility; definitions vary based on pollution.",
        "Concept 3: Policy and legal frameworks (e.g., definitional standards, grants, liability relief) influence the incentives, processes, and viability of brownfield redevelopment.",
        "Zoning as a regulatory mechanism that assigns land-use zones with rules to guide development and grant planning permission.",
        "Form-based zoning vs. use-based zoning and how each approach shapes building form, density, size, and urban form.",
        "Concept 1",
        "Concept 3",
        "Concept 1: Parks serve multiple, sometimes competing functions (human recreation vs. wildlife/natural habitat protection) and the design aims to balance these objectives.",
        "Concept 2: Airport-centered urban form — the aerotropolis consists of a multimodal airport city core plus outlying corridors and clusters that feed off the airport’s accessibility.",
        "Self-sufficiency and mixed land use: housing, industry, and agriculture arranged within a single garden city to capture the benefits of both urban and rural environments.",
        "Satellite-city network with greenbelts and integrated transport: multiple garden cities around a central city linked by road/rail, using a concentric/radial design to control growth and connect economies.",
        "Concept 2: Economic and urban-planning drivers of multipurpose stadiums (cost sharing, suburbanization, highway access, parking versus limited public transit) and their impact on adoption and decline."
      ],
      "parent_articles": [
        "Transportation planning",
        "Transportation planning",
        "Sports venue",
        "Urban renewal",
        "Gentrification",
        "Transport geography",
        "Public transport",
        "Urban design",
        "Transit-oriented development",
        "Transit-oriented development",
        "Transit-oriented development",
        "Regional planning",
        "Adaptive reuse",
        "Smart growth",
        "Smart growth",
        "Spatial planning",
        "Suburbanization",
        "Suburbanization",
        "Suburbanization",
        "Urban sprawl",
        "Urban sprawl",
        "Listed building",
        "Built environment",
        "Grade separation",
        "Commercial property",
        "Real estate development",
        "Garden city movement",
        "Urban renewal",
        "Metropolitan area",
        "Metropolitan area",
        "Transport",
        "Brownfield land",
        "Brownfield land",
        "Zoning",
        "Zoning",
        "Urban air mobility",
        "Urban air mobility",
        "Park",
        "Aerotropolis",
        "Garden city movement",
        "Garden city movement",
        "Multi-purpose stadium"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does organizing urban planning as the sequence research/analysis → public consultation → policy development → implementation create a mechanism that links decisions to outcomes and allows adaptation to changing community needs?",
      "options": {
        "A": "Because researchers fully determine policy decisions, making community input unnecessary.",
        "B": "Because policies derived from initial analysis eliminate the need for implementation or further adjustment.",
        "C": "Because it creates iterative feedback loops: each stage informs the next, so policies integrate evidence and community values, and implementation produces observable outcomes that guide refinement.",
        "D": "Because this structure prevents outcome measurement, allowing planners to avoid evaluating performance."
      },
      "correct_answer": "C",
      "simplification_notes": "Wording was condensed and clarified; the planning stages were written in sequence; emphasis added on the iterative feedback loop concept. Distractors made plausible but incorrect. No core content or correct answer changed.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.0_vs_16",
    "pass_2_attempt": {
      "question": "The coastal city of Marina Bay faces recurrent street flooding during storms (caused by combined sewer overflow), neighborhoods with poor access to transit and parks, rising heat-island effects, and unequal economic opportunities across districts. The mayor asks a newly formed planning team to propose an intervention that prioritizes public welfare (efficiency, sanitation, environmental protection, sustainability) and ensures that planning decisions lead to measurable, equitable outcomes. Which of the following proposals best exemplifies urban planning that (1) treats public welfare as the core objective, (2) explicitly links research/analysis, public consultation, policy development and implementation to outcomes, and (3) employs an interdisciplinary, participatory process to produce inclusive, sustainable improvements?",
      "options": {
        "A": "Commission engineers and private developers to build elevated mixed-use towers and widen arterial roads to increase vehicle throughput; complete designs in six months and fast-track permits, with compensation offered to displaced residents but no formal public workshops.",
        "B": "Undertake a GIS-based flood-risk and equity analysis, convene resident workshops and stakeholder advisory groups, pilot green infrastructure (bioswales, permeable pavements), upgrade sewer capacity in the most vulnerable blocks, revise zoning to support transit-oriented, mixed-income housing, and define monitoring indicators (flood incidents, transit access, park acreage, employment rates) tied to phased implementation.",
        "C": "Deregulate land-use restrictions across the floodplain to attract private investment, rely on market-driven redevelopment to provide amenities, and promise future mitigation if developers choose to invest in stormwater solutions.",
        "D": "Declare the historic core off-limits to new infrastructure; focus all resources on aesthetic preservation and heritage promotion while deferring sewer and transit upgrades to a later, unspecified ‘restoration’ phase without community engagement or measurable targets."
      },
      "correct_answer": "B",
      "generation_notes": "Created a realistic municipal scenario requiring application of public-welfare priorities, linking of analytic and participatory planning processes to outcomes, and interdisciplinary participation; options contrast top-down, market-only, preservation-only, and integrated participatory plans.",
      "concepts_tested": [
        "Public welfare as guiding principle (efficiency, sanitation, environmental protection, sustainability)",
        "Planning as process linking research/analysis, public consultation, policy development, and implementation with measurable outcomes",
        "Interdisciplinary and participatory approaches to produce livable, inclusive, sustainable urban places"
      ]
    },
    "pass_2_reason": "readability_too_high_24.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the idea that government authority is derived from and limited by a higher law function as a constraint on rulers, and through what mechanisms is that constraint typically realized in a constitutional system?",
      "options": {
        "A": "The higher law grants the government full discretion to determine the meaning of its powers, so constraint relies on political will to follow wishes.",
        "B": "The higher law is a mere historical artifact; accountability comes from elections alone, so constraint is extrinsic to the document.",
        "C": "The higher law provides a supreme rule that binds all governmental actors, and its constraints are realized through institutional checks and balances, independent courts, and established procedures that prevent arbitrary action.",
        "D": "The higher law allows leaders to suspend normal rules in emergencies, ensuring quick action even if that temporarily weakens constraints."
      },
      "correct_answer": "C",
      "source_article": "Constitutionalism",
      "x": 1.1732139587402344,
      "y": 0.8167017698287964,
      "concepts_tested": [
        "Concept 1: Government authority is derived from and limited by a higher law (limited government under a higher law).",
        "Concept 2: Institutionalized mechanisms of power control exist to protect citizens’ liberties, including minority rights (checks, balances, and rule-of-law features).",
        "Concept 3: The dual descriptive-prescriptive nature of constitutionalism and its historical development (describing historical struggles vs prescribing essential constitutional elements)."
      ],
      "parent_concepts": [
        "Concept 3: Relationship to broader systems (constitutionalism and Rechtsstaat) and the distinction between the rule of law as a political condition versus rule by man.",
        "Concept 2: Checks and balances as the mechanism and relational dynamic that constrain branches and coordinate inter-branch oversight.",
        "Concept 1: Judicial independence as a foundational principle tied to the rule of law and the separation of powers",
        "Concept 1: Power is constrained by a constitution or unwritten conventions, preventing the monarch from ruling autonomously.",
        "Concept 3: Checks and balances and emergency powers (how presidential actions require parliamentary countersignature or majorities, and what limits exist on executive power).",
        "Concept 2: Modes of embedding amendments (direct textual changes vs. codicils) and how each mode alters the constitutional frame.",
        "Concept 1: The constitution as a procedural framework that defines the principles, the process for making laws, and who has the authority to enact them.",
        "Concept 3: The constitution as a limiter of state power, enshrining rights and boundaries that rulers cannot cross.",
        "Concept 1: Judicial review as a mechanism of checks and balances that enables the judiciary to invalidate actions/laws incompatible with a higher authority (e.g., the constitution).",
        "Concept 3: Legal-philosophical distinction — the contrast between a Rechtsstaat (constitutional/legal state) and a Polizeistaat (police state), highlighting how rule of law can be undermined by police-dominated governance.",
        "Term limits as a mechanism to prevent executive power concentration and prevent “president for life” outcomes."
      ],
      "parent_articles": [
        "Rule of law",
        "Separation of powers",
        "Judicial independence",
        "Constitutional monarchy",
        "Politics of Greece",
        "Constitutional amendment",
        "Constitution",
        "Constitution",
        "Judicial review",
        "Police state",
        "Term limit"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the principle that government authority derives from and is limited by a higher law act as a constraint on rulers, and by what mechanisms is that constraint normally implemented in a constitutional system?",
      "options": {
        "A": "The higher law gives the government broad discretion to define its own powers, so any constraint depends chiefly on political leaders' willingness to comply.",
        "B": "The higher law is mainly a historical or symbolic document; real accountability comes only from regular elections, so constraints are external to the constitution itself.",
        "C": "The higher law functions as a supreme rule that binds all state actors, and constraints are implemented through institutional checks and balances, independent courts, and established legal procedures that prevent arbitrary action and protect rights.",
        "D": "The higher law permits leaders to suspend ordinary rules in emergencies, allowing rapid executive action even if this temporarily weakens constitutional limits."
      },
      "correct_answer": "C",
      "simplification_notes": "Question was shortened and clarified to undergraduate level; technical phrase 'limited by a body of fundamental law' reworded as 'limited by a higher law'. Options were made concise but kept plausible, preserving original distinctions between judicial/institutional constraint, electoral accountability, executive discretion, and emergency powers.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.0_vs_16",
    "pass_2_attempt": {
      "question": "Which of the following concrete country scenarios best exemplifies constitutionalism as described in the article — that is, (1) government authority derives from and is limited by a higher, fundamental law; (2) institutionalized mechanisms exist to control power and protect citizens' liberties (including minorities); and (3) the concept operates both descriptively (reflecting a historical struggle for constitutional recognition) and prescriptively (articulating what a constitution should be)?",
      "options": {
        "A": "Veridia enacted a written constitution after a decades-long reform movement. The constitution declares itself supreme law, creates an independent judiciary with the power of judicial review to strike down statutes, entrenches a bill of rights with explicit minority-language protections, and prescribes a high-threshold amendment procedure. Political actors regularly appeal to constitutional text in debates, and courts have invalidated laws that violated the charter.",
        "B": "Caldonia adopted a charter listing civil liberties, but the executive routinely issues emergency decrees that override those provisions. No impartial tribunal exists to enforce the charter; rights therefore exist largely as rhetoric while political elites govern by decree and justify actions as exigencies of statecraft.",
        "C": "Eldanor has an uncodified constitution based on long-standing parliamentary conventions and customs that historically limited the monarch. Those conventions generally restrain power and guide political behavior, but they are not judicially enforceable and minority protections depend on political goodwill rather than entrenched legal mechanisms.",
        "D": "Novara operates by direct popular lawmaking through frequent referenda; there is no entrenched higher law immune from majority revision. Minority protections are achieved by political coalitions and competitive elections, but any popular majority can repeal protections by simple plebiscite."
      },
      "correct_answer": "A",
      "generation_notes": "Created four country vignettes contrasting written supremacy and judicial review plus entrenched minority protections (A) with cases lacking legal enforcement (B), reliance on unenforceable conventions (C), and pure majoritarianism without higher law (D); option A synthesizes the three target concepts.",
      "concepts_tested": [
        "Limited government under a higher law (supremacy of constitution)",
        "Institutionalized mechanisms of power control (judicial review, bill of rights, minority protections)",
        "Descriptive vs. prescriptive constitutionalism (historical struggle and normative design)"
      ]
    },
    "pass_2_reason": "readability_too_high_36.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a foundationalist approach to justifying political knowledge claims tend to produce more universalizable conclusions than a particularist, bottom-up approach based on local judgments?",
      "options": {
        "A": "Because foundationalism starts from a small set of broad, cross-cultural principles (e.g., basic rights or human needs) that are intended to apply everywhere, whereas particularism builds legitimacy from context-specific judgments that vary across societies, making the resulting claims more local.",
        "B": "Because foundationalism is grounded in empirical surveys across cultures, while particularism relies on a priori reasoning from local myths.",
        "C": "Because foundationalism denies any universal principles and focuses on national traditions, while particularism derives truth from universal human nature.",
        "D": "Because foundationalism depends on majority opinion to justify claims, while particularism uses formal logical deduction from first principles."
      },
      "correct_answer": "A",
      "source_article": "Political philosophy",
      "x": 1.1673022508621216,
      "y": 0.9638171792030334,
      "concepts_tested": [
        "Foundationalist vs. particularist methods for justifying political knowledge claims",
        "Legitimacy of political institutions and normative evaluation of forms of government",
        "Universalism vs. cultural relativism in applying political principles across cultures"
      ],
      "parent_concepts": [
        "Concept 3: Relationship to broader systems (constitutionalism and Rechtsstaat) and the distinction between the rule of law as a political condition versus rule by man.",
        "Concept 3: The historical/evolutionary development of civil society (from Aristotle and Roman concepts to modern interpretations and dissident uses), shaping its current meaning and function.",
        "Concept 1: Separation of powers as a principle that differentiates state functions (legislative, executive, judicial) to maintain the integrity of each function and limit power concentration.",
        "Concept 2: Structural independence and checks-and-balances (trias politica) as the mechanism by which separation operates in practice.",
        "Concept 3: The tripartite design versus fusion/unified power and how the allocation of powers across branches shapes governance outcomes.",
        "Concept 3: Multidimensional theories of corruption (e.g., Machiavelli’s decline of virtue vs. corruption as deviant behavior) and why multiple frameworks are needed to understand, measure, and address corruption.",
        "Concept 3: Cultural and historical framing shaping how social justice emphasizes individual responsibility vs. access to power, and its expansion to diverse domains (gender, ethnicity, migrants, environment).",
        "Concept 1: The hybrid model of governance that combines direct citizen deliberation with representative decision-making.",
        "Citizenship as a legal status linking membership and allegiance to a state with associated rights and duties",
        "Historical evolution and cross-state variation in citizenship, including expansion of rights and discriminatory practices, and how these shape contemporary understandings of citizenship",
        "Global citizenship and universal community as a normative aim of cosmopolitanism",
        "Concept 3: The normative function of ideology (to defend individual liberty, property, free markets, and constitutional limits on state power), representing underlying principles guiding ideological systems.",
        "Concept 1: Statecraft as both art and science of conducting public affairs, and why its definition is contested.",
        "Concept 2: The social contract and general will as mechanisms linking individual liberty to collective political authority.",
        "Concept 3: The historical-relations aspect of republicanism (from Rome to Renaissance/early modern Europe to the American/French revolutions) and how these ideas influenced political transformation.",
        "Concept 3: The constitution as a limiter of state power, enshrining rights and boundaries that rulers cannot cross.",
        "Concept 3: Electoral reforms aim to improve fairness and maximize the meaningful use of votes in electing winners.",
        "Concept 1: Liberal socialism as a synthesis of liberal freedom with socialist emancipation, realized through a mixed economy that combines social ownership and private property to secure liberty.",
        "The balance between individual freedom and government intervention to achieve social justice (mixed economy/welfare state)",
        "Concept 1",
        "Concept 2",
        "Legitimacy as consent and belief enabling governance and influencing political stability"
      ],
      "parent_articles": [
        "Rule of law",
        "Civil society",
        "Separation of powers",
        "Separation of powers",
        "Separation of powers",
        "Political corruption",
        "Social justice",
        "Participatory democracy",
        "Citizenship",
        "Citizenship",
        "Cosmopolitanism",
        "Ideology",
        "Statecraft",
        "Popular sovereignty",
        "Republicanism",
        "Constitution",
        "Voting",
        "Liberal socialism",
        "Social liberalism",
        "Liberalism",
        "Liberalism",
        "Political legitimacy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do foundationalist methods in political philosophy tend to produce conclusions that can be applied across cultures more easily than particularist, bottom-up methods built from local judgments?",
      "options": {
        "A": "Because foundationalists start from a small set of broad, cross-cultural principles (e.g., basic rights or human needs) intended to hold universally, whereas particularists build legitimacy from context-specific judgments that differ between societies.",
        "B": "Because foundationalism is based on systematic empirical surveys comparing many cultures to extract common norms, while particularism relies on isolated local case studies.",
        "C": "Because foundationalism rejects cultural variation and enforces a single national tradition as universal, whereas particularism grounds claims in an assumed universal human nature.",
        "D": "Because foundationalism justifies political claims by appealing to widely accepted legal codes or majority practices across countries, whereas particularism depends on individual intuitions and ad hoc local customs."
      },
      "correct_answer": "A",
      "simplification_notes": "Clarified question wording; shortened sentences; defined foundationalism and particularism in plain academic terms; made distractors plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "The multiethnic state of Auroria adopts a new constitution that centralizes power in a theocratic government, curtails minority political rights, and defends these measures by appealing to a single ‘‘theory of human nature’’ that purportedly justifies strong, coercive authority as necessary for social order. Which methodological stance and cross-cultural claim would most plausibly lead a political philosopher to declare this constitution illegitimate on the grounds that it violates universally applicable standards of political legitimacy (such as political equality, consent, and basic liberties)?",
      "options": {
        "A": "A foundationalist + universalist stance — one that uses top-down principles (e.g., rights grounded in a theory of human nature) and holds that basic moral-political standards apply across cultures; it would denounce the constitution as illegitimate for infringing trans-cultural rights like equality and individual consent.",
        "B": "A particularist + cultural relativist stance — one that evaluates policies by aggregating local judgments and denies trans-cultural standards; it would likely withhold a universal condemnation and treat the constitution as legitimate if it coheres with Auroria’s prevailing local evaluations.",
        "C": "A foundationalist + cultural relativist stance — one that starts from general human-nature principles but insists those principles must be interpreted differently in each culture; it would probably accept the constitution if Aurorian tradition supplies a culturally specific reading that justifies centralization.",
        "D": "A particularist + universalist stance — one that builds normative claims from particular intuitions but nonetheless affirms some universal norms; it would accept the constitution as legitimate so long as a sufficient number of local case-by-case judgments endorse it, even if some abstract universal norms appear violated."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete multiethnic constitutional scenario; offered four plausible combinations of methodological (foundationalist/particularist) and cross-cultural (universalist/relativist) stances; correct answer identifies foundationalist universalism as most likely to condemn violations of trans‑cultural legitimacy standards.",
      "concepts_tested": [
        "foundationalism vs particularism in political methodology",
        "legitimacy and normative evaluation of political institutions",
        "universalism vs cultural relativism in applying political principles"
      ]
    },
    "pass_2_reason": "readability_too_high_26.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why is policy implementation considered the essential mechanism for translating political decisions into observable public programs and actions?",
      "options": {
        "A": "Because implementation converts political intent into actionable programs by allocating resources, designing procedures, and coordinating agencies, thereby turning decisions into observable outcomes.",
        "B": "Because policy decisions automatically produce programs without any administrative steps.",
        "C": "Because the formal law alone determines outcomes, making administration irrelevant to results.",
        "D": "Because public programs emerge spontaneously from budgets, without needing policy interpretation or management."
      },
      "correct_answer": "A",
      "source_article": "Public administration",
      "x": 1.2119431495666504,
      "y": 0.9343379139900208,
      "concepts_tested": [
        "Concept 1: Policy implementation as the mechanism that translates political decisions into observable public programs and actions.",
        "Concept 2: Management as the foundational principle for proper functioning of public organizations (e.g., bureaucratic organization enabling effective governance).",
        "Concept 3: Relationships within governance—how public administration interacts with policy processes, institutions, and broader society, and its positioning within political science."
      ],
      "parent_concepts": [
        "Policy mechanisms and actions designed to influence human behavior to protect the environment and human health",
        "Concept 3: Security institutions must adapt to changing threat landscapes and limited resources (budgets, information systems) to remain effective.",
        "Variation in scope and classification across systems: differences in how civil service is defined (e.g., central vs local, inclusion of QUANGOs) and how public servants are categorized in different countries.",
        "Policy design in response to objections and social change: How conscientious/political/ideological objections and gender inclusion/alternative service shape the structure and legitimacy of conscription (e.g., civil service options, noncombat roles, and later inclusion of women).",
        "Concept 3: Administrative-political power dynamic and reforms (the shift from political heads to administrative Officers and its impact on local governance)",
        "Concept 3: Multidimensional theories of corruption (e.g., Machiavelli’s decline of virtue vs. corruption as deviant behavior) and why multiple frameworks are needed to understand, measure, and address corruption.",
        "Concept 3: Implementation relies on specific policy instruments and evolving tools (e.g., RSA, Selective Finance for Investment, Cassa per il Mezzogiorno) illustrating how regional policy adapts to political contexts and EU frameworks.",
        "Concept 3: Weberian characteristics of bureaucracy (clear roles, hierarchical structure, merit-based advancement) contribute to efficiency and reduced friction through defined roles and multi-level decision processes.",
        "Concept 1: Public works as a multi-dimensional framework linking physical assets to economic, legal, environmental, and social objectives.",
        "Concept 1: The health policy process and governance across multiple levels, linking policy development to implementation and health outcomes, including scale-up.",
        "Concept 2: Operationalization of policy—the translation of national laws and policies into programs, services, and administrative norms.",
        "Concept 2: The five-component framework (clear policy framework, institutional development/legal framework, citizen participation/oversight, human resources/training, sustainability) as a conceptual model and how these components interrelate and overlap with other interventions.",
        "Concept 1: Hierarchical, multi-level structure of administrative divisions (first-level, second-level, etc.) and how these levels enable governance and policy decisions.",
        "Concept 1: Public inquiries function as accountability mechanisms through public hearings and evidence gathering, shaping transparency and government scrutiny.",
        "The planning cycle and cross-organizational coordination (risk identification/evaluation, training, testing, and joint plans across individuals, organizations, and levels of government)",
        "Concept 1: Locus shift of decision-making — decentralization moves authority from a central location/group to local units, enabling greater local control and citizen involvement.",
        "Concept 2: Mechanisms and institutional arrangements (private–public partnerships, mixed economy with state intervention, multi-level government delivery) that implement welfare programs.",
        "Stakeholder relationships and policy/compliance: how relationships with staff, donors, boards, and government policies influence risk management, human resources, and program development.",
        "Interdisciplinary policy analysis: the use of sociology, economics, political science, law, etc., to understand how education systems function and how policies might be changed.",
        "Concept 3: Roles of key institutions in policy execution (how the State Department, Department of Defense, and CIA implement policy in coordination with constitutional powers and legislative oversight).",
        "Concept 3: Value-for-money, accountability, and evaluation (how/why secrecy and mixed evidence influence assessments of PPP success and efficiency)",
        "Concept 2: Budgeting as a mechanism for policy implementation and accountability, including the roles of economists (information provision), accountants (accountability analysis), and managers (policy tool) in the budgeting process.",
        "Concept 3: The relationship between public and private budgeting, focusing on resource management, accountability, and the influence of political processes on budget outcomes.",
        "Regulatory/tendering framework as a control mechanism: Why public tenders, threshold rules, anti-fraud/corruption measures, and international agreements like the GPA are used to ensure fairness, transparency, and integrity in procurement.",
        "Concept 3: The normative debates surrounding affirmative action (benefits vs. risks, such as reverse discrimination and preparedness concerns) and how these debates shape policy design and implementation.",
        "Concept 2: The relationship between leadership, administration, and governance, including the notion that leadership is influenced by broader socio-political/economic models (e.g., neoliberal, business-derived framing).",
        "Concept 1: ICT-enabled transformation of public administration (how ICT changes organizational structure, processes, and value addition)",
        "Concept 2: Stakeholder interaction framework (relationships and interactions among G2G, G2C, G2E, G2B, C2G across governance levels)",
        "Concept 3: Design/participation principles for e-government tools (ideals such as progressive values, ubiquitous participation, geolocation, and public education) and their impact on governance outcomes",
        "Concept 1: The 1894 Local Government Act created elected parish councils to take over secular functions from the parish vestry, illustrating a legal mechanism that reorganized local governance.",
        "Concept 1: The Ombudsman as an independent investigative mechanism that resolves complaints through recommendations or mediation and can influence service quality and rights protection.",
        "Concept 2: How the scope and independence of an ombudsman's mandate (broad public-sector vs. targeted/private sectors; specialized ombudsmen) shape its ability to identify and address systemic issues.",
        "Concept 1: Collaborative governance as a multi-sector, relationship-based approach involving government, community, and private sectors to achieve outcomes greater than any single sector could achieve.",
        "Concept 1: Districts as independent local governmental units governed by a board of education under state law.",
        "Concept 1: Integrated policy framework",
        "Concept 1: Continuity of government as a governing principle—why societies establish procedures to keep essential operations running during catastrophic events.",
        "Concept 3: Institutional relationships in crisis governance—how succession, potential unity governments, and coordination among executive, legislature, and security bodies shape crisis response.",
        "Interdisciplinary framing as mechanism: using political science and organizational theory to explain how power, regulations, and resource allocation govern educational governance and organizational function.",
        "Universality and equal access as a guiding principle for public services",
        "Mixed provision and regulatory mechanisms (public, private with funding, or private with regulation)",
        "Public policy and regulation as a form of public service (linking policy goals to service delivery)",
        "Concept 3: Expansion of auditing across domains (the idea of the Audit Society and non-financial audit areas, illustrating auditing as a broader accountability mechanism).",
        "Concept 3: Empowerment and stakeholder participation as mechanisms driving service delivery reforms, leadership, and policy action across sectors.",
        "Concept 1: Standardized hierarchy and common terminology enable rapid, effective interagency coordination during incidents.",
        "Concept 2: Mechanisms and scope (how orders direct agencies, implement policy, and their binding nature on the executive branch)",
        "Concept 1",
        "Concept 3",
        "Concept 3: The impact of organizational fragmentation of European ANSPs on delays and costs, and how governance reforms (e.g., Single European Sky, Functional Airspace Blocks) aim to address these relationship-based inefficiencies.",
        "Concept 2: Administrative reform acts as a mechanism to adjust governance efficiency and structure (mergers, reviews, and reversals over time).",
        "The three-level governance structure (Kingdom, Counties, Municipalities) and the functional roles of counties (including their use as electoral constituencies)",
        "Concept 3: Integrated governance and the relationship between clinical governance and broader corporate governance, with scope limited to care delivery and patient outcomes."
      ],
      "parent_articles": [
        "Environmental policy",
        "Public security",
        "Civil service",
        "Conscription",
        "Local government in Pakistan",
        "Political corruption",
        "Regional policy",
        "Organizational structure",
        "Public works",
        "Health policy",
        "Health policy",
        "Capacity building",
        "Administrative division",
        "Public inquiry",
        "Emergency management",
        "Decentralization",
        "Welfare state",
        "Arts administration",
        "Education policy",
        "Foreign policy of the United States",
        "Public–private partnership",
        "Public budgeting",
        "Public budgeting",
        "Government procurement",
        "Affirmative action",
        "Educational leadership",
        "E-government",
        "E-government",
        "E-government",
        "Civil parish",
        "Ombudsman",
        "Ombudsman",
        "Collaborative governance",
        "School district",
        "Drug policy",
        "Continuity of government",
        "Continuity of government",
        "Politics in education",
        "Public service",
        "Public service",
        "Public service",
        "Audit",
        "Primary health care",
        "Incident Command System",
        "Executive order",
        "Local government in Nepal",
        "Local government in Nepal",
        "Air traffic management",
        "Administrative divisions of Norway",
        "Administrative divisions of Norway",
        "Clinical governance"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does policy implementation function as the mechanism that turns political decisions into actual public programs and observable actions?",
      "options": {
        "A": "Because implementation translates political intent into concrete programs by allocating resources, establishing procedures, and coordinating agencies and actors, thereby producing observable outcomes.",
        "B": "Because policy decisions automatically create programs and services without any administrative or managerial steps.",
        "C": "Because the formal law or statute alone deterministically produces outcomes, making administration irrelevant to results.",
        "D": "Because public programs arise spontaneously from budget figures, without the need for policy interpretation, procedural design, or management."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording condensed and clarified for undergraduate readers; retained key terms (implementation, resources, procedures, coordination). Distractors were rephrased to be plausible misconceptions.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A city council passes an \"Affordable Housing First\" ordinance requiring the construction of 500 affordable housing units over five years and the provision of tenant support services. Which of the following descriptions best illustrates how public administration translates this political decision into observable public programs while reflecting management as the foundational principle and the sector's relationships with institutions and society?",
      "options": {
        "A": "Senior public administrators draft amendments to the ordinance and lobby the council to change program targets before any executive action—thereby exercising administrative influence over policy outcomes.",
        "B": "The housing department posts the ordinance text online and issues a press release, but no budget is allocated, no staffing plan is developed, and no coordination with community organizations occurs—public visibility without operational follow-through.",
        "C": "A court reviews the ordinance for constitutionality and issues an interpretation that limits its scope; enforcement and program detail are left to independent community groups rather than to municipal agencies.",
        "D": "The municipal housing agency prepares an implementation plan that converts ordinance requirements into annual budgets, staffing and procurement actions, performance metrics, inter-agency coordination mechanisms, and formal partnerships with nonprofits; staff with relevant expertise administer programs, monitor outputs, and report outcomes to the council and public."
      },
      "correct_answer": "D",
      "generation_notes": "Constructed a municipal ordinance scenario requiring students to distinguish policy formulation, symbolic action, judicial review, and concrete administrative implementation that evidences management practices (budgeting, staffing, coordination, performance measurement) and governance linkages.",
      "concepts_tested": [
        "Policy implementation as translation of political decisions into programs",
        "Management (budgeting, staffing, coordination, expertise) as foundation for functioning public organizations",
        "Interactions between public administration, institutions, and broader society (inter-agency coordination and partnerships)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.3_vs_16"
  },
  {
    "original_question": {
      "question": "In comparative literature, why does integrating political theory and historical analysis with close reading of a text yield a deeper understanding than relying on literary analysis alone?",
      "options": {
        "A": "It anchors the text in its historical and political milieu, showing how linguistic choices and narrative strategies encode power relations, ideological struggles, and social change.",
        "B": "It treats the author's biography as the sole source of meaning, reducing the text to personal intent.",
        "C": "It shifts the focus away from the text's form and style, making interpretation subjective and less rigorous.",
        "D": "It confines interpretation to a single language and era, preventing cross-cultural insight."
      },
      "correct_answer": "A",
      "source_article": "Comparative literature",
      "x": 1.0650558471679688,
      "y": 1.04237699508667,
      "concepts_tested": [
        "Interdisciplinary, cross-domain analysis linking literature with history, politics, philosophy, art, and science",
        "Intercultural/transnational orientation across languages and cultures, including connections to world literature and the idea of understanding cultures from the inside",
        "Evolution from language-proficiency-centered practice to theory-driven approaches, including the incorporation of critical theory and broader methodological eclecticism"
      ],
      "parent_concepts": [
        "The dual-process definition of world literature: being read as literature and circulating beyond linguistic/cultural origin."
      ],
      "parent_articles": [
        "World literature"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In comparative literature, why does combining political theory and historical context with close textual reading give a deeper interpretation than using literary analysis alone?",
      "options": {
        "A": "Because it situates the text in its political and historical milieu, showing how linguistic choices and narrative strategies encode power relations, ideological conflicts, and social change.",
        "B": "Because it treats the author's biography as the sole source of meaning, reducing the work to the author's personal intentions.",
        "C": "Because it abandons attention to form and style, making interpretation purely subjective and less methodical.",
        "D": "Because it limits interpretation to a single language and historical period, blocking cross-cultural and transnational insights."
      },
      "correct_answer": "A",
      "simplification_notes": "Rewrote the question in clearer, more concise academic language; removed extended examples and historical background; kept the core idea that interdisciplinarity deepens interpretation. Options made uniformly plausible and clearer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.3_vs_16",
    "pass_2_attempt": {
      "question": "Which of the following research projects best exemplifies contemporary comparative literature as described in the article — namely an intercultural, transnational, and theory-driven field that privileges interdisciplinary analysis of literature in relation to history, politics, philosophy, art, and the sciences rather than exclusive reliance on multilingual philological proficiency?",
      "options": {
        "A": "A scholar fluent in German and French traces the diffusion of a specific motif between 18th-century German and French novels by painstaking archival work to establish direct lines of influence and textual borrowing.",
        "B": "A literary critic compares English-language novels from Canada and Australia to identify recurring archetypal representations of national character, arguing for universal human truths through close textual analysis.",
        "C": "A comparatist fluent in Spanish conducts a nation-based study comparing folklore motifs in peninsular Spanish and Latin American novels, emphasizing philological accuracy and nation-state literary traditions.",
        "D": "A researcher analyzes contemporary Nigerian novels published in English alongside Haitian Creole poetry (using reliable translations), applies postcolonial and migration theory, integrates visual art and oral-history archives, collaborates with historians and anthropologists, and focuses on transnational cultural circulation and lived experience rather than claiming fluency in every source language."
      },
      "correct_answer": "D",
      "generation_notes": "Presented four concrete research-project scenarios mapping to historical schools (French School, American School, traditional philological nation-based work) and to the contemporary interdisciplinary, transnational, theory-driven model; selected the scenario that combines cross-cultural scope, interdisciplinary methods, and theoretical emphasis as correct.",
      "concepts_tested": [
        "Interdisciplinary analysis linking literature with history, politics, philosophy, art, and social sciences",
        "Intercultural and transnational orientation across languages and cultures (world literature perspective)",
        "Shift from language-proficiency-centered practice to theory-driven, methodologically eclectic approaches"
      ]
    },
    "pass_2_reason": "readability_too_high_32.4_vs_16"
  },
  {
    "original_question": {
      "question": "Which statement best explains how self-directed, self-regulated practice enhances critical thinking and helps overcome egocentrism and sociocentrism?",
      "options": {
        "A": "It increases memory capacity so you can defend your beliefs with more facts.",
        "B": "It involves deliberate planning, monitoring, and adjustment of reasoning, which reveals biases and broadens exposure to alternative viewpoints.",
        "C": "It suppresses emotions to maintain a purely neutral stance.",
        "D": "It relies on authority and consensus to determine what counts as a sound judgment."
      },
      "correct_answer": "B",
      "source_article": "Critical thinking",
      "x": 1.2482056617736816,
      "y": 1.0477352142333984,
      "concepts_tested": [
        "Concept 1: Analyzing evidence and recognizing underlying assumptions is central to forming sound judgments.",
        "Concept 2: Critical thinking is trainable and relies on self-directed, self-regulated habits, requiring overcoming egocentrism and sociocentrism.",
        "Concept 3: Socratic questioning and the use of multiple perspectives are mechanisms to test beliefs, reveal irrational thinking, and connect reasoning to effective communication and problem solving."
      ],
      "parent_concepts": [
        "Concept 1: Critical analysis as a mechanism for interpreting media (identifying author/purpose/POV, examining construction techniques and genres, detecting propaganda and bias)",
        "Formal vs informal fallacies: An argument can be formally valid but still fallacious due to the content or reasoning used; the mechanism is the mismatch between form and content.",
        "Sources of fallacies (intentional and cognitive): Fallacies can arise from deliberate manipulation, cognitive biases, ignorance, or language limitations, highlighting causes and motives behind faulty reasoning.",
        "Evaluation of arguments and identification of weaknesses/fallacies (premises, logical strength, counterexamples, post hoc rationalizations)",
        "Suspension of belief pending sufficient evidence (not disbelief) and its role as a disciplined skeptical stance",
        "Concept 1: Red herring as a relevance-based distraction that diverts from the central issue (mechanism).",
        "Ethos (credibility) and Logos (reason) as core modes of persuasive communication",
        "Concept 1: STEM as an umbrella category built on a shared emphasis on critical thinking, problem-solving, and analytical skills across the disciplines.",
        "Concept 3: Relying on abstracts alone can be misleading or insufficient, making it important to consult the full report for accurate conclusions and citations.",
        "Concept 1: Validity vs. soundness — the idea that an argument is valid if the conclusion follows from the premises, and sound if it is valid and all premises are true."
      ],
      "parent_articles": [
        "Media literacy",
        "Fallacy",
        "Fallacy",
        "Argumentation theory",
        "Skepticism",
        "Red herring",
        "Persuasion",
        "Science, technology, engineering, and mathematics",
        "Abstract (summary)",
        "Deductive reasoning"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which statement best explains how self-directed, self-regulated practice improves critical thinking and helps overcome egocentrism and sociocentrism?",
      "options": {
        "A": "It increases factual memory so you can better defend your preexisting beliefs with more information.",
        "B": "It involves deliberate planning, monitoring, and adjustment of one's reasoning, which uncovers cognitive biases and broadens consideration of alternative perspectives.",
        "C": "It suppresses emotions so the thinker can maintain a completely neutral stance.",
        "D": "It relies on deferring to authority and group consensus to decide what counts as a sound judgment."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was tightened for clarity and concision; references to historical figures and detailed definitions were removed. The core idea—that self-regulation exposes biases and expands perspective—was preserved. All options remain plausible distractors.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.1_vs_16",
    "pass_2_attempt": {
      "question": "You are a public-health undergraduate evaluating the claim that the new herbal supplement 'Phytocure' cures chronic fatigue. Available materials: (1) a company-funded, non-randomized pilot study reporting large effects but lacking blinding; (2) dozens of online testimonials; (3) one large, preregistered randomized controlled trial (RCT) showing no effect; (4) a social-media thread where proponents accuse critics of being 'anti-natural'. Which course of action best exemplifies critical thinking as described in the article—i.e., analyzing evidence while recognizing underlying assumptions, exercising self-directed, self-regulated habits to overcome egocentrism/sociocentrism, and using Socratic questioning plus multiple perspectives to test beliefs and improve communication and problem solving?",
      "options": {
        "A": "Systematically identify assumptions in each source (e.g., causation vs correlation, funding bias, placebo, selection bias), interrogate the pilot study's methods using probing questions, weigh the preregistered RCT more heavily while seeking secondary analyses and independent replications, reflect on your own prior preference for 'natural' remedies and adjust confidence accordingly, and consult both clinicians and methodologists to synthesize recommendations for patients.",
        "B": "Favor the pilot study and testimonials because of their large reported effects and because many peers endorse Phytocure; collect similar testimonials from friends to bolster the case, then write a brief summary advocating use pending further positive reports.",
        "C": "Dismiss all pro-Phytocure evidence immediately because you believe supplements are generally ineffective; publish a short critique emphasizing ideological objections rather than examining study design or data.",
        "D": "Suspend judgment entirely and wait for future studies without scrutinizing current evidence, assumptions, or your own biases; when asked to advise patients, defer to the first authoritative source you encounter."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete public-health vignette requiring evaluation of diverse evidence, identification of assumptions, self-reflection on bias, and use of Socratic-style interrogation and consultation—mapping to the three target concepts.",
      "concepts_tested": [
        "Analyzing evidence and recognizing underlying assumptions",
        "Critical thinking as trainable self-directed, self-regulated habits overcoming egocentrism and sociocentrism",
        "Use of Socratic questioning and multiple perspectives to test beliefs and improve communication/problem solving"
      ]
    },
    "pass_2_reason": "readability_too_high_20.4_vs_16"
  },
  {
    "original_question": {
      "question": "To persuade a skeptical, evidence-driven audience about a technical claim, which combination of rhetorical appeals best explains how to align the audience's trust with the acceptability of the reasoning, and why does this combination work?",
      "options": {
        "A": "Ethos alone",
        "B": "Logos and Ethos",
        "C": "Logos and Pathos",
        "D": "Pathos alone"
      },
      "correct_answer": "B",
      "source_article": "Rhetoric",
      "x": -0.1044129729270935,
      "y": 0.4762251675128937,
      "concepts_tested": [
        "The triad of persuasive appeals: logos, pathos, ethos, and how each influences argument and audience response.",
        "The five canons of rhetoric: invention, arrangement, style, memory, delivery, and how they collectively structure a persuasive speech.",
        "The scope and relational role of rhetoric: its application across domains beyond politics and its historical evolution as a discipline (from ancient foundations to modern, cross-domain study)."
      ],
      "parent_concepts": [
        "Concept 1: Critical analysis as a mechanism for interpreting media (identifying author/purpose/POV, examining construction techniques and genres, detecting propaganda and bias)",
        "Concept 1: Visual elements (images, typography, color, layout) are deliberate tools that shape audience interpretation and persuasive effect.",
        "Concept 1: Functions of storytelling (entertainment, education, cultural preservation, moral instruction) and how these purposes shape storytelling forms.",
        "Concept 1: Red herring as a relevance-based distraction that diverts from the central issue (mechanism).",
        "Ethos (credibility) and Logos (reason) as core modes of persuasive communication",
        "Appeals to logic vs. emotion vs. habit (pathways through which attitudes/beliefs are influenced)",
        "Concept 2: How figurative devices (metaphor, simile, hyperbole, etc.) create resemblance, associations, or new imagery, thereby altering interpretation.",
        "Concept 3: The master of ceremonies plays a central role in guiding the flow, engaging the audience, and maintaining pace throughout the event.",
        "Campaign messaging design as a persuasive mechanism (why broad, repeatable talking points are used and how they influence voter support)",
        "The purpose of public speaking is determined by the speaker's intent, and the same intent can yield different speeches for different audiences (principle linking intent, content, and audience).",
        "A combined strategic approach using storytelling and informational content is employed to achieve educational or persuasive goals.",
        "Concept 2: Role of poetry as a political mobilizer — poetry can unify crowds, attract media attention, and serve as a vehicle for protest and political critique.",
        "Concept 3: Roles, audiences, and information flow across contexts (employment, case interviews, mock interviews) determine how information is produced, interpreted, and disseminated."
      ],
      "parent_articles": [
        "Media literacy",
        "Visual rhetoric",
        "Storytelling",
        "Red herring",
        "Persuasion",
        "Persuasion",
        "Literal and figurative language",
        "Awards ceremony",
        "Political campaign",
        "Public speaking",
        "Public speaking",
        "The arts and politics",
        "Interview"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "To persuade a skeptical, evidence-focused audience about a technical claim, which combination of Aristotle's persuasive appeals best aligns the audience's trust with the acceptability of your reasoning, and why?",
      "options": {
        "A": "Ethos alone — rely only on the speaker's credibility and reputation to secure agreement.",
        "B": "Logos and Ethos — present rigorous logical/evidentiary argument (logos) while demonstrating credibility, competence, and trustworthiness (ethos) so the audience both accepts the reasoning and trusts the presenter.",
        "C": "Logos and Pathos — combine logical evidence with emotional framing so the claim is convincing and emotionally engaging.",
        "D": "Pathos alone — rely solely on emotional appeal to move the audience despite limited technical evidence."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed wording, specified a \"skeptical, evidence-focused\" audience, retained the triad (ethos, logos, pathos) and added concise rationales in each option to keep all choices plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.5_vs_16",
    "pass_2_attempt": {
      "question": "Maria, a city-council candidate, prepares a 12-minute address to persuade the council to ban single-use plastics. In her speech she (a) opens with a vivid anecdote about a local fisher finding dead seabirds tangled in bags, (b) cites a peer-reviewed study showing a 40% decline in local fish stocks, (c) reminds listeners of her 20-year record as an environmental organizer, (d) structures the speech with an exordium, narration, confirmation, refutation, and peroration, (e) employs memorable metaphors and plain language, (f) rehearses the text until she can deliver it from memory, and (g) uses controlled gestures, pacing, and vocal variation in presentation. Which option correctly identifies (1) the Aristotelian appeals exemplified by (a), (b), and (c), (2) which of Cicero’s five canons correspond to (d), (e), (f), and (g), and (3) the most accurate claim about the scope and historical role of rhetoric?",
      "options": {
        "A": "(1) (a) pathos, (b) logos, (c) ethos; (2) (d) dispositio (arrangement), (e) elocutio (style), (f) memoria (memory), (g) pronuntiatio/actio (delivery); (3) Rhetoric originated as a civic art but now applies across domains (politics, science, art, media), having evolved from ancient civic practice to a broad interdisciplinary field.",
        "B": "(1) (a) ethos, (b) pathos, (c) logos; (2) (d) inventio (invention), (e) memoria (memory), (f) pronuntiatio (delivery), (g) elocutio (style); (3) Rhetoric is primarily a technique for electoral politics and retains little relevance outside political contexts.",
        "C": "(1) (a) logos, (b) ethos, (c) pathos; (2) (d) elocutio (style), (e) dispositio (arrangement), (f) inventio (invention), (g) memoria (memory); (3) Rhetoric has always been restricted to ceremonial and legal oratory and did not develop connections with scientific or artistic discourse.",
        "D": "(1) (a) pathos, (b) logos, (c) ethos; (2) (d) inventio (invention), (e) dispositio (arrangement), (f) pronuntiatio (delivery), (g) memoria (memory); (3) Modern rhetoric is merely ornamental style with no systematic canons and should not be applied to nonpolitical domains."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete civic-persuasion scenario mapping Aristotle's appeals (pathos/logos/ethos) to speech elements, matched Cicero’s five canons to structural and performative tasks, and included a scope claim reflecting rhetoric's historical civic origins and modern interdisciplinary expansion.",
      "concepts_tested": [
        "Aristotelian appeals (logos, pathos, ethos)",
        "Five canons of rhetoric (inventio, dispositio, elocutio, memoria, pronuntiatio)"
      ]
    },
    "pass_2_reason": "readability_too_high_23.2_vs_16"
  },
  {
    "original_question": {
      "question": "How does embedding CSR strategically, via brand alignment and stakeholder integration, mechanistically influence financial performance and employee outcomes?",
      "options": {
        "A": "It creates reputational capital and trust that reduce risk, attract customers and investors, and motivate employees, leading to improved financial performance and higher engagement.",
        "B": "It reallocates CSR spending into philanthropic grants that automatically boost quarterly profits regardless of core operations.",
        "C": "It imposes regulatory-like costs that dampen flexibility and harm both financial results and employee morale.",
        "D": "It places CSR into activism-focused initiatives that do not connect with market capabilities, leaving employee outcomes unchanged."
      },
      "correct_answer": "A",
      "source_article": "Corporate social responsibility",
      "x": 1.3326551914215088,
      "y": 0.9288647174835205,
      "concepts_tested": [
        "Strategic CSR and its impact on firm performance through brand alignment and stakeholder integration (how/why strategic CSR affects financial and employee outcomes)",
        "Creating Shared Value as an extension of CSR that aims to meet social obligations while achieving profit (how CSV differs from traditional CSR and why it can be mutually beneficial)",
        "Regulation, ESG reporting, and governance as mechanisms that drive CSR adoption and accountability (how reporting and regulatory incentives shape CSR practices)"
      ],
      "parent_concepts": [
        "Stakeholder identification vs. stakeholder salience (normative vs. descriptive): how managers determine who counts as a stakeholder and which stakeholders matter, influencing decisions.",
        "Concept 3: The evolution of marketing definitions toward emphasizing relationships and societal value, reflecting a shift from mere exchange to ongoing stakeholder engagement.",
        "Concept 3: Naming rights can be donated to outside organizations (CSR), with implications for reputation and stakeholder relationships.",
        "Concept 3: Social mission and reinvestment of profits into communities (including multi-stakeholder and platform cooperative models) as drivers of societal impact and sustainability.",
        "Concept 2: Reinvestment of profits into sustainable development and services to align economic activity with social objectives."
      ],
      "parent_articles": [
        "Stakeholder theory",
        "Marketing",
        "Naming rights",
        "Cooperative",
        "Social economy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does embedding CSR strategically—by aligning CSR with the firm's brand and integrating stakeholders—typically influence financial performance and employee outcomes, and by what mechanisms?",
      "options": {
        "A": "It builds reputational capital and stakeholder trust that lower risk, attract customers and investors, and raise employee motivation and retention, thereby improving financial results and engagement.",
        "B": "It simply shifts resources into philanthropic grants and donations that automatically increase quarterly profits independent of the firm's core operations.",
        "C": "It creates regulatory-like compliance costs and reduces managerial flexibility, which harms short‑term financial performance and depresses employee morale.",
        "D": "It focuses CSR on activism disconnected from market capabilities, yielding little effect on sales or employee outcomes."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording made more concise and direct for undergraduates; 'mechanistically' clarified to 'by what mechanisms'; examples removed but core idea preserved. Options rewritten to be clear and plausible alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.3_vs_16",
    "pass_2_attempt": {
      "question": "AquaFresh, a multinational personal-care firm, adopts a three-part initiative: (1) it integrates a long-term “Healthy Homes” program into its core product line—training local distributors, altering product design for low-income markets, and shaping advertising around community health; (2) it markets this program so that a portion of each sale funds local water sanitation microloans (company profits on the product remain positive); and (3) because its home jurisdiction now requires ESG disclosures, AquaFresh publishes audited, standardized ESG reports each year. Which of the following best explains the expected mechanisms and outcomes, consistent with strategic CSR, Creating Shared Value (CSV), and regulatory/ESG influences described in CSR literature?",
      "options": {
        "A": "Strategic CSR (the Healthy Homes integration) should improve both financial and employee outcomes by aligning the brand with stakeholder needs, differentiating products, and reducing reputational and regulatory risk; the water-microloan program exemplifies CSV because the social intervention is embedded in the profit-generating value chain so social benefits and profits co‑emerge; mandatory ESG reporting increases transparency and stakeholder pressure, improving accountability and making it easier for investors and consumers to compare performance (thus reinforcing CSR adoption).",
        "B": "Because strategic CSR diverts resources from core operations, the Healthy Homes program will primarily be a short-term PR boost with no lasting financial or workforce effects; the microloan activity is standard corporate philanthropy rather than CSV; and ESG reporting is largely symbolic—being voluntary it has negligible impact on firm behavior or investor decisions.",
        "C": "The Healthy Homes integration will almost certainly reduce profitability because CSR is a pure cost; CSV requires firms to accept lower margins permanently to achieve social goals; and ESG regulation functions mainly as a punitive instrument that discourages companies from adopting CSR for fear of legal sanctions rather than encouraging transparency or benchmarking.",
        "D": "Strategic CSR only matters when legally mandated, so AquaFresh’s voluntary Healthy Homes program will not affect brand or employees; the microloan-on-sales approach is an unrelated marketing tactic that undermines profit motives rather than creating shared value; and standardized ESG reports increase administrative costs but do not change stakeholder trust or investment outcomes."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic firm scenario to test mechanisms: strategic CSR (brand alignment, stakeholder integration) improves performance; CSV embeds social objectives into core profit-making activities; ESG/regulation drives transparency, accountability, and market incentives—distractors reflect common misunderstandings.",
      "concepts_tested": [
        "Strategic CSR: brand alignment and stakeholder integration effects on financial and employee outcomes",
        "Creating Shared Value (CSV) as embedding social goals into profit-generating business models",
        "Role of regulation and standardized ESG reporting in driving CSR adoption, transparency, and accountability"
      ]
    },
    "pass_2_reason": "readability_too_high_27.6_vs_16"
  },
  {
    "original_question": {
      "question": "How do governance, policy, and sustainability shape infrastructure outcomes, especially in the context of climate adaptation and sustainable development?",
      "options": {
        "A": "They primarily influence funding and regulatory compliance, but short-term incentives often dominate decisions, which can undermine long-term resilience.",
        "B": "They establish long-term planning horizons, set resilience standards, and create incentive structures that encourage adaptive, low-emission, and sustainable investments aligned with SDGs.",
        "C": "They ensure that all infrastructure is designed with uniform global specifications, ignoring local climate risks and community needs.",
        "D": "They are largely ceremonial and do not affect how projects are chosen, financed, or maintained."
      },
      "correct_answer": "B",
      "source_article": "Infrastructure",
      "x": 1.4789106845855713,
      "y": 0.9268661141395569,
      "concepts_tested": [
        "Concept 1: Infrastructure as interrelated systems that enable essential services for society (linking components to societal needs)",
        "Concept 2: Hard infrastructure (physical networks) vs. soft infrastructure (institutions, programs) and how they complement each other",
        "Concept 3: The role of governance, policy, and sustainability (including climate adaptation and SDGs) in shaping infrastructure outcomes and planning"
      ],
      "parent_concepts": [
        "Concept 2: Track infrastructure (two parallel steel rails) distributes weight and enhances capacity and safety, allowing heavier loads than road transport.",
        "Infrastructure and ecosystem enablers: how transportation, communications, and energy infrastructure enable industrial policy and firm competitiveness.",
        "Concept 3: Network connectivity and systemic integration; a dense, interconnected road network facilitates governance, communication, and commerce across the empire.",
        "Concept 1: Unified, all-freeway design with nationally standardized construction and signage as a core principle distinguishing the Interstate System from prior networks.",
        "Transport as a system of infrastructure, vehicles, and operations, and the role of planning and governance in mobility and urban form.",
        "Economic and environmental role of transport: enabling trade and growth while introducing pollution and land-use considerations, and the pursuit of sustainable transport options."
      ],
      "parent_articles": [
        "Rail transport",
        "Industrial policy",
        "Roman roads",
        "Interstate Highway System",
        "Transport",
        "Transport"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do governance, policy, and sustainability priorities shape infrastructure outcomes—including the planning, financing, and design of hard (physical) and soft (institutional) infrastructure—when addressing climate adaptation and the Sustainable Development Goals (SDGs)?",
      "options": {
        "A": "They mainly determine funding and regulatory compliance, but short‑term political and economic incentives often drive decisions that undermine long‑term resilience.",
        "B": "They establish long‑term planning horizons, set resilience and emissions standards, and create incentive structures that encourage adaptive, low‑carbon, and SDG‑aligned infrastructure investments.",
        "C": "They enforce uniform global technical specifications for all infrastructure, which can ignore local climate risks and community needs.",
        "D": "They are largely ceremonial and exert little real influence over which projects are chosen, how they are financed, or how they are maintained."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; explicitly referenced 'hard' and 'soft' infrastructure and SDGs; options rephrased for clarity while preserving the original meanings and plausibility.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.7_vs_16",
    "pass_2_attempt": {
      "question": "Harborville is a mid-sized coastal city with a 50‑year‑old combined stormwater–sewer network, several deteriorating bridges and roads, and increasing frequency of storm surges due to sea‑level rise. The municipal budget is constrained, institutional capacity is weak (outdated land‑use zoning, limited emergency response training), and the city leadership has committed to meeting Sustainable Development Goal 8 ('Industry, Innovation and Infrastructure') while promoting climate adaptation. Which integrated package of actions best reflects an infrastructure strategy that (1) treats infrastructure as interrelated systems delivering essential services, (2) balances hard infrastructure with soft infrastructure measures, and (3) embeds governance, policy and sustainability considerations in planning?",
      "options": {
        "A": "Prioritize rapid construction of large hard‑engineering defenses: enlarge the combined sewer capacity, build a seawall and raise major bridges and roads; fund these through municipal long‑term bonds. Delay institutional reforms and green interventions until revenues rise.",
        "B": "Focus on soft institutional reforms first: revise land‑use zoning, mandate stricter building codes, and invest in emergency training and public awareness campaigns; defer capital upgrades to future budgets to avoid borrowing.",
        "C": "Adopt a mixed approach: upgrade critical sewer sections and repair bridges (hard infrastructure), simultaneously implement green stormwater measures (bioretention, trees, permeable pavements), revise zoning and building codes, strengthen the public works maintenance unit and emergency services (soft infrastructure), and finance the program with a blend of phased municipal bonds, targeted user fees, and public–private partnerships, with explicit performance monitoring tied to climate‑resilience and SDG targets.",
        "D": "Privatize the stormwater and bridge assets to a single private utility under a long‑term concession to mobilize upfront capital; require the concessionaire to meet minimum service levels but leave zoning, emergency response and green infrastructure to separate municipal initiatives."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a concrete coastal city scenario requiring choices among engineering, institutional reform, financing, and sustainability. Options contrast single‑domain approaches with an integrated plan; correct answer combines hard and soft measures, governance reforms, sustainable/green practices, and blended financing aligned with SDG commitments.",
      "concepts_tested": [
        "Infrastructure as interrelated systems enabling essential services",
        "Distinction and complementarity of hard vs soft infrastructure",
        "Role of governance, policy, financing and sustainability (SDGs, climate adaptation) in infrastructure planning"
      ]
    },
    "pass_2_reason": "readability_too_high_23.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the separation between content production and reception, together with a one-to-many distribution model, enable mass media to reach audiences far removed in time and space, and what is the primary trade-off of this separation?",
      "options": {
        "A": "It ensures content is perfectly calibrated for each individual viewer with no interpretation challenges.",
        "B": "It enables content to be stored and broadcast to distant audiences asynchronously, but increases the risk that the original meaning is transformed by different interpretive contexts.",
        "C": "It guarantees that audience feedback is received instantly and used to tailor the message to each viewer.",
        "D": "It eliminates the need for any distribution infrastructure, allowing instantaneous global reach without delay."
      },
      "correct_answer": "B",
      "source_article": "Mass media",
      "x": 1.2315775156021118,
      "y": 1.005912184715271,
      "concepts_tested": [
        "Concept 1: One-to-many distribution model and commodification of symbolic content",
        "Concept 2: Separation between production and reception (and the reach across time/space)",
        "Concept 3: Ownership/conglomerate control and potential media capture shaping content and public agenda"
      ],
      "parent_concepts": [
        "Concept 1: Technology drives distribution and access to music (e.g., printing press enabling sheet music dissemination; gramophone/radio enabling broader listening).",
        "Concept 1: Distribution channels and scheduling",
        "Concept 2: Mechanisms for producing publicity (movement of information via media, the role of a publicist, and the use of publicity stunts to attract coverage).",
        "The influence of media and political messaging (advertising, rhetoric) on shaping public opinion",
        "Concept 3: Audience/media participation shaping social norms and serving as escapism (relationship between consumption, norms, and entertainment)",
        "Concept 2: Shift from traditional broadcast to on-demand streaming and cloud storage as a distribution model enabling viewer-controlled access to content.",
        "Concept 1: Media constructs reality by prioritizing certain issues and assigning salience, thereby shaping what the public perceives as important.",
        "Concept 2: Printing as a driver of mass communication that increases literacy, promotes vernacular languages, and reshapes social and political power structures.",
        "Concept 3: Industrial evolution of printing (from hand-operated to steam-powered rotary presses) as a shift enabling large-scale, industrialized distribution of texts.",
        "Concept 1: Investigative journalism is characterized by in-depth, long-term research aimed at uncovering hidden problems and holding power to account (watchdog/ accountability role).",
        "Concept 1: Sensational framing and visual emphasis as a mechanism to attract readers and increase sales (bold headlines, large illustrations, color, layout).",
        "The relationship between form and purpose (political/satirical use in news/politics vs. entertainment; how medium shapes content)",
        "Accessibility-driven mechanism: how the frequency and prominence of media coverage make certain issues more accessible in memory, increasing perceived importance.",
        "Concept 3: The impact of gatekeeping on public knowledge through selection and encoding, determining the content and nature of messages audiences receive.",
        "Concept 2: Narrative content and mass media (stories, radio, social media) function as mechanisms to shape perceptions and morale, including the use of disinformation/misinformation.",
        "Lead-ins, lead-outs, and hammocking as relational strategies to influence audience flow and promote programs (mechanisms that connect programming placement with audience behavior)",
        "The role of talent-show media exposure (spin-offs) as a mechanism that converts amateur performers into commercially successful artists (cause-effect relationship).",
        "Concept 1: Ordinary people can be the main creators and distributors of news, operating outside traditional journalism and driven by different objectives and legitimacy.",
        "Concept 3: The relationship and impact of citizen journalism within local communities and the public sphere, including distinctions from related forms (community journalism, civic journalism, collaborative journalism).",
        "Concept 1: Media events are planned, ceremonial, live-broadcast occasions designed to generate media publicity and public attention.",
        "Concept 2: The impact of technology and distribution on serial viability and popularity (how VCRs/DVRs and streaming ease following, versus earlier constraints that reduced prime-time serialization and syndication potential)."
      ],
      "parent_articles": [
        "Music technology",
        "Television show",
        "Publicity",
        "Public opinion",
        "Celebrity culture",
        "Television",
        "Agenda-setting theory",
        "Printing press",
        "Printing press",
        "Investigative journalism",
        "Yellow journalism",
        "Caricature",
        "Agenda-setting theory",
        "Gatekeeping (communication)",
        "Psychological warfare",
        "Broadcast programming",
        "Talent show",
        "Citizen journalism",
        "Citizen journalism",
        "Media event",
        "Serial (radio and television)"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the separation between content production and reception, together with a \"one-to-many\" distribution model, allow mass media to reach audiences far apart in time and space, and what is the main trade-off of that separation?",
      "options": {
        "A": "It guarantees content is perfectly customized for every individual viewer and removes interpretation problems.",
        "B": "It lets content be produced, stored and distributed to many distant audiences asynchronously, but it reduces immediate feedback and increases the chance that the original meaning will be transformed by different interpretive contexts.",
        "C": "It ensures audience feedback is received instantly so the message can be tailored in real time to each viewer.",
        "D": "It removes the need for any distribution infrastructure, enabling instantaneous global reach with no delay."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the question to emphasize asynchronous, one-to-many distribution and the trade-off (loss of immediate feedback and risk of reinterpretation); kept terminology like \"one-to-many\" and \"interpretive contexts\" for precision.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.1_vs_16",
    "pass_2_attempt": {
      "question": "Company X, a multinational conglomerate that owns a national newspaper, a television network and a global streaming service, commissions a six-part documentary about energy policy. Identical episodes are distributed simultaneously on prime-time TV, the conglomerate's news website, and its mobile app; episodes remain archived for on-demand viewing. Editorial policy downplays regulatory scrutiny of Company X's primary industry, and promotional inserts are sold to advertisers. Which interpretation best maps this scenario onto the mass-media concepts of one-to-many distribution, commodification of symbolic forms, separation of production and reception (including reach across time/space), and ownership-driven agenda-setting/media capture?",
      "options": {
        "A": "This scenario exemplifies mass media: the documentary is produced as a commodified symbolic product sold and promoted across multiple platforms (one-to-many distribution), the production is institutionally separated from geographically and temporally distant audiences (synchronous broadcast plus archived streaming increases reach across time/space), and concentrated ownership allows editorial framing that can set the public agenda and enable media capture.",
        "B": "This scenario primarily reflects interpersonal communication dynamics because the same documentary is available on multiple devices and viewers can comment in real time, indicating high interactivity and immediate reciprocal feedback between producer and small, segmented audiences.",
        "C": "The example shows that high production values and cross-platform availability mean the content is no longer a commodity; instead, control has shifted to decentralized user-generated networks, so ownership concentration is irrelevant to agenda-setting.",
        "D": "The documentary illustrates commodification and one-to-many distribution only; because streaming makes reception on-demand, production and reception are effectively integrated (no meaningful separation), so ownership cannot significantly influence framing or public agenda."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete conglomerate documentary scenario to test recognition of one-to-many distribution and commodification, the spatial/temporal separation of producers and audiences (broadcast + archived streaming), and the role of concentrated ownership in agenda-setting/media capture.",
      "concepts_tested": [
        "One-to-many distribution model and commodification of symbolic content",
        "Separation between production and reception and reach across time/space",
        "Ownership concentration and media capture/agenda-setting"
      ]
    },
    "pass_2_reason": "readability_too_high_21.3_vs_16"
  },
  {
    "original_question": {
      "question": "How does the distinction between descriptive and normative theories function as a framework for evaluating educational practice, and why is it necessary to use both?",
      "options": {
        "A": "Descriptive theories describe how education actually occurs in practice, while normative theories specify how education ought to occur based on values and aims; using both allows us to evaluate practice by pairing empirical description with value-based critique to decide what should change.",
        "B": "Descriptive theories prescribe what policies should be implemented; normative theories merely observe social power dynamics in schooling.",
        "C": "Descriptive and normative theories are identical; the distinction is unnecessary for evaluation.",
        "D": "Descriptive theories assess only content; normative theories assess only pedagogy."
      },
      "correct_answer": "A",
      "source_article": "Philosophy of education",
      "x": 1.156791090965271,
      "y": 1.027377963066101,
      "concepts_tested": [
        "Descriptive vs normative theories of education as a framework for evaluating educational practice",
        "Epistemic aims of education and the debate between transmitting true beliefs vs developing reasoning/critical-thinking abilities (and the role of indoctrination)",
        "Education, power, and equality: how curriculum content, pedagogy, and policy relate to social power, discrimination, and wealth distribution"
      ],
      "parent_concepts": [
        "Concept 1: Pedagogical approaches in music education (e.g., Dalcroze, Kodály, Orff, Suzuki, Gordon) shape how students develop musical skills, understanding, and audiation.",
        "Concept 3: Experiential education functions as a philosophy that informs multiple methodologies and shapes relationships to other theories and to experiential learning (a subfield), including aims such as developing knowledge, skills, values, and community contribution.",
        "Concept 1: Alignment principle — The entire educational system (theory, structure, instruction, and assessment) is organized to achieve predefined outcomes, with activities and assessments designed to help students reach those outcomes."
      ],
      "parent_articles": [
        "Music education",
        "Experiential education",
        "Outcome-based education"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the distinction between descriptive and normative theories provide a framework for evaluating educational practice, and why is it necessary to use both perspectives (for example, to address debates about knowledge transmission versus fostering critical thinking, concerns about indoctrination, and issues of power and equality)?",
      "options": {
        "A": "Descriptive theories characterize how education actually operates (empirical, value‑neutral accounts), while normative theories prescribe how education ought to be conducted based on ethical and epistemic aims; using both lets us pair empirical diagnosis with value‑based evaluation to identify and justify changes, including concerns about indoctrination, critical thinking, power, and equality.",
        "B": "Descriptive theories primarily prescribe what educational policies should be implemented, whereas normative theories merely record or interpret the social power dynamics present in schools without offering prescriptions.",
        "C": "Descriptive and normative theories are effectively the same; distinguishing them adds no methodological value when evaluating educational practice.",
        "D": "Descriptive theories evaluate only curricular content, and normative theories evaluate only pedagogical methods, so they remain separate and do not need to be combined."
      },
      "correct_answer": "A",
      "simplification_notes": "Rewrote the question in concise academic language, explicitly referenced epistemic aims, indoctrination, power, and equality; provided four plausible answer choices while preserving the original correct answer (A).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_26.7_vs_16",
    "pass_2_attempt": {
      "question": "A national government enacts a compulsory K–12 curriculum that requires students to accept a single official historical narrative, prohibits classroom critique of that narrative, and uses a new high‑stakes standardized test to sort students at age 14 into vocational or academic tracks. Which of the following sets of evaluations best matches how philosophers of education (drawing on the distinctions in the article) would analyze this policy?",
      "options": {
        "A": "Descriptive theories would neutrally characterize what the policy does (content mandated, methods, selection and sorting) without prescribing change; normative theories would judge whether the policy ought to promote autonomy, critical reasoning, or social ends and could condemn mandates that suppress questioning; the curriculum’s emphasis on forced acceptance over critical inquiry exemplifies privileging transmission of beliefs and risks indoctrination (beliefs instilled without evidential support or discouragement of questioning); compulsory schooling plus high‑stakes testing and early tracking instantiate state power and plausibly reproduce social inequalities (favoring wealthier groups and reinforcing class stratification).",
        "B": "Descriptive theories would argue the policy is illegitimate because it violates individual autonomy, while normative theories would merely describe the factual effects of the curriculum; the forced acceptance of a narrative cannot count as indoctrination if the narrative is true; standardized testing is a neutral tool that ensures equality by applying the same measures to all students regardless of background.",
        "C": "Descriptive accounts should prescribe replacing the mandated narrative with multiple competing narratives to promote equality; normative theories must remain value‑neutral and therefore cannot criticize the state’s exercise of compulsory schooling; indoctrination is equivalent to any form of moral education, so criticizing the curriculum as indoctrination is unjustified.",
        "D": "Descriptive theories would focus on whether the curriculum transmits true beliefs and therefore endorse it if the narrative is factually accurate; normative theories would prioritize social cohesion and therefore support compulsory acceptance of the national narrative; because standardized tests are objective, they cannot contribute to unequal outcomes or be seen as instruments of power."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete policy scenario and wrote four multi‑claim evaluative options; only option A correctly applies descriptive vs normative distinction, the epistemic transmission vs reasoning/indoctrination debate, and analyses of state power and inequality from the article.",
      "concepts_tested": [
        "descriptive vs normative theories of education",
        "epistemic aims of education versus indoctrination",
        "education as an instrument of power and its relation to equality and standardized testing"
      ]
    },
    "pass_2_reason": "readability_too_high_20.3_vs_16"
  },
  {
    "original_question": {
      "question": "How does diplomacy function as the mechanism by which a state's internal goals are translated into negotiated, externally binding agreements, and which feature of the negotiation process most robustly creates credible commitments that shape future behavior?",
      "options": {
        "A": "Through iterative bargaining that links concessions to verifiable reciprocal actions, thereby creating credible commitments that constrain future states’ choices.",
        "B": "By replacing domestic political goals with a universal enforcement framework that guarantees treaty compliance regardless of incentives.",
        "C": "By ensuring all private information is instantly disclosed, so outcomes are dictated solely by an objective, fact-based calculation.",
        "D": "By encouraging pursuit of short-term gains without regard to reputation or future negotiation leverage."
      },
      "correct_answer": "A",
      "source_article": "Diplomacy",
      "x": 0.6460745334625244,
      "y": 0.4913314878940582,
      "concepts_tested": [
        "Concept 1: Diplomacy as the mechanism translating state goals into negotiated agreements (how negotiations lead to treaties and influence events).",
        "Concept 2: Institutional framework and standardization of practice (Vienna Convention, accredited officials, diplomatic missions) enabling consistent diplomacy.",
        "Concept 3: Historical evolution and professionalization of diplomacy (from early modern origins to modern practice) shaping current methods and institutions."
      ],
      "parent_concepts": [
        "Concept 1: Public diplomacy aims to inform and influence foreign publics to build support for a state's strategic objectives (principle of purpose and effect).",
        "Concept 2: The relationship between cultural diplomacy and public diplomacy — culture supplies content for public diplomacy, while public diplomacy amplifies and legitimizes cultural messaging.",
        "Concept 1: Science diplomacy as a mechanism that uses cross-border scientific collaboration to advance diplomatic objectives and build international relationships.",
        "Concept 3: Limitations and critiques of science diplomacy (potential power asymmetries, misalignment with actual policies, and questions about effectiveness, especially in conflict contexts).",
        "Concept 3: The role of institutions and networks (e.g., United Religions Initiative, Parliament of the World's Religions, training centers) as mechanisms that enable and sustain interfaith dialogue.",
        "Concept 3: The theoretical framework of gunboat diplomacy as use or threat of limited naval force to gain advantage, not full-scale war.",
        "Concept 2: Evolution and standardization of diplomatic missions (why the embassy became the standard form after WWII and how that shifted the relevance of certain ranks like minister).",
        "Concept 3: Variants and cross-national practices in ranks (how roles like ambassador, papal nuncio, high commissioner, envoy, and chargé d’affaires reflect different legal/status contexts and historical ties).",
        "Economic diplomacy as statecraft: using economic tools (incentives, sanctions) to achieve foreign policy objectives.",
        "Roles and relationships in diplomatic hierarchy: the ambassador’s highest rank, the distinction from chargé d'affaires, and how embassies facilitate government-to-government relations.",
        "Concept 2: The mechanisms of peace processes as a mixture of politics, diplomacy, changing relationships, negotiation, mediation, and dialogue, occurring in both official and unofficial arenas."
      ],
      "parent_articles": [
        "Public diplomacy",
        "Cultural diplomacy",
        "Science diplomacy",
        "Science diplomacy",
        "Interfaith dialogue",
        "Gunboat diplomacy",
        "Diplomatic rank",
        "Diplomatic rank",
        "Economic diplomacy",
        "Ambassador",
        "Peace process"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does diplomacy convert a state's domestic objectives into externally binding agreements, and which feature of the negotiation process most effectively produces credible commitments that shape later state behavior?",
      "options": {
        "A": "By using iterative bargaining that links each concession to verifiable reciprocal actions, thereby producing credible commitments that constrain future choices.",
        "B": "By replacing domestic political objectives with a universal enforcement system that guarantees treaty compliance regardless of a state's underlying incentives.",
        "C": "By requiring instant disclosure of all private information so outcomes are determined solely by objective, factual calculations.",
        "D": "By encouraging states to chase short-term gains without concern for reputation or their leverage in future negotiations."
      },
      "correct_answer": "A",
      "simplification_notes": "Wording was tightened and made more direct for undergraduates; the question still asks how diplomacy turns internal goals into binding agreements and which negotiation feature creates credible commitments. Extraneous historical and institutional detail was removed but the core causal and mechanism-focused content was preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "The newly independent island state of Novara seeks a binding bilateral treaty giving its fishing fleet access to 1000 sq. km of the exclusive economic zone (EEZ) of its larger neighbor, Borealis, for a 10-year period. Novara's foreign ministry proposes three coordinated measures: (i) send an accredited ambassador and open a permanent embassy in Borealis; (ii) conduct formal treaty negotiations using trained diplomats and legal advisers from its foreign ministry; and (iii) rely on the 1961 Vienna Convention provisions (diplomatic immunity and the diplomatic pouch) to protect its personnel and communications. Considering the historical evolution and professionalization of diplomacy, which explanation best explains why this combination is the most likely to translate Novara's policy objective into a durable, enforceable international agreement?",
      "options": {
        "A": "Because permanent missions staffed by accredited ambassadors and professional foreign‑ministry negotiators create institutional continuity and legal standing for state-to-state talks; the Vienna Convention standardizes privileges (immunity, diplomatic pouch) so negotiators can operate securely; together these historically developed practices (professionalization from early modern permanent missions to 20th‑century codification) enable the negotiation, signature, ratification, and later monitoring or arbitration of a formal treaty.",
        "B": "Because public diplomacy (celebrity envoys, social‑media campaigns) combined with ad hoc offers of economic aid will produce popular pressure in Borealis to accept Novara’s request, rendering a formal embassy unnecessary; popular support alone produces binding state treaties without needing Vienna Convention protections or permanent missions.",
        "C": "Because deploying a visible naval task force and threatening limited force (a classic gunboat approach) will coerce Borealis into granting access quickly; historical practice shows coercive shows of force are the most reliable and enforceable method to obtain territorial concessions, obviating the need for accredited diplomats or legal frameworks.",
        "D": "Because hiring private commercial brokers and signing a series of merchant contracts with Borealis’ fishing companies will produce the same practical access as a state treaty; avoiding formal diplomatic channels and Vienna Convention constraints speeds outcomes and avoids the costs of permanent missions."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a concrete treaty negotiation scenario (EEZ access) to require reasoning about negotiation processes, institutional protections (Vienna Convention, embassies), and the historical professionalization of diplomacy; distractors present plausible but incorrect alternatives (public diplomacy, gunboat, private contracts).",
      "concepts_tested": [
        "Diplomacy as mechanism translating state goals into negotiated treaties",
        "Institutional framework and standardization (Vienna Convention, accredited officials, diplomatic missions)",
        "Historical evolution and professionalization of diplomacy (permanent missions, trained foreign ministries)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.0_vs_16"
  },
  {
    "original_question": {
      "question": "According to constructivist IR theory, why might states maintain a regional trade agreement even when immediate material benefits are unclear or uncertain?",
      "options": {
        "A": "Because shifts in relative power between states will make cooperation strategically advantageous in the long run.",
        "B": "Because shared identities, norms, and mutual expectations create a social context in which cooperation is valued and maintained.",
        "C": "Because formal institutions automatically enforce cooperation and punish breaches, regardless of actors' beliefs.",
        "D": "Because states seek to maximize absolute gains and will only cooperate if the payoff calculus is favorable."
      },
      "correct_answer": "B",
      "source_article": "International relations",
      "x": 1.1825013160705566,
      "y": 0.9147484302520752,
      "concepts_tested": [
        "Concept 1: Relationships and interactions among actors (states, IGOs, INGOs, MNCs) via mechanisms like war, diplomacy, trade, and foreign policy.",
        "Concept 2: Theoretical frameworks (realism, liberalism, constructivism) as lenses that explain or shape interpretations of international relations.",
        "Concept 3: Interdisciplinarity and institutional framing of IR (as a subdiscipline or broader multidisciplinary field) and how historical context (WWII, Cold War, globalization) shapes inquiry and theory."
      ],
      "parent_concepts": [
        "Concept 1: Public diplomacy aims to inform and influence foreign publics to build support for a state's strategic objectives (principle of purpose and effect).",
        "Concept 3: The evolution of the field to include non-state actors (media, multinational corporations, NGOs, religious organizations) and cross-sector relationships in a globalized information environment.",
        "The expansion and institutionalization of humanitarian governance over time (scope growth, creation of organizations like the International Red Cross)",
        "The relationships and tensions between humanitarianism and broader power structures (religious beliefs, imperialism/neo-colonialism, gender and class relations, and the role of humanitarian agencies)",
        "Concept 2: External actors shaping state-building in weaker or post-conflict states; how foreign intervention constructs or rebuilds institutions and the implications for legitimacy, governance, and outcomes.",
        "Climate change and other environmental shifts as drivers that alter security, strategy, and planning",
        "Concept 3: Cross-border and international dimensions (effects doctrine, extraterritorial jurisdiction, international agreements) and why jurisdiction and cooperation matter for maintaining competition globally.",
        "Concept 2: Evolution and standardization of diplomatic missions (why the embassy became the standard form after WWII and how that shifted the relevance of certain ranks like minister).",
        "Concept 3: Variants and cross-national practices in ranks (how roles like ambassador, papal nuncio, high commissioner, envoy, and chargé d’affaires reflect different legal/status contexts and historical ties).",
        "Concept 2: Grand strategy framework (primacy, deep engagement, liberal hegemony) and how it dictates the use of military power, alliances, and institutions to achieve goals.",
        "Concept 3: The role of international coordination (OCHA, IASC, UN agencies) in delivering aid and why coordinated responses are necessary for effectiveness.",
        "Concept 1: Sports as an instrument of international relations (how sport channels diplomacy and shapes foreign policy)",
        "Global governance and policy mechanisms: the roles of international organizations (WHO, UN), and policy frameworks (MDGs → SDGs) and cross-sectoral actions shaping implementation and ethics.",
        "Domestic-international policy linkage: globalization necessitating consideration of domestic decision-making within international economic relations.",
        "Multiactor ecosystem: interaction and coordination among state agencies, NGOs, and businesses in economic diplomacy.",
        "Concept 2: Mechanism by which sponsorship becomes military backing (funding, equipment, and sustained military activity shaping outcomes).",
        "Concept 3: Proxy wars as often involving civil wars (external involvement transforming internal conflicts and shaping their duration and nature).",
        "Concept 3: Interdependence of domestic and international authority (how EU/global dynamics shape domestic policy and vice versa)",
        "Concept 1: Human security reframes security as centered on individuals rather than states, altering the relationship between security policy and its referent.",
        "Roles and relationships in diplomatic hierarchy: the ambassador’s highest rank, the distinction from chargé d'affaires, and how embassies facilitate government-to-government relations.",
        "Concept 2: The mechanisms of peace processes as a mixture of politics, diplomacy, changing relationships, negotiation, mediation, and dialogue, occurring in both official and unofficial arenas.",
        "Concept 3: The role of international and regional institutions (e.g., United Nations, League of Nations, regional bodies) in enabling, legitimizing, and sustaining peace processes and in conflict prevention.",
        "Drivers of state compliance with IO decisions (rational incentives vs. normative socialization)",
        "Four-category framework of water politics (everyday management, national water policy, inter-state hydropolitics, global water politics)"
      ],
      "parent_articles": [
        "Public diplomacy",
        "Public diplomacy",
        "Humanitarianism",
        "Humanitarianism",
        "State-building",
        "Military geography",
        "Competition law",
        "Diplomatic rank",
        "Diplomatic rank",
        "Foreign policy of the United States",
        "Humanitarian aid",
        "Politics and sports",
        "Global health",
        "Economic diplomacy",
        "Economic diplomacy",
        "Proxy war",
        "Proxy war",
        "Multi-level governance",
        "Human security",
        "Ambassador",
        "Peace process",
        "Peace process",
        "International organization",
        "Water politics"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to constructivist theory in international relations, why might states continue participating in a regional trade agreement even when immediate material gains are unclear or uncertain?",
      "options": {
        "A": "Because shifts in relative power or strategic balances mean cooperation will become advantageous later, so states cooperate for long‑term strategic reasons.",
        "B": "Because shared identities, norms, and mutual expectations create a social context where cooperation is valued, legitimized, and thus maintained even without clear short‑term material benefits.",
        "C": "Because formal institutions automatically enforce rules and punish violators, producing compliance regardless of actors' beliefs or identities.",
        "D": "Because states are rational actors seeking to maximize material gains and will only cooperate if the expected payoff calculus is favorable."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording shortened and clarified the constructivist explanation; distractors kept as plausible alternatives representing realism (A), institutional enforcement (C), and rationalist/materialist logic (D).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.4_vs_16",
    "pass_2_attempt": {
      "question": "In 2028 Country A imposes broad economic sanctions on Country B after an IGO (the WTO) rules against B; a multinational corporation (MNC) relocates production from B to a third country; an INGO publishes repeated reports naming and shaming B for human-rights abuses; a non‑state hacker group launches disruptive cyber‑attacks on B's ports; and the UN issues a non‑binding statement condemning the attacks but takes no enforcement action. Which of the following best (a) characterizes how the interactions among these actors and mechanisms (war/force, diplomacy, trade, naming-and-shaming) are interpreted, (b) identifies how realism, liberalism, and constructivism would each explain salient aspects of the case, and (c) locates the appropriate disciplinary framing and historical developments that produced scholarship attentive to institutions and economic interdependence?",
      "options": {
        "A": "Interactions are multi-actor and multi-mechanism: states, IGOs, INGOs, MNCs and non‑state groups mutually shape outcomes through sanctions, trade shifts, diplomacy, cyber coercion and normative pressure. Realism explains the sanctions and cyber threats as states (and rivals) pursuing material power and security with unitary, rational calculations; liberalism explains WTO rulings, the MNC's supply‑chain decisions, and the UN/IGO role as institutionalized constraints and incentives produced by economic interdependence; constructivism explains the INGO's naming-and-shaming and the discursive construction of Country B's identity that alters state behavior. Methodologically, this problem fits a multidisciplinary IR approach (political science plus economics, law and history) and reflects scholarship shaped by the post‑World War II institutional turn and Cold War concerns, with late‑20th century globalization further refocusing theory on institutions and interdependence.",
        "B": "Interactions are primarily normative: INGOs and discourse drive outcomes, while material instruments like sanctions or cyber attacks are epiphenomenal. Realism therefore is of limited use because it underestimates NGOs; liberalism reduces everything to state bargaining within institutions and cannot explain MNC behavior; constructivism treats the WTO and UN as merely expressions of shared norms rather than having independent effects. IR should be studied only as a subdiscipline of political science because normative analysis is its central task, and the field's core ideas emerged exclusively with the founding of the first IR chair in 1919.",
        "C": "Interactions are reducible to economic class dynamics: the MNC and WTO act on behalf of capitalist interests to reshape Country B’s economy, while sanctions and cyber operations are tools of capitalist domination. Realism is irrelevant because it ignores class; liberalism is effectively the same as realism in treating institutions as tools of the strongest state; constructivism is subordinate to Marxist dependency logic. The appropriate framework is international political economy within sociology or economics, and the most important historical driver is early modern state formation (Peace of Westphalia), not twentieth‑century wars or globalization.",
        "D": "Interactions should be framed as an anarchical arena where force is primary: the cyber‑attacks and sanctions demonstrate that coercive power still dominates; IGOs, MNCs and INGOs are peripheral at best. Realism therefore fully explains the case and treats non‑state actors as instruments of state power; liberalism overstates institutional autonomy and constructivism wrongly elevates norms. IR is best kept inside political science departments as a state‑centric subdiscipline, and its principal theoretical developments trace to the writings of Thucydides and Machiavelli rather than twentieth‑century institutional responses to WWII and the Cold War."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a concrete 2028 scenario linking sanctions, WTO, MNC supply‑chain moves, INGO naming‑and‑shaming, cyber attacks and UN response; crafted four plausible multi-part answer choices mapping how realism/liberalism/constructivism interpret elements, plus statements about disciplinary framing and historical catalysts; correct option aligns with article's descriptions of theories, interdisciplinarity, and the post‑WWII/Cold War/globalization context.",
      "concepts_tested": [
        "Interactions among multiple international actors (states, IGOs, INGOs, MNCs) via war, diplomacy, trade, naming-and-shaming",
        "Theoretical lenses: realism, liberalism, constructivism and how each explains different elements of a case",
        "Interdisciplinarity/institutional framing of IR and the historical influence of WWII, the Cold War, and globalization on theory"
      ]
    },
    "pass_2_reason": "readability_too_high_31.9_vs_16"
  },
  {
    "original_question": {
      "question": "How does the interaction between the environment (beneficial vs hostile) and the referent's capabilities shape actual security outcomes?",
      "options": {
        "A": "Outcomes depend solely on the strongest capability available, independent of environment.",
        "B": "Outcomes depend solely on whether the environment is beneficial or hostile, regardless of capabilities.",
        "C": "Outcomes depend on the interaction: a beneficial environment lowers the required level of capability and risk, while a hostile environment raises risk and requires more robust and adaptable capabilities; the referent's ability to deploy and adjust those capabilities mediates security.",
        "D": "Outcomes are predetermined by fixed traits of the referent and do not change with environment or capabilities."
      },
      "correct_answer": "C",
      "source_article": "Security",
      "x": 1.39835786819458,
      "y": 0.9939420819282532,
      "concepts_tested": [
        "Concept 1: The security relationship (referent, environment, and capabilities) — security depends on whether the environment is beneficial/hostile and on the referent’s ability to respond; this captures cause-effect and system interplay.",
        "Concept 2: Capabilities as multi-layered mechanisms for security — coercive, protective, warning, diplomatic/social action, and policy tools work together to prevent insecurity, reflecting how different mechanisms address different risks.",
        "Concept 3: Security as both a state and a feeling — the distinction between perceived security and actual security and how perception can diverge from reality, influencing behavior and policy outcomes."
      ],
      "parent_concepts": [
        "Concept 1: Public security affects and is affected by economic prosperity, location attractiveness, and productivity.",
        "Concept 1: Human security reframes security as centered on individuals rather than states, altering the relationship between security policy and its referent."
      ],
      "parent_articles": [
        "Public security",
        "Human security"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do a security referent's capabilities and its environment (beneficial versus hostile) interact to determine actual security outcomes (as opposed to perceived security)?",
      "options": {
        "A": "Outcomes depend only on the single strongest capability the referent possesses, regardless of environmental conditions.",
        "B": "Outcomes depend only on whether the environment is beneficial or hostile; the referent's capabilities are irrelevant.",
        "C": "Outcomes depend on their interaction: a beneficial environment reduces required capability and risk, while a hostile environment increases risk and demands more robust and adaptable capabilities; the referent's ability to deploy and adjust those capabilities mediates actual security.",
        "D": "Outcomes are fixed by immutable traits of the referent and do not change with the environment or with the capabilities it can use."
      },
      "correct_answer": "C",
      "simplification_notes": "Question wording shortened and clarified (explicitly contrasts actual vs perceived security). Technical term 'referent' retained; options rephrased to be concise and plausible while preserving the original meanings.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.1_vs_16",
    "pass_2_attempt": {
      "question": "The coastal city of Port Aegis (a referent) faces three simultaneous pressures from its environment: accelerating sea-level rise that increases storm-surge probability, repeated cyber intrusions against the electrical grid, and widening economic inequality that fuels civil unrest. The municipal council must design a security strategy that improves actual resilience and aligns citizens' perceptions with reality (avoiding security theater). Which of the following mixes of capabilities best reflects an integrated security approach that (a) addresses the environment's hostility, (b) leverages the referent's capacity to respond, and (c) manages public perception responsibly?",
      "options": {
        "A": "Invest in a layered program: construct targeted coastal defenses and resilient critical infrastructure (protective systems); deploy grid segmentation, backups, and regular penetration testing (cyber protective and countermeasure measures); install real-time hazard monitoring and community alert systems (warning); expand social-safety nets, community dialogue forums, and equitable redevelopment policies (diplomatic/social and policy tools); maintain proportionate public-safety forces to deter violence (coercive capability); and communicate transparently about risks and limits of measures to avoid security theater.",
        "B": "Erect a large, highly visible sea wall and increase street-level policing to reassure residents; advertise the measures widely to restore public confidence. Delay costly cyber upgrades and social programs until after the wall is completed to conserve budget.",
        "C": "Prioritise cyber hardening of the grid and negotiate mutual cyber-defense pacts with neighboring cities (coercive/diplomatic cyber focus), while maintaining current flood defenses and social programs. Use occasional public demonstrations of cyber capability to reassure the populace.",
        "D": "Shift most resources into long-term economic restructuring and regional diplomatic agreements to address root causes of inequality and inter-city resource sharing (policy and diplomatic emphasis), temporarily reducing visible protective works and accepting increased reliance on voluntary evacuation plans."
      },
      "correct_answer": "A",
      "generation_notes": "Created a scenario with a referent (city) and hostile environment (sea-level rise, cyberattacks, inequality). Options contrast integrated multi-layered capability mixes vs. single-focus or perception-driven choices; correct answer emphasizes protective, warning, coercive, diplomatic/social, and policy tools plus transparent communication to align perception with reality.",
      "concepts_tested": [
        "security relationship: referent, environment, and capabilities",
        "multi-layered security capabilities (coercive, protective, warning, diplomatic/social, policy)",
        "distinction between perceived security and actual security (security theater and transparent communication)"
      ]
    },
    "pass_2_reason": "readability_too_high_23.3_vs_16"
  },
  {
    "original_question": {
      "question": "How do explicit career-management models (e.g., Blueprint model, Seven C's of Digital Career Literacy) enable effective career management in a dynamic labor market?",
      "options": {
        "A": "They prescribe a rigid step-by-step path that guarantees a stable, lifelong occupation.",
        "B": "They provide a structured, iterative framework that supports ongoing reflection, labor-market scanning, education decisions, and timely career adjustments, thus enabling intentional adaptation to change.",
        "C": "They replace personal agency with algorithmic forecasts that decide openings and career moves for you.",
        "D": "They encourage pursuing only a single, well-defined career track to minimize risk."
      },
      "correct_answer": "B",
      "source_article": "Career",
      "x": 1.312269926071167,
      "y": 1.006327509880066,
      "concepts_tested": [
        "Concept 1: A career is a life-span pattern that integrates work-related and other life experiences into a unique trajectory.",
        "Concept 2: Career management is an active, purposeful process (reflection, labor-market research, education decisions, finding openings, making changes) and can be guided by explicit models (e.g., Blueprint model, Seven C's of Digital Career Literacy).",
        "Concept 3: Societal and economic changes have redefined careers (from a single path to designable, multiple or hyphenated careers; rise of career counselors/advisors) due to broader education and occupational diversification."
      ],
      "parent_concepts": [
        "Concept 2: Different career trajectory models (steady-state, linear, transitory/spiral) and what they imply about progression, responsibilities, and time horizons."
      ],
      "parent_articles": [
        "Career development"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do explicit career-management models (for example, the Blueprint model or the Seven C's of Digital Career Literacy) help an individual manage a career in a rapidly changing labour market?",
      "options": {
        "A": "They prescribe a fixed, step-by-step route that guarantees a single stable, lifelong occupation.",
        "B": "They offer a structured, iterative framework that promotes ongoing reflection, labour‑market research, education/training decisions, job‑search strategies, and timely career adjustments, enabling intentional adaptation to change.",
        "C": "They substitute individual decision‑making with algorithmic forecasts that automatically select openings and career moves for you.",
        "D": "They advise committing to one narrow, well‑defined career track only, to reduce risk."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified and condensed the question; used concise academic language; preserved the core elements (reflection, labour‑market research, education decisions, job search, adjustments) in the correct option; created plausible but incorrect distractors.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.3_vs_16",
    "pass_2_attempt": {
      "question": "Jordan, age 34, began work as a software engineer, paused employment for three years to provide family caregiving, returned to the labour market as a product manager while maintaining freelance app-development contracts, completed two microcredentials in user experience design, consulted a career advisor to map options, and regularly researches job postings and industry skill demands. Which single conclusion about \"career\" and \"career management\" is best supported by the article text?",
      "options": {
        "A": "Jordan’s experience illustrates that a career is a life-span pattern integrating work-related and non-work experiences; contemporary careers are often designed, hybrid or multiple, and effective career management is an active, purposeful process (reflection, labour‑market research, education decisions, finding openings, and making changes) consistent with models such as the Blueprint model and the Seven C’s of Digital Career Literacy.",
        "B": "Jordan’s trajectory shows that a career is primarily an employer-sponsored linear ladder; career management is mainly the organization’s responsibility, and individual training or market research has little influence on outcomes.",
        "C": "Jordan’s combination of caregiving, freelancing and upskilling is an unusual deviation: historically most people hold only one or two jobs and career change of this type is rare and generally discouraged.",
        "D": "Jordan’s multiple roles indicate a lack of career success because career success is measured solely by continuous promotions, increasing salary and unbroken tenure within a single firm."
      },
      "correct_answer": "A",
      "generation_notes": "Created a realistic case study that requires integrating definitions of career as a life‑span pattern, the active components of career management (reflection, LMI, education, making changes) and the historical shift toward hybrid/multiple careers and career advising.",
      "concepts_tested": [
        "career as life‑span integrative pattern",
        "active, purposeful career management and its components and models"
      ]
    },
    "pass_2_reason": "readability_too_high_20.6_vs_16"
  },
  {
    "original_question": {
      "question": "In normative political theory, how does the liberal notion of liberty both justify political authority and constrain it?",
      "options": {
        "A": "Liberty justifies authority by maximizing state power to secure order, with no constraints.",
        "B": "Liberty justifies authority insofar as the state protects negative freedom and fundamental rights, while constraining authority through the rule of law and due process.",
        "C": "Liberty justifies authority by guaranteeing equal outcomes for all citizens, achieved through centralized planning.",
        "D": "Liberty is irrelevant to legitimacy; legitimacy comes from tradition and obedience alone."
      },
      "correct_answer": "B",
      "source_article": "Political philosophy",
      "x": 1.1805484294891357,
      "y": 0.9509312510490417,
      "concepts_tested": [
        "Normative foundations and legitimacy of political institutions (how values like justice, equality, and liberty justify or constrain political power)",
        "Methodological frameworks for justification in political philosophy (foundationalism vs particularism; universalism vs cultural relativism)",
        "Relationship between ideologies and political theory (how liberalism, conservatism, socialism, anarchism, etc., operationalize core values and inform state structures)"
      ],
      "parent_concepts": [
        "Concept 3: Relationship to broader systems (constitutionalism and Rechtsstaat) and the distinction between the rule of law as a political condition versus rule by man.",
        "Concept 3: The historical/evolutionary development of civil society (from Aristotle and Roman concepts to modern interpretations and dissident uses), shaping its current meaning and function.",
        "Concept 1: Separation of powers as a principle that differentiates state functions (legislative, executive, judicial) to maintain the integrity of each function and limit power concentration.",
        "Concept 2: Structural independence and checks-and-balances (trias politica) as the mechanism by which separation operates in practice.",
        "Concept 3: The tripartite design versus fusion/unified power and how the allocation of powers across branches shapes governance outcomes.",
        "Concept 3: Multidimensional theories of corruption (e.g., Machiavelli’s decline of virtue vs. corruption as deviant behavior) and why multiple frameworks are needed to understand, measure, and address corruption.",
        "Concept 3: Cultural and historical framing shaping how social justice emphasizes individual responsibility vs. access to power, and its expansion to diverse domains (gender, ethnicity, migrants, environment).",
        "Concept 1: The hybrid model of governance that combines direct citizen deliberation with representative decision-making.",
        "Citizenship as a legal status linking membership and allegiance to a state with associated rights and duties",
        "Historical evolution and cross-state variation in citizenship, including expansion of rights and discriminatory practices, and how these shape contemporary understandings of citizenship",
        "Global citizenship and universal community as a normative aim of cosmopolitanism",
        "Concept 3: The normative function of ideology (to defend individual liberty, property, free markets, and constitutional limits on state power), representing underlying principles guiding ideological systems.",
        "Concept 1: Statecraft as both art and science of conducting public affairs, and why its definition is contested.",
        "Concept 2: The social contract and general will as mechanisms linking individual liberty to collective political authority.",
        "Concept 3: The historical-relations aspect of republicanism (from Rome to Renaissance/early modern Europe to the American/French revolutions) and how these ideas influenced political transformation.",
        "Concept 3: The constitution as a limiter of state power, enshrining rights and boundaries that rulers cannot cross.",
        "Concept 3: Electoral reforms aim to improve fairness and maximize the meaningful use of votes in electing winners.",
        "Concept 1: Liberal socialism as a synthesis of liberal freedom with socialist emancipation, realized through a mixed economy that combines social ownership and private property to secure liberty.",
        "The balance between individual freedom and government intervention to achieve social justice (mixed economy/welfare state)",
        "Concept 1",
        "Concept 2",
        "Legitimacy as consent and belief enabling governance and influencing political stability"
      ],
      "parent_articles": [
        "Rule of law",
        "Civil society",
        "Separation of powers",
        "Separation of powers",
        "Separation of powers",
        "Political corruption",
        "Social justice",
        "Participatory democracy",
        "Citizenship",
        "Citizenship",
        "Cosmopolitanism",
        "Ideology",
        "Statecraft",
        "Popular sovereignty",
        "Republicanism",
        "Constitution",
        "Voting",
        "Liberal socialism",
        "Social liberalism",
        "Liberalism",
        "Liberalism",
        "Political legitimacy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In liberal normative theory, how does the idea of liberty both provide a justification for political authority and impose limits on that authority?",
      "options": {
        "A": "Liberty justifies authority by granting the state expansive power to secure order and stability, without attaching meaningful constraints.",
        "B": "Liberty justifies authority insofar as the state protects negative freedom and fundamental rights, while constraining authority through the rule of law and due process.",
        "C": "Liberty justifies authority by requiring the state to guarantee equal material outcomes for everyone, implemented via centralized planning.",
        "D": "Liberty is irrelevant to political legitimacy; legitimate authority derives from tradition, obedience, or inherited status rather than liberty."
      },
      "correct_answer": "B",
      "simplification_notes": "Question shortened and wording clarified to target undergraduates. Emphasized that the liberal notion of liberty involves protection of freedoms and legal constraints; distractor options were reworded to remain plausible (authoritarian, socialist, traditionalist readings) while preserving the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.0_vs_16",
    "pass_2_attempt": {
      "question": "A newly independent state convenes a constitutional assembly. Delegates put forward competing justifications for the new constitution. Which of the following options correctly pairs (i) an ideological tradition, (ii) the primary normative values and institutional prescriptions it typically operationalizes, and (iii) the methodological stance for justifying political authority or its limits (choosing between foundationalism vs particularism and universalism vs cultural relativism) as characterized in the article?",
      "options": {
        "A": "Liberalism — Emphasizes individual rights, negative liberty, the rule of law, and protection of private property; prescribes a constitutionally constrained, limited state that secures liberties and market exchange; justifies authority by appeal to basic moral principles (natural rights), i.e., a foundationalist, universalist method.",
        "B": "Conservatism — Emphasizes equality of outcome and collective ownership; prescribes central planning and abolition of private property to realize distributive justice; justifies authority by universal historical laws about class struggle (foundationalist, universalist).",
        "C": "Socialism — Emphasizes maximal individual autonomy and voluntary, stateless associations; prescribes dismantling all public institutions in favor of non-hierarchical local assemblies; justifies authority (or lack thereof) via bottom-up aggregation of particular judgments and cultural particularity (particularist, cultural relativist).",
        "D": "Anarchism — Emphasizes preservation of customs, social continuity, and gradual change; prescribes a strong centralized state to conserve traditions; justifies political power through top-down foundational principles that apply across cultures (foundationalist, universalist)."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a single scenario asking students to match ideology → values & institutions → methodological stance; distractors swap features across ideologies to test understanding of normative foundations, justification methods (foundationalism/particularism; universalism/relativism), and how ideologies operationalize values.",
      "concepts_tested": [
        "normative foundations and legitimacy of political institutions",
        "methodological frameworks for justification in political philosophy (foundationalism vs particularism; universalism vs cultural relativism)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does combining quality assurance (pre-collection) and quality control (during/after collection) improve data integrity, and how do their different roles contribute to credible results?",
      "options": {
        "A": "QA prevents all possible errors before data collection, so QC becomes unnecessary.",
        "B": "QA and QC are redundant; either one alone is sufficient to ensure data integrity.",
        "C": "QA reduces the introduction of errors by standardizing processes and providing clear instructions before collection, while QC detects and corrects errors as they arise or after collection; together they address both prevention and correction, reducing both systematic and random errors and enabling process improvement.",
        "D": "QA focuses only on data analysis, while QC focuses only on data collection, so they operate in completely separate phases with no interaction."
      },
      "correct_answer": "C",
      "source_article": "Data collection",
      "x": 1.365067958831787,
      "y": 1.0222866535186768,
      "concepts_tested": [
        "Concept 1: Data quality directly influences research validity and credibility, with standardized data collection protocols serving as a preventive mechanism against errors.",
        "Concept 2: Quality assurance (pre-collection) and quality control (during/after collection) are complementary strategies for maintaining data integrity.",
        "Concept 3: The selection of data collection instruments and clear usage instructions reduce data collection errors and improve measurement accuracy."
      ],
      "parent_concepts": [
        "Concept 2: Transition from diary-based measurement to automated meters (e.g., LPM) expands measurement scope (year-round) and improves accuracy by capturing more behavior (e.g., channel-surfing).",
        "Concept 1: Interview structure and formats shape information capture (unstructured vs structured vs focused/ladder interviews) and guide responses."
      ],
      "parent_articles": [
        "Audience measurement",
        "Interview"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do quality assurance (QA: actions before data collection) and quality control (QC: actions during and after collection) combine to improve data integrity and make study results credible?",
      "options": {
        "A": "QA eliminates every possible error through planning and standardization, so QC is unnecessary.",
        "B": "QA and QC are essentially redundant; implementing one of them alone is sufficient to ensure data integrity.",
        "C": "QA reduces the introduction of errors by standardizing procedures, providing clear protocols and training before collection, while QC monitors, detects, and corrects errors during and after collection; together they provide prevention and correction, reduce systematic and random errors, and enable process improvement, increasing credibility.",
        "D": "QA deals only with data analysis and QC deals only with data collection, so they operate in separate, non-overlapping phases with no interaction."
      },
      "correct_answer": "C",
      "simplification_notes": "Clarified timing and roles of QA (before collection) and QC (during/after), used concise academic wording, removed examples and peripheral details, preserved the original concepts about prevention vs correction and impact on data integrity.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A multinational research team will collect systolic blood pressure and self-reported physical activity from 12 clinical sites to study cardiovascular risk. To maximize the study's validity and credibility, they must prevent measurement error, ensure consistent procedures across sites, and detect and correct problems during collection. Which of the following project plans best implements standardized protocols as prevention, complements quality assurance with quality control, and minimizes instrument-related errors through appropriate instrument selection and instructions?",
      "options": {
        "A": "Develop a single, detailed standard operating procedure (SOP) describing step-by-step measurement and survey administration; choose a validated automated sphygmomanometer and a pre-tested physical activity questionnaire with explicit scoring rules; require centralized training and certification of all data collectors before fieldwork (QA); schedule routine calibration of devices, institute real-time monitoring and site-level data checks during collection, and perform post-collection audits with documented corrective actions (QC).",
        "B": "Create a brief guideline outlining the study aims and let each site adapt measurement techniques to local preference; hold an initial webinar for staff but no formal certification (QA); rely primarily on a comprehensive statistical cleaning and outlier removal after data collection (QC).",
        "C": "Forego formal SOPs and select the most affordable devices at each site to reduce costs; begin data collection immediately and compensate for inconsistencies by performing intensive post-hoc data reconciliation and imputation after the study concludes (QC only).",
        "D": "Select unvalidated new devices developed by a vendor with no published accuracy data; provide device user manuals but leave training to individual sites; emphasize frequent post-collection meetings to discuss anomalies rather than pre-collection standardization or in-field monitoring."
      },
      "correct_answer": "A",
      "generation_notes": "Presented a multisite measurement scenario and contrasted plans emphasizing QA (prevention, SOPs, training), QC (monitoring, audits), and instrument selection; option A integrates all three concepts, others omit or misplace strategies.",
      "concepts_tested": [
        "Data quality's effect on research validity and use of standardized protocols for prevention",
        "Complementary roles of quality assurance (pre-collection) and quality control (during/after)",
        "Selection of validated data collection instruments and clear instructions to reduce errors"
      ]
    },
    "pass_2_reason": "readability_too_high_20.1_vs_16"
  },
  {
    "original_question": {
      "question": "In the data science workflow, why is it essential to clearly define the end-user decision problem and the associated evaluation criteria before selecting data sources, preprocessing steps, and modeling techniques?",
      "options": {
        "A": "Because it ensures that computational resources are only allocated to the most data-rich approaches.",
        "B": "Because it guarantees that the model will perform equally well across any future problem the user might pose.",
        "C": "Because it anchors the workflow to a concrete objective and metrics, guiding data collection, feature engineering, model choice, and assessment toward supporting real decisions.",
        "D": "Because it makes domain knowledge unnecessary for model building."
      },
      "correct_answer": "C",
      "source_article": "Data science",
      "x": 1.3776426315307617,
      "y": 1.0396182537078857,
      "concepts_tested": [
        "Concept 1: Interdisciplinary integration",
        "Concept 2: Data science workflow and purpose",
        "Concept 3: Relationship to other fields and paradigms"
      ],
      "parent_concepts": [
        "Concept 1: On-field analytics vs. off-field analytics represent two distinct domains with different questions, metrics, and goals (performance vs. business outcomes).",
        "Concept 2: Data collection and analytical methods (advanced statistics, machine learning, simulations) as the mechanisms by which data translate into decisions and strategic planning.",
        "Concept 3: Analytics influence organizational outcomes beyond performance, including ticket/merchandise sales, fan engagement, sponsorship impact, and even betting/gambling markets.",
        "Concept 3: The development and use of foundational statistical tools (e.g., ANOVA, p-values, Fisher's exact test) to draw inferences about biological data.",
        "Concept 1: On-field analytics vs off-field analytics as distinct but related applications aimed at decision-making.",
        "Concept 1: Data mining as the analysis step in knowledge discovery in databases (KDD), focusing on extracting previously unknown, interesting patterns rather than data collection or reporting.",
        "Concept 2: The types of patterns data mining seeks (e.g., clusters, anomalies, association/sequential patterns) and how these patterns can serve as summaries to support predictive analytics and decision making.",
        "Concept 1: Predictive analytics relies on capturing and exploiting relationships between explanatory variables and predicted variables in historical data to forecast unknown future outcomes.",
        "Concept 2: It is forward-looking and distinct from descriptive BI, using past events to anticipate and inform future behavior or events.",
        "Interdisciplinary aim and purpose: developing methods and software tools by integrating biology, CS, mathematics, statistics, and related fields to understand large, complex biological data.",
        "Concept 3: Digital platforms enabling participation and their role in large-scale data collection and machine-learning applications",
        "Concept 1: The transformation pipeline that converts unstructured text into structured data (parsing, feature derivation, database insertion) and then derives patterns, followed by evaluation and interpretation.",
        "Concept 2: Sabermetrics represents a shift from traditional stats to broader, more nuanced metrics to better capture a player's contributions and performance over time.",
        "Concept 2: Learning paradigms in PR (supervised with labeled data vs unsupervised methods) shape the approaches used (classification, regression, sequence labeling, parsing).",
        "Concept 1: Learning from data to generalize to unseen data, i.e., the core goal of ML and the role of empirical risk minimization.",
        "Concept 2: Data-driven, multi-channel data integration and analysis as core mechanisms enabling understanding of customers",
        "The data analysis process is iterative and goal-directed, evolving as feedback from later phases informs earlier steps to better inform decisions."
      ],
      "parent_articles": [
        "Sports analytics",
        "Sports analytics",
        "Sports analytics",
        "Biostatistics",
        "Sports analytics",
        "Data mining",
        "Data mining",
        "Predictive analytics",
        "Predictive analytics",
        "Bioinformatics",
        "Citizen science",
        "Text mining",
        "Baseball statistics",
        "Pattern recognition",
        "Machine learning",
        "Customer relationship management",
        "Data analysis"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why must a data scientist define the end-user decision problem and the evaluation criteria before choosing data sources, preprocessing steps, and modeling approaches?",
      "options": {
        "A": "Because it helps focus computational effort and data collection on the approaches most likely to address that specific problem.",
        "B": "Because it guarantees the resulting model will perform well on any future question the user might ask.",
        "C": "Because it anchors the workflow to a concrete objective and measurable metrics, guiding data collection, feature engineering, model selection, and evaluation so the solution supports the intended decision.",
        "D": "Because it removes the need to use domain knowledge when building and assessing models."
      },
      "correct_answer": "C",
      "simplification_notes": "Question wording shortened and clarified; options rephrased to be concise and directly linked to workflow steps (data collection, preprocessing, modeling, evaluation); preserved original answer key and core decision-oriented concept.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.0_vs_16",
    "pass_2_attempt": {
      "question": "A multidisciplinary team at a hospital aims to predict 30-day readmission for heart-failure patients. The workflow they follow is: secure and integrate EHR and device-sensor data; impute missing values and encode categorical variables; engineer features that include clinical risk scores; train and tune a random-forest classifier; assess discrimination with AUC and calibration plots; deploy the model on a cloud platform for real-time alerts; and continuously monitor model fairness across demographic groups. Which statement best explains how this project exemplifies (1) interdisciplinary integration, (2) a data-science workflow and purpose, and (3) the relationship of data science to adjacent fields/paradigms?",
      "options": {
        "A": "The project integrates domain expertise (clinicians), statistical methodology (imputation, calibration, AUC) and computational systems (cloud deployment, real-time pipelines); its steps map to a standard data‑science lifecycle (data acquisition → cleaning → feature engineering → modelling → evaluation → deployment → monitoring); and it illustrates data science as distinct from, but built on, statistics and computer science — a data‑driven, application‑oriented paradigm often described as the ‘fourth paradigm’.",
        "B": "This is primarily a statistics project because the central activities are model training and evaluation (AUC, calibration); deployment and cloud considerations are secondary engineering details that do not change its essential nature as statistical inference.",
        "C": "This is essentially a software engineering/cloud systems project because the critical challenge is providing a scalable, real‑time alerting pipeline; the modeling and domain inputs are routine and could be replaced with off‑the‑shelf classifiers without altering the project’s core identity.",
        "D": "The project is best characterized as a ‘big data’ initiative since the defining feature is use of distributed cloud resources and sensor data; data science here is synonymous with handling large volumes and parallel processing rather than with interdisciplinary methods or scientific inference."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete clinical prediction scenario that includes participants, concrete workflow steps, evaluation metrics, deployment and monitoring to test interdisciplinary integration, mapping to data‑science lifecycle, and the relation to statistics/computer science and the 'fourth paradigm'.",
      "concepts_tested": [
        "Interdisciplinary integration",
        "Data science workflow and purpose",
        "Relationship to other fields and paradigms"
      ]
    },
    "pass_2_reason": "readability_too_high_20.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the Transactional Model describe communication as a co-constructed, simultaneous process rather than a simple one-way encoding/decoding sequence?",
      "options": {
        "A": "Because simultaneity guarantees a fixed, context-independent meaning.",
        "B": "Because ongoing, simultaneous encoding/decoding by all participants allows meanings to be shaped by each other's frames of reference, so understanding emerges from interaction.",
        "C": "Because the model assumes a perfectly noiseless channel that preserves the original encoding without distortion.",
        "D": "Because it treats feedback as unnecessary, letting the sender control the interpretation entirely."
      },
      "correct_answer": "B",
      "source_article": "Communication theory",
      "x": 1.231831431388855,
      "y": 1.014939546585083,
      "concepts_tested": [
        "The Linear, Interactional, and Transactional models of communication and how their directionality, encoding/decoding, and simultaneity differ.",
        "The two overarching perspectives on communication: transmission (information exchange) and ritual (work to connect and enable that exchange), and what each implies about purpose and process.",
        "The role of social context and norms in shaping language use and communication behavior (why formality varies with context, and how sociolinguistic factors influence communication)."
      ],
      "parent_concepts": [
        "Interpersonal Deception Theory (IDT): examines how communicative context and sender/receiver cognitions and behaviors interact to produce deceptive exchanges.",
        "Encoding/Decoding model: producers encode meanings into texts; audiences decode them (with possible negotiation or opposition), leading to varying interpretations.",
        "Cultural/social context shapes interpretation: shared backgrounds lead to similar readings, while divergent backgrounds can produce aberrant decoding (interpretations that differ from the intended meaning).",
        "Concept 1: Media constructs reality by prioritizing certain issues and assigning salience, thereby shaping what the public perceives as important.",
        "Concept 1: Multiplexing and transmission channels enable simultaneous communication over a single medium (why/how channels are used to increase capacity).",
        "Relationship between digital processing advantages (e.g., error detection/correction, data compression) and the use of different domains (time, frequency, space) and linear vs. nonlinear operations",
        "Concept 1: Sign models and interpretation (Saussure's dyadic vs. Peirce's triadic) and how these structures produce meaning.",
        "Concept 1: Modulation as a mechanism for encoding audio onto radio waves (AM vs FM) and the trade-offs between amplitude and frequency modulation.",
        "Concept 2: The relationship and distinctions between risk communication and crisis communication (scope, goals, and outcomes) and why this distinction matters.",
        "Balancing the message, the media channel, and the audience as a core mechanism to achieve long-term organizational goals.",
        "Concept 3: Evaluation principle: effectiveness is measured by audience comprehension (not solely aesthetic judgment).",
        "Concept 1: Media function as environments that influence human perception, understanding, feeling, value, and even survival."
      ],
      "parent_articles": [
        "Deception",
        "Reception theory",
        "Reception theory",
        "Agenda-setting theory",
        "Telecommunications",
        "Digital signal processing",
        "Semiotics",
        "Radio broadcasting",
        "Risk communication",
        "Strategic communication",
        "Visual communication",
        "Media ecology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does the Transactional Model describe communication as a co-constructed, simultaneous process rather than a simple one-way encode→send→decode sequence?",
      "options": {
        "A": "Because simultaneity guarantees that meanings become fixed and do not depend on social context.",
        "B": "Because participants encode and decode messages at the same time and continuously shape meanings using their different frames of reference, so understanding emerges through interaction.",
        "C": "Because the model assumes a perfectly noiseless channel that preserves the sender's original encoding without distortion.",
        "D": "Because it treats feedback as unnecessary, assuming the sender alone controls how messages are interpreted."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the stem to be more concise and undergraduate-friendly; clarified 'co-constructed' as mutual shaping of meaning and kept technical terms like 'frames of reference'; kept all distractors plausible by referencing noise, feedback, and context.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A multinational software firm provides the following three communicative episodes: (1) The CEO sends a company-wide, one-way e-mail announcing a policy change; (2) Two engineers use an instant‑messaging thread to clarify implementation details, sending intermittent messages back and forth; (3) A synchronous video meeting in which participants frequently overlap speech, use gestures, and invoke shared project history to negotiate a deadline. For each episode, identify (a) the best-fitting communication model (Linear, Interactional, or Transactional), (b) whether the episode is primarily described by the transmission or the ritual perspective, and (c) which sociolinguistic explanation best accounts for why the CEO e-mail is markedly more formal than the IM exchange.",
      "options": {
        "A": "Episode 1: Linear model; transmission perspective — a single sender encodes a message for many receivers (one‑way, archival). Episode 2: Interactional model; transmission perspective — bidirectional exchanges with explicit feedback cycles. Episode 3: Transactional model; ritual perspective — simultaneous sending/receiving and co‑construction of meaning using shared frames. Formality difference: hierarchical social norms and audience expectations (role of sender and context) drive formality in the CEO e‑mail, whereas peer norms and expectations of rapid conversational repair produce informality in IM.",
        "B": "Episode 1: Transactional model; ritual perspective — the CEO’s message is co‑constructed with audience meaning. Episode 2: Transactional model; ritual perspective — IMs are simultaneous, co‑constructed interactions. Episode 3: Interactional model; transmission perspective — the meeting is basically back‑and‑forth feedback about tasks. Formality difference: the CEO e‑mail is formal because e‑mail as a medium forces formal registers, while IMs are informal because the channel is less feature‑rich.",
        "C": "Episode 1: Interactional model; ritual perspective — the e‑mail is intended to build connection as much as inform. Episode 2: Linear model; transmission perspective — IM is simply sender → receiver messages. Episode 3: Transactional model; transmission perspective — the meeting’s simultaneity is primarily about efficient information exchange. Formality difference: formality is determined chiefly by message length and complexity (longer messages tend to be more formal).",
        "D": "Episode 1: Linear model; ritual perspective — a public announcement functions mainly to perform organizational solidarity. Episode 2: Interactional model; ritual perspective — IMs are primarily about social bonding. Episode 3: Transactional model; transmission perspective — the meeting is mostly simultaneous information transfer. Formality difference: the CEO e‑mail is formal because professional etiquette prescribes long sentences and technical vocabulary regardless of social roles."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete workplace vignette mapping each episode to the Linear/Interactional/Transactional models and to the transmission vs ritual perspectives, then required sociolinguistic reasoning about formality based on social context and norms.",
      "concepts_tested": [
        "Linear vs Interactional vs Transactional communication models",
        "Transmission perspective vs ritual perspective",
        "Sociolinguistic influence of social context and norms on formality"
      ]
    },
    "pass_2_reason": "readability_too_high_29.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why does cross-cultural psychology emphasize distinguishing variability across cultures from potential invariance, and how does that principle shape the typical research design for testing universal versus culture-specific findings?",
      "options": {
        "A": "It aims to prove that all phenomena are culture-specific, so studies must avoid cross-cultural comparisons.",
        "B": "It recognizes both possible differences and stable patterns, leading researchers to use measurement equivalence and culturally sensitive designs to test for universal principles while accounting for variance.",
        "C": "It assumes measurement tools are universally valid, so it applies the same tests without adaptation in all cultures.",
        "D": "It argues that culture cannot influence mental processes, so only universal theories are considered."
      },
      "correct_answer": "B",
      "source_article": "Cross-cultural psychology",
      "x": 1.2474005222320557,
      "y": 1.0095460414886475,
      "concepts_tested": [
        "Variability versus invariance: cross-cultural psychology studies how behavior and mental processes differ or remain stable across cultures, and how to recognize and measure that variance.",
        "Methodological approach to universals vs. differences: uses research designs and methods that factor in cultural differences to test for possible universal principles while acknowledging cultural variance.",
        "Relationship to related fields and boundaries: clarifies how cross-cultural psychology differs from cultural psychology and international psychology, outlining conceptual boundaries and influences."
      ],
      "parent_concepts": [
        "The Strange Situation Procedure provides a framework for classifying attachment patterns (secure, avoidant, anxious, disorganized) but findings may reflect social/environmental contexts rather than fixed traits, highlighting measurement and universality considerations.",
        "Intercultural competence as an integrated, multi-component framework (cognitive, affective, behavioral, linguistic) that enables effective cross-cultural communication."
      ],
      "parent_articles": [
        "Attachment theory",
        "Cultural competence"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does cross-cultural psychology separate cultural variability from potential invariance, and how does that distinction affect typical research designs for testing universals versus culture-specific findings?",
      "options": {
        "A": "Because it seeks to demonstrate that all psychological phenomena are culture-specific, so researchers avoid making cross-cultural comparisons and treat each culture in isolation.",
        "B": "Because it acknowledges both cultural differences and possible stable patterns; researchers therefore test for measurement equivalence and use culturally sensitive, multi-sample designs to evaluate universal principles while accounting for cultural variance.",
        "C": "Because it assumes existing measurement tools are universally valid, so investigators apply identical tests across cultures without adaptation or checks for equivalence.",
        "D": "Because it holds that culture has no effect on mental processes, so research focuses only on testing universal theories and ignores cultural context."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the original question into clearer, concise academic language; retained technical terms (e.g., measurement equivalence, culturally sensitive designs); reduced length while preserving the methodological contrast between testing universals and culture-specific effects.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.0_vs_16",
    "pass_2_attempt": {
      "question": "Dr. Alvarez wants to investigate whether a U.S.-developed self-report inventory for \"social anxiety\" captures the same psychological construct in Japan and Nigeria. Which research plan and interpretation best exemplifies the methodological and theoretical stance of cross-cultural psychology (distinguishing it from purely cultural-psychology or international-psychology approaches)?",
      "options": {
        "A": "Use a mixed-method design: begin with emic qualitative interviews in each culture to elicit local meanings of social anxiety and to generate or adapt items; perform careful translation/back-translation; then test measurement invariance across groups with multigroup confirmatory factor analysis (configural, metric, scalar). If you find the same factor structure and metric invariance but differences in intercepts, conclude there is a partially invariant (universal) construct with culture-specific response tendencies. This approach searches for universals while factoring in cultural variance and differs from cultural psychology (which would stop at culture‑specific meanings) and from international psychology (which emphasizes global practice and dissemination).",
        "B": "Translate the U.S. inventory literally into Japanese and a Nigerian language, administer it, and if total scores correlate similarly with an unrelated criterion (e.g., hours spent online) conclude the construct is universal. This straightforward etic strategy is efficient and shows invariance across cultures.",
        "C": "Conduct independent emic studies in Japan and Nigeria, each developing a distinct, locally derived social‑anxiety scale without attempting any cross-cultural statistical equivalence testing; interpret any differences as evidence that the construct cannot be meaningfully compared across cultures.",
        "D": "Validate the inventory only in a larger U.S. sample and then promote its use by clinicians worldwide through training and guidelines; assume that clinical utility in practice implies universal validity of the construct across cultures."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a scenario requiring evaluation of emic/etic methods, measurement invariance, and conceptual boundaries between cross-cultural, cultural, and international psychology; options include common methodological errors (pseudoetic, purely emic, export without validation) to test student discrimination.",
      "concepts_tested": [
        "Variability versus invariance of psychological constructs across cultures",
        "Methodological approaches to test universals (emic/etic, measurement invariance, mixed methods)",
        "Differences and boundaries between cross-cultural psychology, cultural psychology, and international psychology"
      ]
    },
    "pass_2_reason": "readability_too_high_20.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does applying a single religious framework from one tradition to all religions risk misinterpretation in comparative religion, and what methodological approach best mitigates this risk?",
      "options": {
        "A": "It helps unify diverse beliefs under one standard, which is always beneficial and requires no change.",
        "B": "It can privilege certain conceptual schemas from one tradition and obscure the native logics of others; to mitigate, scholars should use pluralistic, reflexive hermeneutics, incorporate emic (insider) perspectives, and employ multiple interpretive frameworks rather than a single pattern.",
        "C": "It guarantees objective analysis by enforcing consistency, so the best mitigation is to further constrain the framework to more rigidly define concepts.",
        "D": "It is harmless because all religions share identical core issues, so no methodological adjustment is necessary."
      },
      "correct_answer": "B",
      "source_article": "Comparative religion",
      "x": 0.4236755967140198,
      "y": 0.46697506308555603,
      "concepts_tested": [
        "Concept 1: Systematic cross-religion comparison yields insights into fundamental philosophical concerns (ethics, metaphysics, salvation).",
        "Concept 2: Investigating origins and similarities across religions to illuminate cross-cultural relationships and shared themes.",
        "Concept 3: Methodological critique about potential biases (e.g., imposing a Christian framework on other religions) and the implications for interpreting other faiths."
      ],
      "parent_concepts": [
        "Cross-tradition interpretation and terminology, including how different texts (Hebrew Bible, New Testament, Quran, Bahá’í Faith, Zoroastrianism) express or symbolize the notion of a divine kingdom, and how factors like translation, audience, and historical context shape its understanding.",
        "Concept 3: Cross-cultural variation of liturgy (e.g., Buddhist liturgy with chanting, sutras, mantras) illustrating a shared ritual idea with tradition-specific practices and settings (temple vs. home)."
      ],
      "parent_articles": [
        "Kingship and kingdom of God",
        "Liturgy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does imposing a single religious framework (for example, reading all traditions through a Christian pattern) risk misinterpreting other faiths in comparative religion, and which methodological response best reduces that risk?",
      "options": {
        "A": "Because a single framework unifies diverse beliefs under one standard and therefore needs no revision; no methodological change is required.",
        "B": "Because it privileges conceptual schemas from one tradition and can obscure the native logic and categories of other religions; to reduce this risk scholars should adopt pluralistic, reflexive hermeneutics, incorporate emic (insider) perspectives, and use multiple interpretive frameworks rather than a single pattern.",
        "C": "Because enforcing a single framework guarantees objective, consistent analysis, so the remedy is to make that framework more rigid and universally applied.",
        "D": "Because all religions address identical core issues, so imposing one framework is harmless and no methodological adjustment is necessary."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was tightened and made more explicit about the risk (privileging one tradition, obscuring native logics). The recommended method kept technical terms (pluralistic, reflexive hermeneutics, emic) but phrased concisely. Examples (Christian pattern) were kept to preserve context.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.1_vs_16",
    "pass_2_attempt": {
      "question": "A comparative religion researcher sets out to (i) analyze conceptualizations of ethics, metaphysics, and soteriology across Christianity, Zoroastrianism, Hinduism, and Chinese Folk Religions; (ii) investigate historical origins and shared themes (for example, dualism in Iranian faiths and Abrahamic traditions, or syncretic blending in East Asia); and (iii) avoid a priori imposing a Christian model that treats religion as exclusive membership or assumes salvation means eternal life. Which methodological design most reliably satisfies all three aims?",
      "options": {
        "A": "Concentrate solely on canonical texts (Bible, Avesta, Vedas, and Daoist scriptures), translate key passages into a uniform theological vocabulary, and then rate each tradition against the Christian norm of ‘salvation as eternal life’; use these scores to draw conclusions about similarity and influence.",
        "B": "Adopt a multi-method comparative framework: combine philological and historical analysis to trace genealogies and diffusion of ideas, ethnographic fieldwork to elicit emic categories and lived syncretism, and conceptual analysis of ethics/metaphysics/soteriology while explicitly refraining from treating Christian categories as universal.",
        "C": "Compile a quantitative database of ritual frequencies and institutional features across the four traditions, run cluster analysis to identify groups with similar ritual profiles, and infer philosophical affinities from the resulting clusters without further textual or historical contextualization.",
        "D": "Apply a linear evolutionary typology that ranks the four traditions from ‘primitive’ to ‘advanced’ based on assumed stages of religious development, then interpret resemblances as evidence of common ancestry with later traditions representing more developed forms of the earlier ones."
      },
      "correct_answer": "B",
      "generation_notes": "Wrote a vignette-style methodological question; options contrast single-method/textual, multi-method emic-sensitive, quantitative ritualist, and biased evolutionary designs; correct answer emphasizes multi-method, emic attention, and historical tracing to avoid Christian-centric bias.",
      "concepts_tested": [
        "systematic cross-religion comparison yielding insights into ethics/metaphysics/salvation",
        "investigating origins and similarities to reveal cross-cultural relationships",
        "methodological critique of imposing a Christian framework and using emic approaches"
      ]
    },
    "pass_2_reason": "readability_too_high_24.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does cultural heritage represent a socially selected subset of the past rather than the entire past, and how does this selective process influence what is prioritized for preservation and protection?",
      "options": {
        "A": "It results from universal, timeless criteria that apply equally to all legacies, guaranteeing equal protection.",
        "B": "It arises from social processes that assign meaning through shared values and power relations, so what gets protected reflects current priorities and can marginalize certain groups.",
        "C": "It is determined solely by physical durability and age, which automatically prioritizes the oldest artifacts.",
        "D": "It is defined exclusively by international treaties that predefine which legacies are protected, independent of local communities."
      },
      "correct_answer": "B",
      "source_article": "Cultural heritage",
      "x": 0.9858678579330444,
      "y": 0.3978029787540436,
      "concepts_tested": [
        "Concept 1: Heritage is a socially selected legacy, not all past legacies. Why/how society determines what constitutes heritage and why this selection matters.",
        "Concept 2: Distinction and preservation mechanisms for tangible, intangible, and natural heritage. Why/how preservation strategies differ by type and what disciplines support them.",
        "Concept 3: Legal protection and institutional frameworks (international agreements, UNESCO, Blue Shield) as relationships that safeguard heritage. Why/how law and institutions influence preservation outcomes and their interaction with global tourism and peacekeeping."
      ],
      "parent_concepts": [
        "Concept 3: The shift from preserving material culture to incorporating broader cultural concepts, including intangible heritage, and recognizing their inseparability from local communities.",
        "Concept 3: CRM’s relationship to broader societal aims (public education, access to culture, preservation of endangered languages, multiculturalism) and its role in promoting global and local cultural heritage.",
        "The relationship between colonial-era collection practices and the institutionalization and uses of museums in Western powers.",
        "Concept 1: Listing as a regulatory mechanism that restricts demolition, alteration, or extension and requires permission from planning authorities (with consultation of central agencies), including potential material-specific requirements.",
        "The museum’s role in society and education, and how political/national agendas shape that role.",
        "Archives preserve records produced by regular activities because they have enduring cultural/historical/evidentiary value."
      ],
      "parent_articles": [
        "Cultural heritage management",
        "Cultural resource management",
        "Museology",
        "Listed building",
        "Museology",
        "Archive"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is cultural heritage described as a socially selected subset of the past rather than the entire past, and how does that selection process influence which tangible, intangible, and natural items are prioritized for preservation and legal protection by institutions and practices (for example, conservation, museology, UNESCO, Blue Shield, or digital preservation)?",
      "options": {
        "A": "Because heritage is chosen by universal, objective criteria that apply equally to all past legacies, so protection is uniform and impartial.",
        "B": "Because societies assign value through shared norms, institutional priorities, and power relations; therefore what is protected reflects contemporary values and political influence, which can marginalize some groups and shape priorities across tangible, intangible, and natural heritage.",
        "C": "Because selection depends solely on physical durability and age, so the oldest and most durable artifacts automatically receive priority for preservation.",
        "D": "Because international treaties and agencies (e.g., UNESCO) alone define which legacies are protected, independent of local communities or social values."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the original multipart question into a single clear sentence; explicitly referenced tangible/intangible/natural types and institutions (conservation, museology, UNESCO, Blue Shield, digital preservation); kept academic wording and the original correct option.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_29.0_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized country's ministry of culture is given a one-time budget of $\\$1.2$ million to develop a five-year conservation plan for three newly identified items: (1) an 18th-century immovable palace with frescoes and a historic organ, (2) an annually performed indigenous harvest ritual that includes songs and an endangered local language, and (3) a culturally significant coastal wetland hosting endemic bird species. The ministry must decide which items to prioritize as ‘heritage’, design preservation strategies appropriate to each type, and engage international institutions to strengthen legal protection and responsible tourism. Which of the following policy packages best reflects the principle that heritage is socially selected, applies distinct preservation mechanisms and disciplines to tangible/intangible/natural heritage, and uses institutional/legal mechanisms (e.g., UNESCO processes, Blue Shield, national law) to improve preservation outcomes while mitigating negative tourism impacts?",
      "options": {
        "A": "Declare all three items automatically as national heritage without local consultation, split the $\\$1.2$M equally among them ($\\$400$k each), digitize everything as the primary preservation method, and immediately apply for UNESCO World Heritage status for all three to attract tourists and international funding.",
        "B": "Initiate formal local consultations to confirm community recognition (social selection) before final designation; allocate funds according to assessed needs (e.g., architectural conservation and controlled-environment systems and art conservation for the palace; community-led safeguarding, language documentation and oral-history archiving for the ritual; habitat restoration and species monitoring for the wetland); use digitization as a complementary measure; pursue selective UNESCO nomination or national legal listing only with community consent; and coordinate with Blue Shield, national heritage law, and a tourism carrying-capacity plan to protect sites from overuse.",
        "C": "Designate the palace as the sole official heritage priority because it is visibly marketable to tourists, spend the entire $\\$1.2$M on structural restoration and a visitor center, record the ritual as an audiovisual exhibit for the museum (but not engage the ritual’s community), and rely on private tourism operators to manage the wetland’s visitation without formal legal protection.",
        "D": "Treat all three items as equivalent and apply the same preservation protocol: conservation-grade storage and centralized museum curation of artifacts and recordings; avoid international engagement to maintain sovereignty over decisions; advertise aggressively to maximize tourism revenue and reinvest returns later in unspecified preservation activities."
      },
      "correct_answer": "B",
      "generation_notes": "Created a scenario requiring application of social selection, tailored conservation disciplines for tangible/intangible/natural heritage, and strategic use of legal/institutional mechanisms; four plausible policy packages contrast correct integrated approach (B) with common flawed alternatives.",
      "concepts_tested": [
        "social selection of heritage and community consultation",
        "distinct preservation mechanisms/disciplines for tangible, intangible, and natural heritage and appropriate use of digitization"
      ]
    },
    "pass_2_reason": "readability_too_high_20.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does anthropology emphasize an interdisciplinary approach bridging biology, sociology, culture, linguistics, and archaeology when studying humanity across the present and past?",
      "options": {
        "A": "To isolate phenomena within a single domain for greater precision.",
        "B": "To capture the full range of human variation by integrating methods and insights from multiple domains, since biology, culture, language, and material traces influence one another over time.",
        "C": "To ensure all subfields use the same methods regardless of domain.",
        "D": "To keep archaeology separate from biological anthropology in boundary-disputes among disciplines."
      },
      "correct_answer": "B",
      "source_article": "Anthropology",
      "x": 1.2301284074783325,
      "y": 1.0009557008743286,
      "concepts_tested": [
        "Interdisciplinary nature of anthropology: bridging biology, sociology, cultures, linguistics, and archaeology to study humanity across present and past.",
        "Distinction and relationships among subfields: how social anthropology focuses on behavior, cultural anthropology on cultural meaning and norms/values, linguistic anthropology on language in social life, and biological anthropology on biology/evolution.",
        "Regional/classification differences in archaeology: archaeology as a branch of anthropology in some regions vs an independent discipline in others, reflecting conceptual boundaries in knowledge organization."
      ],
      "parent_concepts": [
        "Concept 3: The shift from preserving material culture to incorporating broader cultural concepts, including intangible heritage, and recognizing their inseparability from local communities.",
        "Drivers and processes of cultural change (internal vs external forces and cross-cultural contact)",
        "Social mechanisms that regulate group behavior: mechanisms such as status, reciprocity, ostracism, altruism, leadership, and intergroup relations influence cooperation, decision-making, and cohesion.",
        "Tradition as a framework of symbolic meaning and normative practice across domains (arts, religion, social behavior) that guides how rituals, performances, and customs are carried out",
        "Folklore as a system of expressive culture (verbal, material, and customary lore) and the idea that artifacts are defined by their transmission and communal context.",
        "Concept 2",
        "Concept 1: Relationship and distinctions among cultural assimilation, cultural integration, acculturation, and multiculturalism (how they differ and influence each other)."
      ],
      "parent_articles": [
        "Cultural heritage management",
        "Culture",
        "Group dynamics",
        "Tradition",
        "Folklore",
        "Fashion",
        "Cultural assimilation"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does anthropology use an interdisciplinary approach that combines biology, sociology, cultural study, linguistics, and archaeology when studying humans in both the present and the past?",
      "options": {
        "A": "To isolate social or biological phenomena within a single domain so researchers can achieve greater precision.",
        "B": "To capture the full range of human variation by integrating methods and insights from multiple domains, because biology, culture, language, and material remains influence one another across time.",
        "C": "To force all subfields to adopt identical methods and standards regardless of their subject matter.",
        "D": "To maintain clear disciplinary boundaries so archaeology stays separate from biological anthropology during academic disputes."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the stem; listed the key subfields explicitly; made each option a plausible alternative view while preserving the original correct answer and core concept of interdisciplinarity and mutual influence across time.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "A multinational research team proposes a comprehensive study of an ancient cemetery and its living descendants. The project requires: (1) ancient DNA sequencing and osteological analysis to infer population relationships and health; (2) systematic excavation, stratigraphic recording, and cataloguing of pottery, faunal remains, and burial architecture; (3) long-term participant-observation and interviews with descendant-community members about contemporary mortuary practices and meanings; and (4) analysis of inscriptions and historical language change on grave markers to reconstruct past language use and its social functions. Which combination of anthropological subfields should be represented on the team, and how does the institutional placement of archaeology most commonly differ between North America and Europe?",
      "options": {
        "A": "Assemble biological (physical) anthropologists for DNA/osteology, archaeological anthropologists for excavation and material culture, sociocultural (social/cultural) anthropologists for ethnographic fieldwork, and linguistic anthropologists for inscriptions and sociolinguistic analysis. In North America archaeology is typically one of the four fields within anthropology departments; in Europe archaeology is often an independent discipline or placed under related fields such as history or palaeontology.",
        "B": "Assemble forensic anthropologists for DNA/osteology, cultural anthropologists to perform the excavation and interviews, and historical linguists for inscriptions. Archaeology is usually treated merely as a set of techniques rather than a distinct academic subfield; in Europe archaeology is predominately taught inside anthropology departments.",
        "C": "Assemble biological anthropologists, zooarchaeologists, legal anthropologists, and applied linguists. In North America archaeology is usually organized under history departments, whereas in Europe it is almost always a subfield of anthropology.",
        "D": "Assemble physical anthropologists for bones, material culture specialists to excavate, social anthropologists for interviews, and anthropological linguists for inscriptions. Archaeology is uniformly categorized worldwide as the 'anthropology of the past' and is consistently housed within anthropology departments in all regions."
      },
      "correct_answer": "A",
      "generation_notes": "Created a realistic, multi-task research scenario requiring selection of appropriate anthropological subfields and explicit comparison of regional institutional classifications of archaeology; distractors misassign subfields or invert regional placement to test conceptual distinctions.",
      "concepts_tested": [
        "Interdisciplinary nature of anthropology",
        "Distinctions among subfields: biological, archaeological, sociocultural, linguistic",
        "Regional/institutional differences in classification of archaeology (North America vs Europe)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.2_vs_16"
  },
  {
    "original_question": {
      "question": "Why does strategic alignment of HR practices with organizational objectives contribute to sustainable competitive advantage?",
      "options": {
        "A": "It minimizes labor costs by outsourcing all HR activities.",
        "B": "It builds an integrated system where recruitment, development, performance management, and rewards are designed to enable the organization’s key strategic capabilities, creating vertical and horizontal fit between HR and strategy that improves execution and adaptability.",
        "C": "It guarantees immediate short-term profits regardless of market conditions.",
        "D": "It isolates HR from business units to prevent cross-functional conflict."
      },
      "correct_answer": "B",
      "source_article": "Human resource management",
      "x": 1.336417317390442,
      "y": 0.9865471720695496,
      "concepts_tested": [
        "Concept 1: Strategic alignment of HR practices with organizational objectives to gain competitive advantage",
        "Concept 2: HR policies and processes (recruitment, training and development, performance appraisal, rewards/benefits) as mechanisms that improve employee performance and business outcomes",
        "Concept 3: Evolution of HR from transactional tasks to strategic functions driven by globalization, technology, mergers/acquisitions, talent management, succession planning, and diversity and inclusion"
      ],
      "parent_concepts": [
        "Concept 1: Training vs. development as time-horizon oriented processes (short-term effectiveness vs. lifelong, long-term growth).",
        "The \"talent mindset\" and organizational culture as foundational for effective succession planning (principle about how culture enables or hinders succession outcomes)",
        "Concept 2: Organization-wide implementation and shared responsibility (including line managers and cross-department information sharing)",
        "The voluntary vs involuntary turnover distinction and how organizational actions influence each type",
        "Concept 2: Relationship between leadership education/programs and organizational outcomes (retention, skill development, and employer expectations).",
        "Concept 2: The core/peripheral workforce model and flexible contractual relationships as a theoretical framework underlying why organizations rely on interim managers.",
        "Concept 2: Job rotation as a multi-functional HR tool (staffing, motivation, fatigue management, orientation, career development) and how program structure (formal vs informal) and rotation frequency/duration influence its effectiveness."
      ],
      "parent_articles": [
        "Training and development",
        "Succession planning",
        "Talent management",
        "Employee turnover",
        "Leadership studies",
        "Interim management",
        "Job rotation"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does aligning HR practices with an organization's strategic objectives create a sustainable competitive advantage?",
      "options": {
        "A": "By minimizing labor costs through outsourcing all HR activities, thereby reducing overhead.",
        "B": "By creating an integrated HR system (recruitment, training and development, performance management, rewards) that achieves vertical and horizontal fit with strategy, enabling the organization’s key capabilities and improving execution and adaptability.",
        "C": "By guaranteeing immediate short-term profits regardless of market conditions through tighter HR controls.",
        "D": "By isolating HR from business units to avoid cross-functional conflict and keep HR decisions independent."
      },
      "correct_answer": "B",
      "simplification_notes": "Rephrased the question into clear academic language; condensed the original explanation into a concise option B that preserves the concepts of integrated HR systems, vertical/horizontal fit, and improved execution/adaptability. Other options were kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.6_vs_16",
    "pass_2_attempt": {
      "question": "Novatek, a multinational manufacturing firm, has just completed a cross-border acquisition and is experiencing 15% annual turnover among its specialized automation engineers, fragmented appraisal systems across country subsidiaries, and multiple legacy payroll platforms. The CEO has stated the strategic objective: become the industry leader in advanced automation within five years. Which HR initiative most clearly aligns HR practice with that strategic objective, uses HR policies and processes (recruitment, training and development, performance appraisal, rewards/benefits) as mechanisms to improve employee performance and business outcomes, and exemplifies the evolution of HR from transactional work to a strategic function? (Recall the performance-management heuristic $Performance = Ability \\times Motivation \\times Environment$.)",
      "options": {
        "A": "Develop a global HR strategy that implements a centralized HRIS and e-recruiting platform, defines future-oriented competency profiles for automation engineers, runs targeted reskilling and leader-development programs, standardizes KPI-linked performance appraisals tied to the CEO's automation milestones (using the $Performance = Ability \\times Motivation \\times Environment$ framework), creates succession plans for critical technical roles, and redesigns compensation and retention incentives to reward innovation and cross-border collaboration alongside diversity and inclusion initiatives.",
        "B": "Consolidate payroll and benefits administration into a shared-services center, outsource tax and payroll compliance to a third-party Employer of Record, and keep existing local recruitment and appraisal forms unchanged to minimize short-term disruption during the acquisition.",
        "C": "Immediately reduce turnover by hiring replacement engineers through multiple recruitment agencies and offering higher starting salaries for open roles, while postponing any centralized training, performance metric standardization, or succession planning until after integration is complete.",
        "D": "Focus HR effort exclusively on legal compliance and local labor negotiations during the integration: ensure each subsidiary retains its own HR systems and country-specific benefits packages, and defer any investment in HR technology, talent development, or unified performance-reward systems to a later date."
      },
      "correct_answer": "A",
      "generation_notes": "Created an M&A scenario with elevated turnover and fragmented HR systems; correct option (A) bundles strategic alignment (competency-based recruitment, HRIS, e-recruiting), training/development, KPI-linked appraisals, succession planning, rewards, and D&I to show HR's shift from transactional to strategic.",
      "concepts_tested": [
        "Strategic alignment of HR practices with organizational objectives",
        "HR policies and processes as mechanisms to improve employee performance and business outcomes",
        "Evolution of HR from transactional tasks to strategic functions driven by globalization, technology, M&A, talent management, succession planning, and diversity and inclusion"
      ]
    },
    "pass_2_reason": "readability_too_high_21.5_vs_16"
  },
  {
    "original_question": {
      "question": "How does identifying a neural correlate for a mental state shape the methodological approach of cognitive science to explain that state, particularly regarding reduction, functionalism, and levels of explanation?",
      "options": {
        "A": "It obligatorily reduces mental states to a single brain state, privileging reductive physicalism.",
        "B": "It supports a multi-level explanatory strategy where functional roles of mental states are described at the level of computation and behavior, while brain states provide constraint but not sole explanation.",
        "C": "It demonstrates that brain states are mere epiphenomena with no causal role in behavior, invalidating neurobiological explanations.",
        "D": "It shows that subjective experience can be completely explained by algorithmic descriptions, rendering brain data unnecessary."
      },
      "correct_answer": "B",
      "source_article": "Philosophy of mind",
      "x": 1.1700340509414673,
      "y": 1.0821388959884644,
      "concepts_tested": [
        "Concept 1: Mind–body relationship and ontologies (duality vs. monism vs. physicalism; neutral monism and dual-aspect monism)",
        "Concept 2: Reductionism vs. non-reductionism and theories of mental properties (type identity theory, anomalous monism, functionalism, behaviorism)",
        "Concept 3: Neural correlates and scientific implications (how mental properties relate to brain states and influence scientific approaches, including AI/cognitive science)"
      ],
      "parent_concepts": [
        "Mindset as a cognitive process that biases interpretation and decision-making",
        "Mind-brain integration: neuropsychology as a bridge linking brain pathology to cognitive processes and behavior, distinct from but related to neurology and psychology.",
        "Embodiment as a mechanism: Cognition depends on the body and sensorimotor capacities, not just abstract brain processes.",
        "Concept 1: Belief as a mental state with truth-conditions that can be occurrent or dispositional",
        "Privileged access: introspection provides direct, internal access to one’s mental states as a basis for knowledge.",
        "Concept 2: Reflective self-awareness as \"awareness of awareness\" that supports introspection, metacognition, and personal identity.",
        "Concept 3: The scope of intelligence across species (humans, non-human animals, plants) involves debates about boundaries and definitions, illustrating conceptual and methodological limits of the construct.",
        "Microphenomenal vs macrophenomenal experiences (scaling of consciousness across levels and how experience might aggregate)."
      ],
      "parent_articles": [
        "Mindset",
        "Neuropsychology",
        "Embodied cognition",
        "Belief",
        "Introspection",
        "Self-awareness",
        "Intelligence",
        "Panpsychism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If cognitive scientists identify a reliable neural correlate for a particular mental state, how should this shape their methodological approach to explaining that state, especially regarding reduction, functionalism, and different levels of explanation?",
      "options": {
        "A": "It requires reducing the mental state to a single brain state, thereby endorsing reductive physicalism as the only legitimate explanation.",
        "B": "It favors a multi-level explanatory strategy: characterize the functional/computational role of the mental state at cognitive and behavioral levels, while treating brain states as providing necessary constraints and mechanistic details without serving as the sole explanation.",
        "C": "It shows neural states are mere epiphenomena with no causal impact on behavior, so neurobiological explanations are unnecessary or misguided.",
        "D": "It implies subjective experience can be fully captured by algorithmic or computational descriptions alone, making direct brain data redundant for explanation."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording condensed and clarified for undergraduates; preserved technical terms (reduction, functionalism, levels of explanation). Removed extensive historical background and framed the question as a methodological choice after finding a neural correlate. Options rewritten to be concise and equally plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.4_vs_16",
    "pass_2_attempt": {
      "question": "A cross-disciplinary research program reports three robust empirical findings: (1) Whenever human subjects report the subjective experience of seeing 'red' there is a recurrent neural activation pattern N_h in area V4; (2) Nonhuman animals with very different neuroanatomy nevertheless perform the same discriminations and appear to have corresponding experiences despite lacking a V4 homolog (different physical realizers); and (3) an artificial system implemented in silicon reproduces the same input–processing–output profile for 'red'-detection and produces behaviour indistinguishable from humans in controlled tests, despite no biological neurons. Which philosophical account of the mind–body relation and mental kinds is best supported by this pattern of results?",
      "options": {
        "A": "Type identity physicalism: mental kinds (e.g., 'redness') are identical to specific brain-state types (e.g., N_h), so the best scientific move is to reduce mental vocabulary to neural type-theory.",
        "B": "Functionalism: mental states are defined by their causal and systemic roles (relations to inputs, other states, and outputs); thus the same mental kind can be multiply realized by different physical substrates (brains, silicon).",
        "C": "Anomalous monism (non-reductive physicalism): each mental event is identical to a physical event (token identity) but there are no strict psychophysical type-laws, so mental kinds cannot be captured by functional role claims.",
        "D": "Dual‑aspect or neutral monism: the mental and the physical are two aspects of an underlying neutral substance, so empirical multiple realizability counts against both reductionist physicalist and functionalist frameworks."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete empirical scenario (human neural correlate, cross-species differences, and AI implementation) to probe which theory accommodates multiple realizability and substrate‑independence; functionalism is the best fit.",
      "concepts_tested": [
        "Mind–body ontologies (dualism vs monism vs neutral/dual‑aspect monism)",
        "Reductionism vs non‑reductionism; type identity, token identity/anomalous monism, and functionalism",
        "Neural correlates, multiple realizability, and implications for cognitive science/AI"
      ]
    },
    "pass_2_reason": "readability_too_high_29.7_vs_16"
  },
  {
    "original_question": {
      "question": "How does having explicit exclusive powers for central and regional governments in a federal system promote regional autonomy, and what mechanism is typically used to handle policy areas that cross jurisdictions?",
      "options": {
        "A": "It allows the central government to veto all regional policies, ensuring uniform national policy.",
        "B": "It creates non-overlapping domains for each level, clarifying decision-making and enabling regional autonomy, while cross-cutting issues are addressed through intergovernmental coordination or shared powers.",
        "C": "It grants regions total sovereignty over all matters, making the central government irrelevant.",
        "D": "It eliminates the need for any dialogue between levels because jurisdictions never intersect."
      },
      "correct_answer": "B",
      "source_article": "Federalism",
      "x": 1.1799834966659546,
      "y": 0.7750760316848755,
      "concepts_tested": [
        "Concept 1: Division of powers between central/federal and regional governments, creating regional autonomy and delineated competencies.",
        "Concept 2: The spectrum of regional governance (federalism vs. confederalism vs. unitary states) and how shifts in devolution or integration move along that spectrum.",
        "Concept 3: Differences in sovereignty and intergovernmental relationships across systems (how federalism contrasts with confederalism and unitary states and the implications for governance)."
      ],
      "parent_concepts": [
        "Concept 2: Constitutional and legal framework enabling local governance (how protections and enabling legislation authorize local bodies)",
        "Concept 2: Multi-level governance as a mechanism shaping policy implementation and variation (local, state, and federal roles and their impact on education systems).",
        "Concept 1: Locus shift of decision-making — decentralization moves authority from a central location/group to local units, enabling greater local control and citizen involvement.",
        "Federalism and state sovereignty (Tenth Amendment; powers reserved to states vs. federal government)",
        "Concept 1: Locality-first governance — decisions should be made at the most immediate/local level that can resolve them; central authorities intervene only when local levels cannot address the issue.",
        "Concept 2: Decentralization and civic engagement — decentralization has functional and civic value, increasing citizens’ participation in public affairs and providing a counterweight to centralized power.",
        "Concept 2: Multi-layer governance architecture where FIFA provides general guidelines, but national associations and competition bodies determine exact dates and exceptions, creating a decentralized regulatory system.",
        "Concept 1: Distinction between devolution and federalism, particularly revocability of powers and lack of constitutional protection in devolution.",
        "Concept 3: Autonomy versus central sovereignty in devolved arrangements (devolved regions have authority in certain areas but remain under a central, sovereign framework).",
        "The distinction between chartered local governments and general-law local governments, and the concept of home rule as a driver of local autonomy.",
        "Concept 1: Constitutional basis of authority (provinces derive power from the Constitution Act, 1867; territories derive power from Parliament via delegated powers)",
        "Concept 2: Sovereignty and representation (provinces as co-sovereign with lieutenant governors; territories not sovereign and represented by federal commissioners)",
        "Dual sovereignty and limited international sovereignty: why states are not fully sovereign in international law and how sovereignty is shared/limited within the U.S. system.",
        "Concept 2: Education policy is implemented through multi-level governance (local, state, federal), creating relationships and variation in policy across contexts."
      ],
      "parent_articles": [
        "Local government in Pakistan",
        "Education policy",
        "Decentralization",
        "List of states and territories of the United States",
        "Subsidiarity",
        "Subsidiarity",
        "Transfer window",
        "Devolution",
        "Devolution",
        "Local government in the United States",
        "Provinces and territories of Canada",
        "Provinces and territories of Canada",
        "State governments of the United States",
        "Education policy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do constitutionally specified exclusive powers for the central (federal) and regional governments strengthen regional autonomy, and what mechanism is typically used when policy areas span both levels of government?",
      "options": {
        "A": "By giving the central government a unilateral veto over all regional laws, producing a single uniform national policy.",
        "B": "By creating distinct, non-overlapping competencies that clarify decision-making and protect regional authority, while cross-cutting issues are managed through intergovernmental coordination or shared powers.",
        "C": "By assigning regions complete sovereignty over all matters, rendering the central government effectively irrelevant.",
        "D": "By removing the need for intergovernmental dialogue because constitutional jurisdictions never overlap or intersect."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the question to undergraduate level and condensed background detail; retained the constitutional division-of-powers focus and the idea that intergovernmental coordination/shared powers handle cross-cutting policy areas.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.7_vs_16",
    "pass_2_attempt": {
      "question": "The Republic of Novalia adopts a written constitution that (1) grants the central government exclusive competence over foreign policy, national defence and currency; (2) explicitly entitles constituent regions to self-government over police, education and local taxation and provides that any amendment affecting regional powers requires approval by a majority of the regions; (3) creates a bicameral legislature in which the upper chamber gives each region equal representation regardless of population; (4) recognises that some regions have historically negotiated additional, region-specific powers; and (5) allows regional governments to negotiate directly with the central executive in regular First Ministers conferences. Which of the following best characterises Novalia and its position on the spectrum of regional-integration to regional-separation?",
      "options": {
        "A": "An asymmetric federation: a federal state in which sovereignty and competencies are constitutionally divided between centre and regions (with protected regional autonomy, equal regional representation in the upper house and some differentiated powers), placing it between a confederation and a unitary state on the integration–separation spectrum.",
        "B": "A confederation: the central government is merely an agent of the regions with only delegated powers and the regions retain ultimate sovereignty, so Novalia is positioned at the extreme regional-separation end of the spectrum.",
        "C": "A unitary state with devolved powers: regional autonomy is granted by the central authority and therefore revocable, so Novalia sits close to the unitary end of the spectrum despite symmetric upper-house representation.",
        "D": "A supranational union similar to the EU: the central institutions supersede regional sovereignty and the First Ministers conferences indicate that the state functions primarily as an international organisation rather than a domestic federation."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete constitutional scenario that includes exclusive federal competences, entrenched regional rights, bicameralism with equal regional representation and differentiated regional powers to distinguish federalism (specifically asymmetric federalism) from confederal and unitary forms and from supranational unions.",
      "concepts_tested": [
        "Constitutional division of powers and protected regional autonomy",
        "Spectrum of regional governance (confederal – federal – unitary) and movement along it",
        "Sovereignty distribution and intergovernmental relations (representation in upper house, amendment procedures, direct regional negotiation with centre)"
      ]
    },
    "pass_2_reason": "readability_too_high_33.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why is multi-scale integration essential in neuroscience, and how does combining data from molecular, cellular, circuit, and systems imaging levels contribute to understanding brain function?",
      "options": {
        "A": "Because each scale reveals distinct constraints and causal relationships, and integrating them allows one to link molecular mechanisms to circuit dynamics and ultimately to behavior or cognition.",
        "B": "Because macro-scale imaging alone already provides complete explanations, so integrating other scales merely adds unnecessary complexity.",
        "C": "Because molecular data alone suffices to predict system-wide behavior, making higher-level measurements redundant.",
        "D": "Because neural function is entirely scale-free, and integrating scales only serves methodological convenience without improving understanding."
      },
      "correct_answer": "A",
      "source_article": "Neuroscience",
      "x": 1.7882769107818604,
      "y": 1.1413456201553345,
      "concepts_tested": [
        "Emergent properties: How interactions among neurons and glia lead to higher-level properties of neural circuits that cannot be inferred from single components alone.",
        "Multi-scale integration: Why/how neuroscientists study the nervous system across scales (molecular to imaging) and how combining approaches yields a coherent understanding of brain function.",
        "Brain–behavior relationships: How biological processes in the nervous system underlie learning, memory, perception, behavior, and consciousness."
      ],
      "parent_concepts": [
        "Brain-behavior relationship: how injuries or illnesses of the brain affect cognitive and behavioral functions.",
        "Mind-brain integration: neuropsychology as a bridge linking brain pathology to cognitive processes and behavior, distinct from but related to neurology and psychology.",
        "Methods for linking brain and function: lesion studies and electrophysiological recording as evidence for brain-cognition relationships.",
        "Concept 2: The sensory substitution system’s architecture (sensor, coupling system, stimulator) and the role of the coupling system in interpreting and translating signals between modalities.",
        "Concept 2: Hierarchical and cross-modal processing, including evidence that multisensory effects occur in primary sensory areas and are connected to higher association areas.",
        "Concept 1: Binocular combination outcomes (single image, double images, or fused image) and how these outcomes relate to depth perception (fine vs. coarse stereopsis)."
      ],
      "parent_articles": [
        "Neuropsychology",
        "Neuropsychology",
        "Neuropsychology",
        "Sensory substitution",
        "Multisensory integration",
        "Binocular vision"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why must neuroscientists integrate observations across molecular, cellular, circuit, and systems (imaging) scales, and how does doing so improve explanations of brain function and behavior?",
      "options": {
        "A": "Because each scale reveals different constraints and causal relationships; integrating them connects molecular mechanisms to circuit dynamics and emergent network properties that underlie behavior and cognition.",
        "B": "Because macro-scale imaging (e.g., fMRI) by itself provides complete explanations of brain function, so adding finer-scale data only adds unnecessary complexity.",
        "C": "Because detailed molecular data (genes, proteins, synaptic changes) alone is sufficient to predict system-level behavior, making cellular and imaging measurements redundant.",
        "D": "Because neural function is effectively scale-free, so combining data from multiple scales is just a methodological convenience that does not materially improve mechanistic understanding."
      },
      "correct_answer": "A",
      "simplification_notes": "Condensed wording to an undergraduate level, emphasized the role of emergent properties and linking scales (molecular → circuit → behavior), and kept the original correct choice and core concepts intact.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.7_vs_16",
    "pass_2_attempt": {
      "question": "A lab trains mice on a spatial memory task and collects data at multiple scales: molecular assays show a post-training increase in CREB phosphorylation in the dorsal hippocampus; slice electrophysiology reveals a 40% increase in long-term potentiation (LTP) magnitude at Schaffer collateral–CA1 synapses; in vivo recordings show enhanced theta-band (6–10 Hz) coherence between hippocampus and medial prefrontal cortex during memory retrieval; and behaviorally the mice reach the platform faster in the Morris water maze. Which interpretation best illustrates the concepts of emergent properties and multi-scale integration in explaining the brain–behavior relationship?",
      "options": {
        "A": "The increase in CREB phosphorylation is the proximate cause of improved performance: the molecular change alone explains memory because it drives synaptic changes, so molecular-level data are sufficient to account for the behavior.",
        "B": "The faster maze performance is an emergent property of coordinated network dynamics (enhanced hippocampus–prefrontal theta coherence) that cannot be predicted solely from CREB phosphorylation or single-synapse LTP; a coherent explanation requires integrating molecular, cellular, and systems-level data to link biology to behavior.",
        "C": "The augmented LTP at CA1 is both necessary and sufficient for the behavioral improvement; network coherence is an epiphenomenon and can be ignored when relating synaptic physiology to memory.",
        "D": "The observed theta coherence is likely an artifact of recording; behavioral changes result from peripheral sensory enhancements rather than any central neural mechanisms, so brain-level explanations are unnecessary."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a hippocampal-dependent learning scenario with measured changes at molecular, cellular, systems, and behavioral levels; asked which interpretation requires multi-scale integration and recognizes network-level emergent properties.",
      "concepts_tested": [
        "Emergent properties of neural circuits",
        "Multi-scale integration (molecular → cellular → systems → behavior)",
        "Brain–behavior relationships in learning and memory"
      ]
    },
    "pass_2_reason": "readability_too_high_26.5_vs_16"
  },
  {
    "original_question": {
      "question": "Which explanation best captures how diffusion mechanisms of culture—facilitated by media, the Internet, and travel—produce cross-border social relations and shared norms?",
      "options": {
        "A": "Diffusion occurs primarily through unidirectional flows from dominant cultures to others, with local cultures remaining largely unchanged.",
        "B": "Diffusion operates through bidirectional, repeated social interactions across diverse audiences, where meanings are negotiated, translated, and partly adopted into local practices, leading to cross-border social relations and shared norms.",
        "C": "Diffusion requires uniform economic parity and complete homogenization of consumption patterns across all regions.",
        "D": "Diffusion is limited to the spread of tangible goods and does not affect social relations or cultural meanings."
      },
      "correct_answer": "B",
      "source_article": "Cultural globalization",
      "x": 1.21351957321167,
      "y": 0.9823281168937683,
      "concepts_tested": [
        "Concept 1: Diffusion mechanisms of culture (how ideas, meanings, and values spread across borders via media, the Internet, and travel) and the formation of cross-border social relations.",
        "Concept 2: The tension between cultural homogenization and preservation (debates on whether globalization erases local cultures or represents a natural progression facilitated by technology and commerce).",
        "Concept 3: Economic and technological drivers (trade, wealth distribution, macroregional blocs like the EU and NAFTA, and art markets) as catalysts that enable cultural exchange and homogenization."
      ],
      "parent_concepts": [
        "Concept 3: The relationship between universal civilization and world culture, and how architecture negotiates universal technology with local references (as illustrated by the example projects).",
        "Counter-hegemonic/postcolonial orientations (Third Cinema, postcolonial perspectives) shaping cross-border collaboration and production",
        "Socio-cultural and economic impact, with globalization: how mountaineering influences communities and worldviews, including cultural and economic effects shaped by globalization.",
        "Cross-cultural synthesis: how Roman, Byzantine, Iranian, Mesopotamian, and other lands influenced early Islamic architecture and how these influences were adapted.",
        "Concept 3: The global TV market operates via format franchises (e.g., Survivor, Idol) that are licensed and remade across multiple markets, illustrating localization and cross-border business models.",
        "Concept 3: The link between devotional origins and modern global exposure (from Sufi shrines and mehfil-e-sama to international stages and media promotion) and how context influences reach and audience."
      ],
      "parent_articles": [
        "Critical regionalism",
        "Transnational cinema",
        "Mountaineering",
        "Islamic architecture",
        "TV format",
        "Qawwali"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which explanation best describes how cultural diffusion—via media, the Internet, and international travel—generates cross-border social relations and shared norms?",
      "options": {
        "A": "Diffusion is mainly one-way: dominant (often Western) cultures transmit values and practices that overwhelm or replace local traditions, producing a homogenized global culture.",
        "B": "Diffusion operates through two‑way, repeated social interactions across diverse audiences, where meanings are negotiated, translated, and selectively adopted into local practices, producing cross‑border social relations and shared norms.",
        "C": "Diffusion requires equal economic development and complete uniformity in consumption patterns across regions; only when economic parity and identical markets exist do shared norms emerge.",
        "D": "Diffusion is confined to the spread of tangible goods and services and does not significantly change social relationships, values, or cultural meanings."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; academic phrasing preserved. Distractors rewritten to reflect major perspectives from the article (unidirectional homogenization, economic‑parity requirement, material‑only transmission) while keeping the correct negotiated, hybridization model as B.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "Isla Verde, a mid-sized island nation with a distinct local music tradition and artisanal crafts, undergoes rapid change over a decade: it joins a regional trade bloc (reducing tariffs), national internet penetration rises from 12% to 85%, several multinational fast-food and streaming platforms open operations, foreign art collectors begin purchasing and exporting island art, and tourist arrivals triple while labor migrants settle in coastal cities. Drawing on theories and evidence about cultural globalization (diffusion via media, Internet, and travel; economic and technological drivers; and competing views of homogenization vs. preservation), which of the following outcomes is the most plausible aggregate result for Isla Verde's cultural landscape?",
      "options": {
        "A": "Near-complete cultural homogenization within one generation: local traditions disappear as residents uniformly adopt imported consumer practices and Anglo-American media, because high internet access and multinational market penetration inevitably erase local identity.",
        "B": "Practically no change in local culture: local traditions remain intact because cultural identity is resilient to external economic and technological pressures, and trade and tourism principally affect only material consumption without altering meanings or values.",
        "C": "A mixed outcome characterized by significant spread of global consumer forms (fast food, streaming content, foreign tastes) alongside creative hybridization of local traditions (fusion music, tourist-oriented crafts) and periodic social friction (debates over identity, policy responses), driven by trade, wealth flows, digital diffusion, and local agency.",
        "D": "Solely economic commodification of culture: the main consequence is that artisanal production is converted into export commodities with no effect on everyday cultural practices or social relations, because economic integration affects only market structures and not symbolic life."
      },
      "correct_answer": "C",
      "generation_notes": "Created a concrete scenario combining trade-bloc membership, rapid Internet diffusion, entry of multinationals, art market dynamics, tourism and migration; options map to homogenization, preservation, hybridization with friction, and narrow economic commodification. Correct answer reflects ambivalent outcomes discussed in the article (diffusion mechanisms, economic/technological drivers, and hybridization vs homogenization tensions).",
      "concepts_tested": [
        "Diffusion mechanisms of culture (media, Internet, travel) and cross-border social relations",
        "Tension between cultural homogenization and preservation/hybridization",
        "Economic and technological drivers (trade blocs, wealth distribution, art markets) as catalysts of cultural exchange"
      ]
    },
    "pass_2_reason": "readability_too_high_22.2_vs_16"
  },
  {
    "original_question": {
      "question": "How does adaptive management function to support resilience and long-term sustainability in ecosystem management?",
      "options": {
        "A": "It imposes a rigid, long-term plan that cannot adapt to new ecological or social information, ensuring consistency.",
        "B": "It uses iterative cycles of action, monitoring, evaluation, and adjustment, treating management as experiments to learn system responses and refine strategies.",
        "C": "It focuses solely on ecological indicators, ignoring social and political contexts to preserve pristine conditions.",
        "D": "It seeks to maximize short-term economic gains without considering feedbacks from the ecosystem."
      },
      "correct_answer": "B",
      "source_article": "Ecosystem management",
      "x": 1.3992873430252075,
      "y": 0.8802797794342041,
      "concepts_tested": [
        "Concept 1: Holistic integration of ecological health with human social, political, and cultural needs as a governing principle.",
        "Concept 2: Resilience and long-term sustainability as guiding goals, with adaptive management as the mechanism to achieve them.",
        "Concept 3: Context-dependent implementation and diverse governance forms (adaptive management, strategic management, landscape-scale conservation) driven by stakeholder participation."
      ],
      "parent_concepts": [
        "Evolution of understanding: moving from minimum/instream flows to holistic environmental flows recognizes system complexity and multiple services, enabling more comprehensive management.",
        "Concept 3: The consequences of fire suppression and human/environmental changes, including potential unintended effects and the idea that restoring natural fire regimes can be a cost-effective management strategy.",
        "Concept 1: Form-based restoration vs process-based restoration as distinct approaches with different aims and likely outcomes (immediate structural changes vs long-term ecological resilience through restoring natural processes).",
        "Concept 1: Multiple-use management as a framework that balances timber production with biodiversity, water quality, recreation, and other ecosystem services.",
        "Concept 1: Ecosystem-based fisheries management (EBFM) as a comprehensive, ecosystem-focused approach that balances ecological health, productivity, and human needs, contrasted with traditional single-species management."
      ],
      "parent_articles": [
        "Environmental flow",
        "Fire ecology",
        "Stream restoration",
        "Forestry",
        "Fisheries management"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does adaptive management promote ecosystem resilience and long-term sustainability in ecosystem management?",
      "options": {
        "A": "It establishes a fixed, inflexible plan that cannot be changed, prioritizing consistency over new ecological or social information.",
        "B": "It uses iterative, hypothesis-driven cycles of action, monitoring, evaluation, and adjustment—treating interventions as experiments to learn system responses and refine strategies.",
        "C": "It concentrates only on ecological indicators and excludes social, economic, or political contexts to preserve perceived pristine conditions.",
        "D": "It prioritizes maximizing short-term economic returns without accounting for ecosystem feedbacks or long-term consequences."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the question; simplified phrasing while keeping technical terms (e.g., iterative, hypothesis-driven). Options were reworded to remain plausible distractors but preserve original meanings; correct answer unchanged.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.2_vs_16",
    "pass_2_attempt": {
      "question": "You are a regional ecosystem manager for the Loma River delta, an estuarine system experiencing seasonal eutrophication from upstream agriculture, declining native shellfish populations, and frequent flooding that damages infrastructure. The delta supports a small Indigenous community that depends on shellfish for subsistence and cultural practices, commercial fisheries, and several downstream municipalities that draw drinking water. Which of the following management plans best exemplifies the core principles of ecosystem management (holistic integration of ecological and human needs; resilience and long-term sustainability via adaptive management; context-dependent governance with stakeholder participation and landscape-scale thinking)?",
      "options": {
        "A": "Implement a stakeholder-led adaptive program that (1) defines ecological boundaries at the delta and adjacent watershed, (2) reduces nutrient loads through upstream agricultural best-management practices incentivized by payments-for-ecosystem-services, (3) reintroduces shellfish in refugia while monitoring population and water quality indicators, (4) establishes a rotating, co-managed harvest quota with the Indigenous community and commercial fishers, and (5) reviews and adjusts measures annually based on monitoring results.",
        "B": "Issue a unilateral moratorium on shellfish harvesting for 10 years enforced by fines and patrols, combined with a fixed nutrient-discharge limit on farms enforced by punitive penalties, with technical remediation undertaken by a federal agency without local consultation.",
        "C": "Prioritize maximization of commercial fishery yield by engineering the estuary (dredging and building levees to prevent flooding) and applying targeted stocking of a fast-growing non-native shellfish species that tolerates high nutrients to sustain fisheries income.",
        "D": "Designate the delta as a strict no-use nature reserve; remove all human activities including subsistence harvest and agriculture within the watershed, and assign management solely to a national conservation agency that focuses on returning the system to a presumed historical baseline state."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete estuary scenario to test integration of social and ecological goals, emphasis on resilience via adaptive monitoring and iterative adjustment, and context-dependent governance with stakeholder participation and landscape-scale interventions and incentives.",
      "concepts_tested": [
        "Holistic integration of ecological health with human socioeconomic and cultural needs",
        "Resilience and long-term sustainability achieved through adaptive management",
        "Context-dependent implementation and diverse governance forms driven by stakeholder participation (adaptive, strategic, landscape-scale)"
      ]
    },
    "pass_2_reason": "readability_too_high_23.8_vs_16"
  },
  {
    "original_question": {
      "question": "In social science, researchers increasingly use methodological pluralism—combining quantitative and qualitative approaches—to study complex social phenomena. How does this approach most effectively enhance understanding compared to using a single method?",
      "options": {
        "A": "It guarantees generalizable findings because statistics remove subjectivity.",
        "B": "It minimizes research time by collecting both data types in parallel.",
        "C": "It enables triangulation across different sources of evidence, capturing both patterns and contextual meanings, thus addressing both generalizable relationships and situated interpretations.",
        "D": "It simplifies data analysis because fewer theories are needed when multiple methods are used."
      },
      "correct_answer": "C",
      "source_article": "Social science",
      "x": 1.2562133073806763,
      "y": 1.0211354494094849,
      "concepts_tested": [
        "Concept 1: Epistemological divide between positivist science (empirical, strict sense) and interpretivist approaches (social critique, broader sense) and how this shapes what counts as social science.",
        "Concept 2: Methodological pluralism / mixed-methods in social science (eclectic use of quantitative and qualitative methods) to understand complex social phenomena.",
        "Concept 3: Interdisciplinarity and integration of big data/computational tools to study social behavior, especially in digital environments."
      ],
      "parent_concepts": [
        "Concept 1",
        "Economies as systems with interacting components (production, distribution, consumption, savings, investment) and how policies/factors of production affect them"
      ],
      "parent_articles": [
        "Social change",
        "Economics"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Social scientists increasingly use methodological pluralism (mixed methods: quantitative + qualitative) to study complex social phenomena. Compared with using a single method, why does this mixed-methods approach most effectively improve understanding?",
      "options": {
        "A": "It guarantees generalizable findings because statistical analysis removes researcher subjectivity.",
        "B": "It reduces total research time by permitting quantitative and qualitative data to be collected in parallel.",
        "C": "It enables triangulation across different types of evidence, capturing both statistical patterns and contextual meanings, thus addressing generalizable relationships and situated interpretations.",
        "D": "It simplifies data analysis because using multiple methods reduces the number of theoretical frameworks required."
      },
      "correct_answer": "C",
      "simplification_notes": "Language was tightened for undergraduate readers; 'methodological pluralism' was defined as 'mixed methods: quantitative + qualitative'; the core idea of triangulation (patterns vs contextual meanings) was preserved; distractors were made plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "A multidisciplinary research team plans to study why a viral hashtag campaign on social media preceded a wave of street protests in several cities. Which study design best exemplifies contemporary social-scientific practice that (1) acknowledges the positivist demand for empirically testable claims, (2) incorporates interpretivist contextual understanding, and (3) uses interdisciplinary big-data/computational tools to study behaviour in digital environments?",
      "options": {
        "A": "Deploy an online randomized controlled trial (A/B test) where users are randomly exposed to different message framings; measure subsequent engagement and protest attendance with statistical hypothesis tests and report generalizable effect sizes. (Purely quantitative experimental design emphasizing empirical falsification.)",
        "B": "Conduct long-term participant-observation in activist chat groups and perform critical discourse analysis of posts to theorize the symbolic meanings and power relations that motivated participants; produce a narrative critique without statistical hypothesis testing. (Interpretivist, qualitative focus.)",
        "C": "Combine large-scale scraping of social-platform data and network analysis to map diffusion patterns; apply quasi-experimental causal inference (e.g. difference-in-differences estimator $\n\\Delta Y=(Y_{post,treated}-Y_{pre,treated})-(Y_{post,control}-Y_{pre,control})$) to test exposure effects; and conduct follow-up semi-structured interviews and discourse analysis to interpret participants' motives. The team includes political scientists, computer scientists, and cultural anthropologists. (Mixed-methods, computational and interpretive, interdisciplinary.)",
        "D": "Train machine-learning classifiers on millions of posts to predict which users will attend protests and report model performance metrics (accuracy, AUC); release an algorithmic dashboard that flags likely attendees without conducting interviews or causal tests. (Computational, predictive but not interpretive or causal.)"
      },
      "correct_answer": "C",
      "generation_notes": "Created a vignette about a viral hashtag and protests; each option maps to a different epistemological/methodological approach (positivist experiment, interpretivist ethnography, mixed-methods computational+qualitative, pure ML prediction). Correct choice explicitly integrates empirical causal testing, qualitative interpretation, and big-data computational methods.",
      "concepts_tested": [
        "Epistemological divide between positivism and interpretivism",
        "Methodological pluralism / mixed-methods",
        "Interdisciplinarity and computational big-data approaches in social science"
      ]
    },
    "pass_2_reason": "readability_too_high_22.7_vs_16"
  },
  {
    "original_question": {
      "question": "Which statement best captures the difference between the buffering hypothesis and the direct effects hypothesis of social support in relation to health outcomes under varying stress levels?",
      "options": {
        "A": "The buffering hypothesis posits that social support moderates the stress-health link—stronger support reduces the negative health impact of stress—whereas the direct effects hypothesis posits that social support improves health outcomes even when stress is low or absent, via main-effect pathways such as better coping resources or healthier behaviors.",
        "B": "The buffering hypothesis claims social support only improves health when stress is absent, while the direct effects hypothesis claims support only helps under high stress.",
        "C": "The buffering hypothesis suggests social support affects only psychological well-being, whereas the direct effects hypothesis suggests it affects only physical health.",
        "D": "The buffering hypothesis states social support increases perceived stress, while the direct effects hypothesis states it decreases stress but has no impact on actual health outcomes."
      },
      "correct_answer": "A",
      "source_article": "Social support",
      "x": 1.2890046834945679,
      "y": 0.9948550462722778,
      "concepts_tested": [
        "Concept 1: Buffering hypothesis vs direct effects hypothesis — how social support can modify the impact of stress on health (moderation) or have a direct influence on health outcomes.",
        "Concept 2: Four functions of social support (emotional, tangible/instrumental, informational, companionship) and how each function differently affects individuals’ well-being.",
        "Concept 3: Perceived support vs received support vs degree of social integration — how beliefs about support and actual support, as well as network involvement, mediate or influence health and well-being outcomes."
      ],
      "parent_concepts": [
        "Mentorship as a relationship-based process that combines psychosocial support, career guidance, and role modeling delivered through ongoing communication."
      ],
      "parent_articles": [
        "Mentorship"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which statement best describes the difference between the buffering hypothesis and the direct effects (main effects) hypothesis about how social support influences health across different stress levels?",
      "options": {
        "A": "Buffering hypothesis: social support moderates the stress–health relationship so that stronger support reduces the negative health impact of stress. Direct effects hypothesis: social support has a beneficial main effect on health regardless of stress level (e.g., via better coping, healthier behaviours, or physiological pathways).",
        "B": "Buffering hypothesis: social support only improves health when stress is absent. Direct effects hypothesis: support only helps when stress is high.",
        "C": "Buffering hypothesis: social support affects only psychological (mental) well-being. Direct effects hypothesis: social support affects only physical health outcomes.",
        "D": "Buffering hypothesis: social support increases perceived stress, making outcomes worse. Direct effects hypothesis: social support reduces perceived stress but has no measurable effect on health."
      },
      "correct_answer": "A",
      "simplification_notes": "Question phrasing shortened and clarified; retained technical terms (buffering, direct/main effects, moderation). Options rewritten to be concise and plausible distractors while preserving the core comparison.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.1_vs_16",
    "pass_2_attempt": {
      "question": "A 5-year cohort study (n = 1,200) collected measures at baseline and annually: perceived social support (self-report of available assistance), received support (count of supportive acts received in past year), social integration (network size, club/organization membership), exposure to major life stressors, depressive symptom scores, and incidence of hypertension. The study produced these replicated patterns: (1) higher perceived support is associated with lower depressive symptoms regardless of stress level, and also attenuates the slope relating stressors to depressive symptoms; (2) received support shows no consistent inverse relationship with depressive symptoms and, in some high-stress subgroups, correlates with higher depressive symptoms; (3) greater social integration predicts reduced incidence of hypertension independent of stress exposure; (4) emotional support reduces depressive reactions to bereavement more than informational support, while informational/tangible support is more helpful for problem-solving practical stressors. Which interpretation best synthesizes these findings in light of established social support models and empirical evidence?",
      "options": {
        "A": "Perceived support operates via both buffering and direct (main) effects on mental health, social integration and perceived support show main effects on physical health, received (enacted) support rarely shows reliable main effects and can sometimes be harmful, and different functional types (emotional vs informational/tangible) play distinct roles in emotion regulation versus problem-focused coping.",
        "B": "The results indicate that only the buffering hypothesis is valid: social support matters only when people experience stress; perceived support has no main effects, social integration is irrelevant for physical health, and functional differences (emotional vs informational) are negligible.",
        "C": "Received support is the primary mechanism for both mental and physical health benefits: frequent enacted support reduces depressive symptoms and hypertension risk, whereas perceived support and social integration are epiphenomena with little causal relevance.",
        "D": "Social integration solely determines physical and mental health outcomes: larger networks both buffer stress and produce direct health benefits; perceived and received support are interchangeable measures reflecting the same construct, and the distinction between emotional and informational support is unimportant."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a cohort vignette that maps empirical patterns to the buffering vs direct-effects models, distinctions among perceived/received/structural support, and the four functional types; options contrast correct synthesis with plausible but incorrect interpretations.",
      "concepts_tested": [
        "Buffering hypothesis vs direct effects hypothesis",
        "Functions and differential roles of emotional, tangible/instrumental, informational, and companionship support",
        "Perceived support vs received support vs social integration and their differential associations with mental and physical health outcomes"
      ]
    },
    "pass_2_reason": "readability_too_high_28.5_vs_16"
  },
  {
    "original_question": {
      "question": "In a multi-level governance model of media policy, why is policy content often a mix of features from local, national, regional, and international influences rather than being dominated by a single level?",
      "options": {
        "A": "A central authority always imposes uniform standards that all levels must follow.",
        "B": "Policy content emerges from negotiated accommodation among diverse actors, with ideas diffusing across levels as interests align or counterbalance.",
        "C": "Industry groups veto any regulation at any level, preventing substantive policy change.",
        "D": "Legislation at a higher level automatically rewrites all previously existing local policies."
      },
      "correct_answer": "B",
      "source_article": "Media policy",
      "x": 1.2240866422653198,
      "y": 0.9754362106323242,
      "concepts_tested": [
        "Concept 1: Policy formation is driven by external pressures (public opinion, NGOs, industry groups) and political leadership, creating causal links between actors and regulatory action.",
        "Concept 2: Digital convergence creates regulatory gaps—regulation lags behind technological innovation, leading to issues like copyright violations and misinformation, and prompting legal actions and evolving protections (e.g., IP, AI impacts).",
        "Concept 3: Multi-level governance of media policy and its shaping factors (local, national, regional, international; political philosophies, governmental structures, industry influence, legacy policies) and how these relationships influence policy content and direction."
      ],
      "parent_concepts": [
        "Concept 2: Mechanisms to protect independence (legal frameworks reducing ownership concentration; subsidies for independent media)."
      ],
      "parent_articles": [
        "Editorial independence"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a multi-level governance model of media policy, why does policy content typically combine elements from local, national, regional, and international sources rather than being dominated by a single level?",
      "options": {
        "A": "A central authority imposes uniform standards that all lower levels must accept, producing identical policy everywhere.",
        "B": "Policy content results from negotiated accommodation among diverse actors across levels, with ideas and interests diffusing, aligning, or counterbalancing to produce mixed features.",
        "C": "Industry groups have veto power at every level and block substantive regulation, preventing any coherent policy from emerging.",
        "D": "Legislation enacted at a higher level automatically overrides and rewrites all previously existing local and regional policies."
      },
      "correct_answer": "B",
      "simplification_notes": "Removed extended examples and history; focused wording on multi-level governance and the mechanism (negotiation, diffusion, alignment) that generates mixed policy features. Kept technical terms (multi-level governance, diffusion) appropriate for undergraduates.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.7_vs_16",
    "pass_2_attempt": {
      "question": "In the federal state of Solaria, digital convergence has produced a few large conglomerates that provide streaming, social networking, and telecommunications services on shared infrastructure. Recently, sophisticated AI-generated deepfakes and coordinated disinformation campaigns have spread on those platforms. Public protests and several NGOs demand stronger content controls and protections for intellectual property; the platform industry lobbies for voluntary self-regulation and minimal statutory change; the regional trade bloc to which Solaria belongs has adopted a directive that increases platform transparency and limited liability for notice-and-takedown compliance. Given that technological innovation has outpaced existing sectoral laws (broadcast, print, telecom) and Solaria's multi-level governance (municipal, federal, regional), which of the following policy packages is most consistent with the causal relationships and problems described in the article (external actor pressures shaping policy, regulatory gaps caused by digital convergence, and multi-level influences on policy content and direction)?",
      "options": {
        "A": "The federal government enacts an immediate blanket statutory ban on all AI-generated audiovisual content with criminal penalties for creators and platform hosts; municipalities are directed to establish local censorship boards; industry lobbyists are excluded from the drafting process to prioritize public safety.",
        "B": "A coordinated response: federal legislation updates IP and intermediary liability rules to address AI deepfakes and aligns with the regional directive on platform transparency; the law mandates notice-and-takedown procedures, requires audits and algorithmic transparency, and creates co-regulation mechanisms that include NGOs and industry standards bodies; municipalities run public-awareness campaigns and local enforcement complements federal oversight; the statute contains periodic review clauses to adapt to future technological change.",
        "C": "The government accepts the industry's proposal for a voluntary code of conduct and self-certification covering content moderation and IP protection, with no new statutory changes; regional directives are treated as non-binding guidance; local governments are encouraged to negotiate voluntary memoranda with platform operators.",
        "D": "Policymakers decide to apply legacy sectoral regulations separately—enforce broadcast content rules on streaming, telecom access rules on ISPs, and print-media defamation law on user posts—while leaving novel disputes about AI-generated content to be resolved case-by-case in the courts without proactive legislative reform."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete federal scenario with converged platforms and actor pressures; options contrast plausible policy responses. Correct answer integrates multi-level governance, actor-driven co-regulation, addressing regulatory gaps, and adaptive provisions reflecting the article's themes.",
      "concepts_tested": [
        "Actor influence on policy formation (public opinion, NGOs, industry, political leadership)",
        "Regulatory gaps from digital convergence and technology outpacing law (IP, AI, misinformation)",
        "Multi-level governance shaping media policy (municipal, federal, regional dynamics and legacy policies)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does semantic interoperability require both systems to refer to a common information exchange reference model, and how does this model enable automatic interpretation of exchanged data?",
      "options": {
        "A": "It defines a shared set of data element definitions and their relationships so that each data item is interpreted the same way by both sides, making automatic interpretation possible.",
        "B": "It forces both systems to use the same high-level programming language, which ensures consistent data processing automatically.",
        "C": "It limits interpretation to vendor-defined rules, preventing any variation in meaning across systems.",
        "D": "It replaces data formats entirely with a single universal format, so interpretation becomes trivial without any mapping."
      },
      "correct_answer": "A",
      "source_article": "Interoperability",
      "x": 1.4168174266815186,
      "y": 1.0586291551589966,
      "concepts_tested": [
        "Concept 1: Syntactic vs semantic interoperability and the need for a common information exchange reference model to achieve meaningful data interpretation.",
        "Concept 2: The role of open standards in enabling interoperability across vendors and domains, and the distinction between interoperability and mere compatibility.",
        "Concept 3: Cross-domain interoperability as collaboration among multiple social/organizational/political/legal entities to achieve common information exchange."
      ],
      "parent_concepts": [
        "Concept 1: Interoperability and standardization across scripts and legacy encodings (how Unicode unifies disparate character sets and aligns with ISO/IEC 10646 to enable cross-system compatibility).",
        "Concept 2: Interoperability and standardization in taxonomic data (variant identifiers, multiple classification schemes, machine queryability, and semantic/syntactic compatibility).",
        "Concept 3: The impact of backward compatibility on ecosystem success and adoption (relationships with forward compatibility, costs of breaking compatibility, and examples like Wi-Fi and major architectures).",
        "Concept 2: The main integration methods (Vertical, Star, Horizontal/ESB) as mechanisms with distinct trade-offs in cost, scalability, and complexity.",
        "Concept 3: How interface heterogeneity and the chosen integration approach influence cost, complexity, and scalability (e.g., heterogeneous interfaces raise cost; star/spaghetti connections increase complexity; ESB centralizes communication to aid interoperability).",
        "Concept 2: Standard interfaces and open APIs serve as the mechanisms that enable third-party development and seamless integration across systems.",
        "Concept 2: Interoperability and standardization through management technologies and data schemas (SNMP, NETCONF, YANG, SMI, CIM) enabling consistent monitoring and control across devices.",
        "Modularity, integration, and interoperability: building software from services via APIs (like Lego bricks) and the idea of custom vs shared standards",
        "Concept 3: The impact of interface heterogeneity (proprietary vs. heterogeneous interfaces) on integration cost and feasibility, i.e., interoperability as a driver of design decisions.",
        "Data integration and cross-boundary data sharing/reuse enabled by standardized semantics and schemas",
        "Concept 2: Standardization and global scalability – standardization enables payment networks to grow globally (e.g., cross-border systems, SWIFT, CLS) and facilitates interoperability across countries and products."
      ],
      "parent_articles": [
        "Unicode",
        "Biodiversity informatics",
        "Backward compatibility",
        "System integration",
        "System integration",
        "Open architecture",
        "Network management",
        "API",
        "System integration",
        "Semantic Web",
        "Payment system"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does semantic interoperability require both systems to use a common information-exchange reference model, and how does that model enable automatic interpretation of exchanged data?",
      "options": {
        "A": "It defines a shared set of data element definitions and the relationships and constraints among them so that each exchanged datum has the same unambiguous meaning in both systems, enabling automatic interpretation.",
        "B": "It forces both systems to be implemented in the same high-level programming language so their data-processing semantics match automatically.",
        "C": "It restricts interpretation to vendor-specific rules so no system can assign different meanings to the same data.",
        "D": "It eliminates the need for mappings by replacing all local data formats with a single universal format, making interpretation trivial."
      },
      "correct_answer": "A",
      "simplification_notes": "Question text shortened and clarified; retained technical terms (semantic interoperability, reference model); options reworded to be concise and plausible while preserving the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.6_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized city wants to integrate the address registry (land records), emergency dispatch (public safety), and urban flood-management sensor feeds so that (1) systems from different vendors can automatically exchange data without human intervention, (2) the meaning of exchanged data is unambiguous to each receiving system, and (3) multiple public agencies and private vendors remain able to participate on equal terms. Which combination of actions will best achieve syntactic and semantic interoperability across these cross-domain stakeholders?",
      "options": {
        "A": "Establish a cross-domain governance agreement among all agencies and vendors; commission or adopt an open standard (publicly published, non-encumbered) for message formats and protocols; define and publish a common information exchange reference model that specifies data models and unambiguous semantics; and require interoperable product testing/certification for implementations.",
        "B": "Require all vendors to adapt to the city's incumbent proprietary platform (provide vendors with a closed API specification and licensing), and mandate that each agency use the incumbent system's messages so that everyone communicates using the same vendor-defined formats.",
        "C": "Have each agency agree informally on field names and CSV/XML schemas and use custom mapping scripts to convert data between systems as needed, relying on ad hoc coordination rather than formal standards or a reference model.",
        "D": "Permit new vendors to use clean-room reverse-engineering to mimic the incumbent vendor's undocumented protocol, then deploy API gateways that translate between the mimicked protocol and each agency's internal format; handle updates by reactive patches."
      },
      "correct_answer": "A",
      "generation_notes": "Presented a multi-agency city integration scenario requiring syntactic + semantic interoperability and vendor neutrality; options contrast open-standards plus reference model vs compatibility, ad-hoc mapping, and post-facto reverse engineering.",
      "concepts_tested": [
        "Syntactic vs semantic interoperability and the need for a common information exchange reference model",
        "Role of open standards in enabling vendor-neutral interoperability and distinction from mere compatibility",
        "Cross-domain interoperability as collaboration among multiple social/organizational/political/legal entities"
      ]
    },
    "pass_2_reason": "readability_too_high_23.0_vs_16"
  },
  {
    "original_question": {
      "question": "Which mechanism best explains how interdisciplinary education enhances learning outcomes such as cognitive flexibility, active learning, and real-world problem solving?",
      "options": {
        "A": "It encourages students to memorize key concepts from a single discipline and apply them universally.",
        "B": "It exposes students to multiple methods and perspectives, enabling flexible reasoning and transfer of strategies across domains in response to real-world problems.",
        "C": "It reduces cognitive load by limiting exposure to disciplinary vocabularies, thereby avoiding complexity.",
        "D": "It prioritizes theoretical coherence over practical experimentation, limiting hands-on problem solving."
      },
      "correct_answer": "B",
      "source_article": "Interdisciplinarity",
      "x": 1.2716028690338135,
      "y": 0.9938755035400391,
      "concepts_tested": [
        "Concept 1: Integration of methods and insights from multiple disciplines to address complex problems (how combining perspectives enables solving multifaceted issues)",
        "Concept 2: Interdisciplinary education as a driver of cognitive flexibility, active learning, critical thinking, and real-world problem solving (why/how interdisciplinarity improves learning outcomes)",
        "Concept 3: Organizational and pedagogical implications of interdisciplinarity (cross-boundary collaboration, team-taught courses, and the emergence of interdisciplinary fields)"
      ],
      "parent_concepts": [
        "How project complexity/scale leads to multidisciplinary coordination, typically led by an architect (how larger projects necessitate integration of roles).",
        "Interdisciplinarity: comparative literature analyzes literature within history, politics, philosophy, art, science, and other social/cultural production.",
        "The influence of disciplinary frameworks (e.g., biblical archaeology) on interpretation and the shift toward multiple, non-biblical frameworks.",
        "Concept 3: Interdisciplinary collaboration and the coordination of diverse \"ilities\" (reliability, maintainability, logistics, etc.) to ensure all aspects are considered and synergistically integrated.",
        "Concept 3: Interdisciplinary relationships and networks (overlaps with film studies, psychoanalytic theory, cognitive science, etc.) and the idea of \"visual events\"—how visual interfaces enable consumers to seek information, meaning, or pleasure.",
        "Concept 1: Interdisciplinary foundation of environmental education, integrating multiple disciplines to explain how natural environments function and how humans can manage behavior for sustainability.",
        "Systems and interdisciplinary engagement: how social work draws from multiple disciplines to assess and intervene with individuals, families, and structures, bridging personal well-being with policy and organizational change.",
        "Concept 1: Multidisciplinary integration as a mechanism for generating new leadership insights (the principle that crossing disciplines enables thinking beyond unidisciplinary approaches).",
        "Concept 1: Interdisciplinary understanding arises when students bring together concepts, methods, or languages from two or more disciplines to explain a phenomenon, solve a problem, or create a product.",
        "Concept 1: STEM as an umbrella category built on a shared emphasis on critical thinking, problem-solving, and analytical skills across the disciplines.",
        "Concept 3: The emergence of biomedical engineering as its own field demonstrates interdisciplinary integration leading to the development of a distinct profession and methodological framework.",
        "Interdisciplinary integration and the spectrum: the middle ground of historical sociology between the sociology of history and the history of society, and the idea that interdisciplinary approaches better capture how past events relate to present social structures.",
        "Concept 2: Historical ecology requires interdisciplinary, theory-driven synthesis across natural and social sciences (geography, biology, history, sociology, anthropology, etc.) to study environmental history.",
        "Concept 3: Interdisciplinary integration (toxicology, epidemiology, psychology, sociology, anthropology, economics) is essential for informing and shaping risk governance."
      ],
      "parent_articles": [
        "Building design",
        "Comparative literature",
        "Near Eastern archaeology",
        "Systems engineering",
        "Visual culture",
        "Environmental education",
        "Social work",
        "Leadership studies",
        "Integrative learning",
        "Science, technology, engineering, and mathematics",
        "Biomedical engineering",
        "Historical sociology",
        "Historical ecology",
        "Risk governance"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which mechanism best explains how interdisciplinary education improves outcomes such as cognitive flexibility, active learning, and real-world problem solving?",
      "options": {
        "A": "It trains students to memorize core concepts from one discipline and then apply those concepts universally to all problems.",
        "B": "It exposes students to multiple methods and perspectives and requires integrating them, which builds flexible reasoning and the ability to transfer strategies across domains to solve real-world problems.",
        "C": "It lowers cognitive load by restricting exposure to disciplinary vocabularies and concepts, thereby simplifying learning and avoiding complexity.",
        "D": "It emphasizes theoretical coherence within a single framework over hands-on experimentation, which limits opportunities for practical problem solving."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; mechanistic language focused on integration, transfer, and flexibility. Options rewritten to be concise and plausible while preserving the original distractors and the correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.4_vs_16",
    "pass_2_attempt": {
      "question": "A university designs a new undergraduate course, “Urban Heat, Equity, and Resilience,” to address recurring extreme-heat events in a low-income district. The course is co-taught by a climatologist, an urban planner, a public-health researcher, and an economist. Students work in teams to (1) use climate-model outputs and GIS to map heat exposure, (2) conduct household interviews to document adaptive capacity, (3) estimate costs and benefits of shading and cooling interventions, and (4) produce a unified adaptation plan with policy recommendations for the city council. The department is considering three administrative models for the course: (i) keep faculty in their home departments with promotion decisions made entirely by those departments, (ii) create joint-appointments with explicit expectations for interdisciplinary teaching and an interdisciplinary tenure-review committee, or (iii) create a new interdisciplinary program that could eventually award degrees and control hiring. Which description best indicates that this course exemplifies true interdisciplinarity in methods, maximizes the interdisciplinary educational outcomes described in the article, and accounts for realistic organizational/pedagogical implications?",
      "options": {
        "A": "Faculty teach successive single-discipline modules (climate, planning, health, economics). Students submit four separate reports graded by each faculty member. The course remains administratively housed in the climatology department with tenure and promotion decided there.",
        "B": "Faculty integrate methods (quantitative climate modeling and GIS, qualitative household interviews, and economic cost–benefit analysis) into team-based projects that require synthesis into a single adaptation plan; teaching is team-taught, assessments emphasize critical thinking and real-world problem solving, and the university implements joint appointments plus an interdisciplinary tenure-review process or creates an autonomous interdisciplinary program to reduce disciplinary barriers.",
        "C": "Course relies primarily on active-learning workshops and guest speakers from other fields, but assessment uses a standardized multiple-choice exam designed by the climatology department; faculty remain in their home departments with no changes to tenure or hiring practices.",
        "D": "Faculty require students to master the technical tools of one lead discipline (GIS in climatology) before allowing optional exposure to other perspectives; the course is marketed as interdisciplinary but is administratively controlled by the economics department, which provides all grading rubrics."
      },
      "correct_answer": "B",
      "generation_notes": "Created a concrete course scenario to test integration of mixed methods, interdisciplinary pedagogical benefits (active learning, synthesis, critical thinking), and organizational implications (joint appointments, tenure committees, program autonomy). Distractors omit or misapply one or more core concepts.",
      "concepts_tested": [
        "Integration of disciplinary methods to solve complex problems",
        "Interdisciplinary education outcomes: cognitive flexibility, active learning, critical thinking",
        "Organizational and pedagogical implications: team-taught courses, joint appointments, interdisciplinary programs and tenure considerations"
      ]
    },
    "pass_2_reason": "readability_too_high_22.7_vs_16"
  },
  {
    "original_question": {
      "question": "Why does combining abductive and productive reasoning with nonverbal visual/spatial modeling (e.g., sketching, prototyping) enhance a designer's ability to address ill-defined or wicked problems in design thinking?",
      "options": {
        "A": "It pushes designers to lock in a single best solution early, preventing exploration.",
        "B": "It enables generating multiple plausible explanations for ambiguous observations, while visual/spatial modeling externalizes ideas to test and refine them through rapid prototyping.",
        "C": "It replaces user research with formal logic to derive solutions.",
        "D": "It constrains thinking to predefined templates, ensuring consistency across domains."
      },
      "correct_answer": "B",
      "source_article": "Design thinking",
      "x": 1.3910834789276123,
      "y": 1.0492255687713623,
      "concepts_tested": [
        "Concept 1: Design thinking as an iterative, non-linear process with specific activities (context analysis, user testing, framing, ideation, prototyping, evaluation).",
        "Concept 2: The ability to address ill-defined and wicked problems using abductive and productive reasoning and visual/spatial modeling (e.g., sketching, prototyping) as core design-thinking strategies.",
        "Concept 3: Design thinking as a designerly way of knowing/thinking (a cognitive style and body of knowledge) that can be interpreted as varying uses (cognitive style, theory, pedagogy), leading to conceptual ambiguity."
      ],
      "parent_concepts": [
        "The iterative design process, including prototypes and play testing driving revision and refinement",
        "Iterative, feedback-driven design: design cycles repeat until objectives/criteria are satisfied.",
        "Concept 2: Iterative, stage-spanning testing and user research (testing and feedback integrated from requirements through post-production)",
        "Concept 2: Interdisciplinary, user-centered approach that integrates psychology, HCI, information architecture, and user research within technical/business constraints",
        "Concept 1: Emphasizing the user and context to drive problem-solving leads to usable, useful, and safe systems.",
        "The interplay of objective factors (climate, topography, drainage, codes, soils, etc.) and subjective factors (genius loci, client needs, aesthetic decisions) in design decisions.",
        "The design space of concept cars often includes radical or nontraditional materials and layouts, with varying levels of functionality, illustrating the relationship between exploratory design and production feasibility.",
        "Concept 2: Automotive design follows an iterative process (sketches → digital drawings → renderings → models → mock-ups) with consumer feedback guiding refinement."
      ],
      "parent_articles": [
        "Game design",
        "Engineering design process",
        "User-centered design",
        "Interaction design",
        "Human-centered design",
        "Landscape design",
        "Concept car",
        "Automotive design"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does combining abductive and productive reasoning with nonverbal visual/spatial modeling (for example, sketching and prototyping) improve a designer's ability to tackle ill-defined or \"wicked\" problems in design thinking?",
      "options": {
        "A": "It pushes designers to commit early to a single 'best' solution, reducing further exploration and iteration.",
        "B": "It supports generating multiple plausible hypotheses from ambiguous observations (abduction), while visual/spatial models externalize ideas so they can be tested, iterated, and refined quickly via prototyping.",
        "C": "It replaces empirical user research and contextual inquiry with formal deductive logic to derive definitive solutions.",
        "D": "It constrains creativity by imposing predefined templates and standard representations across domains to ensure consistency."
      },
      "correct_answer": "B",
      "simplification_notes": "Question language was tightened for clarity and concision; background detail about design thinking was condensed to focus on how abductive/productive reasoning plus visual modelling aids handling ill-defined problems. Technical terms (abduction, prototyping, externalize, iterated) retained for precision.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "A multidisciplinary municipal team is tasked with reducing coastal flood risk for a small town where climate projections, social values, and local economies pull in different directions (a 'wicked' problem). Their process: (1) begin with official hazard maps and a project brief that mandates a seawall by 2027 (context analysis and a fixed problem statement); (2) conduct a 2‑day ideation workshop producing many sketches and three low‑fidelity modular seawall prototypes; (3) run a single wave‑tank test and one round of resident interviews focused only on aesthetic preferences; (4) engineers select the final design and the mayor approves it. Which evaluation best identifies how this team's approach aligns with core principles of design thinking as described in the article?",
      "options": {
        "A": "The team exemplified design thinking because they performed context analysis, empathy interviews, ideation, sketching, prototyping and testing — therefore their linear project plan qualifies as an iterative, non‑linear design thinking process.",
        "B": "The team partially used design thinking methods but violated core principles: they imposed a fixed problem framing, limited abductive/co‑evolutionary exploration between problem and solution, and restricted participatory decision‑making, so their approach is unlikely to address the wickedness of the problem.",
        "C": "Their main failing is overuse of visual/spatial models; design thinking requires primarily deductive and rule‑based engineering analysis for wicked problems, so prototypes and sketches should have been minimized.",
        "D": "This case shows the term 'design thinking' is inherently ambiguous — since the team applied activities associated with the pedagogy (workshops, prototypes) they therefore fulfilled all senses of the term (cognitive style, theory, and pedagogy) and no further critique is warranted."
      },
      "correct_answer": "B",
      "generation_notes": "Created a concrete municipal planning scenario that requires evaluating iterative framing, abductive/co‑evolutionary reasoning, prototyping, and participatory features of design thinking; options contrast correct critique with plausible misinterpretations.",
      "concepts_tested": [
        "Iterative non‑linear design process and core activities (context analysis, ideation, prototyping, testing)",
        "Addressing wicked problems via abductive reasoning, co‑evolution of problem and solution, and use of visual/spatial modelling",
        "Ambiguity of 'design thinking' as cognitive style, general theory, and pedagogy and implications for practice"
      ]
    },
    "pass_2_reason": "readability_too_high_20.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why does treating design as a universal cognitive function aimed at transforming existing situations into preferred ones help explain why everyday problem-solving often begins with reframing the problem before generating possible actions?",
      "options": {
        "A": "Reframing is unnecessary because problems are already defined with fixed goals and constraints.",
        "B": "Reframing simply delays action and never leads to better options.",
        "C": "Reframing changes how the problem is represented, aligning it with relevant constraints and potential actions, which reveals new viable options to transform the situation.",
        "D": "Reframing forces people to abandon values and focus only on technical feasibility."
      },
      "correct_answer": "C",
      "source_article": "Design",
      "x": 1.4121968746185303,
      "y": 1.0680949687957764,
      "concepts_tested": [
        "Concept 1: Design as intentional creation within goals, constraints, and context, balancing aesthetic, functional, and experiential considerations.",
        "Concept 2: The design process and design thinking as sequences of activities (research, negotiation, reflection, modeling, iteration) that produce a design.",
        "Concept 3: Design as a universal cognitive function and a relationship to action/change (the idea that everyone designs to transform existing situations into preferred ones)."
      ],
      "parent_concepts": [
        "The iterative design process, including prototypes and play testing driving revision and refinement",
        "Architecture as the design process that identifies user needs and meets them within economic and technological constraints.",
        "Elements of design as an interrelated vocabulary shaping the whole: how line, shape, color, texture, value, form, and space relate to each other to organize the artwork.",
        "Concept 1: A design language creates a coherent design system across a suite of products, enabling consistent appearance and user experience.",
        "Concept 1: Interior design aims to enhance health and aesthetics, implying that design choices have effects on user well-being and the usability of a space.",
        "The engineering design process: combining scientific principles, mathematics, and design to solve real problems while balancing function, safety, and economics.",
        "Concept 1: Design thinking as an iterative, non-linear process with specific activities (context analysis, user testing, problem framing, ideation, prototyping, evaluation) that together shape problem solving.",
        "Concept 1: Emphasizing the user and context to drive problem-solving leads to usable, useful, and safe systems.",
        "The interplay of objective factors (climate, topography, drainage, codes, soils, etc.) and subjective factors (genius loci, client needs, aesthetic decisions) in design decisions.",
        "The relationship and distinction between typography and type design (crafts overlapping but not identical; roles of practitioners vary)."
      ],
      "parent_articles": [
        "Game design",
        "Computer architecture",
        "Composition (visual arts)",
        "Design language",
        "Interior design",
        "Engineering",
        "Design thinking",
        "Human-centered design",
        "Landscape design",
        "Typography"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If design is a general cognitive activity in which people devise actions to change an existing situation into a preferred one, why does everyday problem-solving often start by reframing the problem before proposing actions?",
      "options": {
        "A": "Reframing is unnecessary because problems already come with fixed goals and constraints.",
        "B": "Reframing only delays action and does not produce better solutions.",
        "C": "Reframing alters the problem's mental representation, aligning goals, constraints, and context so that new viable actions to transform the situation become apparent.",
        "D": "Reframing forces people to abandon values and focus solely on technical feasibility."
      },
      "correct_answer": "C",
      "simplification_notes": "Clarified premise ('design as a general cognitive activity'), shortened and tightened wording, emphasized 'reframing' as changing mental representation and revealing actions; preserved original concepts and correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.2_vs_16",
    "pass_2_attempt": {
      "question": "You are asked to evaluate four design vignettes and choose the one that best illustrates: (1) design as an intentional creation situated in a specific context that balances goals, constraints, and aesthetic, functional and experiential considerations; (2) a design process composed of research, negotiation with stakeholders, reflective modeling and iterative testing; and (3) the idea that designing is a general human cognitive activity used to transform an existing situation into a preferred one. Which vignette best satisfies all three criteria?",
      "options": {
        "A": "A municipal design team is tasked with redesigning a neighborhood park. They commission ecological and user-research studies, convene co-design workshops with residents and accessibility advocates to reconcile competing needs, develop several CAD models and full-scale pilot installations, and run a six‑week trial to collect behavioural and comfort data. Budget ceilings and local planning regulations constrain layout options. After feedback they revise pathways, play structures and planting to improve safety, aesthetics, and the sensory experience of the space. Meanwhile, local users temporarily reconfigure movable seating during weekends to create social clusters before the team formalizes a design change.",
        "B": "An artist in a private studio sculpts a large metal installation over several months. They rely on intuition and aesthetic judgement, producing successive versions until satisfied. The work is installed in a gallery with no prior consultation with users, no formal research or stakeholder negotiation, and no formal testing; the artist considers the finished piece complete when it matches their personal vision.",
        "C": "A hardware engineer follows a strict specification: requirements are written, a single detailed plan is developed, components are manufactured, and the product is released. The team documents constraints and functional goals but does not run iterative pilots or engage end‑users; any later problems are addressed in a separate maintenance phase months after release.",
        "D": "A homeowner fixes a broken fence by sawing, nailing, and repositioning boards on a rainy afternoon without drawings or prior measurement. The repair is driven by immediate need; the homeowner adapts on the spot to physical constraints and achieves a satisfactory outcome for their household."
      },
      "correct_answer": "A",
      "generation_notes": "Created four concrete vignettes that map to the three target concepts; A integrates intentional balancing of goals/constraints/aesthetics, an explicit iterative research-and-negotiation design process, and an example of everyday design behavior; other options omit one or more core concepts.",
      "concepts_tested": [
        "Design as intentional creation balancing goals, constraints, aesthetic, functional, and experiential considerations",
        "Design process activities: research, stakeholder negotiation, modeling, iterative testing and revision",
        "Design as a universal cognitive activity for transforming situations into preferred ones (everyday designing)"
      ]
    },
    "pass_2_reason": "readability_too_high_23.3_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the social construction of an environmental problem influence the scale and direction of policy responses more than the issue’s raw ecological data alone?",
      "options": {
        "A": "Because policymaking is driven solely by objective ecological severity.",
        "B": "Because frames created by media, policy-makers, and advocacy groups shape perceived urgency, blame, and legitimacy, directing attention and resources.",
        "C": "Because all environmental issues are equally salient once they involve nature.",
        "D": "Because scientists can predict exactly which issues will be politicized."
      },
      "correct_answer": "B",
      "source_article": "Environmental sociology",
      "x": 1.2532051801681519,
      "y": 0.9464102387428284,
      "concepts_tested": [
        "Social factors and the social construction of environmental problems (how society defines and responds to environmental issues)",
        "Holistic/systemic perspective in environmental sociology (shift from anthropocentrism to systems thinking)",
        "Existential dualism and the human–nature relationship (embeddedness in the ecosphere versus unique human capacities)"
      ],
      "parent_concepts": [
        "Concept 2: Mechanisms of unequal distribution of environmental harms (environmental racism, ecological debt) and the dynamics by which burdens can shift from wealthy countries to the Global South."
      ],
      "parent_articles": [
        "Environmental justice"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does the way a society frames or 'constructs' an environmental problem usually determine the scale and direction of policy responses more than the problem’s raw ecological measurements?",
      "options": {
        "A": "Because policymakers rely only on objective scientific measures of ecological harm when choosing responses.",
        "B": "Because frames produced by media, politicians, scientists, and advocacy groups shape perceived urgency, blame, and legitimacy, which channel attention, resources, and policy priorities.",
        "C": "Because once an issue involves the natural environment, all such issues become equally politically salient and receive similar policy responses.",
        "D": "Because scientists can accurately predict in advance which environmental problems will become politically important, so policy follows those predictions."
      },
      "correct_answer": "B",
      "simplification_notes": "Replaced technical phrasing with clearer language, defined 'social construction' as framing, and made each option concise and plausible while preserving the original correct answer and core concept.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized coastal city experiences recurring summer algal blooms that collapse local fisheries and increase hospital visits for respiratory problems. Different actors offer competing explanations: local fishers blame upstream industrial discharge; a coalition of small-scale farmers point to population growth and increased fertilizer use; municipal officials emphasize technological fixes (a proposed aeration system for the bay); environmental NGOs highlight institutional failures in watershed governance and media narratives amplify risks, shaping public concern. Which analytical approach and policy response best exemplifies environmental sociology’s integration of (1) the social construction of environmental problems, (2) a holistic/systemic perspective, and (3) existential dualism about the human–nature relationship?",
      "options": {
        "A": "Prioritize the aeration system as a technical solution funded by the municipality, arguing that human ingenuity can overcome ecological limits and that the problem is primarily a physical one to be solved by engineering.",
        "B": "Implement strict privatization of access to the bay and market-based tradable discharge permits, asserting that individual self-interest and population pressures are the root causes and that commodification will align incentives.",
        "C": "Convene a multi-stakeholder watershed council to redesign land-use and fertilizer practices, reform industrial discharge rules, invest in community monitoring and public communication campaigns that reframe the blooms as produced by social institutions and feedbacks, while recognizing both human innovation and ecological constraints.",
        "D": "Launch a media campaign to downplay the severity of blooms and emphasize economic resilience, treating the episodes as socially constructed risks without changing regulations or underlying production practices."
      },
      "correct_answer": "C",
      "generation_notes": "Created a concrete coastal algal bloom scenario with multiple actors; options map to HEP/technical fix, Neo-Malthusian/market privatization, NEP/systemic multi-stakeholder response (correct), and soft constructionist rhetoric-only response. Tests integration of three core concepts.",
      "concepts_tested": [
        "social construction of environmental problems",
        "holistic/systemic perspective in environmental sociology",
        "existential dualism (human embeddedness vs human capacities)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does treating quality management as an ongoing lifecycle of planning, assurance, control, and improvement help ensure a product or service consistently meets its intended performance?",
      "options": {
        "A": "Because the results from control and assurance feed back into improvement, which updates planning and standards for the next cycle, creating a closed-loop that adapts to actual performance.",
        "B": "Because planning establishes a fixed standard that, once set, remains unchanged; assurance and control merely verify conformance to that fixed standard.",
        "C": "Because improvement is performed only after the final release, and does not influence current process planning or control.",
        "D": "Because assurance focuses on individual performance rather than process, so it doesn't affect long-term consistency."
      },
      "correct_answer": "A",
      "source_article": "Quality management",
      "x": 1.4019112586975098,
      "y": 1.0096851587295532,
      "concepts_tested": [
        "Concept 1: The four components of quality management (planning, assurance, control, improvement) form an ongoing lifecycle that ensures a product or service consistently meets intended performance.",
        "Concept 2: Statistical quality control and standardization are mechanisms that translate processes into consistent quality outcomes, enabling mass production efficiency and ongoing improvement.",
        "Concept 3: Quality management is linked to market and national dynamics (customer expectations, supplier competition, and national strategy), shaping organizational success and competitiveness."
      ],
      "parent_concepts": [
        "Concept 3: The role of competence and soft elements (knowledge, culture, motivation) as integral to quality control, shaping outcomes.",
        "Role of metrics in improvement: using specific indicators (cost, cycle time, defects) to drive measurement, comparison, and action.",
        "Defect prevention as the core of QA and the shift-left approach (how preventing defects earlier in development/production reduces problems later)",
        "Core QA principles: fit for purpose and right first time, and how these principles guide measurement, processes, and quality management across materials, products, and services",
        "Concept 1",
        "Concept 1: Accreditation as a quality assurance mechanism—external evaluation against standards determines accreditation status and funding/recognition.",
        "Concept 1: Standardization as the mechanism by which SOPs improve efficiency, quality, uniformity, and reduce miscommunication and noncompliance.",
        "Concept 2: Quality-outcome linkage — how higher service quality can lead to greater profitability and long-term competitiveness.",
        "Concept 1: Systematic prevention, reporting, and analysis of medical errors as the core mechanism for improving patient safety.",
        "Concept 1: Structure-Process-Outcome framework for measuring quality (what providers can do vs. actions taken vs. effects on health)",
        "Concept 2: The six domains of quality (safe, effective, patient-centered, timely, efficient, equitable) and how they define what “quality” means in health care",
        "Concept 1: Accountability and continuous improvement as core attributes of clinical governance (enabling environments where high standards of care flourish)."
      ],
      "parent_articles": [
        "Quality control",
        "Benchmarking",
        "Quality assurance",
        "Quality assurance",
        "Verification and validation",
        "Educational accreditation",
        "Standard operating procedure",
        "Service quality",
        "Patient safety",
        "Health care quality",
        "Health care quality",
        "Clinical governance"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does treating quality management as a continuous lifecycle of quality planning, quality assurance, quality control, and quality improvement help ensure a product or service consistently meets its intended performance?",
      "options": {
        "A": "Because data and findings from quality control and assurance are fed back into improvement, which updates planning and standards for the next cycle, forming a closed-loop that adapts processes to actual performance.",
        "B": "Because planning establishes a permanent standard that, once set, remains unchanged; assurance and control only verify conformance to that fixed standard.",
        "C": "Because improvement activities are performed only after the final release, so they do not influence current planning or control.",
        "D": "Because assurance focuses on individual worker performance rather than on processes, so it does not support long-term, system-level consistency."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording was shortened and clarified for undergraduate readers; historical context and extraneous detail were removed. The core idea of a feedback (closed-loop) lifecycle connecting control/assurance to improvement and planning was preserved. Options were rephrased to remain plausible misconceptions.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.3_vs_16",
    "pass_2_attempt": {
      "question": "A multinational firm produces consumer drones in two plants: Plant A (domestic) implements a formal Quality Management lifecycle — it performs quality planning (customer and stakeholder requirements), institutes product standardization and interchangeable parts, applies statistical quality control (Shewhart control charts on assembly-line defect rates), conducts ISO 9001-style quality assurance audits, and runs continuous improvement via Kaizen/PDCA with visible leadership engagement. Plant B (offshore) emphasizes rapid cost reduction and high-volume output through outsourcing, minimal process standardization, and ad-hoc inspection-based checks without SPC or a formal QMS.\n\nAccording to the principles and historical evidence of quality management, which outcome is most likely after 18 months of operation?",
      "options": {
        "A": "Plant A will show reduced process variability and lower defect-rate variability (fewer special-cause excursions on control charts), higher customer satisfaction, and better sustained competitiveness; Plant B may achieve lower unit cost short-term but will exhibit higher warranty/return costs and reputational risk over time.",
        "B": "Plant A will incur higher operating costs from SPC and ISO audits and therefore will be unable to compete on price; Plant B’s low-cost outsourcing will automatically produce equal or superior market share despite higher defect rates.",
        "C": "Both plants will converge to the same performance because outsourcing levels global standards; statistical process control and standardization have negligible impact in mature commodity markets.",
        "D": "Plant B will outperform Plant A in customer satisfaction because ad-hoc inspection finds defects faster than statistical quality control, and rapid cost reductions always translate to higher long-term competitiveness."
      },
      "correct_answer": "A",
      "generation_notes": "Created comparative manufacturing scenario contrasting a QMS lifecycle with SPC/standardization versus cost-focused outsourcing; options probe outcomes on defect variability, customer satisfaction, costs, and competitiveness to test integration of the four QM components, statistical control, and market/national implications.",
      "concepts_tested": [
        "Quality management lifecycle: planning, assurance, control, improvement",
        "Statistical quality control and standardization as mechanisms to reduce variability and enable mass-production consistency",
        "Relationship between quality management, market competitiveness, and national/organizational strategy"
      ]
    },
    "pass_2_reason": "readability_too_high_23.0_vs_16"
  },
  {
    "original_question": {
      "question": "Which mechanism best explains how proactive, interventionist industrial policy can drive structural transformation and competitiveness in an economy?",
      "options": {
        "A": "By coordinating targeted investments in infrastructure, technology, and industrial linkages to correct market failures, create scale, and prompt learning-by-doing that private markets alone would not achieve.",
        "B": "By relying on neutral, market-driven resource allocation where the government minimizes distortions and lets firms pick winners based on price signals.",
        "C": "By substituting private investment with public ownership in all strategic sectors to guarantee national competitiveness.",
        "D": "By prioritizing free trade with no conditions, assuming integration into global markets will automatically transform the economy."
      },
      "correct_answer": "A",
      "source_article": "Industrial policy",
      "x": 1.2838729619979858,
      "y": 0.9254167675971985,
      "concepts_tested": [
        "Concept 1: Learning by doing through selective protection/subsidies to nurture infant industries until they become competitive.",
        "Concept 2: Industrial policy aims to drive structural transformation and competitiveness via proactive, interventionist measures (and infrastructure support), not just passive policy.",
        "Concept 3: Relationships with other policy domains (trade policy, macroeconomic policy) and the debates about their compatibility or conflict (e.g., impact on free trade and international cooperation)."
      ],
      "parent_concepts": [
        "Concept 2: The purposes and rationales for nationalization (protecting strategic industries, safeguarding jobs, redirecting profits to the public, and its relation to socialist aims).",
        "Concept 1: Policy incentives and regulatory exemptions (tax holidays, quotas, simplified procedures) as mechanisms to attract foreign direct investment and enable export-oriented production.",
        "Concept 3: Economic development trade-offs and risks (labor rights concerns, potential misuse for illicit activities) arising from SEZ policy implementation and balance between growth objectives and social costs.",
        "Concept 1: Technology policy as active industrial policy to correct market failures and strategically develop national capabilities."
      ],
      "parent_articles": [
        "Nationalization",
        "Special economic zone",
        "Special economic zone",
        "Technology policy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which mechanism best explains how proactive, interventionist industrial policy drives structural transformation and improves a country's competitiveness?",
      "options": {
        "A": "By coordinating targeted investments in infrastructure, technology and firm linkages to correct market failures, generate economies of scale, and promote learning-by-doing that private markets alone would underprovide.",
        "B": "By relying on neutral, market-driven resource allocation where the government minimizes intervention and lets firms 'pick winners' through price signals.",
        "C": "By substituting private investment with public ownership of all strategic sectors so the state directly guarantees national competitiveness.",
        "D": "By prioritizing unconditional free trade and assuming integration into global markets will automatically transform the domestic economy."
      },
      "correct_answer": "A",
      "simplification_notes": "Wording made more concise and direct for undergraduates; retained key mechanisms (infrastructure, technology, linkages, market failures, scale, learning-by-doing); distractors kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "Caledonia implements a 5‑year program of targeted tariffs and subsidies for a nascent electric‑vehicle battery sector, coupled with investments in port upgrades, grid reinforcement, and vocational training for battery technicians. Based on the industrial policy literature, which of the following best characterizes the most likely intended mechanisms and the principal policy tensions this program creates?",
      "options": {
        "A": "Indefinite tariffs and open‑ended subsidies will guarantee domestic firms learn fast enough to become globally competitive; therefore Caledonia need not design exit rules or worry about trade disputes because perpetual protection sustains learning by doing without welfare losses.",
        "B": "Temporary selective protection and subsidies combined with infrastructure and skills investments are designed to generate learning by doing and structural transformation; if these interventions are carefully time‑limited and performance‑conditioned they eliminate the risk of excess capacity and are automatically compatible with international trade rules.",
        "C": "This program is essentially a macroeconomic policy indistinguishable from raising interest rates or changing capital‑gains taxes, so its main effect will be on aggregate demand rather than firm‑level competitiveness, and it will have little to do with trade policy debates.",
        "D": "The program exemplifies proactive industrial policy: temporary selective protection/subsidies plus infrastructure and skills support aim to foster learning by doing and structural transformation by improving firms’ capabilities and linkages. However, such measures are distinct from standard macro tools, can provoke tensions with free‑trade disciplines and international cooperation, and carry risks of government failure (political capture, misallocation, or welfare‑reducing excess capacity) if exit conditions and monitoring are weak."
      },
      "correct_answer": "D",
      "generation_notes": "Created a concrete 5‑year policy scenario testing (1) learning by doing through temporary selective protection/subsidies, (2) infrastructure and skills as enablers of structural transformation, and (3) tensions with trade rules and risks of government failure; offered one balanced answer and three plausible but incorrect alternatives.",
      "concepts_tested": [
        "Learning by doing via temporary selective protection/subsidies for infant industries",
        "Industrial policy as proactive intervention to drive structural transformation and competitiveness with infrastructure support",
        "Interactions and tensions between industrial policy, trade policy, and macroeconomic policy (including risks of government failure and international disputes)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.0_vs_16"
  },
  {
    "original_question": {
      "question": "How does a chronic energy surplus drive obesity and non-communicable disease risk, and how do macronutrient types modulate the body's handling of that surplus via metabolic and hormonal pathways?",
      "options": {
        "A": "All surplus calories are stored the same way, regardless of macronutrient source, so macronutrient balance does not influence obesity risk.",
        "B": "Only physical activity can determine obesity; diet composition cannot influence energy storage.",
        "C": "A chronic energy surplus leads to body fat accumulation, driving obesity and NCD risk; the macronutrient mix can modulate the magnitude and direction of metabolic signals (e.g., insulin, satiety, thermogenesis) that govern how efficiently surplus energy is stored.",
        "D": "Micronutrient adequacy alone determines whether excess energy becomes fat."
      },
      "correct_answer": "C",
      "source_article": "Nutrition",
      "x": 1.5948847532272339,
      "y": 0.8940619230270386,
      "concepts_tested": [
        "Concept 1: Nutrients as energy sources and building blocks, and how their balance (deficiency vs. excess) drives health outcomes (malnutrition, obesity, NCDs) via metabolic processes.",
        "Concept 2: Organism-specific nutrient acquisition and requirements, including diverse strategies (consuming organic/inorganic matter, photosynthesis, internal production) and the universal needs (carbon, energy, water) shaping nutrition across life.",
        "Concept 3: Macronutrients vs. micronutrients and the roles of vitamins/minerals, including how their availability and adequacy influence growth, health, and disease, with implications for dietary guidelines."
      ],
      "parent_concepts": [
        "Moderation/Balance: distributing energy from protein, fats, and carbohydrates and limiting harmful components (e.g., high sugar/salt) to prevent disease and maintain healthy weight.",
        "The relationship between processing levels (primary, secondary, tertiary) and health/nutrition outcomes, including how increasing transformation can lead to issues like high sugar/salt and low fiber in ultra-processed foods."
      ],
      "parent_articles": [
        "Healthy diet",
        "Food processing"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does a chronic positive energy balance (persistent energy intake greater than expenditure) promote obesity and raise risk for non-communicable diseases, and how do macronutrient proportions (carbohydrate, fat, protein) change metabolic and hormonal responses (for example insulin, satiety, thermogenesis) that affect how surplus energy is stored?",
      "options": {
        "A": "All excess energy is handled identically by the body regardless of macronutrient source, so the relative amounts of carbohydrate, fat, or protein do not change obesity risk.",
        "B": "Body weight is determined solely by physical activity; dietary composition cannot influence whether surplus energy is stored as fat.",
        "C": "A chronic energy surplus leads to progressive adipose tissue accumulation and increased NCD risk; the macronutrient mix alters hormonal and metabolic signals (e.g., insulin-driven lipogenesis, differences in satiety and diet-induced thermogenesis, and the higher energy density of fat) that change how efficiently and in what form surplus energy is stored.",
        "D": "Whether excess energy is converted to body fat depends only on micronutrient (vitamin and mineral) adequacy, not on total calories or macronutrient composition."
      },
      "correct_answer": "C",
      "simplification_notes": "Question was shortened and clarified: defined 'chronic energy surplus' as intake > expenditure; explicitly named key metabolic/hormonal mediators (insulin, satiety, thermogenesis) and noted macronutrient differences (energy density, storage efficiency). Language made more concise and examples added for clarity.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_28.3_vs_16",
    "pass_2_attempt": {
      "question": "An agrarian community implements three changes simultaneously: (1) heavy application of synthetic nitrogen fertilizer to cereal fields, (2) increased industrial milling that removes germ and bran from cereals, and (3) a dietary shift where the average adult swaps 50 g/day of cereal starch for 50 g/day of vegetable oil, raising daily energy intake by $(9-4)\\times50=250$ kcal. Which single statement best explains the likely ecological and human-health consequences, using principles of nutrient acquisition, macronutrient/micronutrient roles, and balance of nutrient intake?",
      "options": {
        "A": "Synthetic N boosts plant biomass because plants use inorganic N plus sunlight to synthesize organic carbon compounds, increasing carbohydrate availability to herbivores; milling lowers micronutrient density causing hidden micronutrient deficiencies in people despite higher calories; replacing 50 g starch with 50 g oil increases energy density (fat 9 kcal/g vs carbohydrate 4 kcal/g), promoting overnutrition and greater risk of obesity and NCDs while essential vitamins lost by milling cannot be synthesized by humans.",
        "B": "Increased soil nitrogen allows cattle to synthesize all essential amino acids de novo, so meat quality improves and human micronutrient deficiencies decline; milling mainly removes indigestible fiber and therefore cannot cause micronutrient deficiency, while swapping starch for oil reduces total energy intake because fats are metabolically inefficient.",
        "C": "Industrial milling substantially reduces available carbohydrate calories from the cereals, so the net effect of the three changes will be chronic undernutrition in the population; nitrogen fertilizer benefits are irrelevant because plants cannot use inorganic nitrogen to increase carbohydrate production without extra sunlight.",
        "D": "Higher synthetic nitrogen reduces the need for nitrogen-fixing soil bacteria and therefore increases soil micronutrient concentrations, which prevents any deficiency; swapping starch for oil lowers disease risk because fats are required for vitamin absorption and will compensate for micronutrient losses from milling."
      },
      "correct_answer": "A",
      "generation_notes": "Created a realistic agricultural vignette combining fertilizer use, cereal refining, and macronutrient substitution to test links between nutrient acquisition strategies (plants use inorganic N and light), macronutrient energy densities (carb 4 kcal/g, fat 9 kcal/g), essential micronutrient losses (vitamins/minerals), and health/ecosystem outcomes (hidden deficiency, overnutrition and NCD risk).",
      "concepts_tested": [
        "Nutrients as energy sources and building blocks; effects of deficiency vs excess on health (malnutrition, obesity, NCDs)",
        "Organism-specific nutrient acquisition and universal requirements (plants using inorganic N and light; animals depending on dietary nutrients)",
        "Macronutrients vs micronutrients; roles of vitamins/minerals and implications for dietary guidelines and hidden hunger"
      ]
    },
    "pass_2_reason": "readability_too_high_24.0_vs_16"
  },
  {
    "original_question": {
      "question": "How do impersonal positions and rule-governed decision-making in a bureaucratic organization influence efficiency and accountability, and under what condition might this mechanism fail to deliver the intended benefits?",
      "options": {
        "A": "They concentrate authority in informal leaders, speeding decisions but reducing traceability unless formal audits exist.",
        "B": "They tie decision rights to defined roles and standard procedures, producing predictable decisions and clear lines of accountability; they fail when rules are outdated or misaligned with local conditions.",
        "C": "They remove discretion entirely, guaranteeing optimal efficiency in all contexts.",
        "D": "They rely on ad hoc personal judgment, which always improves adaptability but risks inconsistent accountability."
      },
      "correct_answer": "B",
      "source_article": "Organizational theory",
      "x": 1.2930290699005127,
      "y": 0.9829201102256775,
      "concepts_tested": [
        "Bureaucracy as a mechanism: impersonal positions, rule-governed decision-making, professionalism, chain of command, defined responsibility, and bounded authority; how these features influence efficiency and accountability.",
        "Contingency theory and environmental adaptation: organizations must maximize performance by navigating environmental and internal constraints using diverse response mechanisms; how suitability of structures depends on context.",
        "Division of labor and formalization in rational organizations: specialization of labor and explicit goal specificity; how these elements affect output, coordination, and efficiency."
      ],
      "parent_concepts": [
        "Concept 2: The relationship between governance and management, and how management actions steer policy and organizational direction.",
        "Concept 3: Role clarity and resource/support structures (defined roles, planning time, guidance, organizational backing) enabling efficient and purposeful teamwork.",
        "OD as a systemic, interdisciplinary approach (systems thinking, organizational learning) used to implement and sustain change",
        "Concept 2: Mechanism by which a mission statement communicates purpose/direction and creates organizational identity, guiding stakeholder alignment",
        "Hierarchical leadership, discipline, and control as the structural mechanism coordinating member activity",
        "Centralized management: the trade-off between economies of scale and learning/implementation effort depending on organization size",
        "Concept 2: The core/peripheral workforce model and flexible contractual relationships as a theoretical framework underlying why organizations rely on interim managers.",
        "Concept 1: Interdependence and internal consistency among organizational elements (formal structure, informal culture, processes, HR) with strategy and environment to realize value.",
        "Concept 1: Standardized hierarchy and common terminology enable rapid, effective interagency coordination during incidents.",
        "Concept 2: Scalability and flexibility of ICS allow it to manage incidents of any size or complexity by expanding or contracting the management structure.",
        "Concept 1: Centralization of governance in MLB (from a weak National Commission to a single powerful commissioner) and its impact on league decisions and power dynamics.",
        "Concept 2: Variable organizational forms — AMCs can be partnerships or fully integrated organizations with shared governance."
      ],
      "parent_articles": [
        "Management",
        "Teamwork",
        "Organization development",
        "Mission statement",
        "Political machine",
        "Systems management",
        "Interim management",
        "Organizational architecture",
        "Incident Command System",
        "Incident Command System",
        "Major League Baseball",
        "Academic medical centre"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a Weberian bureaucracy, how do impersonal positions and rule‑governed decision procedures affect efficiency and accountability, and under what circumstance can this mechanism fail to deliver those benefits?",
      "options": {
        "A": "They concentrate decision authority in informal leaders, which can speed decisions but reduce traceability and accountability unless formal audits or oversight are imposed.",
        "B": "They assign decision rights to defined roles and standard procedures, producing predictable decisions and clear lines of accountability; this system breaks down when rules are outdated or misaligned with local conditions.",
        "C": "They eliminate discretion entirely, guaranteeing optimal efficiency and accountability in every context.",
        "D": "They depend on ad hoc personal judgment to improve adaptability, which can increase responsiveness but produces inconsistent accountability."
      },
      "correct_answer": "B",
      "simplification_notes": "Language was tightened and framed as a single focused question. Historical examples and extra background were removed; core concepts (impersonal positions, rule‑governed decisions, efficiency, accountability, and failure when rules misfit context) were preserved and made more concise.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.3_vs_16",
    "pass_2_attempt": {
      "question": "A coastal city's Municipal Emergency Response Agency (MERA) faces two simultaneous constraints: a 20% budget cut that reduces staffing and equipment (resource constraint) and an increase in atypical, rapidly evolving climate-related emergencies (environmental uncertainty). City council demands both clear public accountability and high operational effectiveness in unpredictable conditions. Which organizational design will most likely maximize MERA's performance given these constraints?",
      "options": {
        "A": "Adopt a strict Weberian bureaucracy: highly formalized written rules, rigid chain of command, narrowly specialized positions with bounded authority and tenure protections; centralize decision rights to senior managers to ensure impersonal, rule-governed accountability.",
        "B": "Implement a decentralized contingency-style design: minimal formal rules, fluid roles and authority, cross-functional teams that self-organize for each incident; emphasize rapid local decision-making over standardized procedures to maximize adaptability.",
        "C": "Combine core bureaucratic features for accountability with contingency-based flexible response units: maintain formalized protocols and clear hierarchy for routine responsibilities and public reporting, while deploying cross-trained, temporarily empowered rapid-response teams that use alternative procedures when novel emergencies arise.",
        "D": "Apply Taylorist scientific-management: decompose all tasks into narrowly defined motions, impose strict performance incentives and time standards on responders, and separate planning (managers) from execution (workers) to maximize output per unit of labor."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a realistic emergency-response scenario that forces trade-offs among Weberian bureaucracy (accountability/stability), contingency adaptation (fit to environmental uncertainty), and division of labor/formalization (specialization and goal specificity). Option C integrates the three concepts and is most fit-for-purpose.",
      "concepts_tested": [
        "Weberian bureaucracy: impersonal positions, rule-governed decision-making, chain of command, bounded authority, effects on accountability and efficiency",
        "Contingency theory: fit between organizational structure and environmental/internal constraints; need for diverse response mechanisms",
        "Division of labor and formalization in rational organizations: specialization, goal specificity, standardized protocols and their effects on output, coordination, and adaptability"
      ]
    },
    "pass_2_reason": "readability_too_high_20.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why does interdisciplinarity and cross-disciplinary collaboration tend to enhance our ability to tackle complex, real-world problems, and what mechanism often underlies communication barriers between disciplines?",
      "options": {
        "A": "It enforces a single universal methodology that all fields adopt, reducing the need for translation; communication barriers arise from organizational inertia.",
        "B": "It enables translation of core questions into multiple disciplinary languages, but barriers arise from differences in jargon, concepts, and validation norms.",
        "C": "It guarantees that all disciplines will share the same epistemic standards, with barriers mainly due to unequal access to funding.",
        "D": "It dissolves disciplinary boundaries entirely, making collaboration automatic; barriers exist only at the level of personal trust."
      },
      "correct_answer": "B",
      "source_article": "Academic discipline",
      "x": 1.288155436515808,
      "y": 1.033203363418579,
      "concepts_tested": [
        "Interdisciplinarity and cross-disciplinary approaches as mechanisms to integrate knowledge and address problems beyond narrow specialization, including barriers to communication across disciplines.",
        "The social/organizational boundaries of disciplines (journals, learned societies, and university departments) that define and maintain disciplinary identity and expertise.",
        "The historical evolution and potential future shifts of disciplines (e.g., secularization-era emergence, growth of new fields, and Mode 2/post-academic science) as drivers of changing disciplinary landscapes."
      ],
      "parent_concepts": [
        "Interdisciplinarity: comparative literature analyzes literature within history, politics, philosophy, art, science, and other social/cultural production."
      ],
      "parent_articles": [
        "Comparative literature"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do interdisciplinary and cross-disciplinary collaborations improve our ability to solve complex, real-world problems, and what commonly underlies communication barriers between disciplines?",
      "options": {
        "A": "They impose a single, universal methodology that all fields must adopt, reducing the need for translation; communication barriers mainly come from organizational inertia and resistance to change.",
        "B": "They allow core problems to be reformulated in multiple disciplinary languages and integrate complementary methods and perspectives; communication barriers commonly arise from differences in jargon, concepts, and standards of validation.",
        "C": "They guarantee that all disciplines will share identical epistemic standards, so any communication problems are primarily caused by unequal access to funding and resources.",
        "D": "They dissolve disciplinary boundaries entirely so collaboration becomes automatic; remaining barriers are mainly due to lack of personal trust among researchers."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was tightened and made more concise for undergraduate readers; technical ideas (reformulating problems across disciplines, integration of methods, communication barriers due to jargon/validation norms) were preserved. Distractors were rephrased to remain plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.6_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized university plans to launch a program to address urban heat islands that requires climate modeling, materials science, public health, urban design, and sustained engagement with local communities and city government. The provost’s criteria are: (1) overcome disciplinary barriers that are reproduced by journals, learned societies and departmental silos; (2) reduce communication overhead from divergent jargon and methods; and (3) align with a potential shift toward Mode 2 or “post‑academic” science emphasizing co‑production of knowledge with non‑academic stakeholders. Which organizational design best meets all three criteria?",
      "options": {
        "A": "Create a new single traditional academic department called “Urban Thermal Studies” within the Faculty of Science, with a dedicated journal and degree programs controlled by departmental faculty.",
        "B": "Fund a time‑limited multidisciplinary project in which disciplinary teams from existing departments each work on decomposed subproblems and report back to a central coordinator, but retain full disciplinary governance and publication channels.",
        "C": "Establish an interdisciplinary research institute on campus with joint faculty appointments, shared physical space, a common graduate curriculum, and incentives for cross‑disciplinary publications that primarily target peer‑reviewed disciplinary journals.",
        "D": "Form a transdisciplinary, networked consortium that includes academics from multiple departments, municipal agencies, industry partners and community representatives; create co‑produced research agendas, flexible publication and evaluation practices, and shared governance outside traditional departmental control."
      },
      "correct_answer": "D",
      "generation_notes": "Constructed a concrete university scenario requiring assessment of organizational models; options contrast departmental, multidisciplinary, interdisciplinary institute, and transdisciplinary/Mode 2 consortium to test recognition of barriers, social boundaries, and future shifts.",
      "concepts_tested": [
        "interdisciplinarity vs transdisciplinarity and cross‑disciplinary integration",
        "disciplinary social boundaries (journals, societies, departments) and Mode 2/post‑academic science"
      ]
    },
    "pass_2_reason": "readability_too_high_20.3_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a holistic (systemic) approach in environmental design rely on evaluating social, economic, and ecological factors together when planning a large urban transit project, and how does this affect the resulting design choices?",
      "options": {
        "A": "It prioritizes ecological impact above all else, so social and economic aspects are ignored in the final plan.",
        "B": "It reveals feedback loops and trade-offs among social equity, financial viability, and ecological effects, guiding choices that are resilient across time and contexts.",
        "C": "It speeds up decision-making by reducing the number of factors to consider, allowing faster approval.",
        "D": "It treats all factors as interchangeable, so optimizing one automatically optimizes the others."
      },
      "correct_answer": "B",
      "source_article": "Environmental design",
      "x": 1.3624156713485718,
      "y": 0.9356784224510193,
      "concepts_tested": [
        "Sustainability: minimizing environmental impact through renewable resources, energy-efficient technologies, and eco-friendly materials.",
        "Holistic/Systemic approach: considering interconnected social, economic, and ecological factors in design decisions.",
        "Interdisciplinary collaboration: integrating architecture, geography, urban planning, ecology, sociology, and public policy to create holistic solutions."
      ],
      "parent_concepts": [
        "Concept 1: The interaction of site conditions (soil quality, climate, microclimates, topography) with design decisions (plant selection, layout, material choices) and how these constraints shape the overall garden design."
      ],
      "parent_articles": [
        "Garden design"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "When planning a major urban transit project, why does a holistic (systemic) environmental-design approach evaluate social, economic, and ecological factors together, and how does that influence the design decisions?",
      "options": {
        "A": "It gives ecological concerns absolute priority, so social and economic consequences are largely ignored in the final plan.",
        "B": "It reveals feedbacks and trade-offs among social equity, financial viability, and ecological impacts, guiding design choices that are more resilient and adaptable over time.",
        "C": "It shortens decision timelines by reducing the number of considerations, enabling faster approvals and implementation.",
        "D": "It treats social, economic, and ecological factors as interchangeable, so optimizing one automatically optimizes the others."
      },
      "correct_answer": "B",
      "simplification_notes": "Rewrote the stem for clarity and concision, kept technical terms (holistic/systemic, feedbacks, trade-offs, resilience). Made all four options plausible and retained the original correct choice (B). Removed extraneous examples from the article while preserving core concept.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.4_vs_16",
    "pass_2_attempt": {
      "question": "You are lead designer for a 10‑block urban redevelopment (mixed residential and commercial) with the following objectives: reduce lifecycle greenhouse gas emissions by at least 50% relative to conventional development, increase local employment, improve stormwater management, and preserve biodiversity corridors. Which of the following proposed design packages best demonstrates (simultaneously) sustainability, a holistic/systemic design approach, and effective interdisciplinary collaboration?",
      "options": {
        "A": "Install rooftop solar PV on all new buildings, specify recycled steel structural systems, and provide premium market‑rate housing units; street design remains auto‑oriented with minimal pedestrian facilities. Project procurement prioritizes speed; community consultation is limited to a public notice.",
        "B": "Reorient building layouts for passive solar gains and daylighting, specify high‑performance envelopes and triple glazing, connect buildings to a low‑temperature district geothermal loop, implement green roofs, permeable pavements and on‑site stormwater wetlands, allocate 30% of residential units as affordable housing, create local workforce training tied to construction jobs, and convene a teaming structure of architects, urban planners, ecologists, sociologists, civil engineers and public‑policy advisors; lifecycle analysis projects net energy payback within $12$ years.",
        "C": "Use off‑site prefabricated concrete panels to reduce construction time and waste, incorporate a centralized natural‑gas cogeneration plant for building heating and power, include a materials recycling center, and rely on market mechanisms to deliver affordable housing with no targeted social programs; design team comprises architects and structural/civil engineers.",
        "D": "Convert half the site into restored native habitat and stormwater wetlands with wildlife corridors, restrict building footprints to the remaining area and permit only commercial development to fund the restoration; the project team is led by landscape ecologists and park designers with occasional input from a planning office but no social scientists or workforce development partners."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete redevelopment scenario and four plausible design packages that trade off environmental technologies, social equity, economic measures, and team composition. Option B integrates renewable/efficient tech, stormwater and biodiversity measures, social inclusion, and explicit interdisciplinary collaboration, matching the three target concepts.",
      "concepts_tested": [
        "Sustainability (renewable energy, energy efficiency, eco-friendly materials)",
        "Holistic/systemic design (social, economic, ecological integration)",
        "Interdisciplinary collaboration (architecture, ecology, sociology, planning, policy)"
      ]
    },
    "pass_2_reason": "readability_too_high_23.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does treating popular sovereignty as a principle rather than prescribing a single political form help explain how a non-democratic regime can still claim legitimacy?",
      "options": {
        "A": "It requires that every decision be made by direct vote of all citizens.",
        "B": "Because legitimacy rests on the governed's consent, the exact form—democratic, monarchic, or otherwise—can be justified through constitutional rules that implement or simulate that consent.",
        "C": "It eliminates all forms of constraint on rulers as long as they claim consent.",
        "D": "It ties legitimacy strictly to the presence of elections every fixed interval."
      },
      "correct_answer": "B",
      "source_article": "Popular sovereignty",
      "x": 1.145707130432129,
      "y": 0.8407421112060547,
      "concepts_tested": [
        "Concept 1: Legitimacy derives from the consent of the governed; the source of political authority is the people.",
        "Concept 2: Social contract as the mechanism by which individuals authorize governance and define limits on power (with distinctions among Hobbes, Locke, Rousseau and the idea of the general will).",
        "Concept 3: Distinction between principle and implementation; popular sovereignty as a principle that does not dictate a specific political system and may coexist with non-democratic forms or legalistic interpretations."
      ],
      "parent_concepts": [
        "Concept 1: The executive’s legitimacy and continuance depend on maintaining the confidence of a majority in the parliament (fusion of powers and accountability mechanism)."
      ],
      "parent_articles": [
        "Parliamentary system"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If popular sovereignty is treated as a general principle rather than a requirement to adopt one specific political system, how can a non‑democratic regime still claim political legitimacy?",
      "options": {
        "A": "Because popular sovereignty demands that every law be made by direct vote of all citizens (direct democracy), so only direct voting can make a government legitimate.",
        "B": "Because legitimacy is grounded in the consent of the governed, and different constitutional arrangements—including non‑democratic ones—can be justified as implementing or representing that consent.",
        "C": "Because treating it as a principle removes all constraints on rulers so any leader who asserts popular support is automatically legitimate.",
        "D": "Because popular sovereignty ties legitimacy only to holding elections at fixed intervals, so as long as elections occur the regime is legitimate."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and focused on the core causal point: principle vs. specific implementation. Removed historical detail and social contract exposition while preserving the idea that legitimacy depends on consent and can be asserted by various constitutional forms. Options were rephrased to remain plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "The Republic of Eudaimonia adopts the following constitutional provisions: (1) a preamble declares \"sovereignty resides with the people\"; (2) only male property owners may vote for the legislature; (3) an unelected Protector may suspend the legislature in emergencies; (4) the government conducts an annual state-managed plebiscite claiming to express the \"general will\"; and (5) courts are explicitly barred from overturning laws passed by the legislature. Which of the following analyses best characterizes (a) the source of legitimate political authority under the doctrine of popular sovereignty, (b) which social-contract thinker’s model the Republic most closely approximates in its use of plebiscites and an asserted \"general will,\" and (c) whether this constitutional design illustrates the distinction between the principle of popular sovereignty and its political implementation?",
      "options": {
        "A": "(a) Legitimate authority is, in principle, derived from the consent of the people; (b) the plebiscites and invocation of a \"general will\" most closely evoke Rousseau's model; (c) yes — the constitution proclaims popular sovereignty but the restricted franchise, emergency Protector, and curtailed judicial review show how the principle can be implemented in ways that fall short of full democratic consent.",
        "B": "(a) Legitimate authority resides primarily in the Protector because security trumps consent; (b) the use of plebiscites reflects Locke's model of representation; (c) no — since the Protector secures order, the distinction between principle and implementation is irrelevant.",
        "C": "(a) Because the constitution names the people as sovereign, legitimacy is fully realized regardless of electoral rules; (b) the representative legislature shows the system follows Locke; (c) no — proclaiming popular sovereignty is sufficient proof that the doctrine is implemented faithfully.",
        "D": "(a) Ultimate legitimacy derives from a divine source transferred through institutions (School of Salamanca), so popular consent is secondary; (b) the emergency powers and lack of judicial review align the regime with Hobbesian absolute sovereignty; (c) yes — the system demonstrates that popular sovereignty cannot coexist with limitations on executive power or judicial oversight."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete constitutional scenario that requires students to identify the normative source of legitimacy (consent of the governed), map institutional features to social-contract theorists (Rousseau's general will via plebiscites), and explain principle versus implementation by noting restricted franchise and emergency powers undermine democratic consent.",
      "concepts_tested": [
        "Legitimacy from consent of the governed",
        "Social contract models (Rousseau, Locke, Hobbes)",
        "Distinction between principle of popular sovereignty and its practical implementation"
      ]
    },
    "pass_2_reason": "readability_too_high_32.4_vs_16"
  },
  {
    "original_question": {
      "question": "How does context shape the effectiveness of information openness policies when balancing democratization goals with privacy and security concerns?",
      "options": {
        "A": "The policies are universally beneficial if they increase access, regardless of context.",
        "B": "The same openness policy can yield different outcomes because governance capacity, enforcement, literacy, and market incentives determine how people use, protect, or abuse shared information.",
        "C": "Openness policies always degrade privacy, so context doesn't matter.",
        "D": "Context only affects technical deployment, not social outcomes."
      },
      "correct_answer": "B",
      "source_article": "Information policy",
      "x": 1.3066989183425903,
      "y": 1.0034358501434326,
      "concepts_tested": [
        "Concept 1: Information policy as the mechanism that conditions information flow and thereby shapes decision-making, public discourse, and political activity.",
        "Concept 2: The information lifecycle (creation, collection, organization, dissemination, destruction) as a framework governed by policy decisions.",
        "Concept 3: Competing goals and trade-offs in information policy (e.g., democratization vs. commercialization, privacy vs. access, information security vs. dissemination) and how context shapes policy impact."
      ],
      "parent_concepts": [
        "Concept 3: The role of open access, rights, access economics, and disciplinary variation in shaping how scholarly work is shared and preserved.",
        "Stakeholder roles and policy-based rights: who can originate, change, distribute, or delete information; accountability and governance structures.",
        "Concept 1: Open licensing enables post-publication reuse and copying, shaping how access and distribution work (e.g., Creative Commons licenses)."
      ],
      "parent_articles": [
        "Scholarly communication",
        "Information management",
        "Open access"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does context determine whether an information openness policy advances democratization without unduly harming privacy and security?",
      "options": {
        "A": "Openness policies are always beneficial if they increase access; broader access automatically promotes democratization regardless of context.",
        "B": "The same openness policy can produce very different results because governance capacity, enforcement, user digital literacy, economic incentives, and institutional design shape how shared information is used, protected, or abused.",
        "C": "Openness policies inevitably erode privacy and weaken security, so contextual factors do not change that outcome.",
        "D": "Context only affects technical deployment (e.g., servers, protocols); it does not change the social or political consequences of openness."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified for undergraduates; retained trade-off framing (democratization vs privacy/security). Options made concise and plausible; option B kept core factors (governance, enforcement, literacy, incentives).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.6_vs_16",
    "pass_2_attempt": {
      "question": "The municipal government of Riverton adopts a new information policy with these provisions: (1) all newly created datasets on public services must include standardized metadata and be published on an open portal (creation, organization, dissemination); (2) raw operational logs are retained for 10 years to support longitudinal research (collection, destruction); (3) datasets are released under a license that permits private firms to develop and sell value‑added analytics (commercialization); and (4) anonymization is required but security auditing is limited by budget constraints (privacy, security).\n\nWhich of the following outcomes best demonstrates how this information policy conditions information flow and thereby shapes decision‑making, public discourse, and political activity, while also illustrating the key trade‑offs across stages of the information lifecycle (creation, collection, organization, dissemination, destruction)?",
      "options": {
        "A": "Accessible, well‑organized datasets enable journalists and city planners to use evidence in public debates and policy decisions; private firms build advanced analytical products that are sold behind paywalls (commercialization vs. democratization); long retention of raw logs allows valuable longitudinal studies but increases re‑identification and privacy risks, and limited security audits raise the chance of breaches—showing how lifecycle rules and trade‑offs shape who can use information and how decisions are made.",
        "B": "Because metadata and anonymization are required, all citizens gain equal access to perfect information; private firms profit but no public discourse changes, and long retention only benefits researchers without any privacy or political consequences.",
        "C": "The policy fully prevents commercialization by making all datasets public domain, so only non‑profit researchers influence decision‑making; retention of logs is irrelevant because anonymization eliminates any privacy trade‑offs and security limitations do not affect data use.",
        "D": "Standardized metadata and publication improve technical interoperability only; the policy affects technical processes in the lifecycle but cannot alter who participates in political debate or how policymakers use information, and retention and licensing have negligible social effects."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete municipal scenario that maps specific policy provisions to lifecycle stages and trade‑offs; options contrast correct integrated outcome with realistic but flawed alternatives.",
      "concepts_tested": [
        "Information policy conditions information flow and shapes decision‑making/public discourse",
        "Information lifecycle stages (creation, collection, organization, dissemination, destruction) governed by policy",
        "Competing goals and trade‑offs in information policy (democratization vs commercialization, privacy vs access, security vs dissemination)"
      ]
    },
    "pass_2_reason": "readability_too_high_33.6_vs_16"
  },
  {
    "original_question": {
      "question": "Which mechanism best captures the bidirectional influence between psychology and politics in shaping political behavior?",
      "options": {
        "A": "Policy actions reshape social norms and perceived legitimacy, altering motivation and information processing; in turn, these cognitive and motivational changes influence attitudes and demands that drive future policy.",
        "B": "Psychology deterministically drives politics in a one-way path with no feedback.",
        "C": "Politics shapes psychology solely through external environments, with no impact on cognitive processes.",
        "D": "Attitudes are fixed; political events cannot alter them."
      },
      "correct_answer": "A",
      "source_article": "Political psychology",
      "x": 1.2296180725097656,
      "y": 0.9804385304450989,
      "concepts_tested": [
        "Bidirectional relationship between psychology and politics (psychology as lens for understanding politics and politics as lens for understanding psychology)",
        "Cognitive and social mechanisms underlying political attitudes and behavior (beliefs, motivation, perception, information processing, learning, socialization, attitude formation)",
        "Contextual and group dynamics shaping political behavior (leadership, policy making, ethnic conflict, nationalism, extremism, media influence)"
      ],
      "parent_concepts": [
        "Concept 1: Partisan identity as a psychological mechanism that shapes political beliefs and behavior (not just voting history).",
        "Concept 1: Partisan identification as a psychological/identity-based allegiance that shapes political behavior beyond mere voting patterns.",
        "The interplay between individual voter attitudes and social factors in shaping voting decisions"
      ],
      "parent_articles": [
        "Partisan (politics)",
        "Partisan (politics)",
        "Voting behavior"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which description best captures the two-way (bidirectional) influence between psychological processes and political systems in shaping political behavior?",
      "options": {
        "A": "Political actions (laws, policies, rhetoric) change social norms and perceived legitimacy, which alter people's motivations, perceptions and information processing; those psychological changes then reshape attitudes and demands that influence future policy.",
        "B": "Psychology deterministically drives politics in a one-way path, with no feedback from political change to psychological processes.",
        "C": "Politics influences people only through external conditions (institutions, resources, environment) but does not change cognitive processes, motivations, or information processing.",
        "D": "Individual political attitudes are fixed and immutable; political events cannot alter them."
      },
      "correct_answer": "A",
      "simplification_notes": "Reworded the stem for clarity and concision; kept the core idea of bidirectional influence and the psychological mechanisms (motivation, perception, information processing). Answer choices were made short, plausible alternatives while retaining the original correct option.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.6_vs_16",
    "pass_2_attempt": {
      "question": "Researchers are designing comparative studies to illustrate how psychology and politics interact. Which of the following study descriptions best demonstrates (a) the bidirectional relationship between psychology and politics (psychology used to explain political processes and politics used to explain psychological processes), (b) the cognitive and social mechanisms (e.g., motivated reasoning, information processing, socialization, perception, motivation) underlying political attitudes and behavior, and (c) the contextual and group-level dynamics (e.g., leadership rhetoric, media framing, coalition behavior, policy feedback) that shape political outcomes?",
      "options": {
        "A": "A 25-year longitudinal study following 300 preschool children into adulthood, measuring early temperament and parental socialization practices at ages 3–7 and then correlating those childhood traits with political ideology at age 28. The analysis focuses on stability of traits and predictive power of early personality for later voting behavior.",
        "B": "A lab experiment where participants are randomly exposed to two different news frames about immigration (threat frame vs. economic frame). The study measures immediate shifts in perceived threat, endorsement of authoritarian policies, and support for punitive legislation, emphasizing framing effects on individual cognition.",
        "C": "A mixed-methods project combining content analysis of political leaders' speeches and mass-media campaigns, longitudinal surveys of public beliefs and motivated-reasoning measures, and time-series analysis of party platform changes. The research documents how (1) leaders deploy rhetorical frames to shape mass perceptions and motivated information processing, (2) mass changes in beliefs alter party platforms and policy decisions, and (3) group dynamics (coalition shifts, polarization, feedback from media and interest groups) in turn reshape individual psychological dispositions over time.",
        "D": "A cross-national econometric study that regresses levels of economic inequality and unemployment on the rise of nationalist parties across 40 countries, controlling for demographic and institutional variables, with conclusions focused on structural socio-economic determinants of voting for nationalism."
      },
      "correct_answer": "C",
      "generation_notes": "Created four study vignettes; option C integrates bidirectionality, cognitive/social mechanisms, and group/contextual dynamics, while A, B, and D isolate single aspects as distractors.",
      "concepts_tested": [
        "Bidirectional relationship between psychology and politics",
        "Cognitive and social mechanisms underlying political attitudes (motivated reasoning, perception, information processing)",
        "Contextual and group dynamics shaping political behavior (leadership rhetoric, media framing, coalitions, policy feedback)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.0_vs_16"
  },
  {
    "original_question": {
      "question": "Which statement best explains how the degree of dependence in a symbiotic relationship (obligate vs facultative) shapes its evolutionary stability and trajectory?",
      "options": {
        "A": "In obligate symbiosis, the partners rely on each other for survival, so natural selection strongly favors maintaining the interaction, promoting co-evolution and potential integration; in facultative symbiosis, independent survival weakens selection for cooperation, making the association more labile and less likely to become tightly integrated.",
        "B": "In facultative symbiosis, the relationship is evolutionarily more stable because both partners can survive without each other, ensuring consistent mutual benefit.",
        "C": "Obligate symbiosis evolves only when one partner completely dominates the other, eliminating the possibility of co-evolution or integration.",
        "D": "The degree of dependence has limited impact on evolutionary outcomes; changes in environmental availability of partners are the primary drivers of stability."
      },
      "correct_answer": "A",
      "source_article": "Symbiosis",
      "x": 1.8178740739822388,
      "y": 1.0886904001235962,
      "concepts_tested": [
        "Concept 1: Obligate vs facultative symbiosis and how dependence influences stability and evolution of the relationship",
        "Concept 2: The spectrum of interspecies interactions (parasitism, mutualism, commensalism, competition, amensalism) and their differential fitness effects",
        "Concept 3: Endosymbiosis vs. ectosymbiosis and the role of intimate intracellular partnerships in major evolutionary transitions (e.g., symbiogenesis)"
      ],
      "parent_concepts": [
        "Theoretical frameworks and broad outcomes of coevolution (e.g., geographic mosaic theory; impacts on diversification, major evolutionary transitions, mutualisms, host–parasite and disease dynamics)",
        "Concept 3: The host–parasite relationship as a continuum (parasitism, predation, mutualism, saprophytism) and how transmission strategies and host specificity shape coevolution and outcomes for both parasite and host.",
        "Concept 1: The spectrum of host–symbiont relationships (parasitism, commensalism, mutualism) and how their effects on host and symbiont define the relationship type.",
        "Concept 2: Diverse symbiotic relationships (mutualism, commensalism, amensalism, parasitism) have specific ecological outcomes for participants."
      ],
      "parent_articles": [
        "Coevolution",
        "Parasitism",
        "Host (biology)",
        "Microbial ecology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the degree of partner dependence in a symbiotic relationship (obligate vs facultative) influence its evolutionary stability and likely evolutionary trajectory?",
      "options": {
        "A": "Obligate symbiosis—where partners require each other to survive—creates strong selection to maintain the interaction, promoting co-evolution and potential physiological or genomic integration; facultative symbiosis—where partners can survive independently—reduces selection for tight cooperation, making the association more labile and less likely to become integrated.",
        "B": "Facultative symbiosis is evolutionarily more stable because each partner's ability to survive alone buffers the relationship against partner loss, producing consistent mutual benefits without driving tighter integration.",
        "C": "Obligate symbiosis only evolves when one partner completely dominates the other; such dominance prevents reciprocal co-evolution or integration and fixes the relationship as one-sided.",
        "D": "The degree of dependence has little effect on evolutionary outcomes; instead, external environmental changes in partner availability primarily determine whether a symbiosis is stable or breaks down."
      },
      "correct_answer": "A",
      "simplification_notes": "Clarified the question and definitions (obligate vs facultative), shortened phrasing, removed extended examples, and made distractors plausible while preserving the original correct answer and core concepts about selection, co-evolution, and integration.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.6_vs_16",
    "pass_2_attempt": {
      "question": "Consider three interspecific associations observed in a field study: (i) a reef cnidarian host X contains photosynthetic dinoflagellates Y inside its tissues; X cannot survive without Y, whereas Y has free-living populations in surrounding water; (ii) a grazing mammal Z hosts bacterial species W in its digestive tract that help digest cellulose, but W can also persist in soil when shed; (iii) human head lice L live on the scalp surface and intermittently feed on blood. Which one of the following statements correctly classifies these interactions and describes their expected evolutionary consequences?",
      "options": {
        "A": "(i) is endosymbiosis that is obligate for X but facultative for Y; intracellular partners like Y are prone to genome reduction and accumulation of deleterious mutations (Muller’s ratchet), increasing host–symbiont co-dependence and enabling long-term symbiogenetic transitions. (ii) is a facultative, mutualistic ectosymbiosis in the digestive tract that enhances host digestion and competitive ability but can be lost when environmental reservoirs of W exist. (iii) is ectosymbiotic parasitism that reduces host fitness.",
        "B": "(i) is a facultative ectosymbiosis (because Y can live free); neither partner is obligate, and intracellular localization protects Y from genome reduction. (ii) is an obligate endosymbiosis because gut bacteria live inside the animal; W cannot survive without Z. (iii) is commensalism because lice cause negligible fitness effects in modern humans.",
        "C": "(i) is endosymbiosis obligate for both partners, so Y will not be found free-living; such intracellular symbionts typically evolve increased genome size due to horizontal gene transfer from the host. (ii) is a parasitic interaction because digestion assistance by W is a cost to Z. (iii) is amensalism because lice are unaffected while the human host is harmed.",
        "D": "(i) should be classified as ectosymbiosis because photosymbionts are external to host cells; such relationships cannot drive major evolutionary transitions like symbiogenesis. (ii) is mutualism but always obligate for the host; loss of W would always be lethal to Z. (iii) is mutualism because lice stimulate immune defenses that benefit humans."
      },
      "correct_answer": "A",
      "generation_notes": "Created an integrated scenario testing obligate vs facultative, endo- vs ectosymbiosis, fitness effects across the interaction spectrum, and evolutionary consequences (genome reduction, Muller's ratchet, symbiogenesis). Distractors invert classifications or misstate evolutionary predictions.",
      "concepts_tested": [
        "Obligate versus facultative dependence and its evolutionary stability",
        "Spectrum of interspecies interactions (mutualism, parasitism, commensalism, amensalism) and fitness effects",
        "Endosymbiosis versus ectosymbiosis and role of intracellular partnerships in genome reduction and major evolutionary transitions (symbiogenesis)"
      ]
    },
    "pass_2_reason": "readability_too_high_24.5_vs_16"
  },
  {
    "original_question": {
      "question": "In computational science, why does discretizing a continuous system into a numerical model allow researchers to study complex phenomena, and how do choices of discretization influence the results?",
      "options": {
        "A": "Discretization turns the governing equations into solvable algebraic problems with guaranteed exactness independent of resolution.",
        "B": "Discretization converts the continuous equations into a finite set of approximate equations that can be solved on a computer; the discretization resolution and time stepping control accuracy, stability, and cost, creating a trade-off between fidelity and compute time.",
        "C": "Discretization eliminates all ill-posedness in a problem, ensuring unique solutions when the original continuous problem was unsolvable.",
        "D": "Discretization yields faster results but introduces no error because modern processors compute with perfect precision."
      },
      "correct_answer": "B",
      "source_article": "Computational science",
      "x": 1.5797722339630127,
      "y": 1.0887519121170044,
      "concepts_tested": [
        "Concept 1: Computational science uses mathematical models and computer simulations to solve complex problems, complementing theory and experiments.",
        "Concept 2: The methodology involves defining a system, designing data-extracting experiments, and using models to answer questions about the system.",
        "Concept 3: The field relies on numerical analysis, computational mathematics, and high-performance computing to perform large-scale calculations (often on supercomputers)."
      ],
      "parent_concepts": [
        "Concept 3: HPC as an enabler of data analytics and AI-driven simulations, enabling what-if analyses and advanced modeling across scientific and engineering domains.",
        "The role of computational chemistry as a complement to experimental data and its potential to predict new chemical phenomena."
      ],
      "parent_articles": [
        "High-performance computing",
        "Computational chemistry"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In computational science, why does discretizing a continuous system into a numerical model let researchers study complex phenomena, and how do choices of discretization (spatial resolution and time step) influence the computed results?",
      "options": {
        "A": "Discretization turns the continuous governing equations into algebraic equations that can be solved exactly by a computer, so results are independent of grid resolution.",
        "B": "Discretization converts the continuous equations into a finite set of approximate equations that can be solved on a computer; spatial resolution and time-step size control accuracy, numerical stability, and computational cost, creating a trade-off between fidelity and runtime.",
        "C": "Discretization removes ill-posedness from problems, guaranteeing unique and well-behaved solutions even when the original continuous problem lacked existence or uniqueness.",
        "D": "Discretization allows much faster computation but introduces no error, because modern processors and floating-point arithmetic compute with perfect precision."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the original multi-sentence question into a single clear undergraduate-level question; specified 'spatial resolution and time step' and used technical terms (accuracy, stability, cost) while keeping the original correct answer and preserving alternatives as plausible misconceptions.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.6_vs_16",
    "pass_2_attempt": {
      "question": "A research group wants to use computational science to study heat diffusion on a rectangular plate subject to a time‑varying boundary temperature. Which workflow sequence best exemplifies the computational‑science approach (complementing theory and laboratory experiments) and correctly uses mathematical modeling, numerical analysis, and high‑performance computing?",
      "options": {
        "A": "Define the system and computational experiment (specify geometry, initial/boundary conditions); derive a mathematical model (heat equation); discretize the model (mesh with cell size $h$, time step $\\Delta t$), select numerical methods and analyze stability/error; choose and configure suitable HPC infrastructure (parallelization, MPI/GPU) and optimized libraries; run large simulations, validate results against lab measurements, then refine the model and repeat.",
        "B": "Perform laboratory measurements first to obtain all data; fit an empirical curve and publish results; if more precision is required, later derive a mathematical model from the data but do not use parallel computing—small serial codes suffice for verification.",
        "C": "Derive an analytical solution from theory for all boundary conditions; since the theory is exact, implement a minimal prototype on a workstation and report the analytic predictions without numerical validation or mesh discretization.",
        "D": "Directly run high‑resolution simulations on a supercomputer using a generic solver and default parameters; accept the simulation outputs as ground truth and design laboratory experiments only if discrepancies are suspected."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete heat‑diffusion scenario and provided four plausible workflow sequences; option A encodes the computational‑science cycle: define system/experiment, model, discretize/numerical analysis, choose HPC, simulate, validate, iterate.",
      "concepts_tested": [
        "computational science uses mathematical models and simulations to complement theory and experiments",
        "methodology: define system, design experiments to extract data, use models to answer questions and iterate",
        "reliance on numerical analysis and high‑performance computing for large‑scale calculations"
      ]
    },
    "pass_2_reason": "readability_too_high_20.2_vs_16"
  },
  {
    "original_question": {
      "question": "Why does translating a scientific problem into a mathematical model and numerical algorithm enable understanding of the system, and what ensures that the understanding is meaningful?",
      "options": {
        "A": "Because computers can simulate any system exactly if the code is correct, yielding direct, guaranteed truth about reality.",
        "B": "Because a mathematical model captures essential mechanisms with testable assumptions, and numerical algorithms approximate the model’s behavior; meaningful understanding comes from the model’s validity, discretization accuracy, and the link between inputs and outputs.",
        "C": "Because hardware speed alone guarantees insight; more computing power always yields deeper understanding regardless of the model.",
        "D": "Because analytic solutions provide perfect reflections of reality, and numerical methods merely serve as a decorative check against those solutions."
      },
      "correct_answer": "B",
      "source_article": "Computational science",
      "x": 1.503164529800415,
      "y": 1.0774340629577637,
      "concepts_tested": [
        "Concept 1: Computational science as a third mode of science that complements experimentation and theory, using a framework of system (S), experiment (E), and model (M) to answer questions about S.",
        "Concept 2: The core mechanism of computational science—the translation of scientific problems into mathematical models and numerical algorithms implemented on computers to obtain understanding via simulations.",
        "Concept 3: The role of computing infrastructure (high-performance computing, software, data management) and massive computations (often on supercomputers or distributed platforms) in solving complex problems."
      ],
      "parent_concepts": [
        "Concept 3: HPC as an enabler of data analytics and AI-driven simulations, enabling what-if analyses and advanced modeling across scientific and engineering domains.",
        "The role of computational chemistry as a complement to experimental data and its potential to predict new chemical phenomena."
      ],
      "parent_articles": [
        "High-performance computing",
        "Computational chemistry"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does translating a scientific problem into a mathematical model and a numerical algorithm let us understand the system, and what makes that understanding trustworthy (in the context of model $M$, system $S$, and experiment $E$)?",
      "options": {
        "A": "Because a correct program running on a computer can simulate any real system exactly, so a successful run gives direct, guaranteed truth about reality.",
        "B": "Because the mathematical model $M$ encodes the essential mechanisms with explicit, testable assumptions and the numerical algorithm approximates $M$’s behavior on available computing infrastructure (e.g., HPC); the understanding is meaningful when $M$ is validated against data, discretization and solver errors are controlled, and the mapping from inputs to outputs is well characterized.",
        "C": "Because raw computing power alone guarantees insight: faster hardware and larger simulations always produce deeper, more reliable understanding regardless of the model formulation.",
        "D": "Because closed‑form analytic solutions are the only perfect representations of reality, and numerical algorithms are useful only as a secondary check against those exact solutions."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the question, introduced notation $M$, $S$, $E$ succinctly, emphasized model validity, numerical accuracy, and computing infrastructure; language made more direct while preserving the original concepts.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.7_vs_16",
    "pass_2_attempt": {
      "question": "You are a computational scientist asked to estimate the probability that peak pollutant concentration in a downtown area will exceed a regulatory threshold within 24 hours after an accidental release. Using the computational-science (third-mode) framework that treats a real-world system S, an experiment E, and a model M, which of the following plans best exemplifies the correct computational-science approach (model construction, numerical algorithm, and computing infrastructure) to obtain a validated, predictive statement?",
      "options": {
        "A": "Treat S as the actual urban area; construct M as a mathematical model (e.g., the advection–diffusion PDE $\\partial_t c + \\nabla\\cdot(\\mathbf{u}c)=D\\nabla^2 c+S(t,x)$ with source term, boundary/initial conditions and uncertain parameters); design E as a set of in silico experiments (Monte Carlo sampling of uncertain inputs and parameter sweeps) implemented with a finite-volume discretization and a parallel solver; execute ensembles on high-performance computing (MPI/GPU) to obtain probability distributions (floating-point intensive); validate simulation outputs against sensor data and iteratively adjust M until validation criteria are met.",
        "B": "Formulate M purely by analytical theory to derive a closed-form expression for peak concentration, then publish the result; because theory gives exact solutions there is no need for numerical discretization, large-scale computation, or comparison with measurements.",
        "C": "Ignore mathematical modeling and instead perform a field campaign (laboratory-scale releases and sensor measurements) at various city locations; use those experimental measurements alone to estimate the 24-hour exceedance probability without constructing an executable model or performing large numerical computations.",
        "D": "Build M as a single coarse-grid numerical simulation on a laptop using a simple finite-difference code, run one deterministic scenario with nominal parameter values, and take that single simulation output as the definitive predictive probability for the 24-hour exceedance."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete urban pollutant-dispersion scenario to test understanding of S/E/M framework, translation to PDE-based mathematical model and numerical algorithms, and the necessity of HPC and validation/iteration in computational science.",
      "concepts_tested": [
        "Computational science as third mode of science using system (S), experiment (E), and model (M)",
        "Translation of scientific problems into mathematical models and numerical algorithms implemented as simulations",
        "Role of computing infrastructure (HPC, parallel solvers, floating-point computations) and validation in producing predictive results"
      ]
    },
    "pass_2_reason": "readability_too_high_23.2_vs_16"
  },
  {
    "original_question": {
      "question": "How does adopting a critical approach to studying language ideology change what we infer about beliefs about language and their relation to social structures, compared to a neutral approach?",
      "options": {
        "A": "It treats beliefs as uniform within a culture, assuming little variation and no connection to power.",
        "B": "It foregrounds how beliefs about language function to rationalize and reproduce power relations, linking language beliefs to social hierarchies and policy.",
        "C": "It ignores political interests and focuses solely on cognitive processes behind language use.",
        "D": "It views ideologies as purely symbolic with no influence on everyday social action or policy decisions."
      },
      "correct_answer": "B",
      "source_article": "Language ideology",
      "x": 1.2357733249664307,
      "y": 1.078459620475769,
      "concepts_tested": [
        "Language ideologies are cluster concepts with multiple, overlapping dimensions that connect beliefs about language to broader social, political, and moral interests.",
        "There is variation in language ideologies across cultural groups, and attempting to treat them as homogeneous is analytically problematic; recognizing variation is essential.",
        "Neutral vs. critical approaches shape how ideologies are studied and reveal how language beliefs relate to social structures, power, and policy."
      ],
      "parent_concepts": [
        "The three components of language policy: language practices, language beliefs/ideology, and language intervention/planning, and how they interact to shape outcomes"
      ],
      "parent_articles": [
        "Language policy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Compared with a neutral approach (which treats a single, shared language ideology as representative of a community), how does a critical approach alter what we infer about beliefs about language and their relation to social structures and power?",
      "options": {
        "A": "It treats beliefs as uniform within a culture, assuming little internal variation and disconnecting them from relations of power.",
        "B": "It emphasizes how beliefs about language function to rationalize and reproduce power relations, linking language ideologies to social hierarchies and language policy.",
        "C": "It ignores political and moral interests and focuses narrowly on individual cognitive processes that underlie language use.",
        "D": "It regards ideologies as only symbolic representations without consequences for everyday social actions or institutional policies."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified contrast by briefly defining the neutral approach, tightened wording to focus on inferences about variation, power, and policy, and removed concrete ethnographic examples to keep the question concise.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.3_vs_16",
    "pass_2_attempt": {
      "question": "You are designing a comparative ethnographic study of language beliefs in two neighboring communities: Riverdale, where local schools and religious institutions promote a single 'standard' idiom described by residents as linguistically 'proper' and morally prestigious, and Harborview, where speakers routinely code-switch and valorize bilingual repertoires for social mobility. A national policy-maker reads your interim field notes and proposes a single nationwide standard-language policy, arguing that your observations show a unified community ideology. Which research conclusion or policy recommendation most accurately reflects (a) the characterization of language ideologies as a cluster concept linking linguistic beliefs to broader social, political, and moral interests, (b) attention to intracultural and intercultural variation (avoiding an analytically problematic homogenizing claim), and (c) a critical approach that situates ideological statements within relations of power and policy?",
      "options": {
        "A": "Recommend implementing the national standard-language policy immediately, arguing that the apparent prestige of the 'proper' idiom in Riverdale shows a single, coherent ideology that should be extended to all communities to promote social unity.",
        "B": "Conclude that differences in Riverdale and Harborview are purely reflections of underlying linguistic structure and cognitive constraints, so policy should focus on teaching the grammatical norms of the dominant variety without examining social institutions.",
        "C": "Advise a nuanced response: document the multiple, overlapping ideological dimensions in each community (status, morality, educational access), map intra- and intercommunity variation in beliefs and practices, and analyze how local institutions and state policy reproduce or challenge power; propose pluralistic policy options that acknowledge linguistic diversity rather than imposing a homogenizing standard.",
        "D": "Produce a descriptive ethnography that records Riverdale's self-reported 'proper' usage as the community's ideology and recommend that scholars and policy-makers treat this single account as representative, postponing analysis of policy effects until further archival work is available."
      },
      "correct_answer": "C",
      "generation_notes": "Created a comparative ethnographic scenario where correct option emphasizes language ideology as a cluster concept, the necessity of recognizing variation, and a critical orientation toward power and policy; distractors reflect neutral/homogenizing and structural-only positions.",
      "concepts_tested": [
        "language ideology as a cluster concept linking beliefs to social/political/moral interests",
        "importance of recognizing intracultural and intercultural variation versus homogenizing claims",
        "distinction between neutral and critical approaches and implications for power and language policy"
      ]
    },
    "pass_2_reason": "readability_too_high_28.0_vs_16"
  },
  {
    "original_question": {
      "question": "How do formal ontologies like the Gene Ontology enable cross-species data integration and computational reasoning in bioinformatics, and what principle makes this possible?",
      "options": {
        "A": "By attaching species-specific identifiers to each gene so that data from different organisms can be merged directly.",
        "B": "By enforcing a strict, tree-like hierarchy that ranks all biological terms from most general to most specific, ensuring a single path for inference.",
        "C": "By providing a shared, machine-readable vocabulary with formally defined relations (e.g., is_a, part_of, regulates) that allow data annotated with the same terms to be integrated and reasoned about across species.",
        "D": "By encoding all detailed causal mechanisms of every process, so that any observation can be deduced from the ontology alone."
      },
      "correct_answer": "C",
      "source_article": "Philosophy of biology",
      "x": 0.9554840922355652,
      "y": 1.0487185716629028,
      "concepts_tested": [
        "Concept 1: Reductionism vs. autonomy in biology — whether biological phenomena can (or should) be fully reduced to chemistry/physics and what that implies for scientific explanations.",
        "Concept 2: Ontologies and formal frameworks in biology — how conceptual tools like the Gene Ontology organize biological knowledge and support reasoning in bioinformatics.",
        "Concept 3: Interdisciplinary relationships — how philosophy of biology engages with ethics, epistemology, and metaphysics, and how these relationships influence scientific practice and societal values."
      ],
      "parent_concepts": [
        "Concept 3: The modern synthesis as an integrated framework and evo-devo as an expansion that connects development with genetics, ecology, and other evolutionary disciplines."
      ],
      "parent_articles": [
        "Evolutionary biology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do formal ontologies such as the Gene Ontology allow experimental annotations from different species to be combined and enable computational reasoning, and what principle makes this possible?",
      "options": {
        "A": "By assigning species-specific identifiers to every gene so datasets from different organisms can be merged directly.",
        "B": "By enforcing a strict tree-like hierarchy that orders all biological terms from most general to most specific, providing one unique path for inference.",
        "C": "By providing a shared, machine-readable controlled vocabulary with formally defined relations (for example, is_a, part_of, regulates) so that annotations are species-neutral graph representations and can be integrated and logically reasoned about across species.",
        "D": "By encoding every detailed causal mechanism of all biological processes so that any observation can be deduced from the ontology alone."
      },
      "correct_answer": "C",
      "simplification_notes": "Wording was tightened for clarity and concision; retained technical terms (e.g., \"machine-readable controlled vocabulary\", \"formally defined relations\"); emphasized the species-neutral graph representation as the enabling principle. Distractors were kept plausible but corrected to avoid factual accuracy.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "A multinational research consortium sequences a novel bacterial pathogen and uses the Gene Ontology (GO) to annotate thousands of genes. A molecular research group identifies a GO-annotated gene predicted to encode a virulence factor; they propose using CRISPR to knock it out in vitro and, later, to design a targeted phage therapy. An ecological research group objects, arguing that organismal history, gene regulation, and ecosystem interactions make outcomes unpredictable, and public health ethicists warn that deploying a genetic intervention has social and moral consequences. Which philosophical position best reconciles the practical utility of molecular-level interventions, the methodological autonomy of higher-level biological explanations, and the role of formal ontologies like GO in guiding but not dictating ethical decision-making?",
      "options": {
        "A": "Accept molecular explanations and formal ontologies as indispensable tools for identifying mechanisms (e.g., GO annotations can prioritize candidate genes), while also recognizing that biological organization, historical contingency, and emergent system-level properties create legitimate methodological autonomy; therefore GO is a pragmatic, species-neutral formalism that supports reasoning but does not eliminate the need for ecological validation and ethical deliberation before deployment.",
        "B": "Adopt strict reductionism: because all biological processes ultimately supervene on chemistry and physics, GO annotations offer a direct map to molecular mechanisms that justify immediate genetic intervention; ethical concerns are secondary and may be resolved once the molecular facts are established.",
        "C": "Adopt radical holism: molecular details and ontologies like GO are of little value because only ecosystem-level descriptions can explain outcomes; interventions based on gene-level data should be rejected because higher-level properties cannot be inferred from molecular annotations.",
        "D": "Treat ontologies like GO as providing objective, metaphysical truths about biological kinds such that their graph-theoretical relations alone determine both scientific explanation and policy; once GO indicates a virulence function, intervention is morally and epistemically mandated without further philosophical or ecological analysis."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete pathogen annotation vignette to probe tensions among reductionism, autonomy of biology, and the pragmatic/formal role of ontologies, then created four plausible philosophical stances with one balanced synthesis as correct.",
      "concepts_tested": [
        "Reductionism vs. autonomy of biology",
        "Ontologies and formal frameworks in biology (Gene Ontology)",
        "Interdisciplinary relationships between philosophy, ethics, and scientific practice"
      ]
    },
    "pass_2_reason": "readability_too_high_21.7_vs_16"
  },
  {
    "original_question": {
      "question": "In pharmacovigilance, why is it generally inappropriate to claim a definitive causal link between a drug and an adverse event based on a single report, and how is causality typically established?",
      "options": {
        "A": "Because a single report establishes causality if the event is severe, so no further evidence is needed.",
        "B": "Because causality is proven only by randomized controlled trials; pharmacovigilance disregards case data for decisions.",
        "C": "Because causality is inferred probabilistically using multiple lines of evidence (temporality, dose-response, dechallenge/rechallenge, consistency across reports, and biological plausibility) and signals are evaluated in aggregate before confirmation.",
        "D": "Because only immunologically mediated events can be causally linked; all others require mechanistic proof."
      },
      "correct_answer": "C",
      "source_article": "Pharmacovigilance",
      "x": 1.3991872072219849,
      "y": 0.9291303157806396,
      "concepts_tested": [
        "Concept 1: Safety signal identification and risk mitigation as central principles of pharmacovigilance.",
        "Concept 2: Mechanisms and causal relationships of adverse drug reactions (pharmacological, immunological, idiosyncratic) and the idea that causality can be suspected or established.",
        "Concept 3: Data flow and regulatory relationships in pharmacovigilance (reports from patients/healthcare providers/literature informing regulatory submission and ongoing safety data collection)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is it normally inappropriate to assert a definite causal link between a drug and an adverse event based on a single case report, and how is causality usually established in pharmacovigilance?",
      "options": {
        "A": "Because a single, severe report is sufficient to prove causality—if the event is serious the report alone justifies action.",
        "B": "Because only randomized controlled trials can prove causality, so pharmacovigilance case reports are ignored for causal decisions.",
        "C": "Because causality is inferred probabilistically from multiple lines of evidence (temporality, dose–response, dechallenge/rechallenge, consistency across reports, and biological plausibility); signals come from aggregated data and are then investigated before confirmation.",
        "D": "Because only immunologically mediated adverse events can be causally linked to a drug; non‑immunological events always require full mechanistic proof before any causal claim."
      },
      "correct_answer": "C",
      "simplification_notes": "Question shortened and clarified for undergraduates; retained pharmacovigilance terminology (signal, temporality, dechallenge/rechallenge, biological plausibility) and focused on why single reports are weak evidence and how aggregate, multi‑factor evaluation establishes causality.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.6_vs_16",
    "pass_2_attempt": {
      "question": "Drug X, approved 6 weeks ago for rheumatoid arthritis, has generated the following safety information: 12 spontaneous reports of deep vein thrombosis (DVT) and 3 reports of pulmonary embolism (PE) received by the marketing authorisation holder (MAH) within 3 months; one fatal PE; two reports document positive dechallenge and subsequent positive rechallenge; several cases involve concomitant risk factors (oral contraceptives, active cancer); a 3-case published case series describes similar events; and one SUSAR from an ongoing clinical trial describes a life‑threatening PE. According to core pharmacovigilance principles (signal detection, causality assessment, and regulatory reporting), which of the following best describes the appropriate immediate classification of this finding and the most appropriate next steps?",
      "options": {
        "A": "Classify the cluster as an unconfirmed safety signal (serious and potentially drug-related but not yet causally established). Triage all cases as serious and submit expedited individual case safety reports (ICSRs) to the regulator (where applicable within $7$-$15$ calendar days for life‑threatening/fatal unlisted events). Perform a formal signal assessment using dechallenge/rechallenge information and case quality, review confounders, initiate an observational pharmacoepidemiologic study (retrospective cohort or case‑control) to compare VTE incidence versus background rates, update the Risk Management Plan (RMP) and PBRER/DSUR as appropriate, and communicate preliminary findings to healthcare professionals while awaiting further data before making definitive label changes or market actions.",
        "B": "Refute the signal because multiple patients had alternative risk factors (OCP use, cancer); therefore no expedited regulatory reports are required and the MAH should simply aggregate the cases into the next periodic safety update report (PSUR) without immediate further investigation.",
        "C": "Treat the data as confirming causality (two positive rechallenges and literature cases are sufficient) and immediately request regulator-driven strong risk minimisation (market withdrawal or compulsory REMS) and halt marketing until causality is definitively proven by randomized controlled trials.",
        "D": "Consider these events as adverse events unrelated to drug exposure (not ADRs). Code all verbatim terms to the MedDRA Preferred Term 'Venous thromboembolism' and defer any communication or epidemiologic investigation until at least 12 additional reports are received; include the dataset only in the next routine aggregate periodic report."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic post‑marketing scenario that requires applying PV concepts (signal detection and classification, causality assessment with dechallenge/rechallenge and confounders, regulatory data flow and expedited reporting, and next‑step investigations such as pharmacoepidemiology and RMP/PBRER updates). Option A aligns with guideline‑based PV practice; distractors violate reporting or evidentiary principles.",
      "concepts_tested": [
        "Safety signal identification and appropriate risk‑mitigation steps",
        "Mechanisms and causal assessment of adverse drug reactions (dechallenge/rechallenge, confounders)",
        "Data flow and regulatory reporting requirements (ICSRs, expedited reporting, aggregate reports, RMP/PBRER)"
      ]
    },
    "pass_2_reason": "readability_too_high_30.3_vs_16"
  },
  {
    "original_question": {
      "question": "Why does bioethics rely on integrating insights from life sciences, medicine, law, philosophy, theology, and politics rather than relying on a single discipline when evaluating a controversial medical technology?",
      "options": {
        "A": "It imposes a single, authoritative moral framework by reconciling all disciplines into one rule.",
        "B": "It helps reveal ethical considerations that arise at the intersection of science, law, policy, and culture, which would be missed if only one discipline were considered.",
        "C": "It primarily serves to bureaucratize medical decision-making by multiplying review bodies.",
        "D": "It prioritizes theological doctrine over empirical medical evidence."
      },
      "correct_answer": "B",
      "source_article": "Bioethics",
      "x": 1.2023087739944458,
      "y": 0.9897173643112183,
      "concepts_tested": [
        "Concept 1: Interdisciplinary integration — bioethics connects life sciences, medicine, politics, law, theology, and philosophy to analyze ethical issues.",
        "Concept 2: Normative purpose — bioethics aims to discern what is morally good or bad in health, medical practice, and related technologies, guiding policy and practice.",
        "Concept 3: Scope and boundaries — there is debate over how broad bioethics should be (all questions in biology/medicine) versus more limited scopes (specific treatments or technologies), and what kinds of actions warrant moral evaluation (e.g., all actions affecting organisms capable of feeling fear)."
      ],
      "parent_concepts": [
        "Concept 3: The ethical requirement for a favorable risk–benefit ratio in medical research and the idea of proportionality between the importance of the objective and the risk to subjects, as reflected in the Helsinki Declaration and CONSORT statements.",
        "Ethical oversight and risk-benefit assessment as gatekeepers for trial approval",
        "Concept 2: The role of ethics and oversight (Declaration of Helsinki, IRBs) in human medical research and why ethical considerations shape study design and conduct.",
        "The central role of ethics and oversight (Declaration of Helsinki, IRBs) in conducting human medical research.",
        "Concept 2: Ethical basis for welfare (sentience and moral consideration) and how this premise guides treatment and policy.",
        "Ethics governance mechanisms (codes like the Nuremberg Code, Declaration of Helsinki, Belmont Report; ethics committees) shaping responsible research",
        "Non-directive genetic counseling as a guiding principle to promote informed, autonomous decisions, shaped by historical context.",
        "Concept 2: The ethical principle primum non nocere (do no harm) shaping safety practice.",
        "Concept 1: Technology-enabled enhancement to overcome human limitations (longevity, cognition, well-being) and the associated ethical evaluation of benefits versus dangers."
      ],
      "parent_articles": [
        "Risk–benefit ratio",
        "Clinical trial",
        "Medical research",
        "Medical research",
        "Animal welfare",
        "Research ethics",
        "Genetic counseling",
        "Patient safety",
        "Transhumanism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does bioethics combine insights from life sciences, medicine, law, philosophy, theology, and politics instead of using just one discipline to evaluate a controversial medical technology?",
      "options": {
        "A": "To create a single, authoritative moral rule by reconciling all disciplines into one unified framework.",
        "B": "To reveal ethical issues that appear at the intersections of science, law, policy, and culture—issues that would be missed if only one discipline were used.",
        "C": "To bureaucratize medical decision‑making by increasing the number of review bodies and committees involved.",
        "D": "To prioritize theological doctrine above empirical medical evidence when resolving ethical questions."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was condensed to a single clear question for undergraduates; technical list of disciplines preserved; distractors made plausible criticisms but kept the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "Which of the following vignettes best captures the core character of contemporary bioethics — its interdisciplinary integration, its normative aim of adjudicating what is morally permissible in health and biotechnology to guide policy and practice, and its contested scope about whether moral evaluation should extend beyond strictly clinical interventions to actions affecting organisms capable of suffering?",
      "options": {
        "A": "A national advisory panel composed of clinicians, molecular biologists, lawyers, philosophers, religious leaders, and patient advocates convenes to draft binding policy on human germline gene editing; the panel evaluates scientific risks, legal obligations, theological objections, distributive justice implications, and whether protections should be extended to nonhuman organisms judged capable of fear.",
        "B": "An intensive-care unit ethics committee made up solely of attending physicians and nurses meets to decide whether to withdraw life support from a single terminal patient based strictly on clinical prognosis and hospital protocol, without consulting outside disciplines or considering broader social policy.",
        "C": "A university genetics laboratory optimizes a CRISPR protocol for crop pest resistance, publishes methodological improvements in a technical journal, and develops safety checklists for bench practice, with no public deliberation about the permissibility of the technology or its societal impacts.",
        "D": "A moral philosopher publishes an abstract treatise arguing that personhood grounds absolute moral worth and that human life is inviolable, but the work contains no engagement with clinical cases, empirical science, law, or the practical design of health policy."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed four concrete vignettes contrasting full bioethical practice (interdisciplinary, normative, scope-sensitive) with narrower activities (clinical-only, technical research, abstract philosophy). Chose the panel scenario as the only one satisfying all three target concepts.",
      "concepts_tested": [
        "Interdisciplinary integration",
        "Normative purpose and policy guidance",
        "Scope and boundaries of bioethical evaluation (including organisms capable of suffering)"
      ]
    },
    "pass_2_reason": "readability_too_high_32.2_vs_16"
  },
  {
    "original_question": {
      "question": "Why is informed consent best understood as an ongoing, context-sensitive process rather than a one-time agreement, and how does this mechanism safeguard autonomy, particularly for vulnerable populations?",
      "options": {
        "A": "Because autonomy is fixed at the moment of signing, so ongoing processes merely document what was already decided.",
        "B": "Because genuine autonomy requires ongoing understanding, voluntary participation, and the ability to withdraw, and for vulnerable populations, additional protections (e.g., simplified information, assent, or surrogate decision-making) help ensure decisions reflect the person’s values and best interests.",
        "C": "Because consent is primarily a legal formality that shields researchers from liability regardless of participant understanding.",
        "D": "Because once consent is obtained, researchers can modify study procedures without rechecking participant preferences."
      },
      "correct_answer": "B",
      "source_article": "Research ethics",
      "x": 1.2127914428710938,
      "y": 0.9456058144569397,
      "concepts_tested": [
        "Informed consent and participant autonomy (including protections for vulnerable populations)",
        "Governance mechanisms: ethics codes (Nuremberg Code, Helsinki, Belmont Report) and ethics review committees to regulate conduct and reduce misconduct",
        "Evolution and relationship of medical ethics to bioethics and research ethics, and how historical cases shaped contemporary frameworks"
      ],
      "parent_concepts": [
        "Concept 3: The ethical requirement for a favorable risk–benefit ratio in medical research and the idea of proportionality between the importance of the objective and the risk to subjects, as reflected in the Helsinki Declaration and CONSORT statements.",
        "Ethical oversight and risk-benefit assessment as gatekeepers for trial approval",
        "Concept 2: The role of ethics and oversight (Declaration of Helsinki, IRBs) in human medical research and why ethical considerations shape study design and conduct.",
        "The central role of ethics and oversight (Declaration of Helsinki, IRBs) in conducting human medical research."
      ],
      "parent_articles": [
        "Risk–benefit ratio",
        "Clinical trial",
        "Medical research",
        "Medical research"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is informed consent best treated as an ongoing, context-sensitive process rather than a one-time signature, and how does that practice protect participant autonomy, especially for vulnerable populations?",
      "options": {
        "A": "Because participant autonomy is fixed at the moment of signing, so further discussion only documents the original choice.",
        "B": "Because genuine autonomy requires continuing comprehension, voluntary participation, and the right to withdraw; for vulnerable populations, additional protections (e.g., simplified explanations, assent procedures, or surrogate decision‑makers) help ensure decisions reflect the person’s values and best interests.",
        "C": "Because consent is primarily a legal formality that shields researchers from liability even if participants do not fully understand or cannot change their decision.",
        "D": "Because once consent is obtained, researchers may modify study procedures without rechecking participants’ preferences, making the initial agreement sufficient."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was shortened and clarified for undergraduate readers; retained the key idea that consent must be ongoing and context-sensitive to protect autonomy, and kept concrete examples of additional protections for vulnerable groups (simplified information, assent, surrogates).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.4_vs_16",
    "pass_2_attempt": {
      "question": "An American university and a pharmaceutical company propose a Phase II vaccine trial in Country X. Their recruitment plan targets 200 incarcerated persons who will be offered a payment equal to one month’s wages; consent forms are drafted in legal English only; there is no functioning local ethics committee in Country X, so the investigators plan to rely solely on approval from their US Institutional Review Board (IRB); the protocol states individual test results will not be returned to participants but aggregate results will be published; pregnant women are excluded without explanation. Based on the historical development of research ethics (e.g., the Nuremberg Code, Declaration of Helsinki, Belmont Report) and contemporary governance mechanisms (IRBs/REBs, national/international codes), which of the following best identifies the principal ethical deficiencies and the appropriate corrective actions?",
      "options": {
        "A": "There are no serious ethical deficiencies: US IRB approval is sufficient for international research, offering payment is an accepted recruitment incentive, and omitting individual results is standard to protect confidentiality.",
        "B": "The only ethical problem is not returning individual results; to remedy this, investigators should plan to provide personal diagnostic feedback but need no changes to consent language or governance because payment and prisoner recruitment are permissible with IRB oversight.",
        "C": "Multiple deficiencies exist: incarcerated persons are a vulnerable population requiring extra protections; the payment level may be an undue inducement that compromises voluntary informed consent; consent documents must be in a language and form participants can understand; relying solely on a distant IRB neglects local review and community context as emphasized by international codes; participants have a right to withdraw and to be informed of clinically relevant individual results; the protocol must justify exclusion of pregnant women. Corrective actions include revising consent processes, reducing or restructuring payments, obtaining local ethics review or equivalent local oversight, and adhering to principles of respect for persons, beneficence, and justice from the Nuremberg/Helsinki/Belmont traditions.",
        "D": "The only requirement is to obtain approval from a national-level body in Country X; since international codes are non-binding, investigators can ignore participant language issues and payment concerns once the country’s ministry approves the trial."
      },
      "correct_answer": "C",
      "generation_notes": "Designed a multisite, vulnerable-population scenario requiring application of historical codes (Nuremberg, Helsinki, Belmont), governance mechanisms (IRB/local ethics review), and participant autonomy protections (informed consent, language comprehension, undue inducement, return of results). Option C lists the correct ethical deficiencies and appropriate corrective actions.",
      "concepts_tested": [
        "Informed consent and protections for vulnerable populations (undue inducement, language comprehension, right to withdraw)",
        "Governance mechanisms and historical codes (Nuremberg Code, Declaration of Helsinki, Belmont Report; IRB/REB and local ethics review)",
        "Evolution of medical ethics into research ethics and how historical abuses inform contemporary safeguards"
      ]
    },
    "pass_2_reason": "readability_too_high_20.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why do emergent properties in large-scale service systems constrain traditional component-focused engineering, and which design approach best accounts for these properties?",
      "options": {
        "A": "Because emergent properties arise from interactions among many parts and across scales, making system-level thinking, modular architecture, and iterative experimentation essential.",
        "B": "Because emergent properties are merely measurement artifacts, so design should optimize each component in isolation to predict the whole.",
        "C": "Because emergent properties guarantee that adding more components will always improve overall performance, so design should maximize scale.",
        "D": "Because emergent properties imply service systems are entirely random, so no prediction or structured design is feasible."
      },
      "correct_answer": "A",
      "source_article": "Service science, management and engineering",
      "x": 1.280159592628479,
      "y": 1.0027695894241333,
      "concepts_tested": [
        "Emergent properties and complexity in large-scale service systems, and the implication for design and engineering approaches",
        "SSME as an interdisciplinary, complementary field that integrates science, management, and engineering and shapes curriculum/competencies",
        "Computational thinking as a method to model the dynamics and adaptiveness of service systems using digitized information"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do emergent properties in large-scale service systems make engineering that focuses only on individual components inadequate, and which design approach best handles these properties?",
      "options": {
        "A": "Because emergent properties arise from interactions among many parts and across scales, requiring system-level thinking, modular architecture, iterative experimentation, and computational modeling.",
        "B": "Because emergent properties are measurement artifacts, so optimizing each component in isolation will reliably predict whole-system behavior.",
        "C": "Because emergent properties ensure that adding more components always improves performance, so design should simply maximize scale.",
        "D": "Because emergent properties imply service systems are entirely random, so no structured design or prediction is feasible."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording condensed and clarified ('component-focused' → 'component-only'); preserved key terms (emergent properties, interactions, system-level design). Option A expanded slightly to mention computational modeling; distractors kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "A municipal healthcare network comprises $N=3$ hospitals that share ambulances and transfer patients. Emergency arrivals have a time-varying rate $\\lambda(t)$ with pronounced peaks; despite each hospital optimizing its internal workflows, the network experiences recurrent system-wide bed shortages — an emergent property arising from interactions among hospitals, ambulances and community demand. As the director of a new SSME program charged with (a) recommending a systems-level intervention, (b) defining the curricular competencies graduates should have, and (c) selecting a computational approach to model and adapt the network, which proposal best embodies the principles of Service Science, Management, and Engineering (SSME)?",
      "options": {
        "A": "Convene an interdisciplinary team of systems engineers, operations managers, clinicians and data scientists to design a network-level solution; develop a curriculum emphasizing computational modeling, service design, organizational behavior and data-driven decision making; build a hybrid agent-based/discrete-event computational model that ingests digitized EHR and ambulance GPS streams, runs scenario experiments (e.g., varying $\\lambda(t)$), and supports adaptive policies (real-time routing, dynamic bed allocation) validated by simulation.",
        "B": "Allocate funding to add 20 beds at each hospital and hire more nursing staff, keep the existing hospital-specific process-improvement courses in the curriculum, and model the system using classical single-queue formulas assuming constant arrival rate $\\lambda$.",
        "C": "Standardize triage and transfer protocols across the three hospitals, teach students detailed clinical workflow checklists and regulatory compliance, and avoid computational models to reduce complexity; monitor outcomes quarterly and adjust protocols by committee consensus.",
        "D": "Outsource the network's IT operations to an external vendor to ensure robust digitization, maintain separate departmental curricula (engineering, management, health sciences) with minimal cross-training, and apply steady-state queuing models to each hospital independently to report performance metrics."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic multi-hospital scenario that exhibits emergent system-level behavior; designed answer choices to contrast a holistic SSME approach (interdisciplinary team + computational modeling using digitized data + corresponding curricular competencies) with narrower, single-discipline alternatives.",
      "concepts_tested": [
        "Emergent properties and complexity in large-scale service systems",
        "SSME as an interdisciplinary, complementary field shaping curriculum and competencies",
        "Computational thinking and data-driven modeling (agent-based/discrete-event) using digitized information to study dynamics and adaptiveness"
      ]
    },
    "pass_2_reason": "readability_too_high_21.7_vs_16"
  },
  {
    "original_question": {
      "question": "Mansbridge identifies four views of democratic representation—promissory, anticipatory, surrogate, and gyroscopic. Each view proposes a way that representatives \"act for\" the people and a way the actions are normatively judged. Which statement best explains why these four views collectively still allow us to assess legitimacy, i.e., to judge and sanction representatives, across different stakeholder expectations?",
      "options": {
        "A": "They show that only binding commitments made in campaigns can justify legitimacy.",
        "B": "They indicate that legitimacy can be grounded in different mechanisms of action (promises, alignment with anticipated preferences, delegated surrogate choices, or alignment with the public's orientation) while maintaining a shared evaluative standard for whether actions serve citizens' interests.",
        "C": "They demonstrate that descriptive resemblance between representatives and constituents is the sole determinant of legitimacy.",
        "D": "They claim that normative evaluation requires precise policy outcomes predetermined by constitutional rules."
      },
      "correct_answer": "B",
      "source_article": "Political representation",
      "x": 1.1758580207824707,
      "y": 0.8805001974105835,
      "concepts_tested": [
        "Substantive representation as “acting for” the interests of the represented, contrasted with descriptive/symbolic notions, and the normative criteria used to judge representatives’ actions.",
        "Accountability as a mechanism that enables citizens to judge and sanction representatives based on whether they act in the constituents’ best interests.",
        "Mansbridge’s four views of democratic representation (promissory, anticipatory, surrogate, gyroscopic) and how each accounts for both how representatives act for the people and how their actions are normatively evaluated."
      ],
      "parent_concepts": [
        "How rules for translating votes into seats affect proportionality and representation (allocation mechanisms and their outcomes)",
        "Compensatory vs non-compensatory seat allocation and its effect on proportionality",
        "The role and mechanism of top-up PR seats in compensatory systems (e.g., MMP) to correct for district-level disproportionality"
      ],
      "parent_articles": [
        "Electoral system",
        "Mixed electoral system",
        "Mixed electoral system"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Mansbridge identifies four democratic views of representation—promissory, anticipatory, surrogate, and gyroscopic—each describing how representatives \"act for\" people and how their actions should be judged. Why do these four views, taken together, still allow citizens to judge and sanction representatives' legitimacy across different stakeholder expectations?",
      "options": {
        "A": "They imply that only binding promises made in election campaigns can establish a representative's legitimacy.",
        "B": "They show legitimacy can rest on different mechanisms of action—campaign promises, actions aimed at winning future electoral reward, acting for outsiders, or using personal judgment—while still providing standards to judge whether representatives serve citizens' interests.",
        "C": "They claim that descriptive resemblance (shared race, gender, class, etc.) between representative and constituents is the sole basis for legitimacy.",
        "D": "They insist that normative evaluation requires precise policy outcomes predetermined by constitutional or legal rules."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the stem to focus on Mansbridge's four views and their joint role in enabling legitimacy judgments; clarified each option into concise, plausible alternatives; removed extended theoretical background and kept the core normative question intact.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.5_vs_16",
    "pass_2_attempt": {
      "question": "A newly elected legislator, Maya, campaigned on expanding local health clinics (a clear campaign promise), later sponsors legislation to improve clinics in a neighboring district she does not represent, sometimes votes according to what she believes is best even if unpopular at home, and is re-evaluated by voters both at the next election and through ongoing media scrutiny of her policy record. Which theoretical characterizations and associated normative criteria best describe the types of representation and accountability at work in Maya's behavior?",
      "options": {
        "A": "Substantive representation is assessed by the representative's responsiveness and by observed government action between elections (i.e., 'acting for' constituents' evolving interests); accountability requires citizens have information and sanctioning mechanisms (e.g., re-election, reputational costs) to judge and punish representatives; Mansbridge's typology maps here as promissory (judged by fulfillment of campaign promises), anticipatory (acts to win future electoral reward and judged by voters' subsequent reward/penalty), surrogate (acts on behalf of non-constituents and judged by those outsiders' evaluations), and gyroscopic (acts on the representative's own judgement and is normatively assessed by the coherence/integrity of that judgement).",
        "B": "Substantive representation primarily concerns a representative's demographic resemblance to constituents and is normatively assessed by whether constituents symbolically accept them; accountability operates only through periodic elections and does not require between-election information or sanctioning; Mansbridge's promissory view implies representatives should disregard campaign promises when making policy.",
        "C": "Under the accountability view citizens judge representatives solely via formal party institutions rather than by the representatives' policy actions; substantive representation requires representatives to act exclusively as delegates with no independent judgement; and Mansbridge's anticipatory view describes representatives acting chiefly for people outside their constituency.",
        "D": "Descriptive and substantive representation are synonymous—both focus only on demographic mirroring; Mansbridge's gyroscopic model requires strict adherence to party mandates; and accountability is purely symbolic and cannot lead to sanctions between elections."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete scenario mapping Maya's actions to substantive vs descriptive concepts, accountability mechanisms, and each of Mansbridge's four types; options contain plausible but incorrect theoretical pairings to test discrimination.",
      "concepts_tested": [
        "Substantive vs descriptive representation",
        "Accountability as information and sanction mechanisms",
        "Mansbridge's promissory, anticipatory, surrogate, and gyroscopic models"
      ]
    },
    "pass_2_reason": "readability_too_high_23.9_vs_16"
  },
  {
    "original_question": {
      "question": "In the triple-product model of digital platforms, how do infotainment, attention capture, and data collection interact to drive advertising revenue?",
      "options": {
        "A": "Infotainment provides content; attention capture reduces user engagement; data collection is used to measure performance only, not for ads.",
        "B": "Infotainment attracts users with engaging content; capturing attention increases time-on-platform and ad impressions; data collection enables precise targeting of ads, allowing higher advertiser value and revenue.",
        "C": "Infotainment is unrelated to ads; attention capture is used to push subscriptions; data collection leaks are minimized to protect privacy.",
        "D": "Infotainment is the sole revenue source; attention capture is a side effect; data collection is used to monitor competitors."
      },
      "correct_answer": "B",
      "source_article": "Digital media",
      "x": 1.3330954313278198,
      "y": 1.0343366861343384,
      "concepts_tested": [
        "The triple-product business model of digital media platforms: providing infotainment, capturing user attention, and collecting data to sell to advertisers.",
        "The societal and policy impacts of digital media: disruptive innovation across sectors and the resulting copyright, open-content, and digital-divide challenges.",
        "Interconnectivity as a driver of the Information Age: how networked access enables widespread dissemination and potential transitions (e.g., toward a paperless society) along with associated risks."
      ],
      "parent_concepts": [
        "Concept 2: Shift from traditional broadcast to on-demand streaming and cloud storage as a distribution model enabling viewer-controlled access to content."
      ],
      "parent_articles": [
        "Television"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In the triple-product business model used by digital platforms, how do the three components — infotainment (free content), attention capture, and user-data collection — work together to generate advertising revenue?",
      "options": {
        "A": "Infotainment supplies content; attention capture paradoxically reduces user engagement; and data collection is used only to measure platform performance, not to target ads.",
        "B": "Infotainment attracts and retains users with engaging content; attention capture increases time-on-platform and ad impressions; and data collection enables precise ad targeting, raising advertiser value and revenue.",
        "C": "Infotainment is separate from advertising; attention capture is primarily used to drive paid subscriptions; and data collection is minimized to avoid privacy risks and leaks.",
        "D": "Infotainment is the platform's only revenue source; attention capture is merely a side effect; and data collection is used mainly to monitor competitors rather than to sell ad targeting."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified the three components; technical terms retained; distractor options made plausible but incorrect; correct answer unchanged.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.9_vs_16",
    "pass_2_attempt": {
      "question": "A global digital media platform, Videa, follows a triple-product business model: it provides free infotainment to users, captures attention (averaging $2\\times10^9$ watch‑hours per month), and packages anonymized user profiles into ad segments sold to advertisers. A national regulator wishes to (i) reduce copyright infringement and improve creators' remuneration, (ii) narrow the digital divide so underserved communities gain reliable access to digital media, and (iii) preserve the interconnectivity and network effects that enable large‑scale digital distribution and a transition toward predominantly digital information ecosystems. Which policy package most directly advances all three goals while minimally disrupting the economic incentives of Videa's triple‑product model?",
      "options": {
        "A": "Mandate industry‑wide DRM and increase criminal penalties for unauthorized sharing; prohibit cross‑platform data portability to protect platform business models; and require platforms to pay fixed per‑stream fees to rightsholders.",
        "B": "Subsidize high‑speed broadband deployment in underserved areas; require standardized data portability and interoperability APIs so users and creators can move content and profiles between services; and offer tax incentives for creators who adopt open or copyleft licenses alongside conventional licensing.",
        "C": "Ban targeted advertising and the collection of behavioral data on platforms, and force platforms to convert to a subscription‑only model where all content is behind paywalls; establish a government fund that compensates creators from general tax revenue.",
        "D": "Impose a per‑advertiser ad tax remitted to a cultural compensation pool and require platforms to license all uploaded content through central clearinghouses; subsidize only platform compliance costs for small publishers, without investing in public broadband infrastructure."
      },
      "correct_answer": "B",
      "generation_notes": "Designed a concrete regulatory scenario for a platform using the triple‑product model; each option links specific policy levers to the three target outcomes—copyright/creator remuneration, digital divide, and interconnectivity—so students must evaluate tradeoffs and select the balanced package.",
      "concepts_tested": [
        "Triple‑product business model (infotainment, attention capture, data sale to advertisers)",
        "Societal and policy impacts of digital media (copyright, creator remuneration, open‑content incentives, digital divide)",
        "Interconnectivity and network effects as drivers of the Information Age (data portability, broadband access, transition to digital ecosystems)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.8_vs_16"
  },
  {
    "original_question": {
      "question": "How does digitalization serve as a core mechanism enabling convergence across telecom, computing, and broadcasting?",
      "options": {
        "A": "By standardizing on a single hardware platform that all services must run on.",
        "B": "By breaking signals from diverse sources into a common binary representation, creating a unified digital bit-stream that can be transmitted and processed across domains.",
        "C": "By increasing physical separation between networks to prevent cross-domain interference.",
        "D": "By preserving distinct data formats for each domain and coordinating them with separate control protocols."
      },
      "correct_answer": "B",
      "source_article": "Technological convergence",
      "x": 1.3042117357254028,
      "y": 1.0047483444213867,
      "concepts_tested": [
        "Concept 1: Convergence as the integration of diverse technologies, knowledge, and infrastructures into a single, unified network/architecture.",
        "Concept 2: Digitalization as a core mechanism enabling convergence (breaking signals into bits, creating a common digital bit-stream across telecom, computing, and broadcasting).",
        "Concept 3: Cross-domain or interdisciplinary convergence (bioconvergence and allied acronyms/fields) showing relationships and interactions among distinct disciplines (biology, engineering, IT, nanotechnology, etc.)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does digitalization primarily enable convergence among telecommunications, computing, and broadcasting?",
      "options": {
        "A": "By forcing all services to use a single, standardized hardware platform for execution.",
        "B": "By converting diverse signals into a common binary representation (bytes of ones and zeros), producing a unified digital bit‑stream that all domains can transmit and process.",
        "C": "By increasing physical separation between networks so cross‑domain interference is eliminated.",
        "D": "By keeping each domain's native data formats separate and coordinating them through distinct control protocols."
      },
      "correct_answer": "B",
      "simplification_notes": "Simplified wording to a focused undergraduate question; retained the article's definition that digitalization breaks signals into bytes/ones and zeros and produces a common digital bit‑stream; made all options plausible alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.1_vs_16",
    "pass_2_attempt": {
      "question": "A company develops BioNet, an integrated healthcare platform with these components: (1) wearable biosensors that transduce glucose and heart‑rate signals into digital streams for real‑time cloud analytics; (2) an IP backbone that carries voice calls, video consultations, and sensor telemetry over the same packet network; (3) archival patient records encoded into long DNA sequences for ultra‑dense storage; and (4) a joint R&D program combining molecular biologists, nanotechnology engineers, and machine‑learning researchers to design targeted drug delivery and predictive diagnostics. Which single option best describes how BioNet illustrates technological convergence, digitalization, and bioconvergence as discussed in the article?",
      "options": {
        "A": "BioNet shows convergence because diverse services (voice, video, telemetry) are integrated on a single IP architecture; it exemplifies digitalization because biosensor analog signals are converted into bytes (ones and zeros) and processed as a common digital bit‑stream; and it is a case of bioconvergence since biology is being integrated with engineering, nanotech, and information science in the R&D program.",
        "B": "BioNet does not illustrate convergence because each service (calls, video, sensors) remains logically distinct; digitalization applies only to expanding physical infrastructure like fiber or routers, not to converting biosensor outputs into binary data; and combining biologists with engineers is merely collaboration, not true bioconvergence.",
        "C": "BioNet is primarily a biotechnology project, not convergence: encoding patient records in DNA and doing targeted drug delivery are purely biological innovations and cannot be considered digitalization since biological information cannot be represented as binary $0$ and $1$ streams.",
        "D": "BioNet contradicts media convergence principles because using one network increases single‑point failure risk rather than integration; digitalization would require replacing all analogue devices with a single multi‑purpose 'black box' device, and DNA storage is unrelated to convergence since it is an archival medium separate from networked services."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete healthcare platform scenario that requires recognizing (a) integration of services onto an IP network as convergence, (b) conversion of analog biological signals into binary bytes as digitalization, and (c) interdisciplinary combination of biology, nanotech, and IT as bioconvergence. Distractors misapply definitions or deny digital encoding.",
      "concepts_tested": [
        "Integration of diverse technologies into a unified network/architecture (technological convergence)",
        "Digitalization as breaking signals into binary bit‑streams enabling common processing",
        "Interdisciplinary bioconvergence (integration of biology with engineering, IT, nanotech)"
      ]
    },
    "pass_2_reason": "readability_too_high_28.1_vs_16"
  },
  {
    "original_question": {
      "question": "In the inhibitory control resource/ego-depletion framework, why can repeated self-control exertions sometimes lead to better performance on subsequent self-control tasks, and what does this imply about the underlying mechanism?",
      "options": {
        "A": "Replenishment of a single finite resource occurs instantly after use, so there is no depletion effect to explain; this implies self-control is not related to effort.",
        "B": "After short-term depletion, the same finite resource is temporarily reduced; with practice, two processes can occur: automation reduces the cost of using inhibitory control (making it less resource-intensive), and neural strengthening expands the effective capacity of control over time; thus later tasks can show preserved or enhanced performance, implying that inhibition becomes more efficient or that capacity grows.",
        "C": "Ego-depletion only reflects fluctuations in motivation; practice increases motivation, not the inhibitory mechanism, so performance returns to baseline due to desire rather than control processes.",
        "D": "The resource is external and replenished only during sleep; training merely increases willingness to delay gratification but does not alter the cognitive control system."
      },
      "correct_answer": "B",
      "source_article": "Self-control",
      "x": 1.2705646753311157,
      "y": 1.0252933502197266,
      "concepts_tested": [
        "Inhibitory control and the resource/ego-depletion mechanism of self-control (short-term depletion vs. long-term strengthening)",
        "The relationship between self-control and criminal behavior as described by the General Theory of Crime (traits like impulsivity, genetic variance)",
        "Self-control within virtue/theoretical frameworks (temperance, continence, akrasia) and its philosophical/historical context"
      ],
      "parent_concepts": [
        "Motivation/decision dynamics: addiction often reflects a bias toward immediate gratification with delayed negative consequences, shaping habit formation."
      ],
      "parent_articles": [
        "Addiction"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Within the inhibitory-control (ego-depletion) framework, why can repeated acts of self-control sometimes produce equal or better performance on later self-control tasks, and what does that suggest about the underlying mechanism?",
      "options": {
        "A": "The limiting resource is replenished immediately after use, so there is no true depletion; this would imply self-control is not constrained by effortful resources.",
        "B": "After a short-term drop in resources, practice triggers two complementary changes: automatization reduces the cognitive cost of inhibitory acts, and neural/functional strengthening increases effective control capacity; therefore later tasks can be maintained or improved, implying inhibition becomes more efficient or capacity grows over time.",
        "C": "Ego-depletion simply indexes temporary falls in motivation; repeated exertion raises motivation (not inhibitory ability), so restored performance reflects increased willingness rather than changes to control processes.",
        "D": "The limiting resource is external and only replenished during sleep; training only raises willingness to delay gratification without altering the cognitive control system."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified short-term depletion versus long-term training effects; condensed language; preserved the key idea that practice can both automate inhibition and strengthen neural capacity (answer B). Retained three plausible alternative explanations.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.9_vs_16",
    "pass_2_attempt": {
      "question": "A multidisciplinary research team conducts a longitudinal study combining cognitive testing, criminological survey data, and a philosophy-of-virtue interview. Their main empirical findings are: (1) participants perform worse on inhibitory-control tasks immediately after exerting sustained self-regulation but, after a 6-month regimen of daily self-control exercises, show improved baseline inhibitory performance; (2) a low trait self-control score predicts impulsivity, short-sighted decision-making, and a higher incidence of non-violent criminal convictions in adulthood, and twin analyses of one widely used questionnaire construct estimate genetic influence at approximately $\\sim70\\%$ of variance; (3) interview transcripts show subjects and ethicists using terms like \"continence,\" \"akrasia,\" and \"temperance\" to distinguish failures of will from virtues of moderated desire. Which interpretation best integrates these findings with the theories described in the literature on self-control?",
      "options": {
        "A": "Self-control is essentially a learned habit with no biological basis: short-term failures reflect inadequate training, the correlation with crime is purely environmental, and the classical virtue vocabulary is merely rhetorical; therefore interventions should focus only on changing contingencies and education.",
        "B": "The data support a dual-aspect account: self-control operates as an inhibitory executive function that can be temporarily depleted by effort yet strengthened by practice (consistent with the muscle metaphor); low trait self-control—characterized by impulsivity, risk-taking, and insensitivity to others—predicts criminal behavior as in Gottfredson and Hirschi's General Theory, and questionnaire variance shows a large genetic component (~$\\sim70\\%$); philosophically, this complements the classical distinction between continence and akrasia and Aristotle's temperance as the mean between excess and deficiency.",
        "C": "Because ego-depletion has been refuted by meta-analyses, the immediate drop in task performance must reflect unrelated fatigue; genetics cannot explain questionnaire variance, so the criminological link is an artifact; classical virtue theory is incompatible with empirical psychology and should be discarded when designing interventions.",
        "D": "Self-control is strictly a top-down cognitive control process localized only to the dorsolateral prefrontal cortex, so short-term changes are neural noise, criminality results entirely from prefrontal lesions, and temperance only matters as a cultural label with no behavioral relevance."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed an applied, integrative scenario combining inhibitory-control resource dynamics (short-term depletion, long-term strengthening), the General Theory of Crime with trait descriptions and heritability (~70%), and classical virtue terminology (continence, akrasia, temperance); options include plausible but incorrect alternatives that misstate genetic, empirical, or philosophical claims.",
      "concepts_tested": [
        "Inhibitory control and resource model (ego-depletion vs. strengthening with practice)",
        "General Theory of Crime: low self-control traits and genetic variance",
        "Philosophical concepts: continence, akrasia, temperance as virtue theory"
      ]
    },
    "pass_2_reason": "readability_too_high_26.5_vs_16"
  },
  {
    "original_question": {
      "question": "How does a multi-domain conception of well-being explain why two people who report the same level of happiness can have different overall well-being, for example when one person has good health and strong social ties but economic insecurity, while the other is financially secure but experiences chronic pain and social isolation?",
      "options": {
        "A": "Because happiness fully captures life quality, identical happiness guarantees identical well-being across all domains.",
        "B": "Because well-being depends on multiple domains (physical health, mental health, social connections, income, etc.), identical happiness can mask differences in other domains, leading to different overall well-being.",
        "C": "Because well-being is determined only by external, objective metrics, so subjective happiness cannot influence it.",
        "D": "Because well-being is determined only by individual-level factors and does not involve interactions between different life domains."
      },
      "correct_answer": "B",
      "source_article": "Well-being",
      "x": 1.2402820587158203,
      "y": 1.0136523246765137,
      "concepts_tested": [
        "Concept 1: Theoretical frameworks of well-being (hedonism, desire theories, objective list theories) and how they define the constituents of well-being.",
        "Concept 2: Distinctions between subjective vs. objective well-being and between individual vs. community well-being, including implications for assessment.",
        "Concept 3: Multi-domain nature of well-being (physical, psychological, emotional, social, economic) and the idea that well-being involves balancing positive and negative aspects across domains."
      ],
      "parent_concepts": [
        "The relationship between mental health and functioning (stress management, interpersonal relationships, productive engagement, and community contribution).",
        "Concept 3: Multi-factor causes of loneliness (genetic, cultural, relational deficits, loss, technology use) and corresponding interventions (therapy, antidepressants, social/community activities) illustrating a mechanism-driven approach to addressing it."
      ],
      "parent_articles": [
        "Mental health",
        "Loneliness"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to a multi-domain conception of well-being, why can two people report the same level of happiness yet differ in overall well-being (for example, one has good health and strong social ties but economic insecurity, while the other is financially secure but suffers chronic pain and social isolation)?",
      "options": {
        "A": "Because reported happiness fully captures life quality, so identical happiness implies identical overall well-being across all domains.",
        "B": "Because well-being depends on multiple domains (physical health, mental health, social ties, income, etc.), so identical happiness can mask contrasting conditions in other domains and yield different overall well-being.",
        "C": "Because well-being is determined only by external objective metrics, making subjective happiness reports irrelevant to overall well-being.",
        "D": "Because well-being is determined solely by individual-level factors and does not arise from trade-offs or interactions among different life domains."
      },
      "correct_answer": "B",
      "simplification_notes": "Rewrote the prompt in concise academic language; removed extended philosophical jargon and theory names; kept the illustrative example and emphasized the multi‑domain idea (health, social ties, income). Options were rephrased to be clearer and all remain plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.5_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized city faces rising unemployment, increasing rates of chronic illness, and declining civic participation. Three proposed programs are under consideration: (1) build a large central park and fund weekend festivals (immediate increases in leisure and positive social interaction); (2) provide unconditional monthly cash transfers to low-income households (economic security and ability to satisfy desires); (3) invest in community mental-health clinics combined with job-training and after-school tutoring (targets psychological health, long-term employability, and educational achievement). A recent survey finds that average self-reported life satisfaction is still relatively high despite the objective problems. If the city council's declared aim is to maximize community well-being in a way that (i) recognizes multiple life domains (physical, psychological, social, economic), (ii) attends to both individual and community-level goods, and (iii) balances short-term positive experiences against longer-term objective deficits, which theoretical framework and assessment strategy most coherently justify choosing program (3)?",
      "options": {
        "A": "Adopt a prudential hedonist approach: prioritize program (1) because it increases immediate pleasurable experiences. Measure success primarily via aggregated affect measures (frequency of positive emotions) and short surveys of individual mood; individual subjective reports suffice for policy.",
        "B": "Follow a desire-theory stance: prioritize program (2) because cash transfers satisfy people’s prevailing desires and increase their choices. Assess outcomes via revealed preference and self-reported fulfillment of desires at the individual level, with little weight given to objective community indicators.",
        "C": "Use a pluralist objective-list or hybrid framework focused on community well-being: prioritize program (3) because it addresses multiple objective goods (mental health, employment, education) that contribute to well-being even when subjective life-satisfaction is currently high. Assess both objective community-level indicators (unemployment rates, health metrics, school outcomes) and aggregated subjective measures (life satisfaction, affect), and give priority to interventions improving several domains and long-term functioning.",
        "D": "Rely solely on aggregated subjective life-satisfaction (community-level) and individual evaluations: if surveys show high life satisfaction, maintain current allocations or choose the least costly program, because subjective reports are the only valid measure of well-being and community aggregation replaces the need for objective measures."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a municipal policy scenario contrasting three interventions across domains; options map to hedonism, desire theory, objective-list/hybrid, and a purely subjective aggregation approach to test theory-to-assessment alignment and multi-domain balancing.",
      "concepts_tested": [
        "Theoretical frameworks of well-being (hedonism, desire theories, objective list/hybrid) and policy implications",
        "Distinctions between subjective vs. objective measures and individual vs. community well-being",
        "Multi-domain nature of well-being and balancing short-term pleasures against long-term objective deficits"
      ]
    },
    "pass_2_reason": "readability_too_high_24.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does conceptualizing quality of life as comprising both emotional well-being and life evaluation help prevent misinterpretations when comparing people's well-being?",
      "options": {
        "A": "Because emotional well-being captures day-to-day feelings while life evaluation captures the global judgment of life; these can diverge, so a single metric may miss important aspects of QoL.",
        "B": "Because both constructs are identical and measuring both would be redundant.",
        "C": "Because only emotional well-being matters for policy because people remember how they felt most of the time.",
        "D": "Because life evaluation is purely future-oriented and can't reflect current well-being."
      },
      "correct_answer": "A",
      "source_article": "Quality of life",
      "x": 1.2288987636566162,
      "y": 0.923045814037323,
      "concepts_tested": [
        "Concept 1: Quality of life is multi-dimensional and measured using at least two related constructs—emotional well-being and life evaluation—highlighting that subjective experience and overall life judgment are distinct but connected.",
        "Concept 2: Engaged Theory provides a framework with four domains (ecology, economics, politics, culture) and subdomains that shape QoL, illustrating how cultural factors (beliefs, creativity, identity, well-being) interact with other domains.",
        "Concept 3: Happiness is not synonymous with QoL or standard of living; income and material conditions do not automatically increase QoL, underscoring the need to separate subjective well-being from wealth and to recognize measurement challenges."
      ],
      "parent_concepts": [
        "The relationship between mental health and functioning (stress management, interpersonal relationships, productive engagement, and community contribution)."
      ],
      "parent_articles": [
        "Mental health"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does treating quality of life as two separate subjective measures—emotional well‑being (the frequency and intensity of everyday feelings) and life evaluation (a person's considered overall judgment of their life)—reduce the risk of misinterpreting comparisons of people's well‑being?",
      "options": {
        "A": "Because emotional well‑being captures day‑to‑day affect while life evaluation captures considered, global judgments; these can diverge, so a single metric may miss important aspects of quality of life.",
        "B": "Because the two constructs are identical, so measuring both would be redundant and add no new information.",
        "C": "Because only emotional well‑being matters for policy, since people’s remembered daily feelings are what drive real outcomes.",
        "D": "Because life evaluation is purely future‑oriented and therefore cannot reflect a person's current well‑being."
      },
      "correct_answer": "A",
      "simplification_notes": "Question and choices were shortened and clarified; the two constructs were explicitly defined (daily affect vs. overall judgment). Kept the original core idea that they can diverge and a single measure can mislead. Distractors were made plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.7_vs_16",
    "pass_2_attempt": {
      "question": "Consider two hypothetical countries described by survey and economic data: Alto has per‑capita GDP of $85{,}000$, high life‑evaluation scores (mean 8/10) but low reported daily emotional well‑being (frequent stress, low joy). Bendia has per‑capita GDP of $15{,}000$, moderate life‑evaluation scores (mean 6/10) but high daily emotional well‑being (frequent joy, strong social ties), along with well‑developed cultural practices (creativity, identity, community rituals) but poor ecological sustainability. Which interpretation best aligns with the Quality of Life literature (distinguishing emotional well‑being vs life evaluation, Engaged Theory's four domains, and findings about income and happiness such as plateau effects near $75{,}000$)?",
      "options": {
        "A": "A full assessment requires both emotional well‑being and life‑evaluation measures; Alto's higher income plausibly elevates life evaluation but not daily emotional well‑being (consistent with plateauing of day‑to‑day happiness beyond about $75{,}000$), while Bendia's strong cultural domain can raise emotional well‑being despite lower material standard; Engaged Theory would analyze ecology, economics, politics, and culture to interpret these mixed outcomes.",
        "B": "Because Alto's per‑capita GDP is much higher, its overall quality of life is necessarily superior to Bendia's; subjective reports of daily emotion are unreliable and can be ignored in favor of objective economic indicators.",
        "C": "High reported daily joy in Bendia implies its standard of living is higher than Alto's; happiness is synonymous with standard of living, so GDP differences are irrelevant to comparative quality of life.",
        "D": "Under Engaged Theory, cultural strengths are treated independently of ecology and economics, so Bendia's strong cultural practices cannot significantly affect its overall quality of life unless its ecological and economic metrics match Alto's."
      },
      "correct_answer": "A",
      "generation_notes": "Created a comparative country scenario to force application of three concepts: the distinction between emotional well‑being and life evaluation (including the income plateau ~ $75{,}000$), Engaged Theory's four domains and cultural subdomains, and the non‑equivalence of happiness and material standard of living. Distractors reflect common misconceptions.",
      "concepts_tested": [
        "Distinction between emotional well‑being and life evaluation",
        "Engaged Theory domains (ecology, economics, politics, culture) and cultural subdomains",
        "Separation of happiness/subjective well‑being from income/standard of living and the income‑happiness plateau"
      ]
    },
    "pass_2_reason": "readability_too_high_21.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the fit principle explain that aligning the job, equipment, and environment with a worker's capabilities reduces musculoskeletal strain and injury risk?",
      "options": {
        "A": "Because it keeps joints, muscles, and movements within comfortable, efficient ranges, reducing awkward postures and excessive muscle activation.",
        "B": "Because it mostly alters the cognitive load, making tasks feel more complex and increasing mental fatigue.",
        "C": "Because it focuses on making equipment look better, which somehow reduces physical effort.",
        "D": "Because it requires workers to adapt to mismatched equipment, distributing strain unpredictably."
      },
      "correct_answer": "A",
      "source_article": "Ergonomics",
      "x": 1.4143579006195068,
      "y": 1.0395634174346924,
      "concepts_tested": [
        "Concept 1: The fit principle — designing to match human capabilities and limitations by aligning the job, equipment, and environment with the user.",
        "Concept 2: The cause–effect relationship — proper ergonomic design reduces human error and musculoskeletal risk while increasing safety, health, comfort, and system productivity.",
        "Concept 3: The interdisciplinary framework — ergonomics integrates psychology, biomechanics, engineering, design, and related fields to generate data and methods that inform design decisions."
      ],
      "parent_concepts": [
        "Concept 1: Separation of studio spaces (studio floor, PCR, CAR) to manage noise, heat, and workflow, and the resulting impact on production efficiency and safety.",
        "Concept 3: Role of ergonomic design in reducing usability barriers and improving safe, correct PPE usage",
        "Concept 2: Genre- and ergonomics-driven design principles (why certain controllers or features—like steering wheels for driving games or shoulder triggers—are favored for specific game types, reflecting design-for-use principles)."
      ],
      "parent_articles": [
        "Television studio",
        "Personal protective equipment",
        "Game controller"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to the ergonomic \"fit\" principle, why does aligning the task, equipment, and environment to a worker's physical capabilities reduce musculoskeletal strain and the risk of injury?",
      "options": {
        "A": "Because it keeps joints, muscles, and movements within comfortable, efficient ranges, reducing awkward postures and excessive muscle activation.",
        "B": "Because it primarily changes cognitive demands, making tasks seem more complex and increasing mental fatigue that masks physical strain.",
        "C": "Because it focuses on improving the appearance or styling of equipment, which indirectly lowers perceived physical effort.",
        "D": "Because it forces workers to adapt to poorly matched equipment, spreading physical strain unpredictably across the body."
      },
      "correct_answer": "A",
      "simplification_notes": "Clarified the question to define the \"fit\" principle and focused it on physical capabilities and injury risk; options were rewritten to be concise and plausible while preserving the original distractors.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized electronics factory measured a baseline of $12\\%$ task error rate, $10$ work-related musculoskeletal disorder (WRMD) cases per $100$ workers per year, and average output of $100$ units/day. Over six months the firm introduced an ergonomics program that (a) replaced non-anthropometric tool handles with ergonomically contoured grips (biomechanics/industrial design), (b) installed height-adjustable workstations and anti-fatigue mats (engineering/physiology), (c) simplified on-screen maintenance procedures and standardized visual displays (cognitive psychology/interaction design), and (d) provided brief participatory task redesign workshops (organizational ergonomics). After six months the factory reported a task error rate of $8\\%$, WRMD cases of $6$ per $100$ workers/year, and output of $110$ units/day. Which interpretation best aligns with the core principles of ergonomics as described in the article?",
      "options": {
        "A": "The results are best explained by the fit principle: redesigning the job, equipment, and environment to match human capabilities (using biomechanics, cognitive psychology, engineering and design) causally reduced awkward postures and cognitive load, thereby lowering errors and WRMD incidence and increasing productivity.",
        "B": "The observed improvements likely derive solely from the participatory workshops and training; hardware changes (tool grips, workstations, displays) are peripheral and cannot account for the simultaneous decline in WRMDs and task errors.",
        "C": "Although musculoskeletal risk decreased because of the ergonomic hardware, the simplified displays and standardized procedures probably increased cognitive tunneling and should have raised the error rate; therefore the reported drop in task errors is inconsistent with ergonomic theory.",
        "D": "Ergonomic interventions primarily improve subjective comfort; measurable changes in error rates and productivity are unlikely to result directly from such interventions, so the factory's reported performance changes are probably due to unrelated operational factors."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic intervention scenario with pre/post quantitative metrics to require applying the fit principle, causal effects of ergonomics on safety and productivity, and recognition of the interdisciplinary methods used.",
      "concepts_tested": [
        "Fit principle: aligning job, equipment, and environment with human capabilities",
        "Cause–effect: ergonomic design reduces errors and WRMDs while increasing safety and productivity",
        "Interdisciplinary framework: integration of biomechanics, psychology, engineering, and design in interventions"
      ]
    },
    "pass_2_reason": "readability_too_high_20.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why do structured collaboration practices (like regular reflective sessions and explicit communication norms) tend to improve a team's problem-solving, and how do they affect information flow and cognitive load?",
      "options": {
        "A": "They slow decision-making to allow everyone to voice concerns, increasing information redundancy and enabling better error detection.",
        "B": "They centralize control so decisions are made quickly and consistently.",
        "C": "They remove the need for trust by formalizing interactions, so collaboration can happen without interpersonal warmth.",
        "D": "They foster explicitness and iteration, aligning mental models and distributing cognitive labor, reducing hidden assumptions and supporting faster, higher-quality problem-solving."
      },
      "correct_answer": "D",
      "source_article": "Collaboration",
      "x": 1.3175017833709717,
      "y": 1.0025103092193604,
      "concepts_tested": [
        "Concept 1: Collaboration as a value-creating, shared-outcome process that involves multiple actors and shared space/resources, with governance that can be decentralized or egalitarian.",
        "Concept 2: Structured collaboration and reflective practices (communication, behavior introspection) as mechanisms to improve team problem-solving and collaborative success.",
        "Concept 3: Adversarial collaboration as a form of collaboration where parties with opposing goals still cooperate toward a common outcome, highlighting the complexity of collaborative relationships."
      ],
      "parent_concepts": [
        "Concept 1: Division of labor and collaboration in songwriting (how lyricists, composers, and group members work together and why collaboration emerges in practice)",
        "Co-creation mechanism: input from consumers is gathered as contributions and then selected to shape a product/service.",
        "Division of labor and interaction: equal responsibility versus task-specific roles as a mechanism shaping how collaboration unfolds and outcomes are produced.",
        "Ownership and accountability: group ownership of the text and shared responsibility versus individual authorship, shaping motivation, editing, and revision processes."
      ],
      "parent_articles": [
        "Songwriter",
        "Co-creation",
        "Collaborative writing",
        "Collaborative writing"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do structured collaboration practices (for example, regular reflective sessions and agreed communication norms) improve a team's problem solving, and what do they do to information flow and cognitive load?",
      "options": {
        "A": "They slow decision making to allow everyone to raise concerns, which increases information redundancy and helps detect errors.",
        "B": "They centralize decision authority so decisions are made quickly and consistently by a single controller.",
        "C": "They remove the need for interpersonal trust by formalizing interactions, enabling collaboration without relational commitment.",
        "D": "They make communication more explicit and iterative, align team members' mental models, distribute cognitive work across people, reduce hidden assumptions, and thus support faster, higher-quality problem solving."
      },
      "correct_answer": "D",
      "simplification_notes": "Reworded the stem for clarity and conciseness, kept concrete examples (reflective sessions, norms), used precise terms like 'mental models' and 'cognitive work'. Options were rephrased to remain plausible while preserving original meanings.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "Which of the following real-world scenarios best exemplifies collaboration as (1) a value-creating, shared-outcome process in which multiple actors share virtual or physical space and resources under decentralized or egalitarian governance, (2) the use of structured reflective practices (e.g., explicit communication protocols, retrospectives, behavior introspection) to improve collaborative problem-solving, and (3) an instance of adversarial collaboration where parties with opposing goals cooperate to resolve a substantive disagreement?",
      "options": {
        "A": "A consortium of independent biotech startups, several NGOs, and two university labs form an open vaccine platform. The group operates in shared cloud repositories and a common wet-lab facility; policy decisions rotate among member organizations (consensus-based governance). They run mandatory communication protocols, weekly retrospectives, and post-experiment root-cause analyses to improve protocols. Two competing labs within the consortium—previously disputing a key assay—agree to a jointly designed replication study, each proposing tests to challenge the other's claim, and publish the results together.",
        "B": "A large defense contractor manages a multi-supplier weapons program. The prime contractor issues detailed contracts, central schedules (CPM/PERT), and enforces strict top-down decision control. Suppliers follow rigid specification change procedures to meet milestones; after deliveries there are formal compliance audits but no open retrospectives. Competing suppliers never jointly test one another's claims and disputes are handled by legal escalation rather than cooperative experiments.",
        "C": "Three consumer-electronics companies create a standards consortium to develop a common connector. They contribute designs to a shared codebase, elect a rotating technical chair, and hold structured design reviews and post-release surveys to refine the specification. All members publicly aim to adopt the same standard to expand the market; there are minor commercial tensions but no joint projects intended to settle scientific disputes between adversaries.",
        "D": "Two rival chemical firms accused each other of manipulating catalyst performance data. Under court supervision they agree to co-sponsor an independent lab to test both catalysts; the lab reports comparative results. However, each firm keeps hierarchical internal control (single corporate sponsor decisions), there are no shared repositories or ongoing retrospectives between the firms, and interactions outside the court-ordered test remain adversarial and limited."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed four concrete organizational scenarios; only option A contains all three required elements (shared-value with decentralized governance, explicit reflective practices, and adversarial collaboration). Other options each omit at least one element.",
      "concepts_tested": [
        "Collaboration as shared-value, multi-actor process with decentralized/egalitarian governance",
        "Structured reflective practices (communication protocols, retrospectives) improving collaborative problem-solving",
        "Adversarial collaboration: cooperating parties with opposing goals to resolve disputes"
      ]
    },
    "pass_2_reason": "readability_too_high_25.3_vs_16"
  },
  {
    "original_question": {
      "question": "Why does social integration as a dynamic, participatory process aimed at peaceful coexistence (rather than forced assimilation) tend to foster more durable social cohesion?",
      "options": {
        "A": "It ensures newcomers quickly adopt host norms at the expense of their own identity.",
        "B": "It enables ongoing dialogue and mutual adjustment across groups, allowing shared norms to emerge without erasing identities, thereby reducing social distance.",
        "C": "It prioritizes economic integration, assuming economic parity automatically achieves social harmony.",
        "D": "It encourages replacing multiple identities with a single national identity to prevent conflicts."
      },
      "correct_answer": "B",
      "source_article": "Social integration",
      "x": 1.1991370916366577,
      "y": 0.9630937576293945,
      "concepts_tested": [
        "Concept 1: Social integration as a dynamic, participatory process aimed at peaceful coexistence (not forced assimilation)",
        "Concept 2: Competing theoretical trajectories of integration (assimil­ation, multiculturalism, segmented integration) and factors shaping different paths",
        "Concept 3: The relationship between higher social integration, reduced segregation/ exclusion, and greater access to community life (social cohesion and cohesion of values/practices)"
      ],
      "parent_concepts": [
        "Assimilation processes and determinants (speed/depth, impact of country of origin, first- vs. second-generation)"
      ],
      "parent_articles": [
        "Immigration"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does an approach to social integration that is dynamic and participatory—aimed at peaceful coexistence rather than forced assimilation—typically produce more durable social cohesion?",
      "options": {
        "A": "Because it forces newcomers to abandon their own identities and rapidly adopt host norms, producing uniform behavior.",
        "B": "Because it enables ongoing dialogue and mutual adjustment between groups, so shared norms and practices emerge without erasing minority identities, reducing social distance.",
        "C": "Because it prioritizes economic integration and assumes that achieving economic parity automatically generates social harmony.",
        "D": "Because it aims to replace multiple group identities with a single national identity, eliminating cultural differences that could cause conflict."
      },
      "correct_answer": "B",
      "simplification_notes": "Rewrote the question in clearer, concise academic language; retained contrast between dynamic participatory integration and forced assimilation; preserved the mechanism (dialogue, mutual adjustment, shared norms without erasure) as the correct explanation. Options were kept plausible alternatives reflecting assimilation, economic-first, and identity replacement views.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.8_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized European city receives three newcomer groups and implements three different integration approaches: Municipality A requires newcomers to adopt host-country cultural practices as a condition for accessing public services; Municipality B funds ethnic community centers and bilingual schools so groups can preserve distinct cultural identities while participating civically; Municipality C removes legal barriers to employment and combats discrimination but otherwise intervenes minimally. After two generations the observed outcomes are: in A rapid cultural conformity but persistent social tensions; in B strong ethnic institutions, high civic participation within groups but fewer cross-group friendships; in C divergent outcomes—some groups achieve upward mobility and intergroup integration, others remain marginalized. Which of the following sets of propositions best matches the concept of social integration and the competing theoretical trajectories described in the article?",
      "options": {
        "A": "Only proposition 1 is correct: Social integration is a dynamic, participatory process aimed at peaceful coexistence and is distinct from forced assimilation; the rest are incorrect.",
        "B": "Only propositions 2 and 3 are correct: Assimilation, multiculturalism, and segmented integration describe competing trajectories and greater social integration reduces segregation and increases access to community life; proposition 1 (about not being forced assimilation) is false.",
        "C": "Only propositions 1 and 3 are correct: Social integration is dynamic and not forced assimilation, and higher social integration reduces segregation and expands access to community life; proposition 2 (theories of assimilation, multiculturalism, segmented integration) is false.",
        "D": "All three propositions are correct: (1) Social integration is a dynamic, participatory process distinct from forced assimilation; (2) assimilation, multiculturalism, and segmented integration are competing theoretical trajectories that predict different outcomes depending on individual, contextual and structural factors; (3) higher social integration corresponds to reduced segregation/exclusion and greater access to community life and convergence of social practices and values."
      },
      "correct_answer": "D",
      "generation_notes": "Created a scenario with three municipal policies and intergenerational outcomes; tested (1) distinction between integration and forced assimilation, (2) competing theoretical frameworks (assimilation, multiculturalism, segmented integration) and their determinants, and (3) link between higher social integration and reduced segregation/access to community life. Offered options combining propositions to evaluate conceptual understanding.",
      "concepts_tested": [
        "Social integration as a dynamic, participatory process distinct from forced assimilation",
        "Competing theories of integration: assimilation, multiculturalism, segmented integration and factors shaping trajectories",
        "Relationship between higher social integration, reduced segregation/exclusion, and greater access to community life (social cohesion)"
      ]
    },
    "pass_2_reason": "readability_too_high_27.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why, if cultural diversity is understood through the biodiversity analogy, should policies aim to protect not only existing cultures but also the interactions and processes that produce new cultural forms?",
      "options": {
        "A": "Because a biodiversity-like view implies resilience arises from interdependence and ongoing change, so policies should foster cross-cultural exchange, experimentation, and adaptive governance.",
        "B": "Because biodiversity analogy requires converting all cultures into a single uniform system to maximize efficiency.",
        "C": "Because it argues that cultures are fixed \"species\" whose preservation is independent of interactions.",
        "D": "Because it asserts that cultural value should be determined solely by market metrics, ignoring cross-cultural processes."
      },
      "correct_answer": "A",
      "source_article": "Cultural diversity",
      "x": 1.2185401916503906,
      "y": 0.9488958120346069,
      "concepts_tested": [
        "Concept 1: The five overlapping domains of cultural diversity (economic, artistic, participatory, heritage, multicultural) and how they interrelate, with note that economic concerns dominate international negotiations.",
        "Concept 2: The role of international governance and policy framing (UNESCO, Universal Declaration on Cultural Diversity) and the distinction between broad, global interpretations versus narrower, economic interpretations.",
        "Concept 3: The conceptual distinction and analogy between cultural diversity and biodiversity, including implications for policy and cross-cultural dialogue."
      ],
      "parent_concepts": [
        "Concept 3: CRM’s relationship to broader societal aims (public education, access to culture, preservation of endangered languages, multiculturalism) and its role in promoting global and local cultural heritage."
      ],
      "parent_articles": [
        "Cultural resource management"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If cultural diversity is understood using the biodiversity analogy, why should cultural policy protect not only existing cultures but also the interactions and processes that produce new cultural forms?",
      "options": {
        "A": "Because, like biological ecosystems, cultural resilience depends on interdependence and ongoing innovation; therefore policies should foster cross-cultural exchange, experimentation, and adaptive governance.",
        "B": "Because the analogy implies that cultures should be standardized into a single uniform system to maximize efficiency and reduce variation.",
        "C": "Because it treats cultures as fixed 'species' whose preservation requires keeping each culture static and isolated from others.",
        "D": "Because it suggests cultural value is best judged solely by market metrics, so policy should prioritize commercial success and ignore cross-cultural processes."
      },
      "correct_answer": "A",
      "simplification_notes": "Streamlined wording to an undergraduate level, clarified the biodiversity analogy and its policy implications, shortened options while keeping them plausible distractors, and preserved the original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.4_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized country, Novaterra, is preparing a national cultural policy to present at an upcoming UNESCO-led forum. Novaterra must both (1) satisfy immediate international negotiation pressures that typically prioritize the economic domain of cultural diversity and (2) align with UNESCO's broader anthropological framing (as in the 2001 Universal Declaration on Cultural Diversity) and the biodiversity analogy (treating culture as a \"cultural gene pool\" requiring active safeguarding). Which of the following policy packages best balances these demands by addressing the five overlapping domains of cultural diversity (economic, artistic, participatory, heritage, multicultural), while respecting UNESCO's emphasis on free flow of ideas and the need to conserve diversity analogous to biodiversity?",
      "options": {
        "A": "Adopt a mixed policy that (i) provides incentives and export support to strengthen domestic cultural industries (economic) and negotiates cultural reservations in trade agreements; (ii) enacts statutory protections for artistic freedom and access to diverse cultural content (artistic); (iii) creates participatory grants for minority and indigenous cultural producers to increase representation (participatory/multicultural); (iv) funds both museums and programmes for safeguarding intangible heritage (heritage), including language revitalization and community-led documentation; and (v) establishes a national \"Cultural Diversity Fund\" linked to UNESCO mechanisms (e.g., applying to the IFCD) to support small-scale makers—explicitly citing the 2001 Declaration and the 2005 Convention and framing measures in terms of preserving a cultural gene pool without erecting blanket trade bans.",
        "B": "Prioritise the economic domain by subsidising large domestic cultural exporters, imposing quotas on imported cultural goods, and negotiating strong cultural exceptions in all trade treaties; limit other measures to nominal heritage grants for museums, assuming economic strength will indirectly preserve cultural expression.",
        "C": "Focus the policy on heritage and artistic freedom: create strict legal protections for intangible heritage and museums, and robust anti-censorship laws for artists, but avoid state intervention in markets or trade and provide no targeted support for minority participation or language programmes, arguing that market neutrality respects the free flow of ideas.",
        "D": "Treat cultural diversity primarily as a conservation problem analogous to endangered species: ban certain foreign cultural imports, restrict cross-border cultural flows to prevent 'homogenisation', and create a registry of \"protected\" cultural expressions with criminal penalties for violations—while declining to engage with UNESCO instruments on trade or economic measures."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a scenario requiring integration of the five domains, UNESCO policy framing (2001 Declaration, 2005 Convention), and the biodiversity analogy; produced four plausible policy packages varying in comprehensiveness and conformity with UNESCO norms; A is the only option that addresses all domains and balances economic and anthropological concerns.",
      "concepts_tested": [
        "Five overlapping domains of cultural diversity and their interrelation",
        "UNESCO governance, Universal Declaration on Cultural Diversity, and the distinction between broad anthropological vs narrow economic framings",
        "Analogy between cultural diversity and biodiversity and its policy implications (conservation without isolationism)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.5_vs_16"
  },
  {
    "original_question": {
      "question": "How do internal policies and resource mobilization, together with a long-time horizon, enable grand strategy to coordinate military and nonmilitary instruments across both peacetime and wartime?",
      "options": {
        "A": "They primarily optimize for immediate battlefield outcomes by investing in a single instrument, making cross-instrument coordination unnecessary.",
        "B": "They build enduring capacities (human, economic, institutional) and align investments with long-term objectives, so that military, diplomatic, economic, and informational means can be incrementally developed and synchronized over time.",
        "C": "They ensure that grand strategy remains solely about military strength, discounting diplomatic and economic tools.",
        "D": "They create rigidity that prevents adaptation to changing conditions, undermining the ability to mobilize resources when needed."
      },
      "correct_answer": "B",
      "source_article": "Grand strategy",
      "x": 1.1655961275100708,
      "y": 0.8304063677787781,
      "concepts_tested": [
        "Concept 1: Integration of multiple instruments (military, diplomatic, economic, informational) to pursue long-term national interests.",
        "Concept 2: The role of internal policies and resource mobilization, and the long-time horizon (peacetime and wartime) as mechanisms that enable grand strategy.",
        "Concept 3: Distinctions and relationships between grand strategy, strategy, and foreign policy, including prioritization, cost-benefit analysis, and practical planning guided by leadership."
      ],
      "parent_concepts": [
        "Concept 1: The operational level as a cognitive bridge that translates strategic goals into coordinated campaigns and operations by integrating ends, ways, and means.",
        "Concept 2: Grand strategy framework (primacy, deep engagement, liberal hegemony) and how it dictates the use of military power, alliances, and institutions to achieve goals."
      ],
      "parent_articles": [
        "Operational level of war",
        "Foreign policy of the United States"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do internal policies and resource mobilization, together with a long time horizon, enable a state's grand strategy to coordinate military and nonmilitary instruments across both peacetime and wartime?",
      "options": {
        "A": "They prioritize immediate battlefield success by concentrating investment in a single instrument, eliminating the need to coordinate across different instruments.",
        "B": "They create enduring capacities (human, economic, institutional) and align investments with long-term objectives, so military, diplomatic, economic, and informational means can be developed and synchronized incrementally over time.",
        "C": "They restrict grand strategy to military power alone, excluding diplomatic and economic tools from long-term planning.",
        "D": "They produce institutional rigidity that prevents adaptation to changing circumstances and thus impedes timely resource mobilization when required."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the stem for clarity and concision; removed historical examples and jargon; preserved the causal link between internal policies, resource mobilization, long time horizon, and coordination of multiple instruments. Options kept plausible distractors.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.5_vs_16",
    "pass_2_attempt": {
      "question": "The fictional state of Novaria faces a rising regional competitor, mounting fiscal deficits, and growing domestic labor unrest. The president commissions a 15-year national plan that (1) directs the military to prioritize a balanced naval and air deterrent while retaining a small mobile land force; (2) negotiates a network of defensive treaties and deepens economic ties with neighboring states through preferential trade agreements; (3) funds a multi-year program to modernize the defense industrial base, institutes targeted conscription during major crises, and launches vocational retraining to convert civilian factories for surge production if needed; (4) invests in strategic communications and cultural diplomacy to improve its international image; and (5) ranks objectives (defend core territory, preserve trade routes, maintain domestic prosperity) with cost–benefit estimates and staged implementation milestones under direct presidential authority with senior military advisers. Which characterization best describes this 15-year plan?",
      "options": {
        "A": "A grand strategy: a long‑horizon, politically directed plan that integrates military, diplomatic, economic, informational instruments, includes internal mobilization mechanisms, sets priorities and cost–benefit tradeoffs, and covers peacetime and wartime contingencies.",
        "B": "A theater operational military strategy: a detailed campaign-level plan focused on force employment and immediate battlefield objectives without substantive attention to diplomatic or economic instruments or long-term domestic policies.",
        "C": "A foreign policy manifesto: an expression of values and external partnerships emphasizing trade and diplomacy but lacking concrete internal mobilization measures, prioritized resource allocation, and military integration.",
        "D": "A domestic stabilization policy: primarily an internal socioeconomic package aimed at quelling unrest and shoring up the economy, without a coordinated plan for alliances, military posture, or long‑term international objectives."
      },
      "correct_answer": "A",
      "generation_notes": "Scenario contrasts integrated, long-term, leadership-directed plan with options that isolate military operations, foreign-policy rhetoric, or domestic-only measures; correct answer identifies grand strategy features (instrument integration, internal mobilization, long horizon, prioritization).",
      "concepts_tested": [
        "Integration of military, diplomatic, economic, informational instruments",
        "Role of internal policies and resource mobilization plus long-term peacetime/wartime horizon",
        "Distinction between grand strategy, operational strategy, and foreign policy including prioritization and leadership direction"
      ]
    },
    "pass_2_reason": "readability_too_high_27.1_vs_16"
  },
  {
    "original_question": {
      "question": "How does political secularism, defined as a formal separation of religion from the state's functions and public policy, influence the legitimacy of government decisions in a religiously plural society?",
      "options": {
        "A": "By ensuring laws track the claims of the majority religion and thus stabilize governance.",
        "B": "By establishing neutral rules that apply to all belief systems, thereby reducing religious favoritism and cross-religion conflict.",
        "C": "By mandating that the state adopt atheism as its official stance to guarantee non-religious governance.",
        "D": "By devolving religious authority into separate civil courts, allowing religious leaders to legislate on moral issues."
      },
      "correct_answer": "B",
      "source_article": "Secularism",
      "x": 1.0437915325164795,
      "y": 0.8774303197860718,
      "concepts_tested": [
        "Concept 1: Separation of religion and state (political secularism) as a governing principle and mechanism, including its rationale and impact on public policy and civil life.",
        "Concept 2: Secularism and modernization/naturalism as a relationship, including debates about whether secularism drives modernization or serves to reduce religious influence in favor of material/worldly concerns.",
        "Concept 3: Variations/models of secularism across cultures (American, French laique, Turkish, Indian) and how these different implementations affect religion’s public role, minority rights, and state neutrality."
      ],
      "parent_concepts": [
        "Concept 2: The spectrum of religion-state relations (theocracy vs. official state religion vs. secular governance) and their political/civil rights implications",
        "Concept 1: The relationship between official endorsement and religious rights/privileges. How does governmental backing alter what religions can do and what rights followers have?",
        "Concept 2: Anti-clericalism as a mechanism shaping religion’s role in public and political life (and the replacement of religious symbols with secular equivalents).",
        "Governance models and their impact on religious law (theocracy/established religion vs secular/multicultural states) and their social/legal consequences"
      ],
      "parent_articles": [
        "Religion in politics",
        "State religion",
        "State atheism",
        "Religious law"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a religiously diverse society, how does political secularism — the formal separation of religion from state functions and public policy — affect the perceived legitimacy of government decisions?",
      "options": {
        "A": "By making laws reflect the doctrines or claims of the majority religion, thereby stabilizing governance by aligning state policy with majority beliefs.",
        "B": "By establishing neutral legal rules that apply equally to all belief systems, reducing state favoritism toward any religion and lowering inter-religious conflict over policy.",
        "C": "By requiring the state to adopt atheism as its official stance so that government actions are explicitly non-religious.",
        "D": "By delegating moral and family law matters to separate religious courts, allowing religious leaders to legislate on communal moral issues."
      },
      "correct_answer": "B",
      "simplification_notes": "Question shortened and clarified for undergraduate readers; background material removed while retaining the core idea of how formal separation of religion and state affects legitimacy in plural societies. Options reworded to be concise and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.6_vs_16",
    "pass_2_attempt": {
      "question": "The fictional state of Novaria enacts a constitutional reform package: (1) the constitution forbids the state from supporting or recognising any particular religion; (2) public schools and civil servants are barred from displaying or wearing conspicuous religious symbols; (3) religious personal laws (marriage, inheritance, family courts) are replaced by a single uniform civil code; (4) the government defends these measures as part of a deliberate project of modernization, arguing that public policy should be grounded in empirical, material considerations rather than religious doctrine; private religious worship remains legal. Which existing model of secularism does Novaria most closely resemble, and what is the most plausible consequence for religious minorities and public life?",
      "options": {
        "A": "This most closely resembles French laïcité: an interventionist, state‑supremacy form of secularism that restricts religion in the public sphere. Likely consequence: reduced public visibility and institutional power of religions, stronger state neutrality in law, but increased grievances and claims of discrimination from visible religious minorities.",
        "B": "This most closely resembles the American model of separation: the state avoids establishing religion and protects free exercise but generally refrains from regulating religious symbols. Likely consequence: plural public expression of religion and minimal state intervention in personal law.",
        "C": "This most closely resembles the Indian accommodationist model: the state actively funds and recognises multiple religious communities and preserves separate personal laws. Likely consequence: enhanced protections for minority religious practices and continued legal pluralism.",
        "D": "This most closely resembles state atheism (Marxist model): the state bans religious practice and punishes expressions of belief, enforcing a materialist ideology. Likely consequence: complete suppression of religion and criminalisation of private worship."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete constitutional scenario that maps specific policy choices (bans on symbols, uniform civil code, state justification invoking modernization and empirical policymaking) to secularism models; options contrast French laïcité, American separation, Indian accommodationism, and state atheism to test recognition of model and likely minority impacts.",
      "concepts_tested": [
        "Separation of religion and state (political secularism) as mechanism and impact on public policy",
        "Relationship between secularism and modernization/naturalism (state justification for policy)",
        "Comparative models of secularism (French laïcité, American, Indian, state atheism) and effects on minorities and state neutrality"
      ]
    },
    "pass_2_reason": "readability_too_high_29.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the method by which political power is obtained and legitimized (electoral contest vs hereditary succession) matter for how the government exercises authority and behaves?",
      "options": {
        "A": "Electoral competition always yields weaker authority because leaders must constantly concede to rivals in policy making.",
        "B": "Hereditary succession always yields stronger legitimacy and more predictable policy outcomes due to continuity of rule.",
        "C": "Electoral competition ties legitimacy to consent and creates constraints from institutions and accountability mechanisms, while hereditary succession relies on lineage and tradition, which can provide continuity but may reduce accountability—shaping how boldly authority is exercised and how responsive the government is.",
        "D": "The method of obtaining power is irrelevant to authority once the government has a constitution and a formal separation of powers."
      },
      "correct_answer": "C",
      "source_article": "Government",
      "x": 1.1449105739593506,
      "y": 0.8033658862113953,
      "concepts_tested": [
        "How political power is obtained and legitimized (electoral contest vs hereditary succession) and its impact on government authority.",
        "Separation of powers: the roles of legislature, executive, and judiciary in enforcing and determining policy.",
        "Typologies and relationships between regimes (democracy, authoritarianism, totalitarianism, monarchies, hybrids) and the idea that systems can be overlapping or mixed."
      ],
      "parent_concepts": [
        "Concept 3: Sources and instruments of executive power (decrees/executive orders, control of bureaucracy) and how they interact with legislative and judicial oversight and with policy areas like economics and foreign policy.",
        "Concept 1"
      ],
      "parent_articles": [
        "Executive (government)",
        "Local government in Nepal"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the way leaders gain and justify political power—through competitive elections versus hereditary succession—affect how a government exercises authority and responds to citizens?",
      "options": {
        "A": "Electoral competition always produces weaker authority because elected leaders must constantly yield to rivals and cannot act decisively in policymaking.",
        "B": "Hereditary succession always generates stronger legitimacy and more predictable policy outcomes because continuity of rule stabilizes decision-making.",
        "C": "Electoral competition links legitimacy to popular consent and creates institutional constraints and accountability (e.g., elections, legislatures, courts), whereas hereditary succession bases legitimacy on lineage and tradition, which can provide continuity but often reduces accountability—thus influencing how boldly rulers act and how responsive the government is.",
        "D": "Once a constitution and formal separation of powers are in place, the method of obtaining power no longer affects how authority is exercised or how the government behaves."
      },
      "correct_answer": "C",
      "simplification_notes": "Question wording shortened and clarified for undergraduates; retained core contrast between electoral legitimacy and hereditary legitimacy; preserved the link to institutions (separation of powers, accountability) and effects on responsiveness; options made concise and kept plausibility.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.3_vs_16",
    "pass_2_attempt": {
      "question": "The Kingdom of Aurelia has the following institutional configuration: the head of state is a hereditary monarch who retains reserve powers to dissolve the elected legislature and to appoint or dismiss the prime minister; national legislatures are elected in regular multiparty contests but the ruling party benefits from pervasive media control and campaign finance advantages; the judiciary is formally independent but its supreme-court judges are appointed by the monarch on the recommendation of the prime minister. Which of the following best characterizes Aurelia's source(s) of political legitimacy, the form of government, and the effective separation of powers?",
      "options": {
        "A": "Aurelia is a stable constitutional democracy: political legitimacy derives chiefly from regular electoral contests, the government is a constitutional monarchy with strong rule-of-law protections, and the separation of powers is meaningful because the legislature, executive, and judiciary operate independently.",
        "B": "Aurelia is an absolute monarchy: political legitimacy rests almost entirely on hereditary succession, the monarch is the primary sovereign with unchecked authority, and there is no practical separation of powers since the monarch controls all branches directly.",
        "C": "Aurelia is a hybrid (authoritarian constitutional) monarchy: legitimacy is mixed (hereditary legitimacy for the monarch and contested electoral legitimacy for the legislature), the system combines monarchical and electoral institutions, and separation of powers exists de jure but is weakened de facto by the monarch's reserve powers, dominant-party advantages, and politicized judicial appointments.",
        "D": "Aurelia is a totalitarian one-party state: political legitimacy is produced exclusively by a single ruling ideology and party cadre (not heredity), the regime seeks to control all aspects of society and the separation of powers is irrelevant because the party hierarchy subsumes state institutions."
      },
      "correct_answer": "C",
      "generation_notes": "Created a realistic mixed-regime scenario combining hereditary head-of-state powers, competitive-but-tilted elections, and politicized judicial appointments to test students' ability to identify mixed legitimacy sources, classify regime type (hybrid/authoritarian constitutional monarchy), and assess de jure vs de facto separation of powers.",
      "concepts_tested": [
        "sources of political legitimacy (electoral contest vs hereditary succession)",
        "separation of powers and de jure vs de facto authority of legislature/executive/judiciary",
        "regime typologies and hybrid/mixed systems (democracy, authoritarianism, monarchy)"
      ]
    },
    "pass_2_reason": "readability_too_high_27.8_vs_16"
  },
  {
    "original_question": {
      "question": "How does the interaction between habitus and field mediate whether embodied cultural capital yields social advantage, and what happens if habitus and field are misaligned?",
      "options": {
        "A": "Embodied cultural capital always translates into advantage, independent of field norms.",
        "B": "When habitus aligns with the field's norms, embodied cultural capital is readily recognized and converted into social advantage; when misaligned, the same embodied capital is undervalued or misread, hindering mobility.",
        "C": "Habitus is fixed; fields always adapt to accommodate any habitus, so embodied capital is always valued.",
        "D": "Only objectified or institutionalized forms of capital drive mobility; embodied capital is never influential."
      },
      "correct_answer": "B",
      "source_article": "Cultural capital",
      "x": 1.2182003259658813,
      "y": 0.9889183044433594,
      "concepts_tested": [
        "The three forms of cultural capital (embodied, objectified, institutionalized) and how each contributes to social status and mobility.",
        "The relation between habitus, field, and cultural capital: how embodied dispositions and social positions mediate the use and value of cultural capital.",
        "Cultural capital as a mechanism of social reproduction and mobility within a system of practices, interacting with other forms of capital (economic, social) to create unequal outcomes."
      ],
      "parent_concepts": [
        "Concept 3: Prestige and competitive structure as a driver of incentives and opportunities (how being part of major festivals or a competitive frame creates reputational capital for filmmakers and studios).",
        "The hierarchy of genres in Western and East Asian art as a reflection of beliefs about imagination, manual labor, and scholarly status."
      ],
      "parent_articles": [
        "Film festival",
        "Visual arts"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the interaction between an individual's habitus and the social field determine whether embodied cultural capital produces social advantage, and what happens if habitus and field are misaligned?",
      "options": {
        "A": "Embodied cultural capital always produces social advantage regardless of the field's norms or expectations.",
        "B": "If habitus matches the field's norms, embodied cultural capital is recognized and converted into social advantage; if habitus and field are misaligned, the same embodied capital is undervalued or misread and thus fails to produce mobility.",
        "C": "Habitus is fixed and fields always adjust to accommodate any habitus, so embodied cultural capital is consistently valued and yields advantage.",
        "D": "Only objectified or institutionalized cultural capital drives social mobility; embodied cultural capital has negligible influence on advantage."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was tightened to focus on the key mechanism: recognition and conversion of embodied cultural capital via habitus-field fit. Redundant background removed; options rewritten to remain plausible and preserve contrast between alignment and misalignment.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "Two candidates apply for the same entry-level position at a large multinational law firm (a mainstream professional field whose hiring criteria emphasize prestigious credentials and normative presentation). Candidate A, Maria, grew up in a working-class family: she has highly developed embodied cultural capital in the form of sophisticated verbal fluency and familiarity with literary culture (habitus shaped by parental emphasis on discussion); she owns a high-quality violin and a small private library (objectified cultural capital); but she lacks a university degree. Candidate B, James, comes from an affluent family: he holds an elite university degree and several professional certifications (institutionalized cultural capital), attended private schools (social capital networks), and his family wealth funded internships (economic capital); his embodied mannerisms are more formal but less literarily oriented than Maria's. According to Bourdieu's framework (forms of cultural capital, habitus, field, and conversion into economic capital), which of the following claims best explains which candidate is most likely to achieve upward mobility within this hiring field and why?",
      "options": {
        "A": "Maria is most likely to be promoted because embodied cultural capital (verbal fluency and literary familiarity) and ownership of cultural objects always outrank institutional credentials in professional hiring decisions; the firm will privilege authentic cultural competence over diplomas.",
        "B": "James is most likely to achieve upward mobility because institutionalized cultural capital (an elite degree) combined with his social and economic capital aligns with the law-firm field's legitimized criteria; Maria's embodied and objectified capital have limited convertible value without institutional recognition and a habitus that matches the field's expectations.",
        "C": "Both candidates have equal chances because objectified cultural capital (violin, books) can be sold or demonstrated to produce equivalent economic capital, so material possessions level the field regardless of credentials or habitus.",
        "D": "Neither candidate can change social position because habitus rigidly determines life chances; cultural capital is entirely deterministic, so their childhood class origins fix their mobility outcomes irrespective of degrees or possessions."
      },
      "correct_answer": "B",
      "generation_notes": "Created a comparative hiring vignette linking embodied, objectified, and institutionalized cultural capital to habitus and field; tested conversion of cultural capital into economic capital and interplay with social/economic capital.",
      "concepts_tested": [
        "Forms of cultural capital (embodied, objectified, institutionalized)",
        "Relation among habitus, field, and conversion of cultural capital into economic capital (social reproduction and mobility)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.2_vs_16"
  },
  {
    "original_question": {
      "question": "Why does distinguishing reputation as a past-action-based evaluation from legitimacy and status matter for predicting how an organization will respond to social judgment?",
      "options": {
        "A": "Because reputation can shift when observable actions accumulate, signaling improvements to external audiences, while legitimacy reflects normative acceptance of actions and status reflects relative position; these different bases imply different levers and speeds of organizational response.",
        "B": "Because all three concepts are interchangeable indicators of prestige, so the same response strategy applies regardless of which one changes.",
        "C": "Because legitimacy governs legal permissions, reputation governs everyday trust, and status governs command within a hierarchy; this split means only legitimacy would constrain ongoing behavior.",
        "D": "Because once reputation improves, both legitimacy and status automatically improve as well, leaving no need for targeted responses."
      },
      "correct_answer": "A",
      "source_article": "Reputation",
      "x": 1.3228230476379395,
      "y": 0.9809948801994324,
      "concepts_tested": [
        "Concept 1: Reputation as a mechanism of social control that operates across individual and supra-individual levels, influencing behavior and evaluation.",
        "Concept 2: The relationship and distinctions among legitimacy, status, and reputation (reputation as past-action-based evaluation distinct from legitimacy and status, yet interconnected).",
        "Concept 3: Corporate reputation as a strategic signal and as an aggregation of perceptions within an institutional field, with differing disciplinary perspectives (economic signaling vs sociological description vs management viewpoints)."
      ],
      "parent_concepts": [
        "Concept 3: Prestige and competitive structure as a driver of incentives and opportunities (how being part of major festivals or a competitive frame creates reputational capital for filmmakers and studios)."
      ],
      "parent_articles": [
        "Film festival"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does treating reputation as an evaluation based on an organization's past actions — distinct from legitimacy and status — matter when predicting how the organization will react to social judgment?",
      "options": {
        "A": "Because reputation changes when observable past actions accumulate, signaling improvements (or declines) to external audiences, while legitimacy is about normative acceptance and status is about relative position in a hierarchy; these different bases imply different levers and speeds of organizational response.",
        "B": "Because reputation, legitimacy, and status are essentially interchangeable measures of prestige, so organizations will use the same response strategies no matter which one is affected.",
        "C": "Because legitimacy mainly determines legal or formal permission, reputation mainly determines everyday trust, and status mainly determines rank within a field; thus only legitimacy will reliably limit or direct ongoing organizational behavior.",
        "D": "Because an improved reputation automatically produces higher legitimacy and status, so organizations do not need targeted responses once reputation changes."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording was tightened and focused on the causal distinction: reputation = past-action evaluation; legitimacy = normative acceptance; status = hierarchical position. Extraneous examples and longer background were removed; all options kept plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.3_vs_16",
    "pass_2_attempt": {
      "question": "Aurelia Pharma, a multinational drug company, has built a long record of reliable drug quality (earning high sales and industry awards) but was recently fined for serious environmental violations at one manufacturing site. Within weeks, third‑party blogs, industry associations, and investor reports began to circulate both specific allegations and vague rumours about Aurelia's trustworthiness. Which of the following explanations best captures the role of reputation in this scenario, and correctly distinguishes reputation from legitimacy and status while summarizing the different disciplinary perspectives on corporate reputation?",
      "options": {
        "A": "Reputation is the aggregate of stakeholders' beliefs about Aurelia based on its past actions; it operates as a social control mechanism at both individual and supra‑individual levels, prompting customers, suppliers, and managers to change behavior in response to the fines and gossip. Legitimacy refers to whether Aurelia's actions conform to societal norms (threatened by the environmental breach), and status denotes its position in the industry hierarchy (awards and prestige). Economists view Aurelia's reputation as a strategic signal to markets, sociologists treat it as a description of relative status within the institutional field, and management scholars analyse reputation either broadly (overall perceptions) or specifically (outcome/capability vs behavior/character).",
        "B": "Reputation is essentially the same as legitimacy and status: the environmental fine simply lowers Aurelia's legal standing (legitimacy) and automatically demotes its status, so academics treat all three as one unified construct; hence management and economists focus on repairing legal compliance to restore reputation.",
        "C": "Aurelia's situation shows that reputation is primarily an internal corporate identity created and fully controllable by management through branding and public relations; external blogs and investor reports have limited long‑term effect because reputation is an internally managed asset disconnected from social evaluation.",
        "D": "Reputation is an objective market signal measurable only by financial outcomes (sales and stock price); since Aurelia still has high sales and awards, the environmental fine is unlikely to affect reputation meaningfully because reputation equals measurable market performance rather than social perceptions or norms."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete corporate scenario (Aurelia Pharma) that elicits analysis of reputation as social evaluation and control across multiple levels; options contrast correct multidisciplinary distinctions (legitimacy, status, reputation) with plausible but incorrect conflations.",
      "concepts_tested": [
        "Reputation as social control operating at individual and supra-individual levels",
        "Distinction between reputation, legitimacy, and status and their interrelationships",
        "Disciplinary perspectives on corporate reputation (economic signaling, sociological status, management broad vs specific views)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.6_vs_16"
  },
  {
    "original_question": {
      "question": "In modeling cellular metabolism, why can a constraint-based network model predict feasible flux distributions without parameterizing enzyme kinetics for each step, and what underlying principle enables this?",
      "options": {
        "A": "Because it relies on network topology and mass-balance (stoichiometry) to bound fluxes, exploiting conservation laws; the principle is that global constraints reduce degrees of freedom so predictions follow from structure alone.",
        "B": "Because it uses detailed kinetic constants gathered from experiments and assumes they are the same across conditions; the principle is kinetic uniformity.",
        "C": "Because it assumes all reactions operate at maximal rates; the principle is flux maximization without constraints.",
        "D": "Because it uses random sampling of fluxes and selects those that best fit data; the principle is stochastic approximations."
      },
      "correct_answer": "A",
      "source_article": "Bioinformatics",
      "x": 1.8011879920959473,
      "y": 1.0919948816299438,
      "concepts_tested": [
        "Concept 1: Interdisciplinary integration of computational methods with biological data to derive biological understanding.",
        "Concept 2: Use of computational pipelines/workflows to analyze large-scale genomic data (e.g., identifying genes and SNPs) and relate findings to disease, evolution, or variation.",
        "Concept 3: Modeling, simulation, and systems/structural biology as approaches to understand mechanisms, interactions, and networks in biology."
      ],
      "parent_concepts": [
        "High-throughput sequencing and bioinformatics enable comprehensive genome sequencing, assembly, and analysis, fueling discovery-based research and systems biology.",
        "The link between sequencing technology, data scale, and ecological insight (cost decline enabling large-scale studies and discovery of enzymes/pathways).",
        "Concept 3: Metagenomics and environmental sequencing as methods to identify and characterize the organisms present in a sample, revealing ecological and epidemiological relationships."
      ],
      "parent_articles": [
        "Genomics",
        "Metagenomics",
        "DNA sequencing"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In genome-scale metabolic modeling, how can constraint-based methods (for example, flux balance analysis) predict feasible reaction flux distributions without specifying enzyme kinetic parameters for every reaction? What fundamental principle makes this possible?",
      "options": {
        "A": "Because they use network stoichiometry and mass-balance constraints to bound fluxes and enforce conservation laws; the principle is that global structural constraints reduce degrees of freedom so feasible fluxes follow from network architecture.",
        "B": "Because they compile detailed kinetic rate constants from experiments and assume these rates are invariant across conditions; the principle is kinetic uniformity across the network.",
        "C": "Because they assume every reaction operates at its maximal catalytic rate and infer fluxes by maximizing throughput; the principle is unconstrained flux maximization.",
        "D": "Because they randomly sample large sets of fluxes and retain those that best match observed data; the principle is stochastic approximation and empirical selection."
      },
      "correct_answer": "A",
      "simplification_notes": "Question shortened and focused on genome-scale/metabolic modeling and flux balance analysis; wording clarified (stoichiometry, mass-balance, conservation laws); distractors made concise but plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.3_vs_16",
    "pass_2_attempt": {
      "question": "You are given Illumina paired-end whole-genome sequencing reads from 200 individuals of a plant species: 100 individuals from a drought-tolerant population and 100 from a drought-sensitive population, plus phenotype metadata. Your goal is to (i) identify candidate genetic variants (SNPs and small indels) that associate with drought tolerance, (ii) predict which variants are likely to alter protein function or gene regulation, and (iii) evaluate the mechanistic consequences of high-priority variants at the structural and network/pathway level to generate hypotheses for experimental validation. Which of the following computational pipelines, executed in the given order, best integrates bioinformatics methods to achieve these goals?",
      "options": {
        "A": "1) Quality control and adapter/quality trimming of reads (e.g., FastQC, TrimGalore). 2) Align reads to the reference genome (e.g., BWA-MEM), mark duplicates and perform base quality recalibration. 3) Joint variant calling and genotyping (e.g., GATK HaplotypeCaller/GenotypeGVCFs), followed by variant quality filtering. 4) Population-level analyses: case-control association tests (GWAS or allele-frequency comparison), FST/selection scans to prioritize loci. 5) Functional annotation of variants (e.g., VEP/SnpEff) to flag coding, regulatory, and splice-site changes. 6) Predict impact of missense variants (SIFT/PolyPhen) and annotate regulatory variants with motif/Chromatin-state data. 7) For prioritized missense variants, perform structural modelling/homology modelling or consult AlphaFold predictions and assess effects on stability or binding (e.g., FoldX, docking). 8) Map affected proteins to protein–protein interaction networks and perform pathway/GO enrichment (KEGG, Reactome) and, if needed, construct simple systems-level models (logical/ODE) of the perturbed pathway.",
        "B": "1) De novo assemble each individual genome from the short reads and generate contigs. 2) Align contigs pairwise to the reference and call variants from assembly alignments. 3) Annotate assembled contigs with BLAST to identify genes, then perform per-contig association tests to find contigs associated with drought tolerance. 4) For associated contigs, predict protein structure by threading and run network enrichment on genes found in contigs.",
        "C": "1) Use k-mer counting on raw reads and perform a k-mer-based association test between tolerant and sensitive groups to produce candidate k-mers. 2) Map significant k-mers back to the genome with BLAST to identify candidate SNPs/regions. 3) Annotate these regions using gene databases, then for any coding hits directly perform homology modelling and pathway enrichment without formal variant calling or population-genetics statistics.",
        "D": "1) Align reads to reference and immediately call SNPs per individual with a simple pileup caller without joint genotyping or stringent filtering. 2) Run a transcription factor motif scan on all called SNPs and prioritize SNPs in promoter motifs. 3) For the top promoter SNPs, perform AlphaFold modelling of the nearest protein and infer pathway effects solely from that single-protein model."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic multi-step pipeline scenario that integrates read QC, alignment, joint variant calling, population-level association, functional annotation, structural modelling (AlphaFold/homology), and network/pathway analysis to test interdisciplinary integration and workflow design.",
      "concepts_tested": [
        "Integration of computational methods with biological data to derive biological understanding",
        "Use of computational pipelines/workflows for large-scale genomic variant discovery and association with phenotype (genes, SNPs, disease/evolution/variation)",
        "Modeling and structural/systems-level analyses to evaluate mechanistic impacts and network/pathway consequences"
      ]
    },
    "pass_2_reason": "readability_too_high_22.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the secularization of theological concepts into political concepts function as a mechanism that reshapes how legitimacy is established in modern politics?",
      "options": {
        "A": "It shifts legitimacy from divine command to human reason and public justification by reframing sacred moral vocabularies as universal or civic principles.",
        "B": "It eliminates religious moral concerns from politics, making policy decisions solely technical and devoid of ethics.",
        "C": "It strengthens clerical control over law by embedding scripture directly into constitutional text.",
        "D": "It creates a zero-sum competition among religious groups over who defines the state's moral order."
      },
      "correct_answer": "A",
      "source_article": "Political theology",
      "x": 0.5401283502578735,
      "y": 0.633873462677002,
      "concepts_tested": [
        "Secularization of theological concepts into political concepts as a mechanism shaping modern politics",
        "Cross-cultural trajectories of political theology, including non-Christian traditions and regional contexts",
        "Divergent scholarly orientations within political theology (moral reform vs. social justice) and their analytical implications"
      ],
      "parent_concepts": [
        "Politicisation of religion as a mechanism that can unify a nation and shape national identity."
      ],
      "parent_articles": [
        "Religious nationalism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does secularizing theological ideas into political concepts change how political legitimacy is established in modern states?",
      "options": {
        "A": "It transfers legitimacy from divine authority to human reason and public justification by reframing sacred moral language as universal or civic principles.",
        "B": "It removes religious moral concerns from politics, making policy choices purely technical and ethically neutral.",
        "C": "It strengthens clerical control over law by embedding scripture directly into constitutional texts.",
        "D": "It produces zero-sum competition among religious groups over who defines the state's moral order."
      },
      "correct_answer": "A",
      "simplification_notes": "Rephrased the original into a direct, concise question about secularization and legitimacy; simplified option wording while keeping their intended analytical contrasts; removed specific historical examples and theoretical names to focus on the core mechanism.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.2_vs_16",
    "pass_2_attempt": {
      "question": "In the fictitious country of Novara, the 21st-century constitution contains clauses invoking a 'sovereign emergency' power that allows exceptional measures during crises; legal scholars note this language closely parallels earlier clerical claims about divine sovereignty. Concurrently, two prominent religious movements shape politics: Movement A (a revivalist Christian party) advocates laws enforcing individual moral behavior, while Movement B (a coalition of clergy and grassroots groups) campaigns for land redistribution and state welfare programs in the name of solidarity with the poor. Scholars debating Novara's politics propose several explanations. Which analytical framework most comprehensively accounts for (1) the constitution's secularized 'sovereign' language originating from theological concepts, (2) the presence of both individual moral-reform and collective social-justice religious movements, and (3) the possibility that similar patterns could arise from non-Christian religious traditions in other regions?",
      "options": {
        "A": "A Hobbesian institutionalist explanation: Novara's constitutional language and political movements are best explained by secular state-building imperatives and rational strategies to secure order; religious rhetoric is epiphenomenal and does not shape core political concepts.",
        "B": "A narrow Schmittian secularization thesis: modern political concepts in Novara (like sovereign emergency) are secularized theological concepts derived from Christian theology; the divergent religious movements are secondary and do not require attention to non-Christian trajectories.",
        "C": "A public-theology/civil-society account: focus on the differential roles of religion in civil society versus the state—Movement A and Movement B represent civil-society pressures that influence but do not originate constitutional doctrines, which emerge from legal culture alone.",
        "D": "A comprehensive political-theology framework that combines Schmitt's insight about secularization of theological concepts into key political categories, a typology distinguishing moral-reform (individualist) versus social-justice (collective) religious orientations, and sensitivity to cross-cultural trajectories whereby similar processes can develop in non-Christian contexts (e.g., Islamic, Confucian, or African theologies)."
      },
      "correct_answer": "D",
      "generation_notes": "Constructed a concrete constitutional and movement-based scenario to test the secularization thesis (Schmitt), the typology of moral-reform vs social-justice orientations, and attention to cross-cultural trajectories beyond Christianity; provided plausible distractors emphasizing institutionalism, narrow Schmittian view, and public-theology focus.",
      "concepts_tested": [
        "Secularization of theological concepts into political concepts",
        "Cross-cultural trajectories of political theology including non-Christian contexts",
        "Divergent scholarly orientations: moral reform vs social justice"
      ]
    },
    "pass_2_reason": "readability_too_high_22.4_vs_16"
  },
  {
    "original_question": {
      "question": "How does the institutional difference between a theocracy and a state with an official religion shape the relationship between religious authority and civil authority, and what are the implications for minority rights and policy formation?",
      "options": {
        "A": "In a theocracy, civil authority derives legitimacy from divine guidance and is exercised through religious officials, leading to a centralized, normative order that can enforce religiously defined rules and suppress dissent and minority rights; in a state with an official religion but secular sovereignty, civil authorities retain ultimate legal authority, religious actors influence policy within a secular framework, allowing for pluralism and checks on religious power.",
        "B": "In a theocracy, religious authorities always operate independently of civil authorities to protect minority rights.",
        "C": "A state with an official religion eliminates religious influence from policy completely.",
        "D": "The form of government has no effect on how religious authority interacts with civil authority."
      },
      "correct_answer": "A",
      "source_article": "Religion in politics",
      "x": 0.4704078137874603,
      "y": 0.4892386794090271,
      "concepts_tested": [
        "The role of religion in forming political ideologies and mobilization (e.g., Islamism as identity politics, Christian democracy vs. Christian fascism, Hindutva)",
        "The distinction and implications of theocracy versus state religion for governance and civil authority",
        "Religion as a driver of political extremism and violence (religious terrorism, jihadism) and the mechanisms linking belief to action"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the institutional difference between a theocracy and a state that has an official religion change the balance between religious and civil authority, and what follow-on effects does this have for minority rights and policymaking?",
      "options": {
        "A": "In a theocracy, civil authority claims legitimacy from divine guidance and is often exercised through religious officials, producing a centralized normative order that can enforce religious rules and constrain dissent and minority rights; by contrast, in a state with an official religion the state retains ultimate legal authority, so religious actors may influence policy but do so within a secular legal framework that permits pluralism and institutional checks on religious power.",
        "B": "In a theocracy, religious authorities always operate independently of civil institutions and are specifically structured to protect minority rights.",
        "C": "A state with an official religion removes religious influence from policymaking entirely, producing fully secular public policy.",
        "D": "The form of government (theocracy versus state with an official religion) has no effect on how religious authority interacts with civil authority; those interactions are determined solely by social or cultural factors."
      },
      "correct_answer": "A",
      "simplification_notes": "Reworded the original question into clearer undergraduate-level language, removed detailed historical examples, and emphasized the institutional distinction and practical implications for minority rights and policy formation while keeping the original correct answer and core concepts.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.4_vs_16",
    "pass_2_attempt": {
      "question": "In the hypothetical state of Novara, 70% of the population adheres to a single faith. Three political actors emerge: (1) the Revivalist Front frames its platform around restoring scriptural law and mobilizes mass rallies emphasizing communal authenticity and a distinct religious lifestyle; (2) the Democratic Faith Party campaigns for Novara to adopt the faith as an official state religion while retaining civil courts and the constitutional supremacy of elected officials over clerical bodies; (3) the Spear of Divine is a small clandestine cell that stages bombings and justifies violence as divinely mandated, promising adherents cosmic rewards. Which single analytical statement best interprets these developments in light of scholarly debates about religion and politics?",
      "options": {
        "A": "The Revivalist Front exemplifies religion-as-identity mobilization (akin to broad definitions of Islamism or other religious identity politics) by activating a communal label and lifestyle demands; the Democratic Faith Party’s program describes a state with an official religion—not a theocracy—because the state retains supremacy over religious authorities; and the Spear of Divine’s violence is plausibly linked to high‑stakes sacred beliefs and exclusivist narratives that lower moral and social barriers to violence, making recruitment and radicalization easier.",
        "B": "All three actors indicate Novara has become a theocracy: once a religion is the public reference for politics, clerical and scriptural demands inevitably dictate governance; therefore the distinction between a theocracy and a state with an official religion is analytically negligible, and violent groups like the Spear of Divine are best explained as separate criminal actors with no meaningful connection to doctrinal content.",
        "C": "The Revivalist Front’s success is best explained by treating religion purely as an ethnic or instrumental label (Posner’s fungible identity framework), implying it could be swapped for any other salient group marker; since the Democratic Faith Party keeps courts secular, adopting an official religion will eliminate religiously motivated violence—so the Spear of Divine’s attacks must stem primarily from nonreligious grievances such as unemployment.",
        "D": "All three actors reflect the same phenomenon: religion is only a textual ideology with no special capacity to mobilize or legitimize violence; thus the difference between a theocracy and a state religion is merely semantic, and the Spear of Divine’s actions should be read solely as political insurgency fully orchestrated by rival elites rather than arising from sacred commitments."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete scenario (Novara) to assess students' ability to (1) identify religion-as-identity mobilization, (2) distinguish state religion from theocracy, and (3) explain mechanisms linking sacred, high‑stakes beliefs to recruitment into violent extremism. Options present plausible but distinct theoretical interpretations.",
      "concepts_tested": [
        "religion as identity/political mobilization",
        "theocracy versus state religion and implications for authority",
        "mechanisms linking religious belief to political extremism and violence"
      ]
    },
    "pass_2_reason": "readability_too_high_22.1_vs_16"
  },
  {
    "original_question": {
      "question": "According to the Social Identity Model of Collective Action (SIMCA), why does perceived injustice alone often fail to predict collective action, and how do injustice, efficacy, and identity interact to produce action?",
      "options": {
        "A": "Perceived injustice directly triggers action irrespective of other factors, so the other two only modulate intensity.",
        "B": "Efficacy alone determines action; injustice and identity are unnecessary.",
        "C": "In SIMCA, perceived injustice increases motivation, but action is most likely when there is a congruent combination of group-based identity (to translate grievance into collective purpose) and perceived collective efficacy (to believe coordinated action can succeed); these factors interact and reinforce each other to predict action.",
        "D": "Identity alone determines action; injustice and efficacy do not contribute beyond identity salience."
      },
      "correct_answer": "C",
      "source_article": "Collective action",
      "x": 1.2679991722106934,
      "y": 0.979525625705719,
      "concepts_tested": [
        "Concept 1: The Social Identity Model of Collective Action (SIMCA) as an integrative framework that combines injustice, efficacy, and identity as interrelated predictors of collective action.",
        "Concept 2: Perceived injustice (relative deprivation) and group-based emotions as mechanisms that motivate collective action.",
        "Concept 3: Perceived collective efficacy as the belief that coordinated action is feasible, and its causal role in enabling collective action."
      ],
      "parent_concepts": [
        "Concept 1: Movements organize informal networks and strategic actions to empower oppressed populations to challenge elites, enabling bottom-up social change.",
        "Concept 1: Activism as a spectrum from individual acts to organized social movements; how sustained collective action leads to broader social change.",
        "Concept 3: The relationship between online and offline mobilization, including classifications by reliance on the Internet and examples of hybrid or cross-platform activism (e.g., Occupy Wall Street)."
      ],
      "parent_articles": [
        "Social movement",
        "Activism",
        "Internet activism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In the Social Identity Model of Collective Action (SIMCA), why is perceived injustice by itself often insufficient to predict collective action, and how do perceived injustice, perceived collective efficacy, and social identity combine to produce action?",
      "options": {
        "A": "Perceived injustice directly triggers action regardless of other factors; perceived efficacy and social identity only change how intense the action is.",
        "B": "Perceived collective efficacy alone determines whether people act; perceptions of injustice or shared identity are not necessary.",
        "C": "Perceived injustice raises motivation, but collective action is most likely when a shared social identity frames that grievance into a collective purpose and there is perceived collective efficacy (belief that coordinated effort can succeed); the three factors interact and reinforce one another to predict action.",
        "D": "Shared social identity alone determines collective action; perceived injustice and efficacy add nothing beyond the salience of identity."
      },
      "correct_answer": "C",
      "simplification_notes": "Question wording shortened and clarified; retained technical terms (perceived injustice, perceived collective efficacy, social identity); options kept plausible and preserved the original correct explanation from SIMCA.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.4_vs_16",
    "pass_2_attempt": {
      "question": "A campus coalition is deciding whether to mobilize a mass protest against a proposed tuition hike. Surveyed coalition members report the following: (1) high perceptions that the tuition increase is unfair relative to other universities, producing strong group-based anger; (2) mixed beliefs about whether collective protest can actually change university policy—some messages emphasize successful past campaigns while others emphasize administrative intransigence; (3) the coalition has recently intensified intra-group rituals and symbols, increasing members' sense of shared identity. According to the Social Identity Model of Collective Action (SIMCA), which combination of psychological states would most strongly predict that the coalition will organize a successful protest?",
      "options": {
        "A": "High perceived injustice (group-based anger), high perceived collective efficacy (belief protest can succeed), and a strong salient social identity",
        "B": "High perceived injustice, low perceived collective efficacy, but a strong social identity",
        "C": "Low perceived injustice, high perceived collective efficacy, and a strong social identity",
        "D": "High perceived injustice, high perceived collective efficacy, but a weak or diffuse social identity"
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete campus protest scenario requiring integration of SIMCA's three interrelated predictors; options vary levels of injustice, efficacy, and identity to test understanding that all three high best predict collective action.",
      "concepts_tested": [
        "SIMCA integrative framework (injustice, efficacy, identity)",
        "Perceived injustice and group-based emotions as motivators",
        "Perceived collective efficacy as belief that coordinated action is feasible"
      ]
    },
    "pass_2_reason": "readability_too_high_23.1_vs_16"
  },
  {
    "original_question": {
      "question": "If ethical values guide interpretation of social institutions, how does this principle explain why two analysts might evaluate the same institution differently, and what mechanism drives these differing judgments?",
      "options": {
        "A": "Their different empirical data lead to different descriptive conclusions, with no normative mechanism involved.",
        "B": "They anchor their assessments in distinct ethical commitments, which provide normative criteria (e.g., fairness, rights) that can clash with efficiency-based judgments, leading to principled disagreement.",
        "C": "They both rely on a universal ethical standard, so disagreement cannot persist across contexts.",
        "D": "They disregard empirical facts and rely solely on subjective intuition, making any judgment equally valid."
      },
      "correct_answer": "B",
      "source_article": "Social philosophy",
      "x": 1.1984376907348633,
      "y": 1.004553198814392,
      "concepts_tested": [
        "Ethical values as the guiding lens for interpreting social institutions (principle)",
        "Structure and agency as a core relational mechanism in social phenomena (mechanism/relationship)",
        "The use of interdisciplinary theoretical frameworks (e.g., social ontology, care ethics, cosmopolitan democracy) to analyze society (conceptual framework/relationship)"
      ],
      "parent_concepts": [
        "Concept 3: The normative function of ideology (to defend individual liberty, property, free markets, and constitutional limits on state power), representing underlying principles guiding ideological systems."
      ],
      "parent_articles": [
        "Ideology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If ethical values are the primary lens for interpreting social institutions, why might two analysts evaluate the same institution differently, and what mechanism produces these differing judgments?",
      "options": {
        "A": "They use different empirical evidence and therefore reach different descriptive conclusions; no normative mechanism is involved.",
        "B": "They rely on different ethical commitments (e.g., fairness, rights, care), which supply competing normative criteria; disagreements are driven by those conflicting values and by different emphases on social structure versus individual agency.",
        "C": "They both apply a single universal ethical standard consistently, so persistent disagreement across contexts should not occur.",
        "D": "They ignore empirical facts and depend solely on subjective intuition or bias, making each judgment merely idiosyncratic."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording shortened and clarified; added explicit mention of competing normative criteria and the structure-versus-agency mechanism; retained original concepts (ethical lens, normative criteria, structure/agency).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.9_vs_16",
    "pass_2_attempt": {
      "question": "A public university introduces an algorithmic admissions policy that yields a 30% lower acceptance probability for applicants from low-income neighborhoods and a 20% higher probability for applicants with legacy status. Three researchers propose competing analyses:\n\nA) An empirical sociologist computes the changes in acceptance rates, estimates the effect sizes and p-values, and recommends statistical adjustments to the algorithm to achieve predefined fairness metrics without engaging in moral evaluation.\n\nB) A social philosopher characterizes the policy as an institutional practice that embeds structural barriers limiting the agency of low-income applicants, argues that the university has moral duties grounded in care ethics to mitigate harms, invokes social ontology to explain how the algorithm reconfigures institutional norms, and proposes cosmopolitan-democratic mechanisms for accountability and redress.\n\nC) A legal scholar examines the policy solely in terms of compliance with statutory anti-discrimination provisions and precedent on equal protection, recommending litigation strategies and doctrinal reforms.\n\nD) A behavioral economist builds a formal model of applicant strategic behavior under the algorithm, derives equilibrium strategies and welfare-maximizing incentives, and recommends incentive-compatible adjustments.\n\nWhich research program best exemplifies social philosophy as defined by interpreting social institutions through ethical values, attending to structure and agency, and deploying interdisciplinary frameworks like social ontology, care ethics, and cosmopolitan democracy?",
      "options": {
        "A": "The empirical sociologist who focuses on statistical metrics and algorithmic fairness without normative evaluation.",
        "B": "The social philosopher who analyzes structural constraints on agency, grounds obligations in care ethics, uses social ontology to describe institutional change, and proposes cosmopolitan-democratic accountability.",
        "C": "The legal scholar who focuses exclusively on statutory compliance and litigation strategies under anti-discrimination law.",
        "D": "The behavioral economist who models strategic applicant behavior and recommends incentive-compatible algorithm adjustments."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete case (algorithmic university admissions) and contrasted four disciplinary approaches; correct option matches social-philosophical criteria: ethical valuation of institutions, attention to structure and agency, and interdisciplinary frameworks (social ontology, care ethics, cosmopolitan democracy).",
      "concepts_tested": [
        "Ethical interpretation of social institutions",
        "Structure and agency relationship in social phenomena",
        "Use of interdisciplinary theoretical frameworks (social ontology, care ethics, cosmopolitan democracy)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.6_vs_16"
  },
  {
    "original_question": {
      "question": "Which statement best explains how the combination of economic status, race/ethnicity, residential location, language, and caste shapes access to educational resources and outcomes?",
      "options": {
        "A": "Each determinant reduces access independently, and the total effect is simply the sum of their separate effects.",
        "B": "The determinants interact in ways that produce effects greater than the sum of their parts, creating compounded barriers when several disadvantages co-occur.",
        "C": "The influence of these determinants is random and cannot be tied to any systematic interaction; outcomes depend on chance.",
        "D": "Policy interventions can remove all differences, so interactions among determinants do not affect resource access after policy changes."
      },
      "correct_answer": "B",
      "source_article": "Educational inequality",
      "x": 1.205594539642334,
      "y": 0.9115654230117798,
      "concepts_tested": [
        "Resource distribution as a mechanism driving educational outcomes and social mobility",
        "Measurement validity: distinguishing academic achievement from true learning and other outcomes (learning objectives, skills, persistence)",
        "Interacting social determinants: how economic status, race/ethnicity, residential location, language, and caste collectively shape access to resources and educational outcomes"
      ],
      "parent_concepts": [
        "Open enrollment as a mechanism for school choice and its relationship to selective magnet schools: how policy enables families to move beyond assigned neighborhood schools and how selective admissions affect access.",
        "How tracking functions as a school-wide, long-term sorting mechanism and its potential to create or reinforce internal segregation and differential educational opportunities."
      ],
      "parent_articles": [
        "School choice",
        "Tracking (education)"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which statement best explains how economic status, race/ethnicity, residential location, language, and caste together shape access to educational resources and outcomes (including academic achievement, learning, skills, and persistence)?",
      "options": {
        "A": "Each factor reduces access independently, so the overall effect is just the sum of their separate impacts.",
        "B": "The factors interact and amplify one another, so multiple disadvantages compound to produce effects larger than the sum of individual impacts.",
        "C": "Their influence is essentially random and not systematically related, so educational outcomes mainly depend on chance.",
        "D": "Strong policy interventions can eliminate all differences, so after effective policy change these interacting determinants no longer affect resource access."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the original phrasing, kept the listed determinants and the distinction between resource access and different educational outcomes (achievement, learning, skills, persistence); rewrote options to be concise and equally plausible while preserving the tested concept of interaction/compounding.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.9_vs_16",
    "pass_2_attempt": {
      "question": "A national ministry of education is reviewing two regions to design policy to reduce educational inequality and increase social mobility. Region A has high per-pupil funding, above-average standardized test scores, and high college enrollment, but longitudinal data show low persistence for students from minority/low-income backgrounds and poor post-college employment outcomes. Region B has low per-pupil funding and lower standardized test scores but relatively higher rates of vocational certification, better upward mobility among some immigrant cohorts, and stronger community-based language support programs. Based on the article's discussion of mechanisms driving educational inequality and measurement validity, which policy package and evaluation strategy is most likely to both reduce inequality and capture true improvements in educational efficacy?",
      "options": {
        "A": "Implement targeted redistribution of school funding to equalize resources across regions, expand high‑quality early childhood programs, institute trauma-informed and language‑inclusive schooling, and measure success using a composite of attainment, skill acquisition, persistence, and post‑college employment rather than standardized test scores alone.",
        "B": "Prioritize intensive standardized‑test preparation in Region B and reward schools whose students raise average test scores; evaluate success exclusively by improvements in standardized test percentiles and GPA because test scores are the most objective measure of learning.",
        "C": "Reallocate funds from Region A to Region B for physical infrastructure only (classrooms and textbooks), leave curricula and teacher training unchanged, and assess impact primarily by changes in district‑level enrollment and school completion rates.",
        "D": "Invest mostly in expanding free MOOCs and online content nationally, since increasing access to content will eliminate geographical and socioeconomic barriers; evaluate success by online course enrollment numbers and platform completion certificates."
      },
      "correct_answer": "A",
      "generation_notes": "Created a policy-evaluation scenario contrasting resource distribution, programmatic interventions (early childhood, trauma-informed, language supports), and measurement validity (test scores vs multifaceted outcomes) to test causal mechanisms and interacting social determinants.",
      "concepts_tested": [
        "Resource distribution as a mechanism driving educational outcomes and social mobility",
        "Measurement validity: distinguishing academic achievement (test scores/GPA) from true learning, skills, persistence, and post‑college outcomes",
        "Interacting social determinants: socioeconomic status, race/ethnicity, residential location, and language shaping access and outcomes"
      ]
    },
    "pass_2_reason": "readability_too_high_21.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why is it conceptually more informative to characterize the information society as a framework defined by multiple markers (technological, economic, occupational, spatial, and cultural) rather than as a single indicator or metric?",
      "options": {
        "A": "Because all changes are driven by a single core technology, making other markers unnecessary.",
        "B": "Because different markers capture distinct dimensions of transformation that may not progress uniformly, and together they reveal patterns of interaction and heterogeneity across domains.",
        "C": "Because using multiple markers ensures simple, uniform shifts across society.",
        "D": "Because markers are interchangeable indicators of the same underlying shift."
      },
      "correct_answer": "B",
      "source_article": "Information society",
      "x": 1.2357162237167358,
      "y": 0.9898504614830017,
      "concepts_tested": [
        "Concept 1: ICTs as drivers of societal transformation (how information creation, distribution, and manipulation reshape education, economy, health, government, warfare, and democracy)",
        "Concept 2: The information society as a framework with multiple markers (technological, economic, occupational, spatial, cultural) and its relation to other societal models (industrial, post-industrial, network/knowledge society)",
        "Concept 3: Governance and policy mechanisms (Tunis Agenda, Internet governance) that enable and shape the development of the information society"
      ],
      "parent_concepts": [
        "Concept 2: Printing as a driver of mass communication that increases literacy, promotes vernacular languages, and reshapes social and political power structures.",
        "Concept 2: Digital media as a driver of disruptive innovation and social transformation across industries (publishing, journalism, education, entertainment, politics) due to interconnectivity and the Internet.",
        "Concept 3: The shift from physical inputs to knowledge-intensive production, requiring highly skilled, adaptable, problem-solving workers and relational capabilities.",
        "Concept 2: Information literacy as a means of empowerment and social participation (a human-rights framed idea that enables individuals to seek, evaluate, and use information to achieve personal, social, occupational, and educational goals and to promote social inclusion).",
        "Concept 3: Technological evolution (e.g., Web 2.0) alters scope, speed, and applications of online communities, driving new forms of interaction and uses (e.g., real-time communication, marketing, conflict-alerting).",
        "Concept 3: The Internet as a medium-agnostic platform that broadens access to services, reducing location- and time-related constraints."
      ],
      "parent_articles": [
        "Printing press",
        "Digital media",
        "Knowledge economy",
        "Information literacy",
        "Online community",
        "Telecommunications"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is it more informative to define the information society by multiple markers—technological, economic, occupational, spatial, and cultural—rather than by a single metric?",
      "options": {
        "A": "Because a single core technology drives all social change, so the other markers are redundant.",
        "B": "Because each marker captures a different dimension of transformation that can progress unevenly; taken together they show how technologies, economic structures, occupations, spatial organization, and culture interact and produce heterogeneous patterns.",
        "C": "Because using multiple markers guarantees simple, uniform shifts across all sectors, which makes measurement easier.",
        "D": "Because the markers are interchangeable measures of the same underlying change and can be substituted without changing the analysis."
      },
      "correct_answer": "B",
      "simplification_notes": "Question text shortened and clarified; retained the list of five markers; options rewritten to be concise, plausible, and analytically distinct while preserving the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.1_vs_16",
    "pass_2_attempt": {
      "question": "The government of the middle-income country Arbora commissions a 10-year plan to transform into an information society. Which of the following policy packages most coherently operationalizes the role of ICTs as drivers of change across education, economy, health, government, warfare and democratic participation, while addressing the multiple markers of an information society (technological, economic, occupational, spatial, cultural) and incorporating appropriate governance and financing mechanisms exemplified by the Tunis Agenda and contemporary Internet governance debates?",
      "options": {
        "A": "A coordinated program that builds national broadband and data-centre infrastructure (technological), funds digital curricula and lifelong reskilling programs for information-sector occupations (occupational/cultural), provides tax credits and seed grants for information-service firms and health/edu e‑platforms (economic), subsidizes rural last‑mile connectivity and regional digital hubs to reduce spatial divides (spatial), adopts balanced IP reform that supports open-source and targeted DRM, and commits public financing plus public–private partnerships while actively participating in multistakeholder Internet governance fora consistent with the Tunis Agenda.",
        "B": "A program that prioritises rapid infrastructure build‑out (fiber/5G) and large foreign data‑centre investment (technological), but leaves workforce training and education to market forces, centralises procurement in a few multinational firms, enforces stringent proprietary IP and content controls, and refuses engagement in international Internet governance — expecting private capital to drive all downstream social and institutional change.",
        "C": "A reindustrialisation package that reallocates ICT funds to subsidise domestic hardware manufacturing and protect factories via tariffs (economic/technological), focuses on automation for manufacturing jobs (occupational), and keeps education and health systems largely unchanged, arguing that material production must be rebuilt before any information‑driven transformation is viable.",
        "D": "A laissez‑faire strategy that abolishes ICT regulation, removes public financing for broadband, relies entirely on market entry of digital platforms (economic), makes no commitments to rural access or reskilling (spatial/occupational), and treats Internet governance as a corporate matter, asserting that minimal state intervention will maximise information‑sector growth."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a nation‑level policy scenario to test integration of ICT-driven sectoral change, the multi-dimensional markers of an information society, and governance/financing elements (Tunis Agenda, multistakeholder Internet governance). Options contrast balanced, governance‑engaged policy (correct) with infrastructure‑only, manufacturing‑focused, and laissez‑faire alternatives.",
      "concepts_tested": [
        "ICTs as drivers of societal transformation across multiple sectors (education, economy, health, government, warfare, democracy)",
        "Information society markers (technological, economic, occupational, spatial, cultural) and relation to industrial/post‑industrial/network/knowledge models",
        "Governance and policy mechanisms that shape the information society (Tunis Agenda, ICT financing, multistakeholder Internet governance)"
      ]
    },
    "pass_2_reason": "readability_too_high_26.7_vs_16"
  },
  {
    "original_question": {
      "question": "How does gatekeeping in political communication influence which policy issues gain attention and consequently shape policy outcomes?",
      "options": {
        "A": "Gatekeepers ensure all voices and issues are presented with equal prominence, so policy outcomes mirror broad public opinion.",
        "B": "Gatekeepers select which issues and voices reach the public, shaping agenda and perceived salience, which policymakers respond to, thereby influencing policy outcomes.",
        "C": "Gatekeeping eliminates misinformation, so policy outcomes are unaffected by media framing or issue salience.",
        "D": "Gatekeeping only affects the speed of message delivery, not which issues are considered by policymakers."
      },
      "correct_answer": "B",
      "source_article": "Political communication",
      "x": 1.2253447771072388,
      "y": 0.9642546772956848,
      "concepts_tested": [
        "Concept 1: Information flow and gatekeeping in political communication — how the movement of information through media shapes political influence and policy outcomes.",
        "Concept 2: Economic constraints and media ownership shaping political messaging — how capital, ownership, and editor selection influence which voices and messages are amplified.",
        "Concept 3: Propaganda, framing, and spin as mechanisms in political communication — how deliberate messaging and spin doctors influence public perception and government credibility."
      ],
      "parent_concepts": [
        "Concept 3: The credibility and effectiveness of public inquiries in shaping public opinion and media attention, including how findings that criticize or exonerate the government affect trust.",
        "Concept 1: Advocacy as a multi-channel mechanism for influencing policy and decisions (through research, media, messaging, education).",
        "Campaign messaging design as a persuasive mechanism (why broad, repeatable talking points are used and how they influence voter support)",
        "Concept 1: Media framing and audience-driven sensationalism in scandal coverage",
        "Concept 2: Role of poetry as a political mobilizer — poetry can unify crowds, attract media attention, and serve as a vehicle for protest and political critique.",
        "Concept 1: Perceived legitimacy and belief in success as determinants of coup outcomes. How coup-makers’ ability to convince others that the coup will succeed drives actual success or failure."
      ],
      "parent_articles": [
        "Public inquiry",
        "Advocacy",
        "Political campaign",
        "Political scandal",
        "The arts and politics",
        "Coup d'état"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does gatekeeping in political communication determine which policy issues gain public attention and thereby influence policy decisions?",
      "options": {
        "A": "Gatekeepers present all voices and issues with equal prominence, so policy outcomes simply reflect broad public opinion.",
        "B": "Gatekeepers select which issues and voices reach the public, shaping the public agenda and perceived issue salience; policymakers respond to that salience, so gatekeeping influences policy outcomes.",
        "C": "Gatekeeping primarily removes misinformation, so media framing and issue salience do not affect policy outcomes.",
        "D": "Gatekeeping only alters the speed or timing of message delivery, not which issues policymakers consider when making policy."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was shortened and clarified for undergraduates. Emphasized gatekeeping as selection by media actors and retained key mechanisms—agenda-setting, salience, framing/spin, and ownership effects—while keeping the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.0_vs_16",
    "pass_2_attempt": {
      "question": "In the democratic state of Belloria a controversial national security law was enacted after a three-week media cycle. Key facts: (1) Three major daily newspapers are owned by a single corporate conglomerate that appoints their editors; (2) labour unions bought ad space criticizing the law but were refused publication on the grounds of \"space constraints\"; (3) the government press office, led by a former journalist-turned-press-secretary, ran coordinated daily briefings framing the law as necessary to prevent an imminent threat; (4) a political consultancy used microtargeted social media ads to transmit simplified fear-based messages to specific demographic segments; (5) subsequent polls showed a substantial increase in public support for the law. Which single explanation best integrates the roles of information flow and gatekeeping, economic constraints and media ownership, and propaganda/framing/spin to account for the observed shift in public opinion?",
      "options": {
        "A": "OmniCorp's ownership and editor appointments functioned as gatekeeping by limiting dissenting union ads and privileging sympathetic coverage (economic constraint); the press secretary's coordinated briefings and fear-framed messaging constituted spin and framing (propaganda); targeted social-media ads amplified these frames to receptive audiences, producing agenda-setting and priming effects that shifted public opinion.",
        "B": "Social-media microtargeting alone explains the opinion change: digital ads directly altered individual beliefs independent of legacy media or ownership, so newspaper gatekeeping and denied union ads were incidental and not causally important.",
        "C": "The unions were denied ad space for neutral commercial reasons ('space constraints'), and the press briefings merely clarified technical legal details; the public updated preferences via rational deliberation rather than via framing, ownership influence, or spin.",
        "D": "OmniCorp's refusal to run union ads created a backlash that initially increased sympathy for unions; government spin then corrected the narrative, but the decisive factor was balanced algorithmic exposure on social platforms that provided equal time to all perspectives."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete multi-actor scenario (newspapers, unions, press office, consultancy, social media) requiring synthesis of gatekeeping, economic ownership effects, and framing/spin mechanisms to explain agenda-setting and priming; option A integrates all three concepts while distractors isolate or misattribute causes.",
      "concepts_tested": [
        "Information flow and gatekeeping (agenda-setting, priming)",
        "Economic constraints and media ownership affecting message amplification",
        "Propaganda, framing, and spin as mechanisms shaping public perception"
      ]
    },
    "pass_2_reason": "readability_too_high_24.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does optimizing the balance among message content, media channel, and audience characteristics function as a core mechanism in strategic communication management?",
      "options": {
        "A": "By ensuring the message resonates with the audience through an appropriate channel, it reduces misinterpretation, increases uptake, and builds cumulative trust that aligns with long-term goals.",
        "B": "By maximizing the number of channels used, regardless of audience relevance, to amplify reach for short-term metrics.",
        "C": "By focusing solely on the message's technical accuracy, ignoring channel fit or audience preferences.",
        "D": "By centralizing control in a single department and bypassing audience feedback to accelerate decision making."
      },
      "correct_answer": "A",
      "source_article": "Strategic communication",
      "x": 1.3643156290054321,
      "y": 0.9742472767829895,
      "concepts_tested": [
        "Concept 1: Balance of message, media channel, and audience as a core mechanism of strategic communication management",
        "Concept 2: The 5 Ps framework (plan, pattern, position, perspective, ploy) as a guiding model for strategy and reflexive action",
        "Concept 3: Alignment of communication campaigns with organizational goals to achieve long-term effects (image, cooperation, market position) across internal/external contexts"
      ],
      "parent_concepts": [
        "Concept 3: Theoretical frameworks guiding crisis response (Apologia Theory, Image Repair Theory, and Situational Crisis Communication Theory) and how attribution of responsibility shapes recommended strategies (e.g., denial, reducing offensiveness, corrective action, mortification)"
      ],
      "parent_articles": [
        "Crisis communication"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is optimizing the balance among message content, media channel, and audience characteristics central to strategic communication management?",
      "options": {
        "A": "Because matching the message to the right channel and audience reduces misinterpretation, increases uptake, and builds cumulative trust that aligns with long-term organizational goals.",
        "B": "Because using the maximum number of channels, regardless of audience relevance, amplifies reach and improves short-term performance metrics.",
        "C": "Because prioritizing only the technical accuracy of the message—while ignoring channel fit and audience preferences—ensures correct information is always delivered.",
        "D": "Because centralizing control in a single department and bypassing audience feedback accelerates decision-making and keeps communications consistent."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording was shortened and clarified for undergraduate readers; retained the focus on balancing message, channel, and audience and alignment with long-term goals; distractors were kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.6_vs_16",
    "pass_2_attempt": {
      "question": "A multinational NGO aims to increase childhood vaccination uptake in a rural province while preserving local trust and strengthening long-term collaboration with community leaders. Which of the following strategic communication plans best demonstrates (a) deliberate balancing of message, media channel, and audience; (b) application of the $5$ Ps (plan, pattern, position, perspective, ploy) as an organizing framework; and (c) alignment of the campaign with the NGO's long-term organizational goals for image, cooperation, and sustainable impact across internal and external stakeholders?",
      "options": {
        "A": "Design a phased campaign that begins with stakeholder mapping (elders, health workers, youth) and crafts three tailored messages: one factual health brief for clinics, one story-driven testimonial for local radio, and one short SMS reminder for caregivers. Use the $5$ Ps explicitly: a documented plan (three phases), a pattern of weekly consistent local broadcasts and clinic dialogues, a position that frames the NGO as a partner not an authority, a perspective rooted in community needs, and a ploy to preempt misinformation via trained local spokespeople. Set SMART objectives (uptake targets, trust indices) and assign responsibilities and metrics for internal coordination and long-term relationship building.",
        "B": "Produce a high-production national TV advertisement and coordinated paid social-media ads carrying a single upbeat message about vaccination benefits. Measure success by immediate increases in clinic visits over the next month. Central communications team manages all content; local offices are given the finished materials without adaptation. No explicit use of the $5$ Ps; focus is on rapid visibility rather than stakeholder-specific tailoring.",
        "C": "Support a policy push that links incentives and penalties to vaccination status and disseminate a uniform directive-style message to the province: vaccination is mandatory for school enrollment. Deploy ministry officials to issue public statements and rely on official bulletins as the principal media. Emphasize enforcement and compliance metrics; little attention is paid to audience segmentation, community perspective, or long-term image effects.",
        "D": "Run an internal rebranding and staff morale campaign highlighting the NGO's mission and recent achievements, including a new logo and values booklet. Distribute materials to employees and donors and hold internal workshops. External messaging remains generic and unchanged; there is no tailored outreach to community groups, no metrics tied to vaccination uptake, and no formal strategic framework like the $5$ Ps."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete NGO vaccination scenario; each option maps to different levels of adherence to balancing message/media/audience, explicit use of the $5$ Ps, and alignment with long-term organizational goals. Option A integrates all three core concepts.",
      "concepts_tested": [
        "Balance of message, media channel, and audience",
        "Application of the $5$ Ps framework (plan, pattern, position, perspective, ploy)",
        "Alignment of communication campaigns with organizational long-term goals (image, cooperation, sustainability) across internal and external contexts"
      ]
    },
    "pass_2_reason": "readability_too_high_24.2_vs_16"
  },
  {
    "original_question": {
      "question": "How does the internal diversity of the environmental movement, including submovements such as environmental justice and indigenous rights, influence its ability to mobilize broad support while also shaping its strategic coherence?",
      "options": {
        "A": "By quickly consolidating around a single, universal policy without negotiation, increasing efficiency.",
        "B": "By broadening appeal to a wider audience, but introducing coalitional tensions that require ongoing negotiation and prioritization, which in turn shapes the movement's strategic direction.",
        "C": "By preventing any shared aims from emerging, causing the movement to stall and fail to organize.",
        "D": "By ensuring perfect alignment of tactics across all groups, leading to an unchanging, globally uniform strategy."
      },
      "correct_answer": "B",
      "source_article": "Environmental movement",
      "x": 1.3953648805618286,
      "y": 0.8799563646316528,
      "concepts_tested": [
        "Concept 1: The environmental movement is a diverse, international coalition with internal tensions and non-uniform goals, influencing its unity and strategic direction.",
        "Concept 2: Submovements and identities (environmental justice, indigenous rights) and the climate movement arise as the movement expands to address equity and crises.",
        "Concept 3: The movement’s focus evolves in response to scientific advances and environmental crises (e.g., ozone depletion, climate change, GM crops), linking science to activism and policy."
      ],
      "parent_concepts": [
        "Concept 3: Biodiversity preservation as an expanded objective and the relationship/contrast between the conservation movement and the broader environmental movement (ideology and practice implications)."
      ],
      "parent_articles": [
        "Conservation movement"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the internal diversity of the environmental movement — including submovements like environmental justice and indigenous rights — affect its ability to build wide public support and maintain strategic coherence?",
      "options": {
        "A": "By rapidly unifying behind a single universal policy with no negotiation, which increases organizational efficiency.",
        "B": "By expanding appeal to a broader public but creating coalition tensions that require continual negotiation and prioritization, and these negotiations in turn shape the movement's strategic direction.",
        "C": "By preventing any shared goals from forming, causing the movement to stall and fail to organize effectively.",
        "D": "By producing perfect alignment of tactics and goals across all groups, resulting in an unchanging, globally uniform strategy."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was made more concise and academic; retained mention of submovements (environmental justice, indigenous rights) and the dual effects: broader appeal vs. internal tensions shaping strategy. Removed historical examples and extra detail.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "An international coalition convenes to decide whether to endorse the introduction of a genetically modified drought‑resistant maize on lands held by an Indigenous community to adapt to increasing droughts from climate change. The coalition includes grassroots activists opposed to GM organisms as \"unnatural,\" scientists who cite reduced pesticide use and increased water efficiency, Indigenous leaders who insist on land‑rights and free, prior and informed consent, environmental justice advocates worried about burdens on marginalized peoples, and a climate‑focused subgroup that argues decarbonization (including controversial support for nuclear power) should take precedence. Which statement best characterizes how this scenario reflects the nature of the contemporary environmental movement described in the article?",
      "options": {
        "A": "The scenario illustrates that the environmental movement is a diverse, international coalition with internal tensions and distinct submovements (e.g., environmental justice, Indigenous rights, the climate movement) whose priorities and strategies are shaped by scientific developments and emergent crises, producing contested policy choices rather than uniform positions.",
        "B": "The scenario shows that the environmental movement is a single, unified international actor that consistently rejects technological interventions like GM crops and nuclear power in favor of a single conservationist agenda.",
        "C": "The scenario demonstrates that environmental movements prioritize technological solutions above social equity and therefore always support scientifically endorsed interventions regardless of Indigenous consent or justice concerns.",
        "D": "The scenario indicates the movement remains narrowly focused on classical conservation (preserving landscapes and species) and is largely unaffected by modern scientific findings or climate‑related crises."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete multi‑stakeholder decision scenario involving GM crops, Indigenous rights, environmental justice, and climate/nuclear debates to test understanding of movement diversity, internal tensions, emergence of submovements, and science-driven shifts in focus.",
      "concepts_tested": [
        "Environmental movement diversity and internal tensions",
        "Emergence of submovements (environmental justice, indigenous rights, climate movement) and science informing priorities"
      ]
    },
    "pass_2_reason": "readability_too_high_23.3_vs_16"
  },
  {
    "original_question": {
      "question": "Which mechanism best explains how practice or experience leads to selective strengthening and weakening of neural connections, producing cortical remapping and map expansion, and why these changes are most dynamic during development yet persist into adulthood?",
      "options": {
        "A": "Activity-dependent synaptic modification (Hebbian plasticity) coupled with changes in inhibitory circuitry that bias which connections strengthen or weaken.",
        "B": "Global growth of neurons across the cortex that increases network size regardless of activity.",
        "C": "Random, activity-independent rewiring of synapses that occurs spontaneously over time.",
        "D": "Uniform, nonselective scaling of all synapses so that overall activity remains constant without changing specific connections."
      },
      "correct_answer": "A",
      "source_article": "Neuroplasticity",
      "x": 1.829030156135559,
      "y": 1.1499520540237427,
      "concepts_tested": [
        "Concept 1: Neuroplasticity as the brain’s capacity to reorganize and rewire neural connections in response to learning, experience, injury, or sensory/cognitive change, from single-neuron changes to large-scale cortical remapping.",
        "Concept 2: Activity-dependent plasticity and lifespan dynamics (greater plasticity in development; still present in adulthood with implications for learning, memory, development, and recovery from brain damage).",
        "Concept 3: Diverse forms of plasticity (e.g., homologous area adaptation, cross-modal reassignment, map expansion, cortical remapping, compensatory mechanisms) and how these mechanisms support functional reorganization after experience or injury."
      ],
      "parent_concepts": [
        "Concept 1: Multilingualism is associated with enhanced language learning abilities compared with monolingualism (a cause-effect/relationship principle that can be probed with why/how questions)."
      ],
      "parent_articles": [
        "Multilingualism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Which mechanism best accounts for how practice or experience causes selective strengthening and weakening of specific synaptic connections—producing cortical remapping and map expansion—that is especially potent during development but remains for learning and recovery in adulthood?",
      "options": {
        "A": "Activity-dependent synaptic modification (Hebbian plasticity; LTP/LTD) combined with changes in inhibitory circuitry that bias which connections are potentiated or depressed, producing specific map reorganization and stronger effects during developmental critical periods yet retained in adulthood.",
        "B": "A global increase in neuron number and growth across the cortex that enlarges networks nonspecifically, causing map expansion independent of patterned activity.",
        "C": "Random, activity-independent synaptic turnover and spontaneous rewiring that gradually reshuffles cortical maps without requiring correlated neuronal activity.",
        "D": "Uniform, nonselective homeostatic scaling of all synapses that preserves overall firing rates but does not alter which specific connections encode learned functions."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording was condensed and focused on core mechanism: selective, activity-dependent synaptic change driving cortical remapping and lifespan differences. Distractors were rewritten to be plausible but incorrect (global growth, random rewiring, uniform homeostatic scaling).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.0_vs_16",
    "pass_2_attempt": {
      "question": "Which set of experimental or clinical observations best illustrates (a) neuroplastic change across scales from synaptic to large-scale cortical remapping, (b) activity-dependent plasticity with lifespan dynamics (greater plasticity during development but retained capacity in adults), and (c) diverse functional forms of plasticity such as homologous area adaptation, cross-modal reassignment, map expansion, and compensatory mechanisms?",
      "options": {
        "A": "1) Intensive spatial-navigation training in adult London taxi drivers produces both increased hippocampal gray‑matter volume (map expansion) and enhanced hippocampal synaptic potentiation measured electrophysiologically. 2) An adult patient with a large left‑hemisphere stroke gradually regains speech because right‑hemisphere homologous language regions increase activation and assume production duties (homologous area adaptation). 3) Prelingually deaf children implanted with cochlear implants before age 3 acquire near‑normal spoken language, whereas implantation after age 5 yields much poorer outcomes (sensitive‑period/developmental difference in activity‑dependent plasticity).",
        "B": "1) Phantom‑limb pain in amputees always disappears because the cortical representation for the limb becomes permanently inactive after amputation. 2) Long‑term meditation practitioners show modest increases in cortical thickness in attention‑related regions, proving that only form of adult plasticity is experience‑dependent cortical thickening. 3) Cochlear implantation at age 10 typically restores normal language, demonstrating no sensitive period for auditory system plasticity.",
        "C": "1) After peripheral nerve transection and regeneration in an adult musician, the cortical hand map remains completely unchanged, showing that adult cortex cannot reorganize. 2) Blind expert echolocators recruit occipital (visual) cortex when processing echoes, indicating cross‑modal reassignment. 3) Chronic pain patients never recover altered somatotopic maps even after successful treatment, implying maladaptive plasticity is irreversible.",
        "D": "1) Robot‑assisted post‑stroke therapy always produces immediate and complete cortical remapping demonstrated on fMRI, proving mechanistic cortical reorganization is rapid and uniform. 2) Seasonal breeding birds show hippocampal volume fluctuation, showing neuroplasticity is restricted to non‑mammalian species. 3) Bilingual adults show no structural white‑matter differences from monolinguals, indicating language experience does not alter brain connectivity."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a composite scenario: taxi drivers (map expansion + synaptic potentiation), stroke recovery via homologous area adaptation in adulthood, and cochlear‑implant sensitive period illustrating developmental > adult plasticity. Distractors mix plausible but incorrect or incomplete claims.",
      "concepts_tested": [
        "scales of neuroplasticity (synaptic to cortical remapping)",
        "activity‑dependent plasticity and lifespan dynamics (sensitive periods vs adult plasticity)",
        "forms of functional plasticity (homologous area adaptation, cross‑modal reassignment, map expansion, compensatory mechanisms)"
      ]
    },
    "pass_2_reason": "readability_too_high_32.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a profit-driven organization of work tend to generate precarious employment, and through what mechanism does this relationship operate?",
      "options": {
        "A": "Because firms recognize labor costs as fixed investments that must be protected through permanent, fully insured employment.",
        "B": "Because firms treat labor as a variable cost to be minimized, using flexible, contingent, or outsourced labor to cut costs and shift risk away from the employer.",
        "C": "Because consumer demand forces firms to hire more workers with stable schedules to ensure consistent service.",
        "D": "Because laws require all workers to be classified as employees with benefits to promote social protection."
      },
      "correct_answer": "B",
      "source_article": "Precarious work",
      "x": 1.2201251983642578,
      "y": 0.8888081312179565,
      "concepts_tested": [
        "Concept 1: Profit-driven capitalist organization of work as a mechanism that treats employment as a cost to be minimized, leading to precarious work (insecurity, low pay, lack of protections).",
        "Concept 2: The relationship framework between standard employment and precarious work, including how flexibility, uncertainty, and lack of control define precariousness versus the traditional, defined-employer–employee relationship.",
        "Concept 3: Macro-level drivers (globalization, shift to the service sector, information technology) as causal forces that increase demand for flexible labor and erode standard employment, with varying social consequences by gender, age, race, and class."
      ],
      "parent_concepts": [
        "Concept 3: Flexibility versus precarity and contract/IP considerations in gig work (trade-offs for workers and implications for rights)"
      ],
      "parent_articles": [
        "Gig economy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does a profit-driven, capitalist organization of work tend to produce precarious employment, and what mechanism connects profit-seeking to worker insecurity and weak protections?",
      "options": {
        "A": "Because firms view labor as a fixed capital-like investment that should be protected via permanent, fully insured employment contracts.",
        "B": "Because firms treat labor as a variable cost to be minimized, so they use flexible, contingent, or outsourced labor to reduce wages and benefits and shift risk away from the employer.",
        "C": "Because rising consumer demand forces firms to hire more workers on stable schedules to guarantee consistent service, reducing precariousness.",
        "D": "Because legal requirements classify all workers as employees with benefits, which creates standardized, secure jobs for everyone."
      },
      "correct_answer": "B",
      "simplification_notes": "Question reworded to be concise and clearer; preserved the core mechanism that profit-seeking treats labor as a cost to be minimized and therefore promotes flexible, contingent staffing. Distractors were made plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.3_vs_16",
    "pass_2_attempt": {
      "question": "Consider a multinational apparel firm that, over two decades, offshored manufacturing to lower-wage countries, replaced stable domestic factory jobs with local on-call staff and platform-based freelancers, implemented algorithmic scheduling, and reclassified many workers as independent contractors to reduce pension and health-benefit obligations. Which interpretation best integrates (a) a profit-driven capitalist organization of work that treats employment as a cost to be minimized, (b) the contrast between the postwar “standard employment relationship” and precarious work (marked by insecurity, low pay, lack of protections, and limited control over hours), and (c) macro-level drivers such as globalization, the shift toward service and platform-mediated labor, and information technology that increase demand for flexible labor and produce uneven social consequences by gender, age, race, and class?",
      "options": {
        "A": "The firm’s behavior exemplifies how profit-maximizing enterprises treat labor as a reducible cost, using offshoring, contract reclassification, and algorithmic scheduling—enabled by globalization and information technology—to replace the postwar standard employment relationship with precarious forms (on-call, gig, platform work) that are insecure, poorly protected, and variably harmful across gender, age, race, and class.",
        "B": "The firm’s shift primarily reflects workers’ demand for autonomy: platform freelancing and on-call roles increase individual agency, allowing employees to trade standardized benefits for higher personal flexibility and broad improvements in well‑being, irrespective of macroeconomic trends or employer cost considerations.",
        "C": "This transformation is driven chiefly by technological inevitability: information technology alone renders long-term employer–employee bonds obsolete, so the loss of standard employment results from technological progress rather than firms’ cost-minimizing incentives or global market changes, and social consequences are uniform across groups.",
        "D": "Government deregulation alone explains the decline of standard employment: relaxed labor laws removed protections and benefits, so precarious jobs proliferated independent of corporate profit motives, globalization, or sectoral shifts; the pattern affects all workers equally regardless of gender, age, race, or class."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete firm-level scenario and provided four interpretive syntheses; correct option integrates employer cost-minimization, contrast between standard and precarious employment, and macro drivers with unequal social effects.",
      "concepts_tested": [
        "Profit-driven capitalist organization of work treating employment as a cost",
        "Contrast between standard employment relationship and precarious work (insecurity, lack of protections, limited control)",
        "Macro-level drivers: globalization, shift to service/platform labor, information technology and their unequal social consequences"
      ]
    },
    "pass_2_reason": "readability_too_high_32.8_vs_16"
  },
  {
    "original_question": {
      "question": "How does contextual immersion followed by iterative design steps contribute to the effectiveness of human-centered design?",
      "options": {
        "A": "It emphasizes collecting a complete set of features from users during initial immersion and then implementing them in a single pass without changes.",
        "B": "It surfaces tacit needs and contextual constraints during immersion; iterative cycles enable testing and refining concepts in real contexts, ensuring the solution adapts to actual use and constraints.",
        "C": "It relies on expert intuition after immersion to design a solution that minimizes user input.",
        "D": "It guarantees a perfect solution after the first prototype because immersion captures all requirements upfront."
      },
      "correct_answer": "B",
      "source_article": "Human-centered design",
      "x": 1.373971939086914,
      "y": 1.0490596294403076,
      "concepts_tested": [
        "Concept 1: User-centered focus and application of human factors to improve usability, effectiveness, and well-being",
        "Concept 2: Contextual immersion/observation followed by iterative design steps (brainstorming, modeling, prototyping, implementation)",
        "Concept 3: Relationship to participatory action research and the notion that HCD aims to produce solutions rather than merely document problems, enabling ongoing innovation"
      ],
      "parent_concepts": [
        "Concept 2: Iterative, stage-spanning testing and user research (testing and feedback integrated from requirements through post-production)",
        "Concept 2: Interdisciplinary, user-centered approach that integrates psychology, HCI, information architecture, and user research within technical/business constraints"
      ],
      "parent_articles": [
        "User-centered design",
        "Interaction design"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does human-centered design typically begin with contextual immersion (observing users in their real environment) and then proceed through iterative steps such as brainstorming, modeling, prototyping and testing?",
      "options": {
        "A": "Because immersion lets designers collect a complete, fixed list of user features up front, which are then implemented in a single development pass without further changes.",
        "B": "Because immersion reveals tacit needs and contextual constraints, and iterative cycles of prototyping and testing let teams refine concepts in real contexts so solutions adapt to actual use and limitations.",
        "C": "Because after immersion designers rely on expert intuition to create a final solution that minimizes further user involvement.",
        "D": "Because immersion guarantees that the first prototype contains all requirements, so one prototype is sufficient to produce a perfect solution."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded to be concise and explicit about 'contextual immersion' and 'iterative steps (brainstorming, modeling, prototyping, testing)'; retained original alternatives but made them clearer and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "A municipal transit authority wants to redesign a set of neighborhood bus stops to improve usability, safety, and well-being for older adults and visually impaired riders. Which project plan best exemplifies human-centered design (HCD) as described in the article — including application of human factors, contextual immersion, iterative design, and the participatory-action ethos of producing solutions rather than merely documenting problems?",
      "options": {
        "A": "Form multidisciplinary teams that first conduct ride-alongs and in-situ ethnographic observation of passengers at target stops, then run co-creation workshops with elderly and visually impaired riders to generate ideas; develop low-fidelity and then field-tested prototypes (e.g., modified seating, tactile guidance, signage) at a subset of stops; collect usability and safety metrics and participant feedback; iterate designs and scale the implemented solutions across the network.",
        "B": "Commission human factors engineers to design an optimal bus-stop layout in the lab using ergonomic standards and simulated users; validate the layout with short usability tests in a controlled environment; then mandate agency-wide installation based on engineering specifications and cost-benefit calculations without further community engagement.",
        "C": "Conduct a large-scale survey and structured interviews to document problems and preferences of riders, compile a comprehensive report highlighting barriers, and distribute the report to planners and advocacy groups for consideration, leaving implementation to future policy processes.",
        "D": "Hold several internal rapid-ideation sessions with transit planners and product designers to sketch innovative concepts, produce polished renderings and a single high-fidelity prototype, then pilot that prototype at all stops without prior field observation or iterative co-design with affected rider groups."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete transit redesign scenario and four plausible project plans to discriminate full HCD practice (immersion, ethnography, co-creation, iterative prototyping, implementation) from partial or non-HCD approaches.",
      "concepts_tested": [
        "Application of human factors to improve usability, effectiveness, and well-being",
        "Contextual immersion and iterative design cycle (observation, brainstorming, prototyping, implementation)",
        "Integration with participatory action research ethos—producing practical solutions through stakeholder co-creation"
      ]
    },
    "pass_2_reason": "readability_too_high_21.5_vs_16"
  },
  {
    "original_question": {
      "question": "How do digital communication networks most effectively influence the scalability and resilience of cross-border social movements?",
      "options": {
        "A": "By enforcing a centralized, leader-driven command that coordinates all actions in a uniform way.",
        "B": "By letting platform algorithms automatically set a single strategy for all participants, removing local variation.",
        "C": "By enabling distributed, asynchronous coordination among diverse participants, lowering participation costs, expanding reach, and increasing adaptability, while also introducing vulnerabilities like information overload and fragmentation.",
        "D": "By ensuring that online actions reliably translate into immediate policy concessions from governments."
      },
      "correct_answer": "C",
      "source_article": "Social movement",
      "x": 1.1657648086547852,
      "y": 0.9370527267456055,
      "concepts_tested": [
        "Concept 1: Movements as bottom-up organizational structures and strategies that empower marginalized populations to challenge more powerful elites (with some movements aiming to preserve existing power). This captures a mechanism of social change and its variability.",
        "Concept 2: The relationship between social movements and political systems (democratization, agenda setting, influence on politics). This addresses how movements interact with state power and political processes.",
        "Concept 3: The role of technology and communication networks (e.g., internet, social media) in mobilizing, coordinating, and expanding collective action across borders. This highlights a modern mechanism enabling globalization of movements."
      ],
      "parent_concepts": [
        "Concept 2: Empowerment through mobilization and addressing structural inequalities",
        "Concept 1: Activism as a spectrum from individual acts to organized social movements; how sustained collective action leads to broader social change.",
        "Concept 3: The relationship between online and offline mobilization, including classifications by reliance on the Internet and examples of hybrid or cross-platform activism (e.g., Occupy Wall Street).",
        "Collective identity as a framework for understanding social movements and collective action, including its relation to opportunities/constraints, leadership, ideologies, and alliances.",
        "Direct action as a mechanism that leverages economic or political power to obstruct practices or solve problems."
      ],
      "parent_articles": [
        "Community organizing",
        "Activism",
        "Internet activism",
        "Collective identity",
        "Direct action"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do digital communication networks most effectively affect the scalability and resilience of cross-border (transnational) social movements?",
      "options": {
        "A": "By imposing a centralized, leader-driven command structure that coordinates actions uniformly across contexts.",
        "B": "By letting platform algorithms automatically determine a single strategy for all participants, eliminating local variation in tactics and messaging.",
        "C": "By enabling distributed, asynchronous coordination among diverse participants, reducing participation costs, widening reach, and increasing adaptability, while also creating vulnerabilities such as information overload, fragmentation, and platform dependence.",
        "D": "By guaranteeing that online mobilization directly produces immediate policy concessions from national governments."
      },
      "correct_answer": "C",
      "simplification_notes": "Rephrased the original question into concise academic language for undergraduates; preserved the focus on scalability, resilience, and trade-offs of digital networks. Options were tightened to be plausible and kept core contrasts (centralization, algorithmic control, distributed coordination, guaranteed policy success).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.2_vs_16",
    "pass_2_attempt": {
      "question": "Consider a hypothetical movement, \"Greenwave,\" that originates among coastal small-scale fishers marginalized by multinational fishing firms. Greenwave develops a collective identity, coordinates weekly nonviolent beach blockades and data-sharing via encrypted messaging apps, and uses viral hashtags to attract international NGOs and sympathetic journalists. Within two years Greenwave pressures the national parliament to place fisheries reform on the legislative agenda; a faction converts itself into a political party, while another faction allies with local conservative leaders to defend traditional access arrangements. Which analysis best synthesizes the three dynamics described in the article: (1) movements as bottom-up organizational strategies that empower marginalized populations but can also preserve existing power, (2) the relationship between movements and political systems (agenda-setting, party formation, democratization), and (3) the role of communication technologies in transnational mobilization?",
      "options": {
        "A": "Greenwave illustrates that bottom-up networked organization and shared collective identity empower marginalized groups to make collective claims and challenge elites; communication technologies amplified coordination and transnational support, increasing the movement’s capacity to set the political agenda and produce party formation, while internal splits show that movements can also pursue conservative or preservationist goals or be co-opted—outcomes depend on resources and political opportunity structures.",
        "B": "Because Greenwave used encrypted apps and viral hashtags, technology alone explains its success: the internet substitutes for organizational strength and political opportunity, so movements will reliably force policy change regardless of the type of political regime or resource base.",
        "C": "Greenwave’s emergence and effects are best explained solely by objective deprivation: material loss among fishers automatically produces movements that influence politics only if they later formalize as parties; online networks are incidental and irrelevant to agenda-setting or transnational support.",
        "D": "Greenwave demonstrates that social movements are primarily top-down instruments of local elites: the movement’s public protests and social-media presence are orchestration by conservative leaders to preserve elite-controlled access, and technology merely propagates elite narratives rather than empowering marginalized actors."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete scenario (Greenwave) to require integration of three core concepts: bottom-up empowerment and possible preservationist trajectories; interaction with political institutions (agenda-setting, party formation, political opportunity); and the enabling role of digital communication in coordination and transnationalization. Distractors each misrepresent one or more concepts.",
      "concepts_tested": [
        "Bottom-up organizational empowerment and variability of movement aims",
        "Interaction between social movements and political systems (agenda-setting, party formation, democratization)",
        "Role of communication technologies and social networks in mobilization and transnational coordination"
      ]
    },
    "pass_2_reason": "readability_too_high_23.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why is it common for a state's foreign policy to reflect an integration of domestic political pressures, the actions of other states, and the wider geopolitical setting, rather than following a single objective?",
      "options": {
        "A": "Because domestic politics always dominate irrespective of external behavior.",
        "B": "Because policymakers evaluate trade-offs among competing domestic interests, anticipated responses from other states, and the constraints/opportunities created by the geopolitical context, so each factor revalues the costs and benefits of potential actions.",
        "C": "Because external factors completely dictate policy with no room for domestic influence.",
        "D": "Because foreign policy is determined by random ad hoc decisions."
      },
      "correct_answer": "B",
      "source_article": "Foreign policy",
      "x": 0.6501541137695312,
      "y": 0.507666826248169,
      "concepts_tested": [
        "Concept 1: Foreign policy formulation is shaped by multiple interacting factors (domestic politics, behavior of other states, geopolitical context) that influence policy choices.",
        "Concept 2: The objectives of foreign policy are interconnected and collectively form a comprehensive strategy (defense/security, economic benefits, humanitarian aid).",
        "Concept 3: Institutions and actors (diplomatic corps, think tanks) function as mechanisms that generate, inform, and implement foreign policy decisions."
      ],
      "parent_concepts": [
        "Concept 2: Evolution and standardization of diplomatic missions (why the embassy became the standard form after WWII and how that shifted the relevance of certain ranks like minister).",
        "Concept 2: Grand strategy framework (primacy, deep engagement, liberal hegemony) and how it dictates the use of military power, alliances, and institutions to achieve goals.",
        "Economic diplomacy as statecraft: using economic tools (incentives, sanctions) to achieve foreign policy objectives."
      ],
      "parent_articles": [
        "Diplomatic rank",
        "Foreign policy of the United States",
        "Economic diplomacy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do states typically design foreign policy by balancing domestic political pressures, the actions of other states, and the broader geopolitical environment rather than pursuing a single objective?",
      "options": {
        "A": "Because domestic political forces always determine foreign policy outcomes regardless of external conditions.",
        "B": "Because policymakers weigh trade-offs among competing domestic interests, anticipate other states' likely responses, and consider geopolitical constraints and opportunities, so each factor changes the costs and benefits of possible actions.",
        "C": "Because foreign policy is fully dictated by external factors—other states and geopolitics—with no significant domestic influence.",
        "D": "Because foreign policy decisions are made randomly or ad hoc without systematic consideration of domestic or external factors."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was tightened and made more direct for undergraduate readers; kept the three influencing factors and the trade-off reasoning. Options were rephrased to be concise while remaining plausible alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.2_vs_16",
    "pass_2_attempt": {
      "question": "Arcadia is a middle-power democracy whose economy depends heavily on exports. Recently, a neighboring great power imposed steep tariffs on Arcadian key exports while simultaneously conducting close military exercises near Arcadia’s maritime borders. Domestically, public opinion polls show strong pressure on the Arcadian government to protect local industries and jobs. At the same time, a small allied state two time zones away is experiencing a humanitarian collapse and requests targeted assistance. Arcadia’s diplomatic corps is modest but competent; an independent think tank has provided a policy brief recommending a multilateral negotiation strategy to lift tariffs, targeted humanitarian aid conditioned on reform, and increased diplomatic consultations with regional allies.\n\nWhich foreign policy course of action best demonstrates (a) formulation shaped by interacting factors (domestic politics, other states’ behavior, geopolitical context), (b) interconnected objectives (security, economic, humanitarian) forming a comprehensive strategy, and (c) appropriate use of institutions and actors (diplomats and think tanks) to develop and implement policy?",
      "options": {
        "A": "Immediately mobilize armed forces to the border, impose sweeping unilateral trade sanctions on the tariff-imposing great power, and redirect most funds from foreign aid to defense spending—relying primarily on emergency decrees bypassing the think tank recommendations.",
        "B": "Adopt the think tank’s multilateral negotiation plan to seek tariff relief through regional institutions, provide targeted humanitarian assistance to the allied state conditioned on governance reforms, convene alliance consultations to monitor security risks, and task the diplomatic corps to coordinate implementation and public messaging.",
        "C": "Prioritize domestic political appeasement by maintaining current trade ties despite tariffs, increasing direct cash transfers to affected domestic industries, and postponing any humanitarian aid until the tariff dispute is fully resolved—minimizing international engagement to avoid escalation.",
        "D": "Close Arcadia’s borders to trade with the great power, unilaterally suspend diplomatic relations, and convert existing foreign aid budgets into a large one-time grant to the allied state without consulting regional partners or the diplomatic service."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete mid-sized democratic state scenario with simultaneous economic, security, and humanitarian pressures; options test integration of multiple influencing factors, interconnected objectives, and institutional roles (diplomatic corps, think tank).",
      "concepts_tested": [
        "Multiple interacting factors shaping foreign policy formulation (domestic politics, other states’ behavior, geopolitical context)",
        "Interconnection of foreign policy objectives (defense/security, economic interests, humanitarian aid)",
        "Roles of institutions and actors (diplomatic corps, think tanks) in generating and implementing foreign policy"
      ]
    },
    "pass_2_reason": "readability_too_high_20.8_vs_16"
  },
  {
    "original_question": {
      "question": "In transportation planning, why is combining quantitative analysis with qualitative and mixed-methods approaches essential when evaluating alternatives, rather than relying on a single method?",
      "options": {
        "A": "Quantitative analysis alone is sufficient to forecast both performance and social acceptance, making qualitative input unnecessary.",
        "B": "Qualitative methods reveal values, perceptions, and contextual constraints; quantitative methods provide measurable performance across criteria; together they enable evaluating trade-offs and holistic impacts.",
        "C": "Mixed-methods simply complicate the process without adding insight, so a single method is preferable.",
        "D": "Qualitative methods only serve to persuade stakeholders and do not contribute to objective evaluation."
      },
      "correct_answer": "B",
      "source_article": "Transportation planning",
      "x": 1.392566442489624,
      "y": 0.8829249739646912,
      "concepts_tested": [
        "Concept 1: Planning in transportation is guided by multiple theoretical models (e.g., rational planning, incremental planning, collaborative planning) that influence how decisions are made.",
        "Concept 2: Sustainability and environmental considerations drive the evolving role of transport planners, promoting integrated policies and behavior-change approaches to reduce car dependence.",
        "Concept 3: Decision-making combines quantitative analysis with qualitative and mixed-methods approaches to evaluate alternatives across multiple criteria, reflecting a holistic assessment of impacts and options."
      ],
      "parent_concepts": [
        "Concept 1: The link between land-use patterns (low-density, single-use zoning) and transportation outcomes (car dependence, longer travel times, higher transport costs).",
        "Concept 3: Multimodal integration and design options — grade separation accommodates multiple transport modes (roads, rail, canals, etc.) and can be implemented via bridges, tunnels, or combinations of both.",
        "Concept 1: Unified, all-freeway design with nationally standardized construction and signage as a core principle distinguishing the Interstate System from prior networks.",
        "Concept 2: Electric traction and platform design (high platforms and aligned doors) enhance speed, safety, and efficient boarding, reducing gaps between train and platform.",
        "Concept 1: Dynamic routing and route optimization based on passenger origins and destinations.",
        "Why/how upgrading the network (electrification, in-cab signaling, new trains, Crossrail/Thameslink) enables higher capacity, faster service, and improved reliability to accommodate more passengers."
      ],
      "parent_articles": [
        "Urban sprawl",
        "Grade separation",
        "Interstate Highway System",
        "Rapid transit",
        "Demand-responsive transport",
        "Rail transport in Great Britain"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why should transportation planners combine quantitative analysis with qualitative and mixed-methods approaches when evaluating alternatives, rather than using only one method?",
      "options": {
        "A": "Quantitative analysis alone can reliably forecast both technical performance and public acceptance, so qualitative input is unnecessary.",
        "B": "Qualitative methods reveal values, perceptions, political and contextual constraints, while quantitative methods provide measurable performance across criteria; together they allow assessment of trade-offs and holistic impacts.",
        "C": "Mixed-methods mainly add complexity and cost without improving understanding, so using a single rigorous method is preferable.",
        "D": "Qualitative methods only help to persuade stakeholders and do not provide objective information useful for evaluation."
      },
      "correct_answer": "B",
      "simplification_notes": "Made the wording clearer and more concise for undergraduates, focused the question on the core reason for combining quantitative and qualitative methods, and kept all four options plausible while preserving the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.7_vs_16",
    "pass_2_attempt": {
      "question": "A metropolitan planning organization (MPO) is preparing a 10-year transportation plan for a city with rising congestion, air pollution, and unequal access to employment. Their adopted process includes: (i) convening engineers, community groups and private businesses to co‑generate alternatives; (ii) running four‑step travel demand models (trip generation, distribution, mode choice, assignment) and supplementing model outputs with focus groups, equity impact appraisal and qualitative case studies; (iii) prioritizing congestion pricing, reallocating curbspace to bus lanes and protected cycleways, and rezoning around transit nodes to encourage mixed‑use, transit‑oriented development; and (iv) implementing measures incrementally with pilots, monitoring, and adaptive revisions. Which statement best characterizes the planning paradigm used by this MPO?",
      "options": {
        "A": "A pluralistic, sustainability‑oriented transport planning paradigm that integrates multiple theoretical models (rational, collaborative and incremental), explicitly targets reduced car dependence via integrated land‑use and behaviour‑change measures, and combines quantitative modelling with qualitative and equity assessments for multi‑criteria decision making.",
        "B": "A traditional rational 'predict‑and‑provide' approach that relies mainly on travel demand forecasting to justify expanding highway capacity, with minimal stakeholder engagement and little attention to land‑use change or behavioural interventions.",
        "C": "A purely political, short‑term decision process driven by elected officials that substitutes technical analysis with ad hoc interventions focused on immediate traffic relief and avoids systematic monitoring or environmental appraisal.",
        "D": "A strictly incremental, community‑led process that eschews technical models and prioritizes small pilot projects and local consultations without region‑level quantitative analysis or integrated sustainability goals."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete MPO scenario combining stakeholder collaboration, four‑step models, sustainability measures (congestion pricing, transit, TOD), and mixed quantitative/qualitative evaluation; options contrast traditional predict‑and‑provide, political ad hoc, and purely incremental approaches.",
      "concepts_tested": [
        "Multiple planning models (rational, collaborative, incremental)",
        "Sustainability and reducing car dependence through integrated policies and behaviour change",
        "Use of quantitative (four‑step modelling) plus qualitative/mixed‑methods evaluation and multi‑criteria assessment"
      ]
    },
    "pass_2_reason": "readability_too_high_24.1_vs_16"
  },
  {
    "original_question": {
      "question": "In environmental epidemiology, researchers cannot ethically expose people to hazards to test effects. How does this constraint influence how researchers assess whether an environmental exposure affects health, and which methodological approach best supports causal inference under these conditions?",
      "options": {
        "A": "By treating any observed association as proof of causation if it appears consistent across settings, since exposures cannot be randomized.",
        "B": "By relying on cross-sectional snapshots and assuming temporality from exposure to outcome in all cases.",
        "C": "By exploiting natural variation in real-world exposures and using rigorous confounding control, assessment of temporality, dose–response evaluation, and triangulation across multiple study designs to infer causality without randomization.",
        "D": "By only using animal experiments and extrapolating findings to humans, since direct human exposure studies are unethical."
      },
      "correct_answer": "C",
      "source_article": "Environmental health",
      "x": 1.7217210531234741,
      "y": 0.9730183482170105,
      "concepts_tested": [
        "Concept 1: Environmental factors external to a person determine health outcomes, and environmental health seeks to assess and control these factors to prevent disease.",
        "Concept 2: Environmental epidemiology investigates the relationship between environmental exposures and human health, using observational studies due to ethical constraints on exposing people to hazards.",
        "Concept 3: Environmental health is multidisciplinary, integrating environmental science, toxicology, epidemiology, and environmental/occupational medicine to understand and manage environmental determinants of health."
      ],
      "parent_concepts": [
        "Concept 1: Water quality is defined and controlled by the intended use, with treatment and standards needed to ensure safety and suitability.",
        "Concept 2: Health-based and aesthetic regulatory frameworks (primary vs. secondary standards; EPA vs. FDA) drive how contaminants are limited and monitored to protect public health.",
        "Pathogen control is central, often achieved through disinfection, with a residual disinfectant maintained in the distribution system to prevent recontamination.",
        "Concept 3: Environmental indicators and measurements (e.g., DO, COD, BOD, pH, nitrates, heavy metals, pesticides) as links between chemical processes and environmental health, reflecting underlying mechanisms.",
        "Concept 1: The cause-effect relationship between artificial light at night and ecological/health impacts, including how night-time contrast intensifies effects.",
        "Concept 2: Indoor emission sources and activities (off-gassing from furnishings, cooking, smoking, cleaning) and their contribution to indoor pollutant levels.",
        "Concept 3: The health consequences of indoor air quality, including the burden of household air pollution in developing countries and associated mortality/morbidity.",
        "Concept 2: Soil contamination (e.g., lead and heavy metals) in urban environments is a key mechanism/constraint that affects health risks and food safety in urban agriculture."
      ],
      "parent_articles": [
        "Water quality",
        "Water quality",
        "Water treatment",
        "Environmental chemistry",
        "Light pollution",
        "Indoor air quality",
        "Indoor air quality",
        "Urban agriculture"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Because environmental epidemiologists cannot ethically assign people to harmful exposures, how do they establish whether an environmental exposure causes health effects, and which approach best supports causal inference without randomization?",
      "options": {
        "A": "Treat associations that are consistent across settings as definitive proof of causation, since exposures cannot be randomized.",
        "B": "Rely primarily on cross-sectional studies and assume the exposure preceded the outcome in all cases.",
        "C": "Exploit natural variation or natural experiments in exposure and combine rigorous control for confounding, clear assessment of temporality, dose–response analysis, and triangulation across multiple observational designs to infer causality without randomization.",
        "D": "Use only animal experiments and extrapolate the results to humans, because direct human exposure studies are unethical."
      },
      "correct_answer": "C",
      "simplification_notes": "Question wording was tightened and made more direct; retained the idea that ethical limits force observational approaches and emphasized techniques (natural experiments, confounding control, temporality, dose–response, triangulation) that support causal inference. Distractors were kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.6_vs_16",
    "pass_2_attempt": {
      "question": "In the town of Rivermouth, located downstream from an industrial facility that discharges chemical X, clinicians report a cluster of increased pediatric asthma admissions and gastroenteritis cases. As an environmental health investigation team charged with (1) determining whether environmental exposure to chemical X is responsible, (2) quantifying population exposure, and (3) implementing measures to prevent further illness, which of the following approaches best reflects the principles of environmental health and the roles of its contributing disciplines?",
      "options": {
        "A": "Conduct an observational epidemiologic study (e.g., case–control or cohort) to test the association between exposure and health outcomes—because deliberate human exposure would be unethical—while commissioning toxicology studies in animals to examine mechanisms and dose–response, using exposure science to measure and map individual and community exposure levels, and implementing engineering controls and regulatory actions (emission reduction, water treatment, site remediation) to reduce external environmental exposures and prevent disease.",
        "B": "Design a randomized controlled trial that intentionally exposes consenting adult volunteers to graded doses of chemical X to establish causality directly in humans, then rely on public health education alone to encourage behavior change (e.g., avoiding river water) as the primary prevention strategy.",
        "C": "Rely primarily on animal toxicology data to estimate human risk and immediately mandate medical surveillance and clinical treatment programs for affected children, without conducting population exposure measurements or community-level epidemiologic studies.",
        "D": "Attribute the cluster mainly to genetic susceptibility and individual behaviors, prioritize screening for genetic markers in the pediatric population, and implement advice-based interventions (handouts, counseling) rather than engineering, exposure remediation, or regulatory measures."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic community exposure scenario requiring selection of an observational epidemiologic design due to ethical constraints, and integration of toxicology, exposure science, and engineering/regulatory interventions to control external environmental factors—testing all three target concepts.",
      "concepts_tested": [
        "Environmental determinants of health and disease prevention by controlling external factors",
        "Use of observational study designs in environmental epidemiology due to ethical constraints",
        "Multidisciplinary integration of toxicology, exposure science, epidemiology, and engineering/law in environmental health practice"
      ]
    },
    "pass_2_reason": "readability_too_high_23.9_vs_16"
  },
  {
    "original_question": {
      "question": "In a system of limited government, promulgated laws and equality before the law, together with requiring consent for taxation and delegation, constrain rulers by tying power to pre-approved norms. How does this mechanism explain why a government action is legitimate?",
      "options": {
        "A": "It permits rulers to modify the rules as needed to address new challenges.",
        "B": "It ensures that government action is legitimate only if it lies within established laws that apply equally to all, and only with consent.",
        "C": "It guarantees that rulers can unilaterally delegate authority to other branches whenever necessary.",
        "D": "It allows the government to tax without consent if it serves the common good."
      },
      "correct_answer": "B",
      "source_article": "Limited government",
      "x": 1.1653012037277222,
      "y": 0.8908056616783142,
      "concepts_tested": [
        "Concept 1: Government power is constrained by foundational principles such as promulgated laws, equality before the law, and explicit consent/limits on taxation and delegation. How these mechanisms restrict rulers and what makes a law legitimate.",
        "Concept 2: The legitimacy of government rests on a social contract in which powers are delegated by the people and can be revoked; why and how consent defines the scope of governmental authority.",
        "Concept 3: Limited government aims to protect individual liberty through checks on power; the relationship between theoretical limits and practical outcomes (e.g., erosion of checks in many countries) and why maintaining these checks matters."
      ],
      "parent_concepts": [
        "Concept 1: Power is constrained by a constitution or unwritten conventions, preventing the monarch from ruling autonomously."
      ],
      "parent_articles": [
        "Constitutional monarchy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to the doctrine of limited government—promulgated laws, equal application of law, consent for taxation, and prohibition on delegating legislative power—why is a government action considered legitimate?",
      "options": {
        "A": "Because it allows rulers to change or reinterpret the rules as circumstances require to meet new challenges.",
        "B": "Because the action falls within established, publicly promulgated laws that apply equally to everyone and is taken only with the people's consent (e.g., consent to taxation and delegation).",
        "C": "Because rulers may unilaterally delegate their legislative authority to other offices or officials when they judge it necessary.",
        "D": "Because the government may impose taxes without prior consent if it can justify them as serving the common good."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was tightened to an undergraduate level, removed historical background, and focused on Locke-style constraints (promulgation, equality, consent, no delegation). Options were kept plausible but aligned with the original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.9_vs_16",
    "pass_2_attempt": {
      "question": "The newly independent Republic of Andoria is drafting its founding constitution. The drafters want to embody classical liberal limits on government—specifically Locke's four limitations (that government must govern by promulgated laws, laws must aim at the common good, taxes require the consent of the people or their deputies, and the legislature must not delegate its law‑making authority) —and also to protect individual liberty by instituting institutional checks that make those limits durable against erosion. Which of the following constitutional designs best implements those principles while minimizing the risk that checks on government power will rapidly erode?",
      "options": {
        "A": "Require all laws to be publicly promulgated in an official gazette and declare equal legal status for all citizens; allow the legislature to authorize executive agencies to issue subordinate regulations and levies without further legislative approval; require elections every six years for the legislature; create a single national court whose judges are removable by simple legislative majority.",
        "B": "Require laws to be publicly promulgated and constrained to serve the public good; require taxation to be authorized by the legislature elected by the people (or by popular referendum) and prohibit delegation of primary law‑making authority to any unelected body; establish a separation of powers with an independent judiciary that can adjudicate constitutional limits, regular free elections, and constitutional amendment rules that require supermajorities.",
        "C": "Vest broad law‑making and taxing powers in a unicameral assembly that may enact emergency decrees without publication; permit the assembly to delegate tax‑setting to a ministerial finance office; institute routine government oversight of the courts and allow the assembly to remove judges by simple majority vote to ensure democratic responsiveness.",
        "D": "Adopt a doctrine of the 'general will' where the annually elected legislature is supreme and may both make and execute laws in the name of popular sovereignty; require occasional publication of laws; allow flexible delegation of rule‑making to elected committees; include only advisory judicial review with no power to invalidate legislation."
      },
      "correct_answer": "B",
      "generation_notes": "Create a realistic constitutional drafting scenario and four plausible constitutional designs; correct option (B) maps onto Locke's four limitations (promulgation, common good, consent for taxation, no delegation) and includes institutional checks (separation of powers, independent judiciary, supermajority amendment rule) to prevent erosion.",
      "concepts_tested": [
        "Lockean limitations on governmental power (promulgated laws, common good, consent for taxation, no delegation)",
        "Social contract and consent via elections/referenda as the basis of governmental legitimacy",
        "Institutional checks (separation of powers, independent judiciary, supermajority amendments) and their role in protecting individual liberty and preventing erosion of limits"
      ]
    },
    "pass_2_reason": "readability_too_high_20.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does viewing the criminal justice system as an interdependent network of police, courts, and prisons help ensure the rule of law, rather than treating these bodies as independent, isolated actors?",
      "options": {
        "A": "It ensures that all decisions are made by a single authority, speeding up outcomes.",
        "B": "It creates a system of mutual checks and procedural standards where arrests, charges, trials, and detention are subject to oversight and rights protections.",
        "C": "It reduces the need for due process because different agencies can correct themselves without external review.",
        "D": "It concentrates authority in the police to coordinate actions across the state."
      },
      "correct_answer": "B",
      "source_article": "Criminal justice",
      "x": 1.188427209854126,
      "y": 0.771416425704956,
      "concepts_tested": [
        "Concept 1: The criminal justice system as an interdependent network of institutions (police, courts, prisons) that operate together to maintain the rule of law.",
        "Concept 2: Law enforcement as a mechanism involving investigation, arrest, and the use of coercive power within jurisdiction to initiate proceedings and enforce laws.",
        "Concept 3: The system’s goals (rehabilitation, crime prevention, and moral support for victims) as guiding principles shaping practices and outcomes."
      ],
      "parent_concepts": [
        "Concept 1: Protection is designed to reduce retaliation risk to witnesses to encourage testimony and maintain the integrity of the justice system.",
        "Concept 2: Core mechanisms of protection (new identities, relocation, ongoing protection, and supportive services) and the case-by-case decision process for admission.",
        "Concept 3: Punishment functions as a mechanism of social control to defend norms and maintain the rule of law, linking to deterrence, prevention, and societal order.",
        "Context-dependent form and purpose of sanctions (criminal punishment vs. civil penalties vs. international sanctions)",
        "Concept 3: The effect of mandatory sentencing (and related reforms) on the distribution of power between judges and prosecutors, illustrating how policy choices alter judicial discretion and can invoke concerns about activism versus restraint."
      ],
      "parent_articles": [
        "Witness protection",
        "Witness protection",
        "Punishment",
        "Sanctions (law)",
        "Judicial discretion"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does conceptualizing the criminal justice system as an interdependent network of police, courts, and prisons better protect the rule of law than treating these institutions as isolated, independent actors?",
      "options": {
        "A": "Because it places decision-making authority in a single agency, which speeds up case resolution.",
        "B": "Because it establishes mutual checks, procedural standards, and oversight so arrests, charging, trials, and detention are subject to review and rights protections.",
        "C": "Because it reduces the need for formal due process by relying on agencies to correct errors internally without external review.",
        "D": "Because it concentrates authority in the police so they can coordinate enforcement uniformly across the state."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the stem to be more concise and academic; removed historical detail and examples; kept the comparison between an interdependent network and isolated institutions; made each option plausible and retained the original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.3_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized city establishes a program to reduce recidivism for non-violent drug offenders. Under the program: (1) local police, upon arresting a qualifying suspect, may divert the case to a specialized treatment court rather than filing traditional criminal charges; (2) the prosecutor evaluates the referral and can offer participation in a supervised treatment-and-restitution plan instead of immediate prosecution; (3) the court monitors progress, mandates vocational training and counseling, and orders restitution to victims; (4) probation officers supervise compliance and report outcomes to the court, and successful completion can result in reduced sanctions or dismissal. Which statement best explains how this program exemplifies the core features of the criminal justice system described in the article?",
      "options": {
        "A": "It illustrates an interdependent network—police, prosecutors, courts, and corrections—working together to maintain the rule of law, with law enforcement initiating proceedings through arrest/diversion and coercive authority, while the program prioritizes rehabilitation, crime prevention, and victim reparation.",
        "B": "It primarily shows law enforcement power because police arrest suspects and therefore determine final outcomes; the court and probation merely execute the police's decisions, so the program is mainly a policing initiative rather than a system of separate institutions.",
        "C": "It reflects a community-led restorative process that operates independently of state authority: since participation is voluntary and focused on reconciliation, it does not involve the courts or police as official institutions of the criminal justice system.",
        "D": "It demonstrates an incapacitation strategy because transferring offenders to supervised community programs removes them from opportunities to offend, and the principal goal is public protection rather than rehabilitation or victim support."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete diversion-court scenario that requires students to identify interdependence of police, prosecution, courts, and corrections; the initiating coercive role of law enforcement; and the programmatic goals of rehabilitation, prevention, and victim support.",
      "concepts_tested": [
        "Criminal justice as interdependent network of institutions",
        "Law enforcement roles: investigation, arrest, coercive initiation within jurisdiction",
        "System goals: rehabilitation, crime prevention, and moral support/victim restitution"
      ]
    },
    "pass_2_reason": "readability_too_high_22.8_vs_16"
  },
  {
    "original_question": {
      "question": "In life history theory, why does natural selection produce trade-offs such as investing more in current reproduction at the expense of future survival or reproduction when an organism has a finite energy budget?",
      "options": {
        "A": "Because energy and resources are finite, allocating more to current reproduction reduces resources available for maintenance and future reproduction.",
        "B": "Because future survival always yields higher fitness than current reproduction, so trade-offs are driven by changing preferences.",
        "C": "Because organisms can perfectly predict future environmental conditions and allocate resources accordingly without constraints.",
        "D": "Because current reproduction does not affect future survival or reproduction, making trade-offs unnecessary."
      },
      "correct_answer": "A",
      "source_article": "Life history theory",
      "x": 1.8100149631500244,
      "y": 1.1114310026168823,
      "concepts_tested": [
        "Trade-offs and resource allocation: how organisms balance reproduction, survival, and parental investment under energy constraints to shape life history strategies.",
        "Evolutionary optimization of life history traits: natural selection drives strategies that maximize fitness given environmental pressures, leading to predictable patterns across species.",
        "Timing and sequencing of life events: definition and consequences of age- and stage-specific patterns (birth, maturation, first reproduction, juvenile development, senescence) as a unified life history strategy influenced by ecology."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In life history theory, why does natural selection produce trade-offs such as investing more energy in current reproduction at the expense of future survival or future reproduction when an organism has a finite energy budget?",
      "options": {
        "A": "Because energy and other resources are limited, so allocating more to current reproduction necessarily reduces the resources available for somatic maintenance and future reproduction.",
        "B": "Because future survival always yields higher fitness than current reproduction, so trade-offs are driven by a universal preference for future investment.",
        "C": "Because organisms can perfectly predict future environmental conditions and therefore allocate resources without physiological constraints.",
        "D": "Because current reproduction does not influence later survival or fecundity, so trade-offs are not due to resource allocation."
      },
      "correct_answer": "A",
      "simplification_notes": "Wording shortened and clarified: replaced lengthy explanation with a concise question about resource allocation and trade-offs; distractor options rephrased to remain plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.6_vs_16",
    "pass_2_attempt": {
      "question": "Two geographically adjacent populations of the same small rodent species inhabit different environments. Population A lives where adult extrinsic mortality is high and food availability is highly unpredictable; Population B lives where adult extrinsic mortality is low and food availability is stable. Individuals have a fixed lifetime energy budget that must be allocated among growth (which increases future fecundity), current reproduction, and somatic maintenance (which increases survival). According to life history theory and the reproductive value trade-off (RV = current reproduction + residual reproductive value), which combination of life history traits is most likely to be favored by natural selection in Population A versus Population B?",
      "options": {
        "A": "Population A: early age at first reproduction, small adult body size, high annual fecundity with low parental investment and a shorter adult lifespan; Population B: delayed age at first reproduction, larger adult body size, lower annual fecundity per event but higher parental investment and a longer adult lifespan.",
        "B": "Population A: delayed age at first reproduction and high parental investment to buffer offspring against unpredictable food and predation; Population B: early reproduction with minimal parental care because stable food allows many generations quickly.",
        "C": "Population A and B should both evolve larger adult body size and delayed reproduction because increased body size unambiguously raises lifetime fitness regardless of mortality regime.",
        "D": "Population A: semelparity (single massive reproductive event late in life) because high mortality favors investing heavily in one big brood; Population B: continued annual reproduction with negligible parental investment because low mortality removes the need for parental care."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a two-population scenario varying extrinsic mortality and resource predictability to test trade-offs in energy allocation, reproductive value, and timing of life events; options include plausible distractors invoking parental investment, semelparity, and mistaken universals about body size.",
      "concepts_tested": [
        "Trade-offs and resource allocation between growth, reproduction, and maintenance",
        "Evolutionary optimization of life history traits under differing extrinsic mortality and environmental predictability",
        "Timing and sequencing of life events (age at first reproduction, body size, reproductive schedule, lifespan)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.2_vs_16"
  },
  {
    "original_question": {
      "question": "In the three-component model of language policy, how does misalignment between language ideology and planned interventions influence policy outcomes?",
      "options": {
        "A": "It causes language practices to change automatically regardless of ideology, because interventions are the decisive lever.",
        "B": "It reduces efficacy because ideology shapes acceptance and actual use of interventions; without alignment, interventions may be ignored or reinterpreted, leading to limited, uneven, or short‑lived changes in practice.",
        "C": "It makes the hierarchy of rules emerge; ideology becomes the only determinant while practices are irrelevant.",
        "D": "It ensures immediate, uniform adoption across all communities due to strong normative claims."
      },
      "correct_answer": "B",
      "source_article": "Language policy",
      "x": 1.2245244979858398,
      "y": 1.070617914199829,
      "concepts_tested": [
        "Concept 1: Language policy as a sociocultural process governed by power dynamics and normative claims about language forms and uses, influencing language statuses and rights.",
        "Concept 2: The three-component model of language policy—language practices, language beliefs/ideology, and interventions/planning—and how their interaction shapes policy outcomes.",
        "Concept 3: The relationship between regulation and implementation, including historical contingency and varying explicitness across states (e.g., Toubon law, Charter of the French Language)."
      ],
      "parent_concepts": [
        "Concept 1: Language shift as a mechanism—prestige, social/economic power, and globalization drive speakers to adopt dominant languages, leading to endangerment of minority languages.",
        "Concept 1: Language shift as a mechanism for language endangerment, driven by social/economic power and prestige (globalization, dominant languages).",
        "Concept 2: The relationship between signage (multilingual vs. monolingual) and audience/readership expectations, informing how public space organization communicates identity and policy.",
        "Concept 1: Standardization as an institutional mechanism (government recognition, schooling, grammars, dictionaries) that designates what counts as a \"standard\" dialect and influences language use."
      ],
      "parent_articles": [
        "Endangered language",
        "Endangered language",
        "Linguistic landscape",
        "Dialect"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to the three-component model of language policy (language practices, language beliefs/ideology, and interventions/planning), what is the most likely effect when a policy's planned interventions are not aligned with the prevailing language ideology?",
      "options": {
        "A": "Interventions will automatically change language practices regardless of ideology, because planning is the decisive lever for practice change.",
        "B": "Policy efficacy is reduced: ideology shapes whether people accept and use interventions, so misaligned interventions may be ignored, resisted, or reinterpreted, producing limited, uneven, or short‑lived changes in practice.",
        "C": "Ideology becomes the sole determinant of outcomes; regulations and interventions become irrelevant and practices remain unchanged.",
        "D": "Misalignment does not matter: interventions are adopted immediately and uniformly across communities because policy creates strong normative claims."
      },
      "correct_answer": "B",
      "simplification_notes": "Question shortened and clarified to reference Spolsky's three components explicitly; wording made more concise while preserving the interaction between ideology, interventions, and practices and the role of acceptance and power.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.0_vs_16",
    "pass_2_attempt": {
      "question": "In the multilingual state of Rivoria, three developments occurred over two decades: (1) the 2000 Rivorian Official Language Act — a highly explicit statute requiring public institutions to use Rivorian in official signage and administration; (2) a persistent societal ideology that Rivorian confers higher socio-economic mobility and prestige than minority languages; and (3) a set of community-driven, small-scale language revival projects in three rural districts of the minority language Talen (bilingual preschool programs, local media, and multilingual street signage). By 2020, Rivorian use dominated urban public life and Talen declined in most urban areas, but Talen stabilized and even increased in the three rural districts. Which analysis best explains these outcomes in terms of (a) the three-component model of language policy (practices, beliefs/ideology, interventions/planning) and (b) the role of power, normative claims, historical contingency, and implementation explicitness?",
      "options": {
        "A": "The Official Language Act, despite its explicit regulatory wording, operated largely as a top-down intervention without sufficiently altering everyday language practices or the dominant ideology; socio-economic power and prestige incentives maintained Rivorian use in urban domains, while localized community interventions that changed practices and created favorable norms stabilized Talen in the rural districts—this outcome exemplifies how policy success requires alignment among practices, beliefs, and implemented interventions.",
        "B": "Because the 2000 Act was highly explicit, it should have reversed Talen decline everywhere; the fact that Talen persists only in rural districts indicates that national legislation alone is always sufficient to create language vitality, and community projects were irrelevant to the outcome.",
        "C": "The dominant societal ideology about prestige fully determined all shifts: legal regulations and local interventions had negligible impact. Talen's stabilization in rural districts is best explained by accidental demographic shifts unrelated to language practices or planning.",
        "D": "Historical contingency alone explains the pattern: long-standing historical ties of the rural districts to Talen determined its persistence regardless of contemporary beliefs, implementation, or power relations; the Official Language Act and community projects were epiphenomenal."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete two-decade scenario (Rivoria) that requires applying Spolsky's three-component model and concepts of power, normative claims, implementation explicitness, and historical contingency to explain divergent urban/rural outcomes; four options offered with one correct integrative analysis.",
      "concepts_tested": [
        "Language policy as a sociocultural process governed by power dynamics and normative claims",
        "Spolsky's three-component model: language practices, beliefs/ideology, and interventions/planning",
        "Relationship between regulation and implementation including explicitness and historical/contextual factors"
      ]
    },
    "pass_2_reason": "readability_too_high_26.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why do traditional regulation models, designed for physical goods and local markets, struggle to govern the digital economy, and what regulatory approach best addresses cross-border data flows and platform-based business models?",
      "options": {
        "A": "Traditional models assume static, localized assets and single-seller relationships; they fail to account for cross-border data flows, network effects, and multi-sided platforms. The adaptive approach involves harmonized, outcome-based standards for privacy and competition, enabling data portability and interoperability, with cross-border enforcement and regulatory experimentation (sandboxes) to balance innovation and protection.",
        "B": "Traditional models already fit digital platforms; no adaptation is necessary, since regulations can be applied exactly as before.",
        "C": "The digital economy requires only sector-specific rules for each category of service; centralizing all regulation into a single universal standard across all jurisdictions is best.",
        "D": "The best adaptation is to rely exclusively on self-regulation by platforms and rely on consumer choice."
      },
      "correct_answer": "A",
      "source_article": "Digital economy",
      "x": 1.2973235845565796,
      "y": 0.9649307131767273,
      "concepts_tested": [
        "Transformation mechanism of the digital economy (infrastructure, e-business, e-commerce) and how digitalization changes production, distribution, and trade.",
        "Regulation and governance relationships (privacy, competition, taxation) and how policy must adapt to digital-enabled activities.",
        "Data, connectivity, and IoT as drivers of new value creation and productivity (embedded digital services and data flows shaping business models)."
      ],
      "parent_concepts": [
        "Concept 3: Multi-channel/online-offline retail and the impact of digital technologies on payment methods, services, and consumer reach."
      ],
      "parent_articles": [
        "Retail"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do regulatory frameworks designed for physical goods and local markets struggle to govern the digital economy, and which regulatory approach best handles cross-border data flows and platform-based, multi-sided business models?",
      "options": {
        "A": "Because traditional rules assume static, localized assets and one-to-one seller relationships; they do not account for cross-border data flows, network effects, and multi-sided platforms. The appropriate response is an adaptive, harmonized, outcome-based regime for privacy and competition that enables data portability and interoperability, supports cross-border enforcement, and uses regulatory experimentation (sandboxes) to balance innovation and protection.",
        "B": "They do not struggle: existing regulations for physical goods and local markets can be applied unchanged to digital platforms, so no special adaptation is necessary.",
        "C": "The digital economy should be governed by sector-specific, national rules tailored to each category of service; cross-border harmonization is unnecessary and a single global standard is impractical.",
        "D": "The best approach is exclusive self-regulation by platform operators, relying on market competition and consumer choice rather than public regulation."
      },
      "correct_answer": "A",
      "simplification_notes": "Compressed the original stem to a single clear question, used direct academic language, removed extended examples and historical detail, and kept essential regulatory concepts (cross-border data, network effects, multi-sided platforms). Options were rewritten to be concise and plausible; correct answer letter retained.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "SmartHomeX is a multinational firm that designs and sells IoT-enabled thermostats. It manufactures hardware in Country M, hosts customer telemetry and analytics on cloud servers in Country N, sells devices via its own online platform and third‑party marketplaces, provides over‑the‑air firmware updates and personalized energy‑saving recommendations derived from continuous sensor data, and contracts local technicians as independent installers through its app. Which of the following choices best (a) maps these activities to the three components of the digital economy (e‑business infrastructure, e‑business, e‑commerce), (b) identifies the primary regulatory challenges policymakers must address, and (c) explains how IoT, data and connectivity create new value and productivity for SmartHomeX?",
      "options": {
        "A": "Correct mapping: e‑business infrastructure — IoT devices, cloud servers, telecom networks, analytics software and technical staff; e‑business — remote device management, data analytics, platform scheduling and firmware updates (processes conducted over computer networks); e‑commerce — online sale/subscriptions for thermostats and digital services. Regulatory challenges: cross‑border data flows and privacy (e.g., GDPR transfers and data localization), digital services taxation and profit allocation, competition/market power from platform network effects, and labor classification for gig installers. Mechanisms: continuous telemetry and connectivity enable personalization, predictive maintenance, supply‑chain and inventory optimization, and stronger network effects that increase platform value and reduce transaction costs, thereby raising productivity.",
        "B": "Mapping: e‑business infrastructure — only physical manufacturing and servers; e‑business — online sales and marketplaces; e‑commerce — firmware updates and analytics. Regulatory challenges: principally consumer product safety and requiring servers to be located where sales occur; data privacy and taxation are secondary. Mechanisms: IoT mainly creates value by enabling cheaper manufacturing through automated production rather than through data or connectivity.",
        "C": "Mapping: e‑business infrastructure — software and analytics only; e‑business — hardware production and distribution; e‑commerce — app‑based installer coordination. Regulatory challenges: focus exclusively on antitrust to break up platforms; taxation and privacy are not key concerns. Mechanisms: data and IoT generate value primarily by increasing electricity consumption that scales economies of scale.",
        "D": "Mapping: e‑business infrastructure — just the online storefront; e‑business — third‑party marketplaces and installers; e‑commerce — all device functionality and personalization. Regulatory challenges: best addressed by banning cross‑border data transfers to force local hosting; competition and labor issues are negligible. Mechanisms: network effects reduce consumer surplus and therefore do not contribute to productivity gains."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a scenario (SmartHomeX) linking IoT devices, cloud analytics, online sales, and gig installers; created four options combining component mapping, regulatory issues, and mechanisms of value creation — only option A correctly aligns infrastructure/e‑business/e‑commerce, lists GDPR/data flow, taxation, competition and labor concerns, and explains IoT/data productivity mechanisms.",
      "concepts_tested": [
        "Digital economy components: e‑business infrastructure, e‑business, e‑commerce",
        "Regulatory challenges: privacy/data flow, taxation, competition/antitrust, labor classification",
        "Drivers of value creation: IoT, continuous data flows, connectivity, network effects, productivity gains"
      ]
    },
    "pass_2_reason": "readability_too_high_21.9_vs_16"
  },
  {
    "original_question": {
      "question": "In the Attributes–Threats–Means framework for dependability, why is it more effective to relate threats to specific means and to particular attributes rather than considering attributes in isolation?",
      "options": {
        "A": "It isolates attributes from threats and means, enabling independent optimization, which guarantees overall dependability.",
        "B": "It links specific threats to actionable means and to measurable attributes, allowing targeted investments that preserve or improve those attributes under changing conditions.",
        "C": "It assumes threats are unpredictable and thus requires uniform, broad mitigation across all attributes, which simplifies decision-making.",
        "D": "It treats dependability as a single scalar metric, ignoring the separate attributes and their different responses to threats."
      },
      "correct_answer": "B",
      "source_article": "Dependability",
      "x": 1.4420245885849,
      "y": 1.0673093795776367,
      "concepts_tested": [
        "Concept 1: The Attributes–Threats–Means framework as a core model for understanding and improving dependability.",
        "Concept 2: The evolutionary expansion of dependability to include safety and security, showing how the scope and measurement of dependability develop over time.",
        "Concept 3: The notion of time-bounded, trustworthy service in real-time computing, and how guarantees must hold despite faults or attacks."
      ],
      "parent_concepts": [
        "Concept 2: Self-testing, memory recovery, and backup modules as autonomous fault-detection and repair mechanisms"
      ],
      "parent_articles": [
        "Fault tolerance"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In the Attributes–Threats–Means framework for dependability, why is it preferable to map specific threats to concrete means and to particular dependability attributes (for example availability, reliability, safety, integrity, maintainability) rather than considering attributes in isolation?",
      "options": {
        "A": "It isolates attributes from threats and means, allowing independent optimization of each attribute and thereby guaranteeing overall dependability.",
        "B": "It connects identifiable threats to actionable countermeasures and to measurable attributes, so investments can be targeted to preserve or improve those attributes under changing conditions.",
        "C": "It assumes threats are inherently unpredictable and therefore requires uniform, broad mitigation across all attributes, which simplifies decision-making.",
        "D": "It treats dependability as a single scalar metric, ignoring that different attributes respond differently to specific threats."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording made more concise and academic; explicitly named common attributes as examples; focused the question on mapping threats to means and attributes; preserved original intent and answer choices.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_27.4_vs_16",
    "pass_2_attempt": {
      "question": "A medical ventilator control subsystem is required to produce control updates within $10\\ \\text{ms}$ and must continue to meet this deadline even if one of its pressure sensors is compromised by an adversary. During validation the engineering team records: (a) whether updates are produced continuously over prolonged operation; (b) a software defect that exists in the deployed code but only manifests under a rare patient breathing waveform, appearing unpredictably and sporadically; (c) a design strategy that allows the subsystem to meet the $10\\ \\text{ms}$ deadline despite a compromised sensor by using redundant sensors and a voting mechanism. Which option correctly maps (a) to a dependability attribute, (b) to the persistence classification of the defect, and (c) to the dependability means?",
      "options": {
        "A": "(a) Reliability; (b) Intermittent; (c) Fault tolerance",
        "B": "(a) Availability; (b) Transient; (c) Fault prevention",
        "C": "(a) Safety; (b) Permanent; (c) Removal during development",
        "D": "(a) Integrity; (b) Transient; (c) Fault forecasting"
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic real-time system scenario (ventilator, $10\\ \\text{ms}$ deadline) and asked for mapping of (a) attribute, (b) persistence class, (c) means using terminology from Attributes–Threats–Means; distractors use other valid terms to test distinction between availability/reliability, transient/intermittent/permanent, and prevention/removal/forecasting/tolerance.",
      "concepts_tested": [
        "Attributes–Threats–Means framework (mapping attributes, fault persistence, and means)",
        "Evolution of dependability scope (distinguishing reliability, safety, integrity, availability, and security-related measures)",
        "Real-time dependability: time-bounded trustworthy service and use of fault tolerance to maintain guarantees under attacks"
      ]
    },
    "pass_2_reason": "readability_too_high_22.2_vs_16"
  },
  {
    "original_question": {
      "question": "Why does generalizing input test cases improve robustness, and what role does testing play in validating that generalization?",
      "options": {
        "A": "Generalization reduces the number of inputs to check so you can verify all cases exhaustively; testing then certifies those few cases guarantee correctness.",
        "B": "Generalization creates a representative family of inputs that captures likely variations, increasing the chance the system handles unseen instances in that family; testing (including fuzz testing and fault injection) probes the system with varied and unexpected inputs to verify graceful behavior and detect weaknesses that the generalized set misses.",
        "C": "Generalization increases code complexity and thus requires less testing because the family covers all edge cases by design.",
        "D": "Generalization ensures the system will be perfect for any input; testing is unnecessary."
      },
      "correct_answer": "B",
      "source_article": "Robustness (computer science)",
      "x": 1.4786823987960815,
      "y": 1.0794214010238647,
      "concepts_tested": [
        "Generalization of input cases as a design principle to improve robustness and the role of testing in validating it",
        "Redundancy and software diversity as mechanisms to tolerate failures, including why blind code addition is harmful and how equivalent functionality enables failure replacement",
        "Interaction between robustness, evolvability/adaptability, and testing techniques (how testing demonstrates robustness and supports adaptable design)"
      ],
      "parent_concepts": [
        "Concept 2: Self-testing, memory recovery, and backup modules as autonomous fault-detection and repair mechanisms"
      ],
      "parent_articles": [
        "Fault tolerance"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does grouping many possible inputs into a smaller set of representative test cases (generalization) improve a program's robustness, and what role does testing play in checking that this generalization is valid?",
      "options": {
        "A": "Generalization cuts the number of inputs so you can exhaustively check every case; testing then proves those few cases guarantee correct behavior for all inputs.",
        "B": "Generalization selects a representative family of inputs that captures likely variations, increasing the chance the system handles unseen instances from that family; testing (for example fuzz testing and fault injection) exercises varied and unexpected inputs to confirm graceful handling and to reveal weaknesses the generalized set might miss.",
        "C": "Generalization makes the code more complex and therefore needs less testing because the representative family is assumed to include all edge cases by design.",
        "D": "Generalization guarantees the system will behave correctly for any input, so additional testing is unnecessary."
      },
      "correct_answer": "B",
      "simplification_notes": "Rewrote the question in clearer undergraduate-level language, preserved the idea that representative test sets improve robustness and that testing (including fuzzing and fault injection) validates that generalization. Options were rephrased to remain plausible while keeping the original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.4_vs_16",
    "pass_2_attempt": {
      "question": "You are designing a payments microservice that parses and validates user-submitted transaction amounts (in cents) and forwards them to a clearing service. The project lead asks you to improve robustness and make the service evolvable. The team proposes the following measures: (1) create a compact representative test-suite with values like $-1$, $0$, $1$, and $10^6$ plus automated fuzz tests; (2) add a second parser implemented independently (different algorithm and developer) that can replace the primary parser automatically when health checks fail; (3) reduce code size by copying the primary parser and adding ad-hoc guards around it; (4) verify robustness using periodic fault injection and monitor behavioral divergence between parsers. Which single design choice below best implements robustness principles from the article — including generalization of test cases, controlled redundancy via software diversity, and using testing to support evolvability — while avoiding the pitfall of blind code addition?",
      "options": {
        "A": "Combine (1), (2) and (4): maintain a small representative test-suite augmented with fuzzing, implement an independently developed redundant parser (software diversity) with automated health checks and failover, and validate both via periodic fault injection and divergence monitoring.",
        "B": "Combine (1), (3) and (4): use the representative tests and fault injection but implement redundancy by copying the primary parser and adding quick guards to reduce code size; rely on monitors to detect failures.",
        "C": "Rely solely on exhaustive testing of all 32-bit integer amounts and fast fail-safe logging; do not add redundant components, but aim to prove correctness by exhaustive input coverage.",
        "D": "Prioritize performance and small codebase: keep only one highly optimized parser, produce precise user-facing error messages, and reject malformed inputs early; add no redundant parser and no fault-injection testing."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete payments microservice scenario to require application of generalized test-case selection plus fuzzing, software-diverse redundancy with automated failover, and validation via fault injection; options contrast correct controlled redundancy with blind copying, impractical exhaustive testing, and insufficient single-component strategies.",
      "concepts_tested": [
        "Generalization of input cases and role of fuzz testing/fault injection",
        "Redundancy and software diversity versus blind code addition; automated failover and equivalence",
        "Interaction between robustness, evolvability/adaptability, and testing to demonstrate robustness"
      ]
    },
    "pass_2_reason": "readability_too_high_21.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does propagandistic messaging that is repeated across multiple media channels tend to shift public attitudes more effectively than a single-channel message, and how does deliberate suppression or diversion of competing viewpoints contribute to this effect?",
      "options": {
        "A": "Repetition across channels creates perceived ubiquity and social proof, boosting credibility and reducing motivation to scrutinize the message; suppression or diversion of competing viewpoints narrows the information landscape, increasing exposure to the dominant narrative and reinforcing attitude change.",
        "B": "Repetition across channels mainly increases the emotional impact of the message, but suppression of competing viewpoints has no systematic effect on attitudes because people only respond to content quality.",
        "C": "Repetition across channels ensures numerical accuracy by cross-checking facts in every medium, while suppressing other viewpoints makes it easier for audiences to learn all sides.",
        "D": "The strategy works because audiences always compare the content across channels and form a balanced view; cross-channel repetition and suppression are neutral props that neither help nor hinder attitude change."
      },
      "correct_answer": "A",
      "source_article": "Media manipulation",
      "x": 1.256628394126892,
      "y": 0.9922653436660767,
      "concepts_tested": [
        "Concept 1: Media channels as enablers of propaganda and shapers of public opinion (the role of mass/digital media in enabling manipulation and spreading narratives)",
        "Concept 2: Specific manipulation mechanisms (rhetorical strategies, disinformation, propaganda techniques, logical fallacies) and why they influence audiences",
        "Concept 3: Propaganda as one-sided, repetitive messaging across multiple media to influence attitudes, including suppression/attention-diversion as means to reduce exposure to alternatives"
      ],
      "parent_concepts": [
        "Concept 2: Use of unverified claims, fake interviews, pseudoscience, and sensational crime coverage as strategies to influence public opinion and boost readership."
      ],
      "parent_articles": [
        "Yellow journalism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does repeating a propagandistic message across multiple media channels shift public attitudes more effectively than a single-channel message, and how does deliberately suppressing or diverting competing viewpoints amplify this effect?",
      "options": {
        "A": "Cross-channel repetition creates perceived ubiquity and social proof, raising the message's apparent credibility and lowering recipients' motivation to scrutinize it; deliberate suppression or diversion of competing viewpoints narrows the information environment so audiences are exposed more often to the dominant narrative, reinforcing attitude change.",
        "B": "Repetition across channels mainly increases the emotional intensity of the message, but suppressing competing viewpoints has little systematic effect because people respond only to the intrinsic quality of content.",
        "C": "Repetition across multiple channels guarantees factual cross-checking and numerical accuracy by verifying the same facts in every medium, while suppressing other viewpoints makes it easier for audiences to learn all sides.",
        "D": "The approach works because audiences consistently compare versions of the content across channels and therefore form a balanced, critical view; consequently, cross-channel repetition and suppression are neutral tactics that neither help nor hinder attitude change."
      },
      "correct_answer": "A",
      "simplification_notes": "Clarified and shortened the two-part question into direct academic language; retained core concepts (repetition → ubiquity/social proof → reduced scrutiny; suppression/diversion → narrowed information landscape → reinforced attitudes); options rewritten to be concise and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.0_vs_16",
    "pass_2_attempt": {
      "question": "In the fictional country of Veridia, the ruling party runs the following coordinated campaign during an election cycle: (1) the state-owned television channel airs the same short segment every evening lauding the government and never broadcasting opposition viewpoints; (2) thousands of automated social media accounts amplify a pro-government hashtag and post identical supportive messages; (3) paid influencers publish sensational headlines accusing the opposition of criminality without documentary evidence; (4) local authorities repeatedly deny permits for opposition rallies and major newspapers give the government segments priority coverage; (5) when an independent media outlet publishes a corruption allegation, the government releases a dramatic foreign-policy incident that dominates the news cycle; (6) a marginal blog posts an unverified study linking the opposition to foreign agents, and larger outlets report on the blog's claim rather than verifying it themselves. Which one of the following best characterizes how these actions exemplify (i) media channels enabling propaganda, (ii) the manipulation mechanisms and the psychological reasons they influence audiences, and (iii) propaganda as one-sided repetitive messaging that uses suppression or diversion to limit exposure to alternatives?",
      "options": {
        "A": "(i) Items (1) and (2) show how mass and digital channels enable propaganda by providing repeatable broadcast and amplification; (ii) items (2) and (3) illustrate astroturfing, clickbait and disinformation that exploit social proof, availability and authority heuristics to persuade audiences; (iii) items (1), (4) and (5) demonstrate one-sided repetitive messaging combined with suppression (denying permits, preferential coverage) and diversion (the manufactured foreign-policy incident) to reduce exposure to alternatives; item (6) is an example of information laundering.",
        "B": "(i) Only item (1) qualifies as channels enabling propaganda because social media bots are ephemeral and do not constitute a media channel; (ii) item (3) is mere sensationalism, not a manipulation mechanism, so it does not rely on cognitive biases; (iii) items (4) and (5) are independent political acts and do not function as propaganda because they do not involve repeated messaging across media.",
        "C": "(i) Items (2) and (6) are examples of legitimate grassroots mobilization and routine reporting, respectively, rather than media-enabled propaganda; (ii) item (3) represents normal investigative journalism, so it does not employ rhetorical fallacies or disinformation; (iii) item (1) cannot be propaganda since state TV is a single channel and repetition across different media is required for propaganda to work.",
        "D": "(i) All items are PR tactics but none amount to propaganda because propaganda requires direct government deception; (ii) the psychological impact claimed (social proof, availability, authority) is irrelevant because audiences always verify sensational claims before sharing; (iii) information laundering (item 6) cannot influence mainstream outlets because reputable media never report on marginal blogs without verification."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a single-scenario question mapping specific campaign actions to the three target concepts: channels-as-enablers, manipulation mechanisms and cognitive biases, and propaganda's one-sided repetition plus suppression/diversion; provided distractors that misattribute or deny key mechanisms.",
      "concepts_tested": [
        "Mass and digital media channels as enablers of propaganda",
        "Specific manipulation mechanisms (astroturfing, clickbait, disinformation, information laundering) and cognitive biases they exploit",
        "Propaganda as one-sided, repetitive messaging using suppression and diversion to limit exposure to opposing views"
      ]
    },
    "pass_2_reason": "readability_too_high_44.8_vs_16"
  },
  {
    "original_question": {
      "question": "How do continuity and interaction contribute to the educative value of an experience in experiential education, and how do they help distinguish educative, mis-educative, and non-educative outcomes?",
      "options": {
        "A": "Continuity links the current experience to future ones and interaction aligns the experience with the learner’s internal goals; together they enable reflection and lasting growth, making the experience educative.",
        "B": "The educative value depends only on the number of activities performed, regardless of reflection or future application.",
        "C": "An experience is educative simply because it is entirely novel, while familiarity automatically leads to mis-educative or non-educative outcomes.",
        "D": "Educative value arises when the learner is isolated from feedback, so their internal interpretation remains unchallenged."
      },
      "correct_answer": "A",
      "source_article": "Experiential education",
      "x": 1.2486298084259033,
      "y": 0.9795590043067932,
      "concepts_tested": [
        "Concept 1: Learning occurs through direct experience combined with focused reflection to increase knowledge, develop skills, clarify values, and contribute to the community.",
        "Concept 2: The educational value of an experience depends on continuity and interaction; experiences can be educative, mis-educative, or non-educative based on reflection and outcomes.",
        "Concept 3: Experiential education is a guiding philosophy that informs a range of methodologies and is distinct from but connected to other educational theories and models (e.g., it influences practices like service learning, Outward Bound, and Freirean approaches)."
      ],
      "parent_concepts": [
        "Concept 2: Learning through action and reflection (experiential learning) as the mechanism that generates understanding."
      ],
      "parent_articles": [
        "Service-learning"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to Dewey's experiential-education criteria, how do continuity and interaction determine whether an experience is educative, mis-educative, or non-educive?",
      "options": {
        "A": "Continuity connects the present experience to past and future experiences while interaction aligns the experience with the learner's internal needs or goals; together, plus focused reflection, they produce lasting growth and make an experience educative.",
        "B": "The educative value depends only on the quantity of activities performed; more activities automatically produce learning regardless of reflection or future relevance.",
        "C": "Any entirely novel or unfamiliar experience is educative, whereas familiar experiences are automatically mis-educative or non-educative.",
        "D": "An experience becomes educative when the learner is isolated from external feedback so their personal interpretation is unchallenged."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording made more concise and focused on Dewey's terms 'continuity' and 'interaction'; options rewritten to be plausible distractors while preserving original meanings; removed extraneous phrasing.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.1_vs_16",
    "pass_2_attempt": {
      "question": "A university piloted four programs to teach undergraduates civic competence and practical skills. Using the Association for Experiential Education’s formulation and Dewey’s criteria (especially continuity and interaction), which program best exemplifies experiential education and why?\n\nProgram descriptions:\nA) A semester-long, credit-bearing community-research placement in which students spend eight hours weekly at a local nonprofit, attend weekly facilitator-led seminars for focused reflection linking fieldwork to course theory, receive formative feedback, and are placed in a follow-on internship the next term.\nB) A single-day campus-wide litter clean-up where students work in shifts for a few hours; participation is recorded for a participation grade but there is no structured reflection or curricular integration.\nC) A series of repetitive laboratory procedures in a skills course where students follow strict protocols; they submit a brief checkbox-style reflection focused on whether they followed steps correctly and are evaluated mainly on procedural compliance.\nD) A week-long outdoor adventure expedition with daily oral debriefs; the experience is intense and reflective but is offered as an extracurricular that neither references prior coursework nor leads to subsequent learning experiences.",
      "options": {
        "A": "A: Semester-long, credit-bearing community placement with weekly guided reflection, formative feedback, and follow-on internship — combines direct experience, focused reflection, continuity, and community contribution.",
        "B": "B: Single-day clean-up with attendance grading and no structured reflection — provides direct experience but lacks reflection and continuity, so is likely non-educative.",
        "C": "C: Repetitive lab tasks with checkbox reflections and emphasis on compliance — experience with reflection is superficial and may distort future growth, making it mis-educative.",
        "D": "D: Intensive week-long expedition with debriefs but no curricular links — offers interaction and reflection but lacks continuity, so produces transient learning without sustained development."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete multi-program scenario requiring application of Dewey’s continuity/interaction criteria, reflection importance, and the idea that experiential education is a guiding philosophy realized through methods like service learning; created plausible distractors illustrating non-educative and mis-educative cases.",
      "concepts_tested": [
        "direct experience combined with focused reflection to increase knowledge, skills, values, and community contribution",
        "Dewey’s criteria of continuity and interaction and classification of experiences as educative, mis-educative, or non-educative"
      ]
    },
    "pass_2_reason": "readability_too_high_20.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why does adopting an axiomatic foundation enhance rigor in mathematics after encountering paradoxes or counterintuitive results?",
      "options": {
        "A": "It asserts that every statement is true once accepted, preventing any further scrutiny of proofs.",
        "B": "It defines a small, explicit base of axioms and derives all results through formal deduction, making dependencies and potential inconsistencies transparent.",
        "C": "It relies on empirical testing of statements before accepting them as theorems, ensuring alignment with observed data.",
        "D": "It replaces logical deduction with intuitive appeal to avoid the sting of paradoxes."
      },
      "correct_answer": "B",
      "source_article": "Pure mathematics",
      "x": 1.5889856815338135,
      "y": 1.1773215532302856,
      "concepts_tested": [
        "The emergence of axiomatic methods as a mechanism to restore rigor after paradoxes and counter-intuitive results",
        "The relationship between pure and applied mathematics: these are not rigidly separated; ideas can originate in pure math and later apply to real-world problems",
        "The motivational basis of pure mathematics: pursuit of intellectual challenge and aesthetic beauty drives inquiry, rather than immediate application"
      ],
      "parent_concepts": [
        "Concept 3: The fluid, debated boundaries of what counts as applied mathematics versus applications of mathematics (no consensus on branches; crossovers like cryptography; differing views among mathematicians)."
      ],
      "parent_articles": [
        "Applied mathematics"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "After mathematicians discovered paradoxes and counterintuitive results around 1900, why did adopting an axiomatic foundation increase mathematical rigor?",
      "options": {
        "A": "It declares every accepted proposition to be true without further verification, preventing scrutiny of proofs.",
        "B": "It starts from a clear, explicit set of axioms and derives all theorems by formal deduction, so assumptions, logical dependencies, and possible inconsistencies become transparent.",
        "C": "It requires empirical testing of mathematical statements against observed data before they are accepted as theorems, ensuring they match reality.",
        "D": "It abandons formal deduction in favor of intuitive reasoning and aesthetic judgment to avoid paradoxes."
      },
      "correct_answer": "B",
      "simplification_notes": "Question reworded concisely for undergraduate readers; preserved the link between paradoxes and need for axiomatic methods. Options were kept plausible and clarified; no technical content removed.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.9_vs_16",
    "pass_2_attempt": {
      "question": "Consider the following historical and conceptual vignette: mathematicians in the early 20th century confront counterintuitive discoveries such as non‑Euclidean geometries and paradoxes like Russell's paradox, prompting a broad program to restore logical security to mathematics; decades later, abstract results in number theory unexpectedly underpin practical cryptosystems (for example, the difficulty of factoring an integer $n=pq$ used in RSA); and many researchers state that they pursue mathematics chiefly for intellectual challenge and aesthetic beauty rather than immediate practical use. Which set of conclusions best matches the depiction of pure mathematics in the article?",
      "options": {
        "A": "(i) The appropriate historical response to paradoxes and counterintuitive theories was to develop and systematize axiomatic methods to restore rigor; (ii) Many results originally regarded as purely abstract later found applications (e.g., number theory to cryptography), so the pure/applied division is not rigid; (iii) Pure mathematicians are often motivated primarily by intellectual challenge and aesthetic beauty rather than immediate application.",
        "B": "(i) Pure mathematics was abandoned as a pursuit after paradoxes because it could not be made rigorous; (ii) Most pure theories never find real applications, so the distinction between pure and applied is absolute; (iii) Pure mathematicians chiefly pursue problems because of immediate practical utility.",
        "C": "(i) The discovery of paradoxes led mathematicians to reject axiomatic approaches in favor of empirical testing of mathematical claims; (ii) The historical examples of applied uses (e.g., RSA) are anomalies and do not affect the philosophical separation of pure and applied mathematics.",
        "D": "(i) The response to foundational paradoxes was to tighten rigor by axiomatization; (ii) Pure mathematics is strictly divorced from applications and its practitioners refuse any notion that abstract results can become useful; (iii) Aesthetic value plays no role in motivating research in pure mathematics."
      },
      "correct_answer": "A",
      "generation_notes": "Presented a concrete vignette (non‑Euclidean geometries, Russell's paradox, RSA factoring $n=pq$) and asked students to choose which combination of historical/philosophical conclusions aligns with the article: axiomatization after paradoxes, permeability of pure/applied boundary, and aesthetic/intellectual motivation.",
      "concepts_tested": [
        "Axiomatic method as response to paradoxes and counterintuitive results",
        "Relationship and permeability between pure and applied mathematics (examples like RSA)",
        "Motivations of pure mathematicians: intellectual challenge and aesthetic value"
      ]
    },
    "pass_2_reason": "readability_too_high_27.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a dialogue designed as a Socratic inquiry rely on a deliberate sequence of questions rather than one speaker delivering conclusions, in terms of how it advances philosophical understanding?",
      "options": {
        "A": "Because it helps the interlocutors memorize predefined conclusions through repetition.",
        "B": "Because a sequence of guiding questions compels participants to articulate hidden assumptions, test them against counterarguments, and derive insights through their own reasoning, which reveals inconsistencies and deepens understanding.",
        "C": "Because it centers on winning the argument by persuading others rather than examining the ideas themselves.",
        "D": "Because it relies on delivering a definitive conclusion first and then using questions to justify it."
      },
      "correct_answer": "B",
      "source_article": "Dialogue",
      "x": 0.7723355293273926,
      "y": 1.0985921621322632,
      "concepts_tested": [
        "Concept 1: Dialogue as a vehicle for dialectic and philosophical inquiry (Socratic method)",
        "Concept 2: The interplay between argumentation and character portrayal within dialogue",
        "Concept 3: Historical evolution and cross-cultural adoption of the dialogue form (origins, adaptations, transmission)"
      ],
      "parent_concepts": [
        "Concept 1: Intercultural dialogue as a deliberate, open, and respectful process whose primary goal is understanding rather than agreement.",
        "Concept 1: Interview structure and formats shape information capture (unstructured vs structured vs focused/ladder interviews) and guide responses."
      ],
      "parent_articles": [
        "Intercultural dialogue",
        "Interview"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does a Socratic-style philosophical dialogue proceed by a deliberate sequence of questions rather than by one speaker asserting conclusions, in terms of how it advances philosophical understanding?",
      "options": {
        "A": "Because asking many questions mainly helps participants memorize preset conclusions through repetition and reinforcement.",
        "B": "Because guided questions force participants to state and examine hidden assumptions, confront counterexamples, and draw conclusions through their own reasoning, exposing inconsistencies and deepening understanding.",
        "C": "Because the method is primarily aimed at winning an argument and persuading others of the questioner’s position rather than jointly examining ideas.",
        "D": "Because the dialogue first presents a definitive conclusion and then uses questions only to justify or defend that already-declared answer."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the original question into clearer undergraduate-level phrasing, removed historical examples, and focused on the epistemic function of the question sequence; options kept plausible and the correct answer unchanged.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "You are given three brief excerpts of dialogue-style texts: (1) A classical Athenian exchange in which a philosopher asks probing questions to elicit definitions and to expose contradictions in an interlocutor's claims; (2) A 19th-century literary conversation that foregrounds witty repartee and vivid personalities while also carrying moral or philosophical points; (3) A 20th-century classroom/group session in which participants agree to suspend persuasion tactics, speak from personal experience, and seek mutual understanding to inform collective action. Which option best maps the primary role of dialogue in each excerpt with respect to (i) dialogue as a vehicle for dialectic/Socratic inquiry, (ii) the interplay of argumentation and character portrayal, and (iii) the form's historical evolution and cross-cultural adaptation into pedagogical and group-practice contexts?",
      "options": {
        "A": "(1) Exemplifies Socratic dialectic: structured questioning to refine definitions and reveal contradictions; (2) Illustrates the interplay between argumentation and character‑drawing: lively personalities and witty anecdote carry philosophical content; (3) Demonstrates historical evolution/adaptation: dialogue repurposed (e.g., Freire, Bohm) as an egalitarian, praxis‑oriented pedagogy and group practice.",
        "B": "(1) Primarily a dramatic device emphasizing characterisation rather than dialectic inquiry; (2) A strict revival of Platonic method that uses questioning to arrive at essential definitions; (3) A conventional debating format whose aim is to persuade others and win arguments rather than to transform practice or understanding.",
        "C": "(1) An inherited performance from early Sicilian mimes where theatrical effect outweighs argumentative content; (2) A pedagogical technique designed to equalise teacher–student power and produce social change; (3) A reinstatement of the Socratic elenchus in modern educational settings, identical in method and purpose to Plato's dialogues.",
        "D": "(1) A hybrid that gives equal weight to dramatized character and dialectical proof so neither function predominates; (2) An explicitly philosophical form that rejects characterisation in favour of pure logical refutation; (3) An ancient, unchanging tradition traceable in identical form from Sumerian disputations through modern pedagogies."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a comparative scenario (Platonic, 19th-century literary, 20th-century pedagogical/Bohm-Freire) and offered four plausible mappings; correct option aligns Socratic dialectic with Plato, character‑driven argument with literary dialogues, and modern adaptation with egalitarian/praxis-oriented dialogue.",
      "concepts_tested": [
        "Dialogue as vehicle for dialectic/Socratic inquiry",
        "Interplay between argumentation and character portrayal",
        "Historical evolution and cross-cultural adoption of dialogue form (transmission and adaptation into pedagogy and group practice)"
      ]
    },
    "pass_2_reason": "readability_too_high_32.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does relying solely on operational capabilities (efficiently running current activities) fail under radical discontinuous change, and how do dynamic capabilities address this limitation?",
      "options": {
        "A": "They allow adaptation, integration of new knowledge, and reconfiguration of resources to create new routines suited to the new environment.",
        "B": "They prioritize cost-cutting and outsourcing to maintain current operations without changing underlying routines.",
        "C": "They keep the same resource base while waiting for market conditions to revert to the old regime.",
        "D": "They rely exclusively on internal routines, ignoring external partners and new technologies that could enable change."
      },
      "correct_answer": "A",
      "source_article": "Dynamic capabilities",
      "x": 1.335715889930725,
      "y": 0.986164927482605,
      "concepts_tested": [
        "Concept 1: Dynamic capabilities as a processual set of abilities (adapting, integrating, reconfiguring resources) to match changing environments.",
        "Concept 2: The relationships and bridges between dynamic capabilities and broader theories (resource-based view, routines, evolutionary theory) and what this implies for theory testing.",
        "Concept 3: The distinction between dynamic capabilities and operational capabilities, and their roles in achieving short-term adaptability versus long-term competitive survival under radical change."
      ],
      "parent_concepts": [
        "Concept 2: The stored-capabilities investment principle and the resource development dimension (invest in current resources to develop new capabilities rather than dispose and replace) and why this enhances flexibility and reduces future costs."
      ],
      "parent_articles": [
        "Resource management"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why are operational (ordinary) capabilities — the firm's abilities to run current activities efficiently — insufficient when an industry undergoes radical, discontinuous change, and what do dynamic capabilities provide instead?",
      "options": {
        "A": "Dynamic capabilities enable the firm to adapt, integrate new knowledge and external assets, and reconfigure its resource base to create new routines suited to the changed environment.",
        "B": "They emphasize aggressive cost-cutting and outsourcing to preserve current operations without altering underlying routines.",
        "C": "They maintain the existing resource base and wait for market conditions to revert back to the prior regime.",
        "D": "They depend solely on internal routines and ignore external partners, new technologies, and external knowledge that could support transformation."
      },
      "correct_answer": "A",
      "simplification_notes": "Question condensed and clarified: defined 'operational capabilities' in parentheses, focused on the contrast with dynamic capabilities, and used concise academic language. Options kept plausible and aligned with the article; core concept and correct answer preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.8_vs_16",
    "pass_2_attempt": {
      "question": "EuroAuto is a mature incumbent automaker whose competitive advantage has historically depended on an optimized assembly-line process and tight supplier coordination. Suddenly a modular electric vehicle (EV) architecture emerges that requires rapid software–hardware integration, external developer ecosystems, and new supplier capabilities. Senior management must respond to survive this radical discontinuity. Which of the following strategic actions best exemplifies exercising dynamic capabilities (as a process of adapting, integrating and reconfiguring resources), aligns with the dynamic-capabilities perspective relative to the resource-based view and routines/evolutionary theories, and is properly distinguished from ordinary operational capabilities?",
      "options": {
        "A": "Create cross-functional 'integration squads' to learn software–hardware integration, form strategic alliances with battery and platform software firms to import new competences, systematically reconfigure production modules and redeploy staff from legacy lines to new modular assembly — thereby building new strategic assets and changing the firm's resource base.",
        "B": "Implement a plant-wide program to reduce defects by 20% through tighter quality-control checklists and incremental efficiency improvements on the existing assembly line to preserve current margins.",
        "C": "Preserve existing assembly-line routines and concentrate lobbying efforts to delay regulatory adoption of the new EV standard, hoping the technological shift slows down.",
        "D": "Centralize R&D decisions and expand the firm's patent portfolio around existing mechanical subsystems to protect current proprietary technologies and make incremental expansions of product variants."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete disruption scenario where students must identify which organizational actions represent higher-order dynamic capabilities (learning, integration, reconfiguration) versus ordinary operational responses, and relate those to resource-based and evolutionary/routines theory.",
      "concepts_tested": [
        "Dynamic capabilities as adapting, integrating, reconfiguring resources",
        "Relation between dynamic capabilities, resource-based view, and routines/evolutionary theory",
        "Distinction between dynamic (higher-order) capabilities and ordinary operational capabilities"
      ]
    },
    "pass_2_reason": "readability_too_high_23.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does public participation function as a mechanism and justification for political legitimacy and justice in a participatory democracy?",
      "options": {
        "A": "It shifts all decision-making power to the people and removes institutions from policymaking.",
        "B": "It expands legitimate actors to include ordinary citizens, makes decision processes transparent and deliberative, and creates accountability, thereby aligning outcomes with public values and enhancing perceived justice.",
        "C": "It guarantees that every policy will have unanimous citizen support, ensuring universal legitimacy.",
        "D": "It short-circuits representative processes, sacrificing deliberation for speed and efficiency."
      },
      "correct_answer": "B",
      "source_article": "Participatory democracy",
      "x": 1.1854907274246216,
      "y": 0.9014378190040588,
      "concepts_tested": [
        "Concept 1: Hybrid governance model that blends direct citizen deliberation with representative institutions",
        "Concept 2: Public participation as a mechanism and justification for political legitimacy and justice",
        "Concept 3: Institutional mechanisms (e.g., participatory budgeting) as concrete implementations of participatory democracy and their impact on policy decisions"
      ],
      "parent_concepts": [
        "Concept 3: Design/participation principles for e-government tools (ideals such as progressive values, ubiquitous participation, geolocation, and public education) and their impact on governance outcomes",
        "Participatory, inside-out organization: citizens as active actors, decisions grounded in local conversations, broad leadership involvement, and local control over development processes.",
        "Concept 1: Empowerment and joint decision making as central to participation (Social Movement Perspective) – ownership and control reside with primary stakeholders, and dialogue leads to shared solutions.",
        "Non-hierarchical, consensus-based governance with power-sharing as an organizational mechanism"
      ],
      "parent_articles": [
        "E-government",
        "Asset-based community development",
        "Participatory development",
        "Mutual aid"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a participatory democracy, why does direct public participation serve both as a mechanism for making decisions and as a justification for political legitimacy and justice?",
      "options": {
        "A": "Because it hands all policymaking authority entirely to citizens and removes institutions from the process.",
        "B": "Because it expands who is recognized as a legitimate political actor to include ordinary citizens, makes decision processes more transparent and deliberative, and creates accountability—aligning policies with public values and enhancing perceived justice and legitimacy.",
        "C": "Because it guarantees unanimous citizen support for every policy, which ensures universal legitimacy.",
        "D": "Because it bypasses representative processes, prioritizing speed and efficiency at the expense of deliberation and careful decision‑making."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was shortened and focused on how participation functions as mechanism and justification; language made clearer for undergraduates while preserving concepts of legitimacy, deliberation, transparency, accountability, and institutional context. Options kept plausible alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized city with significant income inequality adopts a hybrid participatory governance reform: (1) a 150-person citizens' assembly selected by stratified sortition to deliberate on citywide priorities; (2) a participatory budgeting process allocating 10% of the municipal discretionary budget with neighborhood assemblies proposing projects; and (3) formal review and ratification of assembly recommendations by the elected city council. After two cycles the city reports: increased trust in local government, a 35% rise in projects located in low-income neighborhoods, reduced reports of petty clientelism in procurement, and most assembly recommendations implemented by the council. Which analytical conclusion best synthesizes how this reform illustrates (a) a hybrid governance model blending direct deliberation and representative institutions, (b) public participation as a source of political legitimacy and distributive justice, and (c) how institutional mechanisms like participatory budgeting produce concrete policy impacts?",
      "options": {
        "A": "The reform demonstrates an effective hybrid: sortition-based deliberation and participatory budgeting produced redistributive outcomes and higher perceived legitimacy, while the council’s ratification provided scalability and legal implementation—showing participatory institutions can both justify and materially alter policy.",
        "B": "The reform shows that direct democracy via mass referendums would have been superior because only citywide votes can generate genuine legitimacy and distributive outcomes; small assemblies and targeted budgets are inherently tokenistic and cannot change structural inequalities.",
        "C": "The reported changes are likely coincidental; participatory mechanisms mainly serve as public relations tools, and any decrease in clientelism or redistribution must be attributed to independent administrative reforms rather than citizens’ assemblies or budgeting processes.",
        "D": "Sortition-based assemblies undermine political egalitarianism because the small randomly selected group cannot represent the majority; participatory budgeting tends to favor those already politically mobilized, so the observed implementation rates reflect elite capture rather than increased legitimacy or justice."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete municipal case showing citizens' assemblies, participatory budgeting, and council ratification; options contrast hybrid-benefit synthesis with common critiques (referendums, tokenism, elite capture).",
      "concepts_tested": [
        "Hybrid governance combining direct deliberation and representative institutions",
        "Public participation as a mechanism for political legitimacy and distributive justice",
        "Institutional mechanisms (participatory budgeting, citizens' assemblies) and their policy impacts"
      ]
    },
    "pass_2_reason": "readability_too_high_29.1_vs_16"
  },
  {
    "original_question": {
      "question": "How does the concept of a totem, as a symbol representing a social group, help explain why the traditional magic-vs-religion dichotomy is inadequate, and what does it reveal about the function of religion in many societies?",
      "options": {
        "A": "It shows religious symbols address individual curiosities about nature, reinforcing the view that religion primarily explains natural phenomena.",
        "B": "It demonstrates that symbolic objects can simultaneously bind group identity, kinship, and ritual practice, highlighting religion's role in social cohesion rather than as a simple progression from magic to belief.",
        "C": "It supports the idea that religion is merely a misclassification of magic, with no meaningful social function beyond correcting cognitive biases.",
        "D": "It proves that all cultures share an identical religious function, thereby denying cultural variation in religious practice."
      },
      "correct_answer": "B",
      "source_article": "Anthropology of religion",
      "x": 1.1798418760299683,
      "y": 1.0127297639846802,
      "concepts_tested": [
        "Concept 1: Evolutionary framework of religion (animism → magic → religion → science) and its critiques; why scholars proposed these stages and what criticisms arise (e.g., evidence, cultural bias, modern applicability).",
        "Concept 2: Religion as a social phenomenon connected to other institutions and worldviews; how anthropologists analyze the function of religion within societies and its role in navigating the world.",
        "Concept 3: Redefining religious categories beyond simple dichotomies (magic vs. religion) and introducing concepts like totem; how these ideas illustrate the complexity of interpreting religious phenomena across cultures."
      ],
      "parent_concepts": [
        "Concept 3: Cross-cultural variation of liturgy (e.g., Buddhist liturgy with chanting, sutras, mantras) illustrating a shared ritual idea with tradition-specific practices and settings (temple vs. home)."
      ],
      "parent_articles": [
        "Liturgy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the concept of a totem—an object or symbol representing a social group—undermine the simple magic-versus-religion distinction, and what does it indicate about religion's primary function in many societies?",
      "options": {
        "A": "It shows religious symbols mainly address individual attempts to explain natural phenomena, supporting the idea that religion's primary role is to account for the natural world.",
        "B": "It demonstrates that symbolic objects can simultaneously bind group identity, kinship, and ritual practice, indicating religion often functions to create social cohesion rather than representing a linear progression from magic to belief.",
        "C": "It claims religion is simply a mislabeling of magic with no broader social role, reducing religious practices to corrections of cognitive errors.",
        "D": "It argues that because totems perform similar roles everywhere, all cultures have an identical religious function and there is no meaningful cultural variation in religious practice."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the original question to focus on how totems challenge the magic-vs-religion dichotomy and emphasize religion's social function; removed extended historical background while preserving core theoretical contrast and outcome.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.7_vs_16",
    "pass_2_attempt": {
      "question": "An anthropologist conducts ethnography on a Pacific island where (1) carved canoe prows are described by villagers as inhabited by ancestral spirits; (2) specialist ritual practitioners perform spells before long-distance voyages to secure fish and favorable winds; and (3) a centralized priestly class organizes annual rites that symbolically unite several clans around a carved animal emblem. One colleague interprets these data using an evolutionary sequence of religion ($\\text{animism} \\rightarrow \\text{magic} \\rightarrow \\text{religion} \\rightarrow \\text{science}$), another emphasizes ritualized problem‑solving and psychological functions, and a third reads the carved emblem as a representation of collective social life. Which interpretive framework best (a) rejects a simplistic evolutionary hierarchy, (b) explains how religious symbols and rituals function as expressions of social organization, and (c) moves beyond a strict magic vs. religion dichotomy by treating symbolic objects (like the carved emblem) as socially constituted rather than merely 'primitive animism'?",
      "options": {
        "A": "An evolutionist account that places the canoe prows and spells in an early 'animistic/magic' stage and treats the priestly annual rites as an incipient 'religion' stage; this explains change over time but risks imposing a Western developmental hierarchy.",
        "B": "A Durkheimian/totemic interpretation that reads the carved prow and animal emblem as collective representations through which society projects its power and identity; rituals and specialist practices function to integrate groups and maintain social order, thereby rejecting a linear evolutionary ranking and collapsing the magic/religion binary into socially meaningful practices.",
        "C": "A Malinowskian functionalist reading that separates magic (the voyage spells) as instrumental technology for risk management and religion (the priestly rites) as psychological/social reinforcement; useful for distinguishing functions but less adequate at accounting for the emblem as a symbol of collective identity or critiquing evolutionary taxonomy.",
        "D": "An Evans‑Pritchard style analysis emphasizing the internal logic of belief: treat spells, spirits, and priestly rites as elements of a coherent indigenous cosmology that should be decoded on its own terms; this explains cognitive consistency but does not primarily theorize the emblem as a social institution or confront evolutionist hierarchies."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed an ethnographic island scenario combining animism, magic, priesthood, and totemic emblem; wrote options mapping to Tylor/Frazer (evolutionism), Durkheim (totem/social force), Malinowski (functionalism), and Evans‑Pritchard (internal logic) to test rejection of evolutionary hierarchy, social function of religion, and moving beyond magic/religion dichotomy.",
      "concepts_tested": [
        "Evolutionary framework of religion and its critiques",
        "Religion as a social institution and its functions",
        "Totemism and transcending the magic vs. religion dichotomy"
      ]
    },
    "pass_2_reason": "readability_too_high_23.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why is it important in intellectual history to study ideas in relation to the thinkers who conceptualize and apply them, rather than in isolation?",
      "options": {
        "A": "Because the meaning of ideas is fixed and universal, independent of the author or context.",
        "B": "Because ideas are developed, contested, and transformed within specific intellectual networks, audiences, and historical moments; the author’s position and constraints shape how ideas are produced and received.",
        "C": "Because only the author’s personal biography determines the value and truth of an idea.",
        "D": "Because ideas are mere byproducts of language, so context is irrelevant."
      },
      "correct_answer": "B",
      "source_article": "Intellectual history",
      "x": 0.8698552846908569,
      "y": 1.0295490026474,
      "concepts_tested": [
        "Interdependence of ideas and their thinkers: ideas develop in relation to the people who conceptualize and apply them, not in isolation.",
        "Dual-context study of ideas: examining ideas both as abstract propositions for critical application and in concrete terms of culture, life, and history.",
        "Evolution and frameworks of the discipline: the historical shift from history of philosophy/cultural history to intellectual history, including Lovejoy’s unit-ideas and the move from “history of ideas” to “intellectual history.”"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why should intellectual historians study ideas together with the thinkers and historical contexts that produced and used them, rather than treating ideas as isolated, timeless entities?",
      "options": {
        "A": "Because the meaning of ideas is fixed and universal, independent of the author or historical setting.",
        "B": "Because ideas are developed, contested, and transformed within specific intellectual networks, audiences, and historical moments; the author’s social position, institutional constraints, and intended audience shape how ideas are produced, expressed, and received.",
        "C": "Because only the author’s personal biography determines the value and truth of an idea.",
        "D": "Because ideas are mere byproducts of language and textual form, so their historical or social context is irrelevant."
      },
      "correct_answer": "B",
      "simplification_notes": "Question phrasing was tightened to undergraduate level; extraneous historical details were removed. Key discipline terms (e.g., 'context', 'intellectual networks') were kept to preserve the tested concept. Options were made concise and kept plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.1_vs_16",
    "pass_2_attempt": {
      "question": "You are evaluating four proposed research designs for a study of the concept of \"freedom\" from the 17th to the 19th century. Which design best reflects the contemporary discipline of intellectual history as described in the article, emphasizing that ideas develop in relation to thinkers and must be studied both as abstract propositions and in concrete cultural/historical contexts, while acknowledging the field's evolution from Lovejoy's unit-ideas toward historically sensitive contextualism?",
      "options": {
        "A": "Identify a single invariant definition of \"freedom\" that recurs unchanged in canonical philosophical texts, extract that core unit-idea, and analyze only its logical permutations across authors—treating the concept as an abstract entity largely independent of authors' social milieux.",
        "B": "Analyze material and non-linguistic artefacts (architecture, music, visual arts) from the period to demonstrate how non-verbal media instantiate concepts of \"freedom,\" without close attention to the texts or biographies of thinkers who coined or promoted the term.",
        "C": "Trace the shifting meanings of \"freedom\" by (i) identifying recurring conceptual elements reminiscent of Lovejoy's unit-ideas, (ii) examining how particular thinkers formulated and applied those elements in essays, speeches, and institutional practice, and (iii) situating those formulations within the social, political, and cultural life of their historical contexts.",
        "D": "Reject narrative continuity and treat the period as discontinuous discursive formations; reconstruct the discourses in which statements about \"freedom\" became possible, focusing on epistemic structures rather than on individual authors or the concrete reception of ideas."
      },
      "correct_answer": "C",
      "generation_notes": "Created a vignette comparing four methodological designs to test recognition of thinkers' role, dual-context analysis, and the field's shift from Lovejoy's unit-ideas toward contextualist intellectual history; option C integrates these elements.",
      "concepts_tested": [
        "Interdependence of ideas and their thinkers",
        "Dual-context study of ideas (abstract propositions and concrete cultural/historical contexts)",
        "Evolution of the discipline from Lovejoy's unit-ideas to contextualist intellectual history"
      ]
    },
    "pass_2_reason": "readability_too_high_21.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does advancing from \"involvement\" to \"empowerment\" on a public participation ladder typically increase the capacity of the public to influence a decision?",
      "options": {
        "A": "It shifts final decision-making authority from officials to the participants, granting them power to set goals, approve plans, or veto options.",
        "B": "It simply expands the amount of technical information available to participants while leaving decision power with officials.",
        "C": "It makes participants' preferences automatically count as the definitive outcome, replacing expert judgments.",
        "D": "It reduces participation by restricting who can be involved, thereby speeding up decisions."
      },
      "correct_answer": "A",
      "source_article": "Public participation (decision making)",
      "x": 1.2677006721496582,
      "y": 0.9503679871559143,
      "concepts_tested": [
        "Concept 1: Participation as redistribution of power to include marginalized or “have-not” citizens, enabling meaningful influence over decisions (Arnstein’s citizen power, tokenism, nonparticipation).",
        "Concept 2: Levels of participation and their associated influence (information, consultation, involvement, collaboration, empowerment) and how moving up the ladder changes decision-making power.",
        "Concept 3: Representativeness and legitimacy in participation (who participates, how they are represented, and how much influence they receive), including criteria for authentic participation."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "On a public-participation spectrum (for example IAP2's levels from information to empowerment), why does moving from “involvement” to “empowerment” typically increase the public’s capacity to influence a decision?",
      "options": {
        "A": "Because it transfers final decision-making authority from officials to participants, giving them power to set goals, approve plans, or veto options.",
        "B": "Because it simply supplies participants with more technical information while formal decision-making authority remains with officials.",
        "C": "Because participants’ preferences automatically become the definitive outcome, fully replacing expert judgment.",
        "D": "Because it narrows who may participate, reducing numbers to speed decisions but not increasing actual influence."
      },
      "correct_answer": "A",
      "simplification_notes": "Question rephrased to reference a participation spectrum (IAP2) and made language clearer and more concise; distractor options kept plausible and consistent with original misconceptions; core idea of power redistribution (Arnstein’s citizen power) preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.0_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized city (population 200,000) intends to redesign a low-income neighborhood long excluded from planning decisions. The population is 60% higher-income and 40% lower-income; historically the lower-income residents have been under-represented in municipal processes. Planners propose four participatory designs. Using Arnstein’s notion that participation should redistribute power to include the “have-not” citizens, the IAP2 spectrum (information → consultation → involvement → collaboration → empowerment), and Fung’s three legitimacy questions (who participates and are they representative; what is the method of communication/decision-making; how much influence is granted), which design best exemplifies authentic, redistributive participation that gives marginalized residents meaningful decision-making power?",
      "options": {
        "A": "A 200-person citizens' assembly formed by stratified random selection with deliberate oversampling so low-income residents constitute 50% of delegates; sessions use neutral deliberative facilitation and expert briefs; the assembly’s voted recommendations on land use and a dedicated local budget are legally binding on the city council (delegated decision authority).",
        "B": "A series of open evening town-hall meetings publicized citywide and streamed online; anyone may speak or submit comments; city staff prepare a summary report and the city council retains final, non-binding decision authority after considering the input.",
        "C": "A 12-member advisory committee appointed by the mayor composed primarily of local business owners and homeowners; the committee meets monthly, issues policy recommendations, and the council usually adopts them without further public deliberation.",
        "D": "A participatory budgeting process where any resident can propose projects and vote online; the winning projects receive funding directly from a discretionary municipal fund, but there are no measures to ensure demographic representativeness or to support deliberation among under-represented groups."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete municipal scenario contrasting selection method, deliberative procedure, and decision authority to test Arnstein's redistribution of power, IAP2 levels, and Fung's legitimacy criteria. Option A aligns with citizen power/empowerment and representativeness; other options illustrate tokenism, elite capture, or lack of representativeness.",
      "concepts_tested": [
        "Redistribution of power to include marginalized citizens (Arnstein’s citizen power vs tokenism/nonparticipation)",
        "Levels of participation and influence (IAP2 spectrum: information → empowerment) and how binding authority changes outcomes",
        "Representativeness and legitimacy (who participates, method of deliberation, and degree of authority granted)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a systems-contextual, lifespan-oriented practice with cultural sensitivity enhance the effectiveness of counseling psychology compared to approaches that focus only on the individual?",
      "options": {
        "A": "It treats distress as purely within the individual and ignores external influences, making treatment planning simpler.",
        "B": "It recognizes that individuals are embedded in interdependent systems (family, peers, work, institutions) and change over time, and that cultural meanings shape what is considered distress and what counts as helpful, enabling multi-level and developmentally appropriate interventions.",
        "C": "It relies on standardized, one-size-fits-all techniques that disregard cultural differences but accelerate service delivery.",
        "D": "It focuses exclusively on removing symptoms through crisis intervention, neglecting preventive and developmental aspects."
      },
      "correct_answer": "B",
      "source_article": "Counseling psychology",
      "x": 1.2174919843673706,
      "y": 0.9645670056343079,
      "concepts_tested": [
        "Concept 1: Systems-contextual, lifespan-oriented practice with cultural sensitivity",
        "Concept 2: Prevention and education as core aims of counseling psychology",
        "Concept 3: Generalist, broad-scope practice integrating multiple sub-disciplines under cohesive guidelines to improve well-being and functioning"
      ],
      "parent_concepts": [
        "Concept 1: The mechanism of career counseling — integrating topic-specific advice with counseling techniques to help clients make complex career decisions."
      ],
      "parent_articles": [
        "Career counseling"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is a systems‑contextual, lifespan‑oriented approach that is culturally sensitive more effective in counseling psychology than an approach that focuses only on the individual?",
      "options": {
        "A": "Because it treats problems as located solely within the individual and ignores social and cultural influences, which simplifies diagnosis and treatment planning.",
        "B": "Because it views people as embedded in interdependent systems (family, peers, work, institutions), recognizes development and change across the lifespan, and attends to cultural meanings of distress—enabling multilevel, developmentally appropriate interventions and emphasis on prevention and education.",
        "C": "Because it relies on standardized, one‑size‑fits‑all techniques that downplay cultural differences but speed up and standardize service delivery.",
        "D": "Because it concentrates exclusively on removing symptoms through crisis intervention, thereby neglecting preventive, educational, and developmental aspects of care."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified and shortened the stem and options, replaced verbose phrasing with concise academic terms (systems, lifespan, cultural meanings, prevention/education), while keeping the original distinctions between individual‑only and systemic, developmental, culturally informed approaches.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "A counseling psychologist working for a municipal health department designs a five‑year program for a culturally diverse immigrant community that includes: school‑based resilience workshops for adolescents, career‑planning and job‑readiness modules for adults, couples and family therapy, rehabilitation support for people with disabilities, culturally adapted outreach in multiple languages, liaison activities with schools and employers, and a train‑the‑trainer curriculum emphasizing prevention and measurement of outcomes. Which statement best captures why this program exemplifies the core principles of counseling psychology?",
      "options": {
        "A": "It uses a systems‑contextual, lifespan‑oriented approach that is culturally sensitive and prioritizes prevention and education while integrating a broad range of sub‑disciplines (career, family, rehabilitation, educational) under cohesive practice guidelines to improve well‑being and functioning.",
        "B": "It primarily treats severe mental disorders using psychiatric diagnosis and pharmacotherapy in an inpatient setting, relying on medical models rather than prevention or community education.",
        "C": "It focuses exclusively on vocational placement and job coaching as a narrow specialty intervention without addressing family, developmental, or cultural contexts.",
        "D": "It provides forensic evaluations to assess legal competency and concentrates on standardized clinical diagnostics intended for courtroom use rather than prevention or community liaison."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete community program vignette; created options contrasting counseling psychology's systems‑oriented, preventive, culturally sensitive, generalist scope with clinical/medical, narrow vocational, and forensic models.",
      "concepts_tested": [
        "systems‑contextual lifespan practice with cultural sensitivity",
        "prevention and education as central aims",
        "generalist broad‑scope practice integrating multiple sub‑disciplines"
      ]
    },
    "pass_2_reason": "readability_too_high_25.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does integrating local communities and governance structures into ecological restoration efforts often lead to more durable and successful outcomes than top-down designs alone?",
      "options": {
        "A": "It guarantees the use of the most advanced global techniques regardless of local context.",
        "B": "It leverages local ecological knowledge, aligns goals with community needs, and improves governance and enforcement, increasing legitimacy, relevance, and long-term maintenance.",
        "C": "It makes restoration faster by bypassing scientific assessment.",
        "D": "It ensures restoration targets exactly reproduce historical conditions regardless of current social and ecological constraints."
      },
      "correct_answer": "B",
      "source_article": "Ecological restoration",
      "x": 1.5143318176269531,
      "y": 0.9077156782150269,
      "concepts_tested": [
        "Concept 1: Restoration as a retroactive process distinct from preventative conservation, guiding how goals and methods differ from conservation efforts.",
        "Concept 2: Social-ecological restoration and stakeholder involvement, highlighting that local communities and governance influence restoration outcomes.",
        "Concept 3: Baselines and goal setting (historical baseline vs. current/ecosystem-function baselines) and how baseline choice shapes restoration strategies and expectations."
      ],
      "parent_concepts": [
        "Concept 1: Form-based restoration vs process-based restoration as distinct approaches with different aims and likely outcomes (immediate structural changes vs long-term ecological resilience through restoring natural processes).",
        "Concept 3: Evaluation and uncertainty in restoration outcomes, including the importance of monitoring and the potential time lag before benefits are realized."
      ],
      "parent_articles": [
        "Stream restoration",
        "Stream restoration"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does involving local communities and local governance in ecological restoration generally produce more durable and successful outcomes than purely top‑down designs?",
      "options": {
        "A": "It guarantees use of the latest global technical methods regardless of local ecological or social context.",
        "B": "It leverages local ecological knowledge, aligns goals with community priorities and realistic baselines, and strengthens local governance and enforcement, thereby increasing legitimacy, relevance, and long‑term maintenance.",
        "C": "It speeds up restoration by bypassing scientific assessment and stakeholder consultation.",
        "D": "It ensures restoration targets exactly reproduce historical baseline conditions regardless of current social and ecological constraints."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the question language for clarity; emphasized social‑ecological restoration and baseline/goal issues in the correct option; made distractors plausible misinterpretations (technical transfer, speed by skipping science, strict historical baselines).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized city seeks to address a heavily degraded estuarine site that was drained and channelized for industry in the 1950s. Current conditions include poor water quality, altered hydrology, dominance of invasive reedbeds, and ongoing flood risk to adjacent neighborhoods. Three planning teams propose different approaches:\n\nTeam A: Recreate the pre-1950 hydrology and species composition exactly as documented in historical maps and records, with minimal accommodation for current urban infrastructure.\n\nTeam B: Enact strict protection of the existing degraded channel to prevent further loss (no major interventions), and invest primarily in nearby upland conservation easements to prevent future habitat loss.\n\nTeam C: Convene a co-designed project with the local Indigenous community, municipal stormwater managers, and neighborhood groups to reconstruct wetland hydrology where feasible, prioritize restoration of key ecosystem functions (flood attenuation, water filtration, native habitat), incorporate Indigenous Traditional Ecological Knowledge (TEK), and set targets that account for current climate projections and urban constraints.\n\nTeam D: Carry out limited, high-intensity measures: apply herbicide and mechanical removal to eliminate invasive reeds in selected plots and plant aggressive native grasses at high density, without addressing the altered hydrology or engaging local stakeholders.\n\nWhich team’s proposal best exemplifies the principles of ecological restoration (distinct from conservation), uses a social-ecological restoration approach, and applies an appropriate baseline/goal-setting strategy given a transformed urban estuary?",
      "options": {
        "A": "Team A, because returning the system to the historical pre-1950 state represents the pure restoration goal of repairing past damage and therefore is the most faithful restoration approach.",
        "B": "Team B, because preventing further degradation through protection is the most practical way to conserve biodiversity and avoids the risks and costs of active intervention.",
        "C": "Team C, because it explicitly pursues retroactive ecosystem recovery (restoration rather than mere protection), integrates stakeholders and Indigenous TEK (social-ecological restoration), and sets functional, climate-aware targets rather than an inflexible historical baseline.",
        "D": "Team D, because rapid removal of invasives and dense native planting minimizes immediate ecological harm and is a cost-efficient restoration strategy even without hydrological reconstruction or broad stakeholder engagement."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a concrete urban estuary scenario contrasting conservation vs restoration, stakeholder-inclusive social-ecological restoration, and the choice between strict historical baselines and functional/climate-aware goals. Options present plausible but distinct strategies to test understanding of the three target concepts.",
      "concepts_tested": [
        "Restoration vs conservation (retroactive repair vs preventative protection)",
        "Social-ecological restoration and stakeholder/Indigenous involvement",
        "Baseline selection and pragmatic goal-setting (historical baseline vs functional/climate-adjusted targets)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a systems-based risk management approach that integrates hazard identification, hazard analysis, and control across the full life-cycle typically yield safer outcomes than a traditional condition-based safety strategy that focuses on controlling observed conditions after an incident occurs?",
      "options": {
        "A": "It concentrates safety resources on past accident data to predict future events.",
        "B": "It accounts for the interactions among components, human operators, procedures, and the environment, including interfaces, across design, production, operation, and maintenance, enabling preventive controls before failures happen.",
        "C": "It assumes safety is guaranteed once hardware reliability exceeds a threshold, ignoring human factors.",
        "D": "It delays hazard remediation until after deployment to test how the system behaves in real use."
      },
      "correct_answer": "B",
      "source_article": "System safety",
      "x": 1.4755674600601196,
      "y": 1.064045786857605,
      "concepts_tested": [
        "Concept 1: Systems-based risk management as an integrated, lifecycle-oriented approach that includes hazard identification, hazard analysis, and control, contrasting with traditional condition-based safety strategies.",
        "Concept 2: Synergy and interdependencies—how interactions among system parts and with the external environment affect safety, highlighting the importance of interfaces.",
        "Concept 3: Multidomain and lifecycle scope—system safety applies across hardware, software, human factors, procedures, and training, throughout the life-cycle of a system or product to prevent, eliminate, or control hazards."
      ],
      "parent_concepts": [
        "Concept 2: Safety and risk relationships — eliminating at-grade crossings reduces the likelihood and severity of collisions between vehicles, and between vehicles and trains/pedestrians."
      ],
      "parent_articles": [
        "Grade separation"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does a systems-based, lifecycle risk-management approach that integrates hazard identification, hazard analysis, and controls usually produce safer outcomes than a traditional condition-based strategy that reacts to observed conditions after an incident?",
      "options": {
        "A": "It focuses safety effort on analyzing past accident data and controlling conditions observed during prior incidents to anticipate future events.",
        "B": "It explicitly accounts for interactions among components, software, human operators, procedures and the environment (including interfaces) across design, production, operation and maintenance, enabling preventive controls before failures occur.",
        "C": "It treats safety as achieved once hardware reliability crosses a threshold and therefore neglects human and organizational factors.",
        "D": "It postpones remediation until after deployment to observe real-world behavior and then fixes hazards based on operational feedback."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was tightened and condensed; technical phrasing retained (e.g., 'lifecycle', 'hazard identification/analysis/controls'); distractors were kept plausible but made more concise. Core contrast between systems-based preventive approach and reactive condition-based strategy was preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.8_vs_16",
    "pass_2_attempt": {
      "question": "An aerospace company is developing an autonomous urban delivery drone composed of flight-control software, a lithium-ion battery pack, a package-release actuator, lidar obstacle sensing, and a remote operator interface. The drone will operate in dense urban corridors subject to wind gusts, multipath GPS errors, radio interference, and frequent pedestrian interactions. Which of the following safety-management plans best exemplifies a systems-based, lifecycle-oriented risk-management approach that accounts for synergy, interdependencies, and multidomain scope?",
      "options": {
        "A": "Perform a Functional Hazard Assessment (FHA) in the concept phase; run HAZOP and FMEA to identify hazards arising from interactions between hardware, software, procedures, human operators and the urban environment; define explicit interface and allocation requirements (including e.g. a target catastrophic-failure probability < $10^{-6}$ per flight-hour) and trace those safety requirements into design, verification, training, maintenance and end-of-life disposal; maintain system-level safety evidence and update analyses throughout the lifecycle.",
        "B": "Defer most safety work until after field incidents occur; use post-accident epidemiological investigations to identify hazardous conditions and then apply physical condition controls (barriers, signage) at locations where accidents happened; certify components individually but postpone system integration analysis until late testing.",
        "C": "Specify only high-reliability components (low $MTBF$) and perform extensive bench testing of batteries, motors and sensors; assume that exceptional component reliability will ensure system safety and limit further analysis to final acceptance testing of assembled units.",
        "D": "Require each subsystem vendor to certify its own safety without a coordinated system-level hazard analysis; collect interface documents from vendors but do not integrate or analyze cross-domain human–software–hardware interactions, leaving procedures and operator training to separate organizations."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed an autonomous drone scenario to contrast a full systems-based, lifecycle risk-management plan (A) with traditional reactive, component-focused, and siloed approaches (B–D). Included explicit lifecycle activities, interface management, multidomain analysis and a quantitative safety target to test understanding.",
      "concepts_tested": [
        "systems-based lifecycle risk management",
        "synergy and interdependencies (interfaces)",
        "multidomain scope: hardware, software, human factors, procedures, training"
      ]
    },
    "pass_2_reason": "readability_too_high_20.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why does ecocriticism borrow theories and methods from ecology and environmental history when analyzing a literary text, and what conceptual advantage does this interdisciplinary approach provide over a single-disciplinary reading?",
      "options": {
        "A": "It shifts attention away from literary meaning toward empirical ecological data, treating the text primarily as a natural science case study.",
        "B": "It enables the analyst to map narrative details onto ecological concepts (like systems, cycles, feedback) and place-based relations, so the text can reveal how human and nonhuman actors interact within environmental processes.",
        "C": "It requires judging the text solely by the accuracy of its ecological descriptions, minimizing cultural or aesthetic analysis.",
        "D": "It implies that environmental issues are purely technical problems fixable by science, removing ethical considerations from interpretation."
      },
      "correct_answer": "B",
      "source_article": "Ecocriticism",
      "x": 1.0869592428207397,
      "y": 0.9903122782707214,
      "concepts_tested": [
        "The core relationship studied: literature and the physical environment, and the idea that analyzing this relationship can illuminate environmental concerns.",
        "Interdisciplinary methodology: ecocriticism borrows theories and methods from ecology, environmental history, and related fields, applying them to literary analysis.",
        "Ethical/practical aim: recouping dignity for nature writing and engaging with environmentalist praxis, including exploring possible solutions to environmental issues and broadening the scope of texts studied."
      ],
      "parent_concepts": [
        "Concept 3: Ethical/restorative framing in the 1990s and the central role of climate-change discourse in guiding the goals and reception of environmental art."
      ],
      "parent_articles": [
        "Environmental art"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does ecocriticism draw on theories and methods from ecology and environmental history when interpreting a literary text, and what conceptual advantage does that interdisciplinary stance provide over a single-discipline reading?",
      "options": {
        "A": "It shifts interpretation away from literary meaning toward empirical ecological data, treating texts primarily as case studies for natural science rather than aesthetic or cultural objects.",
        "B": "It allows critics to map narrative features onto ecological concepts (for example, systems, cycles, feedbacks, and place-based relations), so the text can reveal how human and nonhuman agents interact within environmental processes.",
        "C": "It requires judging a work solely by the factual accuracy of its ecological descriptions, thereby downplaying cultural, ethical, or formal literary analysis.",
        "D": "It implies environmental problems are purely technical and solvable by science alone, which removes ethical and political dimensions from interpretation."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording condensed and clarified; historical and institutional details were removed; the interdisciplinary advantage was stated more directly (mapping narrative elements to ecological concepts). Options were kept plausible and the correct option letter preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.8_vs_16",
    "pass_2_attempt": {
      "question": "In a senior seminar, students read Marina López's novel Tide of Smoke, which follows a coastal community suffering from industrial contamination. One student proposes a research project that: (1) close-reads the novel's depictions of estuarine processes and species interactions, invoking the ecological concept of trophic cascades to interpret character behavior; (2) situates the text alongside archival materials on regional industrial policy and oral histories from affected communities; and (3) argues that the novel can be used in public pedagogy to support local remediation campaigns and to restore critical attention to contemporary nature writing. Which critical framework best describes this proposed project?",
      "options": {
        "A": "Ecocriticism — because it analyzes the relationship between literature and the physical environment, borrows ecological and historical methods, and advances environmentalist praxis.",
        "B": "New Historicism — because it places the novel in historical contexts and uses archival documents to read the text against the grain.",
        "C": "Ecopoetics — because it foregrounds the novel’s aesthetic and formal innovations in representing nature without making activist claims.",
        "D": "Environmental history — because it uses historical records and oral histories to reconstruct past environmental changes rather than interpreting literary form."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete classroom scenario requiring selection of the framework that integrates literary–environmental analysis, interdisciplinary borrowing (ecology, history), and activist/ethical aims—matching ecocriticism.",
      "concepts_tested": [
        "literature–environment relationship",
        "interdisciplinary methodology in ecocriticism",
        "ethical and practical commitments (environmentalist praxis)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a student-centered, inquiry-based art classroom (TAB) tend to cultivate a culture of initiative and exploration, and how does this mode of learning affect students' understanding of art?",
      "options": {
        "A": "It reduces feedback and replaces it with routine drill, leading to faster skill mastery.",
        "B": "It constrains students to a narrow set of outcomes defined by the teacher to ensure uniformity.",
        "C": "It aligns with intrinsic motivation by letting students choose meaningful projects and pose questions, making learning purposeful and enabling deeper sense-making through reflection.",
        "D": "It eliminates the need to discuss meaning, focusing solely on technical accuracy."
      },
      "correct_answer": "C",
      "source_article": "Visual arts education",
      "x": 1.0485087633132935,
      "y": 1.019032597541809,
      "concepts_tested": [
        "Concept 1: Student-centered and inquiry-based learning (as exemplified by TAB) shifts classroom culture and curricular emphasis toward student initiative and exploration.",
        "Concept 2: Contrast between discipline-based art education (DBAE) and alternative, meaning-focused approaches (imagination, interpretation, personal experience) and how they encode different aims (skills/criticism/history vs. meaning-making).",
        "Concept 3: The use of reflective questioning and emotional connections to foster deeper meaning and critical thinking about art (e.g., asking why the artist made certain choices)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a student-centered, inquiry-based art classroom (for example, Teaching for Artistic Behavior, TAB), why does this approach foster student initiative and exploration, and how does it affect students' understanding of art?",
      "options": {
        "A": "It reduces formative feedback and replaces guided practice with routine drills, producing faster technical mastery but limiting inquiry and exploration.",
        "B": "It constrains activity to teacher-defined outcomes and uniform projects to ensure consistent standards, which reduces student initiative.",
        "C": "It aligns with students' intrinsic motivation by allowing choice of meaningful projects and encouraging question-led investigation and reflection, making learning purposeful and promoting deeper understanding of artistic decisions.",
        "D": "It eliminates discussion of meaning and focuses solely on technical accuracy and measurable outcomes."
      },
      "correct_answer": "C",
      "simplification_notes": "Condensed the original wording, named TAB as the exemplar, emphasized student choice, intrinsic motivation, question-led investigation, and reflection; kept distractors that reflect teacher-centered, drill-focused, or technique-only alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.6_vs_16",
    "pass_2_attempt": {
      "question": "A university art instructor designs a three-day unit for an undergraduate studio course: Day 1 consists of instructor-led exercises in perspective drawing, demonstrations of glazing techniques, and a short lecture on the historical development of chiaroscuro; Day 2 is an open studio in which each student proposes a personal project, selects media, and the instructor acts as a consultant while students pursue their self-directed work; Day 3 begins with the instructor showing a contemporary painting, asking students “Why do you think the artist made this choice?”, soliciting initial interpretations, then providing biographical and cultural context before asking students to revise their readings and write a reflective response connecting the work to their own experiences. Which pairing of educational models best maps to Days 1–3 respectively?",
      "options": {
        "A": "Day 1: Discipline-Based Art Education (DBAE); Day 2: Teaching for Artistic Behavior (TAB); Day 3: Meaning-focused/interpretive (reflective questioning and emotional connection).",
        "B": "Day 1: TAB; Day 2: DBAE; Day 3: Studio-based technical practice without interpretive emphasis.",
        "C": "Day 1: Meaning-focused/interpretive; Day 2: DBAE; Day 3: TAB.",
        "D": "Day 1: Apprenticeship/Atelier method; Day 2: Behaviorist skills training; Day 3: Pure art appreciation with no student reflection."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete three-day classroom scenario mapping distinct pedagogical practices to DBAE (skills/history/criticism), TAB (student-centered choice-based studio), and reflective meaning-making (guided questioning and emotional connection). Distractors are plausible alternative mappings.",
      "concepts_tested": [
        "Discipline-Based Art Education (DBAE) characteristics",
        "Teaching for Artistic Behavior (TAB) and student-centered/inquiry-based learning",
        "Reflective questioning and emotional connection as meaning-focused art education"
      ]
    },
    "pass_2_reason": "readability_too_high_22.8_vs_16"
  },
  {
    "original_question": {
      "question": "How does the mechanism of decision-making in supranational versus intergovernmental regional integration affect member states’ sovereignty and the pace of policy harmonization, and why?",
      "options": {
        "A": "Supranational forms transfer binding decision-making authority to a central authority that can adopt and enforce common rules across all members, reducing national sovereignty and enabling faster, more uniform policy change; intergovernmental forms rely on negotiations among sovereign states, preserving sovereignty and requiring consensus, which slows or blocks rapid convergence.",
        "B": "Supranational forms keep sovereignty intact because central rules are only advisory; intergovernmental forms delegate all policy decisions to a central parliament, eroding sovereignty.",
        "C": "Supranational forms inherently slow policy harmonization due to centralized veto power; intergovernmental forms implement decisions automatically without domestic ratification, accelerating convergence.",
        "D": "Supranational forms coordinate only economic policy with non-binding guidelines; intergovernmental forms centralize all security and environmental policy under a single authority, which preserves national autonomy."
      },
      "correct_answer": "A",
      "source_article": "Regional integration",
      "x": 1.21376633644104,
      "y": 0.8770135045051575,
      "concepts_tested": [
        "Concept 1: Mechanisms and forms of regional integration (supranational vs intergovernmental) and how each influences decision-making sovereignty.",
        "Concept 2: The relationship between removing trade/mobility barriers and outcomes (economic prosperity, security, cohesive policy stance).",
        "Concept 3: The degree of integration depends on willingness to share sovereignty; deep integration vs shallow integration and the practical difficulties involved."
      ],
      "parent_concepts": [
        "Concept 2: International governance and regional cooperation (Barbados Programme, UN-OHRLLS, AOSIS, regional bodies) function as mechanisms to coordinate policy, advocate, and support SIDS’ sustainable development.",
        "Regional Trade Agreements (RTAs) as policy tools: their intended benefits (increased trade within a region) and drawbacks (potential unfairness, gridlock), and their potential to lead to larger, broader deals."
      ],
      "parent_articles": [
        "Small Island Developing States",
        "Commercial policy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do supranational and intergovernmental forms of regional integration differ in where decision-making authority is placed, and how does that difference affect member states’ sovereignty and the speed and uniformity of policy harmonization?",
      "options": {
        "A": "Supranational systems transfer binding decision-making power to a central authority that can adopt and enforce common rules across members, which reduces national sovereignty but enables faster, more uniform policy harmonization; intergovernmental systems keep decisions with sovereign states and rely on negotiated consensus, preserving sovereignty but slowing or blocking rapid convergence.",
        "B": "Supranational systems leave sovereignty largely intact because central rules are only advisory and non-binding; intergovernmental systems delegate most policy decisions to a central parliamentary body, which erodes sovereignty but speeds harmonization.",
        "C": "Supranational systems inherently slow harmonization because a central authority creates additional veto points and bureaucratic delay; intergovernmental systems automatically implement agreed rules without domestic ratification, so they achieve faster convergence.",
        "D": "Supranational systems are limited to coordinating economic policies through non-binding guidelines and therefore do not affect sovereignty; intergovernmental systems centralize security and environmental policy under a single agency, which paradoxically preserves national autonomy."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording condensed and clarified to explicitly ask where authority lies and the consequences for sovereignty and policy speed; technical terms (supranational/intergovernmental, consensus, binding enforcement) retained; distractors rewritten to be plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.7_vs_16",
    "pass_2_attempt": {
      "question": "Eight neighboring states in the fictional Caledonia region are drafting a regional integration agreement. They must choose between two institutional frameworks and parallel policy packages:\n\nProposal S (Supranational): establish a Commission empowered to adopt binding regulations by qualified majority, a regional court to enforce compliance, a customs union (common external tariff), full free movement of workers with mutual recognition of professional qualifications, and a binding regional environmental directive that harmonizes emission standards.\n\nProposal I (Intergovernmental): create a Council where decisions require unanimity and compliance is voluntary, implement staggered bilateral free-trade agreements that lower tariffs over time, permit temporary labor mobility via visas without mutual recognition of qualifications, and adopt a non-binding environmental declaration.\n\nWhich of the following best characterizes the most likely comparative outcomes of Proposal S versus Proposal I with respect to (1) the degree of sovereignty pooling and decision-making speed, (2) depth of economic integration and measured intra-regional trade growth, and (3) the ability to adopt and enforce cohesive regional policies (e.g., environmental standards and coordinated security/conflict-prevention measures)?",
      "options": {
        "A": "Proposal S will entail greater pooling of sovereignty and faster, majority-based decision-making, produce deeper economic integration with larger increases in intra-regional trade, and enable more cohesive and enforceable regional policies (including environmental harmonization and stronger collective security measures). Proposal I will preserve national sovereignty (veto power), yield shallower integration with smaller trade gains, and result in weaker, non-binding policy coordination.",
        "B": "Proposal S will have little effect beyond tariff alignment because tariff removal is the dominant driver of trade; Proposal I will produce deeper integration because unanimity and voluntary compliance generate stronger national ownership and therefore better implementation, leading to larger intra-regional trade and more cohesive policies than the supranational model.",
        "C": "Proposal S will increase intra-regional trade but simultaneously raise the likelihood of interstate tension and conflict because loss of sovereignty provokes domestic nationalist backlashes; Proposal I will reduce the risk of conflict by keeping decisions unanimous and protecting national prerogatives, even if economic integration proceeds more slowly.",
        "D": "Both proposals will produce equivalent economic outcomes in terms of intra-regional trade growth because tariff reduction alone determines trade flows; the institutional form only affects symbolic sovereignty arrangements and has no material effect on the capacity to implement cohesive regional policies or affect security dynamics."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a comparative scenario contrasting supranational vs intergovernmental institutions with concrete policy measures (customs union, labor mobility, enforcement mechanisms) to test effects on sovereignty pooling, depth of integration/intra-regional trade, and capacity for cohesive regional policy and security.",
      "concepts_tested": [
        "Mechanisms and forms of regional integration (supranational vs intergovernmental) and effects on sovereignty",
        "Relationship between removing trade/mobility barriers and outcomes (intra-regional trade, economic prosperity, security, cohesive policy stance)",
        "Degree of integration (deep vs shallow integration) and practical difficulties of harmonization and enforcement"
      ]
    },
    "pass_2_reason": "readability_too_high_24.7_vs_16"
  },
  {
    "original_question": {
      "question": "Why does devolution in the United Kingdom lead to multiple, nation-specific administrative layers rather than a single UK-wide system?",
      "options": {
        "A": "Because devolution created fully independent central governments for England, Scotland, Wales, and Northern Ireland, each controlling all policy areas within their borders.",
        "B": "Because devolution assigns different policy competences to Scotland, Wales, and Northern Ireland, creating distinct administrative jurisdictions, while reserved powers remain with the UK Parliament in Westminster.",
        "C": "Because all administrative powers are centralized in a single UK-wide authority that applies uniformly across the four nations.",
        "D": "Because the presence of separate legal systems automatically ensures a single administrative layer across the UK."
      },
      "correct_answer": "B",
      "source_article": "Administrative geography of the United Kingdom",
      "x": 0.8463658690452576,
      "y": 0.7456387877464294,
      "concepts_tested": [
        "Devolution creates multiple, nation-specific administrative layers rather than a single UK-wide system.",
        "The UK comprises distinct legal systems (England & Wales shared; Scotland and Northern Ireland separate), influencing administrative organization.",
        "Historical unions and reforms (Acts of Union 1707/1800; partition of Ireland) underpin current governance structures and the absence of a single unified administrative layer."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does devolution in the United Kingdom produce separate, nation-specific administrative layers instead of a single uniform UK-wide system?",
      "options": {
        "A": "Because devolution created fully independent central governments for England, Scotland, Wales, and Northern Ireland that control all policy areas within their borders.",
        "B": "Because devolution allocates different policy competences to Scotland, Wales, and Northern Ireland, creating distinct administrative jurisdictions, while certain reserved matters remain with the UK Parliament at Westminster.",
        "C": "Because all administrative powers are centralized in a single UK-wide authority that applies uniformly across the four nations.",
        "D": "Because the existence of separate legal systems by itself guarantees a single, unified administrative layer across the UK."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; emphasized 'devolved competences' and 'reserved matters' from the article; removed extended historical detail while keeping the core reason for nation-specific administrative layers.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "You have been commissioned to evaluate a policy proposal to create a single, statutory \"UK Regional Governance Tier\" that would sit above existing local authorities and coordinate healthcare delivery across the entire United Kingdom. Which combination of constitutional and administrative realities most accurately explains why implementing such a UK-wide, uniform tier would be legally and politically complex?",
      "options": {
        "A": "Because devolution has produced nation-specific administrative layers and competencies (e.g. Scotland's 32 council areas, Wales' 22 unitary authorities, Northern Ireland's 11 districts and England's mixed counties/combined authorities), because the UK contains distinct legal systems (England and Wales share one system while Scotland and Northern Ireland each have separate legal systems), and because the present asymmetric, uncodified constitutional settlement—shaped by the Acts of Union 1707 and 1800 and the partition of Ireland in 1922—means there is no single pre-existing UK administrative tier that can simply be overlaid without substantial legislative change and intergovernmental consent.",
        "B": "Because of the heterogeneous structure of local government (unitary authorities, counties, boroughs, parishes) and the existence of Crown Dependencies and overseas territories, while legal-system differences and the history of the unions are largely irrelevant to creating a UK-wide administrative tier.",
        "C": "Because England and Wales have separate legal systems that would resist harmonisation under a UK tier, whereas devolution creates only minor administrative variation and the historical Acts of Union do not affect present-day administrative design.",
        "D": "Because the UK lacks a single written constitution, Westminster can unilaterally impose a UK-wide administrative tier across all nations without regard to devolved competencies or distinct legal systems; the main difficulty is merely political opposition from local councils."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete policy scenario (UK-wide regional governance for health) requiring application of devolution asymmetry, distinct legal systems (E&W shared; Scotland and NI separate), and historical constitutional origins (Acts of Union, partition) to identify obstacles; distractors omit or misstate one or more core concepts.",
      "concepts_tested": [
        "Devolution and nation-specific administrative layers",
        "Distinct legal systems within the UK (England & Wales; Scotland; Northern Ireland)",
        "Historical unions and constitutional asymmetry (Acts of Union 1707/1800; partition 1922) and their impact on administrative unity"
      ]
    },
    "pass_2_reason": "readability_too_high_21.6_vs_16"
  },
  {
    "original_question": {
      "question": "How does the transition from packaged retail distribution to online/digital platforms reshape the economics of game development, and why does this shift tend to enable indie games and new monetization models?",
      "options": {
        "A": "By dramatically lowering upfront distribution costs and barriers, enabling global reach for small teams; combined with platform-enabled monetization (free-to-play, microtransactions, subscriptions) that rewards ongoing player engagement, this shift reduces financial risk and makes indie development economically viable.",
        "B": "By increasing discovery costs and gatekeeping, causing only well-funded franchises to reach audiences and thereby suppressing indie development.",
        "C": "By raising required upfront budgets to meet stricter platform certification, which paradoxically forces studios to consolidate into larger teams.",
        "D": "By eliminating monetization concerns entirely, so developers focus only on distribution channels without changing revenue strategies."
      },
      "correct_answer": "A",
      "source_article": "Video game",
      "x": 1.3781565427780151,
      "y": 1.249577283859253,
      "concepts_tested": [
        "Concept 1: Industry lifecycle and stabilization — how market crashes lead to lasting practices that shape development and distribution.",
        "Concept 2: Distribution/platform impact on development — how transitions (arcade/console/PC to online/mobile/digital/cloud) influence the rise of indie games and new monetization models.",
        "Concept 3: Global demographics and monetization — how regional markets and device proliferation shift player demographics toward casual gaming and new monetization approaches."
      ],
      "parent_concepts": [
        "Concept 1"
      ],
      "parent_articles": [
        "Interactive fiction"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How did the shift from packaged retail distribution to online/digital platforms change the economics of game development, and why does that shift tend to enable indie developers and new monetization models?",
      "options": {
        "A": "By greatly lowering upfront distribution costs and market-entry barriers, giving small teams global reach; together with platform-supported monetization (free-to-play, microtransactions, subscriptions) that rewards ongoing player engagement, this reduces financial risk and makes indie development economically viable.",
        "B": "By increasing discovery costs and platform gatekeeping, so that only well-funded franchises reliably reach large audiences, thereby suppressing indie development.",
        "C": "By raising required upfront budgets to meet stricter platform certification and quality expectations, which forces consolidation of studios into larger teams.",
        "D": "By eliminating monetization concerns entirely, so developers only need to select distribution channels without changing their revenue strategies."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording was shortened and made more direct; mechanisms were clarified (lower distribution costs, global reach, platform monetization models, reduced financial risk). Distractors were rephrased to remain plausible alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "Arcadia Interactive is a fictional game company whose strategic moves over four decades mirror shifts in the real video game industry: after a severe market crash in the early 1980s they accepted strict platform licensing and distribution controls for their console releases; in the 2000s they focused on high-budget 'AAA' console titles sold as physical products; after 2008 they began publishing small-team titles via digital storefronts; in the 2010s they launched free-to-play mobile games monetized with microtransactions aimed at casual players in Southeast Asia; and by 2020 they offered cloud-streamed versions of key titles through a subscription. Which single explanation below best links these decisions to the industry lifecycle, platform/distribution transitions, and global demographic/monetization trends described in the article?",
      "options": {
        "A": "These decisions reflect historical patterns: the 1983 crash led platform holders to impose licensing/quality controls (e.g., Nintendo’s post-crash practices) to stabilize the market; the Internet and digital storefronts lowered distribution barriers and enabled indie/small-team publishing alongside AAA; rapid mobile proliferation and growth in Asian markets shifted player demographics toward casual play, driving free-to-play and games-as-a-service monetization (microtransactions/gacha); and cloud streaming reduces local hardware requirements, enabling subscription-based distribution and broader reach.",
        "B": "The company’s choices demonstrate that the 1980s crash was solved by removing platform licensing, which encouraged many new hardware clones; indie games later rose because consoles became technically incapable of running modern titles, forcing developers to move to PCs and mobile devices; mobile monetization declined because casual players resist spending, so Arcadia’s microtransaction strategy would likely fail.",
        "C": "Arcadia’s evolution shows that digital distribution and app stores primarily favored large AAA publishers and effectively eliminated small-team indie development; the shift to mobile reduced overall monetization opportunities worldwide, so targeting Southeast Asia with free-to-play microtransactions is unlikely to increase revenues; cloud streaming mainly benefits single large studios rather than expanding market access.",
        "D": "The trajectory indicates that the 1983 crash permanently ended arcade and console markets in favor of PCs, so platform holders’ licensing was irrelevant; the indie boom was caused entirely by cloud gaming rather than digital storefronts; and Asian markets have historically preferred consoles and therefore would not be a primary source of casual mobile revenue."
      },
      "correct_answer": "A",
      "generation_notes": "Created a single applied scenario mapping Arcadia's multi-decade strategic choices to the article's claims: (1) crash → licensing/control (Nintendo), (2) internet/digital distribution → indie rise, (3) mobile/Asian market growth → casual demographics and new monetization, (4) cloud → lower hardware barrier and subscription models. Distractors present plausible but contradicted claims.",
      "concepts_tested": [
        "Industry lifecycle and stabilization after market crash (licensing and quality control)",
        "Impact of distribution and platform transitions on development (digital distribution enabling indie games, cloud gaming lowering hardware requirements)",
        "Global demographics and monetization shifts (mobile proliferation, Asian markets, casual gaming, games-as-service and microtransactions)"
      ]
    },
    "pass_2_reason": "readability_too_high_29.8_vs_16"
  },
  {
    "original_question": {
      "question": "How do interactivity and multimodality in electronic literature function as enabling features that shape its aesthetics and reader engagement, and why does this matter for how meaning is produced?",
      "options": {
        "A": "They enforce a fixed, print-like sequence, preserving traditional aesthetics and limiting reader involvement.",
        "B": "They shift agency to the reader, enabling non-linear exploration, choice-driven paths, and multimodal cues that let meaning emerge from interaction.",
        "C": "They serve primarily decorative purposes, adding images and sounds without affecting interpretation or engagement.",
        "D": "They require uniform hardware standards, making engagement uniform across readers."
      },
      "correct_answer": "B",
      "source_article": "Electronic literature",
      "x": 0.8306713104248047,
      "y": 1.149916410446167,
      "concepts_tested": [
        "Concept 1: Digital capabilities (interactivity, multimodality, algorithmic generation) as enabling features that shape the aesthetics and reader engagement of electronic literature.",
        "Concept 2: Born-digital nature and preservation challenges (obsolescence, lack of traditional publishing metadata like ISBN) driving archival infrastructures and scholarly study.",
        "Concept 3: Relationships with online communities and platforms (netprov, social media, Instapoetry, etc.) as drivers of genre formation and sustained practice in electronic literature."
      ],
      "parent_concepts": [
        "Concept 1"
      ],
      "parent_articles": [
        "Interactive fiction"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do interactivity and multimodality in electronic literature act as enabling features that alter its aesthetics and reader engagement, and why does this matter for how meaning is produced?",
      "options": {
        "A": "They impose a fixed, print-like sequence that preserves traditional literary aesthetics and reduces reader participation.",
        "B": "They shift agency toward the reader, enabling non-linear navigation, choice-driven paths, and multimodal cues (text, image, sound) so that meaning emerges through interaction and varied trajectories.",
        "C": "They are primarily decorative: images, animation, or sound enhance style but do not change interpretation or the reader’s engagement.",
        "D": "They demand uniform hardware and platform standards so all readers have the same experience, which determines a single intended meaning."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified question language for undergraduates, condensed wording, made technical terms explicit (non-linear navigation, multimodal cues), and kept answer choices plausible and concise. Removed ancillary historical detail to focus on how interactivity/multimodality affect aesthetics and meaning production.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.9_vs_16",
    "pass_2_attempt": {
      "question": "Your university library is developing an archival and critical-policy statement for three born-digital works: (1) City of Lexias — a 1997 hypertext published on CD-ROM using Storyspace where readers follow branching \"lexias\" by clicking links; (2) Night Tweets — a 2016 collaborative poetry project published on Twitter that depends on threaded replies, hashtags, and community remixing; (3) Auto‑Love 1952 — an early combinatory love‑letter generator originally executed on a Z22 whose original source code is lost but whose algorithmic outputs were documented. Which archival strategy and scholarly characterization best aligns with (a) how digital capabilities (interactivity, multimodality, algorithmic generation) shape aesthetics and reader engagement, (b) the preservation challenges of born‑digital works (software/hardware obsolescence and lack of traditional publishing metadata), and (c) the role of online platforms and communities in forming and sustaining new genres?",
      "options": {
        "A": "Adopt a multi‑pronged policy: for City of Lexias preserve a disk image and either emulate Storyspace or migrate its link architecture while documenting user paths and nonlinear reading experiences; for Night Tweets capture API‑level thread snapshots, hashtags, replies, and contributor metadata to preserve the social context and affordances that produce Instapoetry/netprov; for Auto‑Love 1952 reconstruct or reimplement the generator from documentation, archive many generated outputs and the combinatory rules. Scholarly statement: electronic literature’s aesthetics emerge from interactivity, multimodality and algorithms; born‑digital objects need emulation/migration and bespoke archives because they lack ISBNs and depend on specific platforms and communities to constitute genres.",
        "B": "Treat all three works like ordinary texts: convert City of Lexias and Auto‑Love outputs to a single printable PDF and save Night Tweets as a set of representative screenshots. Emphasize that preservation mainly requires a readable textual transcript; deemphasize emulation or platform capture. Scholarly statement: interactivity and platform context are secondary to the underlying text, so born‑digital issues are logistical rather than aesthetic.",
        "C": "Focus preservation on hardware: keep original CD‑ROM drives, a Z22 (or its spare parts), and active Twitter accounts archived by maintaining the accounts live. Do not capture community metadata. Scholarly statement: online communities are ephemeral and not central to genre formation; conserving the original machines is sufficient to preserve literary value.",
        "D": "Assign ISBNs and standard library catalog metadata to each work and store a descriptive record plus one exemplar file. For Night Tweets, saving only the canonical tweet texts is adequate. Scholarly statement: the main barrier is bibliographic discoverability; once cataloged like print books, these works are preserved regardless of interactivity or platform behavior."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete archival scenario with three representative works; options contrast correct preservation/emulation, community/context capture, and algorithmic reimplementation against plausible but incorrect simplifications (print conversion, hardware‑only, or bibliographic fixes).",
      "concepts_tested": [
        "Digital capabilities shaping aesthetics and reader engagement (interactivity, multimodality, algorithmic generation)",
        "Born‑digital preservation challenges (obsolescence, lack of ISBN/traditional metadata)",
        "Role of online platforms and communities in genre formation (netprov, Instapoetry, Twitterature)"
      ]
    },
    "pass_2_reason": "readability_too_high_34.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does translating a baseband signal to a higher passband via modulation enable effective frequency-division multiplexing (FDM) and practical transmission?",
      "options": {
        "A": "Because modulation shifts the baseband spectrum to distinct passbands at different center frequencies, allowing multiple channels to coexist without interference; the higher carrier frequency also enables smaller antennas and components, addressing physical size constraints.",
        "B": "Because shifting to a higher frequency inherently increases data integrity by making signals immune to all noise.",
        "C": "Because baseband and passband are interchangeable in wireless media, so no special purpose is needed.",
        "D": "Because converting to a higher frequency reduces the channel bandwidth, allowing more channels in the same spectrum."
      },
      "correct_answer": "A",
      "source_article": "Signal modulation",
      "x": 1.5721129179000854,
      "y": 1.075895071029663,
      "concepts_tested": [
        "Concept 1: Modulation encodes information by varying a carrier’s amplitude, frequency, or phase.",
        "Concept 2: The baseband vs passband distinction and the role of modulation in enabling transmission at higher frequencies and enabling multiplexing (FDM).",
        "Concept 3: Different modulation schemes (ASK, FSK, PSK, QAM) illustrate trade-offs between noise robustness, spectral efficiency, and data rate."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does modulating a baseband signal onto a higher-frequency carrier enable practical transmission and allow frequency-division multiplexing (FDM)?",
      "options": {
        "A": "Because modulation translates the baseband spectrum to distinct passbands centered at different carrier frequencies, so multiple channels can occupy separate frequency bands without mutual interference; also, using a higher carrier frequency reduces required antenna and component sizes, making transmission physically practical.",
        "B": "Because shifting a signal to a higher frequency inherently removes noise and interference, so data integrity is always improved at higher carriers.",
        "C": "Because baseband and passband behave identically in wireless media, so modulation is unnecessary for transmission or multiplexing.",
        "D": "Because converting signals to a higher carrier frequency reduces each channel's bandwidth, which lets more channels fit into the same spectrum."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording shortened and clarified for undergraduates; kept FDM and antenna-size reasons; distractors made concise but plausible misconceptions.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "An engineer must choose one digital modulation format from {ASK, FSK, PSK, QAM} for each of three links with these constraints:\n\nLink A: a battery-powered RFID-style sensor, extremely power-constrained, very short range, implementation simplicity prioritized over spectral efficiency.\nLink B: a cable-television distribution over a single coax carrying many TV channels via frequency-division multiplexing (FDM); maximizing channels per Hz (spectral efficiency) is critical.\nLink C: a satellite downlink that is power-limited and uses a non-linear high-power amplifier where constant-envelope/modulation resilience to amplifier nonlinearity is required.\n\nWhich assignment of modulation types (A, B, C) is most appropriate, and which explanation best justifies why the signals are shifted from baseband to a higher-frequency passband for Links B and C?",
      "options": {
        "A": "A = ASK; B = QAM; C = PSK — ASK suits simple, low-power RFID; QAM provides the high spectral efficiency needed to pack many FDM channels on coax; PSK (e.g., QPSK) has constant-envelope/power-efficient variants suitable through non-linear satellite amplifiers. Signals are upconverted from baseband to passband to put information onto higher-frequency carriers so the medium/antennas are practical and to enable FDM multiplexing of multiple channels.",
        "B": "A = FSK; B = QAM; C = PSK — FSK is placed on the sensor for its noise robustness; QAM for cable; PSK for satellite. Signals are upconverted primarily to reduce broadband thermal noise by moving to higher frequencies.",
        "C": "A = ASK; B = PSK; C = QAM — ASK for RFID; PSK for cable TV because of robustness; QAM for satellite to maximize data rate. Signals are upconverted so that switching-class amplifiers can be used efficiently.",
        "D": "A = FSK; B = ASK; C = PSK — FSK for sensors; ASK used on the cable to keep modulators simple; PSK for satellite. Upconversion is unnecessary because baseband signals can be multiplexed directly on the same medium."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete three-link design scenario that requires mapping modulation types to typical trade-offs (power/simple implementation vs spectral efficiency vs amplifier nonlinearity) and included the correct baseband→passband justification (practical carrier frequency and FDM).",
      "concepts_tested": [
        "Modulation encodes information by varying amplitude, frequency, or phase (ASK, FSK, PSK, QAM)",
        "Baseband versus passband distinction and why signals are upconverted (practical transmission, antenna/medium constraints, and FDM)",
        "Trade-offs among modulation schemes: noise robustness, spectral efficiency, data rate, and amplifier nonlinearity suitability"
      ]
    },
    "pass_2_reason": "readability_too_high_20.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the principle of maximum power efficiency in energetics predict that an ecosystem will adjust its internal energy-flow network until the environmental energy load matches its internal resistance, and what happens if the load exceeds the resistance?",
      "options": {
        "A": "Because this arrangement yields the maximum steady rate of useful energy transfer (power) given internal constraints; if the external load is higher than the internal resistance, the system cannot sustain the throughput and experiences excessive dissipation or destabilization, prompting reorganization.",
        "B": "Because it minimizes energy throughput to preserve system structure; if load > resistance, the system simply stores energy until reserves prevent further change.",
        "C": "Because it eliminates all energy exchange with the environment to maintain equilibrium; if load > resistance, the system becomes completely closed and ceases functioning.",
        "D": "Because it relies on random fluctuations to optimize energy capture; if load > resistance, nothing systematic changes and the system remains in the same state."
      },
      "correct_answer": "A",
      "source_article": "Systems ecology",
      "x": 1.5717077255249023,
      "y": 0.9804150462150574,
      "concepts_tested": [
        "Energetics as a unifying mechanism: applying energy flow principles to ecological systems, including the idea that energetics constitute ecosystem principles and the maximum power efficiency principle.",
        "Open-system boundaries and exchanges: using diagrams to define system boundaries, recognizing that ecological work deals with open rather than closed systems and that exchanges with the environment influence function.",
        "Emergence and cross-scale analogies: ecosystems exhibit emergent properties, and reasoning by formal analogy allows principles to operate across different system scales (e.g., via the Energy Systems Language)."
      ],
      "parent_concepts": [
        "Energy flow and the role of decomposers in trophic dynamics",
        "Concept 2: The relationship between ecosystem engineering and ecological outcomes (influence on species richness, resource availability, and how this differs from trophic effects associated with keystone species).",
        "Concept 1: Microbes interact with their environment and participate in biological/chemical pathways, shaping ecological processes."
      ],
      "parent_articles": [
        "Food web",
        "Ecosystem engineer",
        "Microbial ecology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to the systems-ecology principle of maximum power efficiency, why will an ecosystem reconfigure its internal energy-flow network until the external (environmental) energy load matches its internal resistance, and what happens if the external load exceeds that internal resistance?",
      "options": {
        "A": "Because matching load and internal resistance yields the maximum steady rate of useful energy transfer (power) given the system's constraints; if the external load exceeds internal resistance, the system cannot sustain the throughput, leading to excessive dissipation or destabilization and prompting reorganization.",
        "B": "Because this arrangement minimizes total energy throughput to protect the system's structure; if load > resistance, the system accumulates or stores energy until reserves buffer further change.",
        "C": "Because the ecosystem then eliminates energy exchange with the environment to maintain equilibrium; if load > resistance, the system becomes effectively closed and stops functioning.",
        "D": "Because the system relies on random fluctuations to find higher energy capture; if load > resistance, nothing systematic changes and the system stays in its prior state."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording shortened and clarified terms (external load, internal resistance, throughput, dissipation); kept the core energetic principle and outcome. Distractors rewritten to be plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_26.2_vs_16",
    "pass_2_attempt": {
      "question": "A coastal wetland is being modeled using a systems-ecology energetics analogy: solar input to the marsh is $2000\\ \\text{kJ/day}$, and internal ecosystem constraints (transport losses, metabolic inefficiencies, structural impedance) are represented by an internal resistance $R_i=50$ (arbitrary resistance units). Human activities (urban runoff, altered hydrology) change the environmental load $R_e$ on the system. Using the formal analogy to the electrical maximum-power-transfer principle employed in systems ecology, and taking into account the systems-ecology emphasis on open-system boundaries and emergent behavior, which of the following statements is most accurate?",
      "options": {
        "A": "Net usable power (ecosystem productivity) is maximized when $R_e=R_i$ (i.e. $R_e=50$); the wetland must be treated as an open system because material and energy fluxes (e.g., nutrient inflows) cross the system boundary; mismatches between $R_e$ and $R_i$ produced by increased runoff can move the ecosystem away from its sustainable steady state and produce emergent phenomena (e.g., hypoxia or algal blooms).",
        "B": "Productivity is maximized when environmental load is minimal ($R_e\\rightarrow0$), because less external load always increases usable energy; the wetland is effectively a closed system if its vegetation is self-contained, so external nutrient flows are irrelevant to system function.",
        "C": "Maximum productivity occurs when $R_e\\gg R_i$ because a large environmental load forces the ecosystem to process more energy; systems ecology treats only energy exchanges as open while material flows can be neglected without affecting emergent system properties.",
        "D": "Net productivity is independent of $R_e$ and depends only on the absolute solar input; ecosystems behave like closed systems for energetic calculations unless there is a physical break in the boundary, and emergent behaviors are simply the sum of individual organism processes."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete coastal-wetland scenario applying the maximum-power-transfer analogy ($R_e=R_i$), emphasized open-system boundaries (flux arrows) and emergent outcomes from load–resistance mismatches; distractors reflect common misconceptions about closed systems, neglect of material flows, and wrong extremal conditions.",
      "concepts_tested": [
        "Energetics as unifying mechanism and maximum-power principle",
        "Open-system boundaries and exchanges",
        "Emergence and cross-scale formal analogy (energy-systems analogy)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.7_vs_16"
  },
  {
    "original_question": {
      "question": "Why is it conceptually useful to decompose the total aerodynamic force on a flight vehicle into separate lift and drag components, and how does this decomposition illuminate why increasing wing aspect ratio reduces induced drag for a fixed lift?",
      "options": {
        "A": "Because lift and drag are produced by the same exact mechanism, separating them shows that any design change will affect both equally; higher aspect ratio increases induced drag.",
        "B": "Because lift relates to wing circulation and downwash while drag relates to energy lost to wake; increasing aspect ratio lowers downwash per unit lift, reducing induced drag for the same lift.",
        "C": "Because drag alone determines performance; lift does not constrain speed or range and can be ignored in optimization.",
        "D": "Because the decomposition proves that increasing angle of attack always decreases drag, so higher angles of attack are always more efficient."
      },
      "correct_answer": "B",
      "source_article": "Aerospace engineering",
      "x": 1.7443630695343018,
      "y": 0.8271856307983398,
      "concepts_tested": [
        "Concept 1: Multidisciplinary integration in aerospace engineering — how aerodynamics, propulsion, avionics, materials science, structural analysis, and manufacturing interact to achieve flight vehicle performance.",
        "Concept 2: Lift and drag as fundamental aerodynamic forces — the principle of separating and understanding these forces and their impact on aircraft performance, including historical development (Cayley’s separation of lift and drag).",
        "Concept 3: Expansion from aeronautical to aerospace engineering — how inclusion of spaceflight broadens scope, implies different design/testing requirements, and necessitates teamwork across specialized domains."
      ],
      "parent_concepts": [
        "The relationship between attitude (roll, pitch, yaw) and aerodynamic forces (lift, drag) via angle of attack and bank, including how pitching up or down changes lift.",
        "Concept 3: Expendable vs reusable launch vehicles (and partial reuse) as a relationship-driven design consideration; why reusability changes cost, engineering constraints, and recovery strategies.",
        "Concept 3: Design mechanisms that enable performance improvements across flight phases (adaptive compliant wings, variable-sweep wings)"
      ],
      "parent_articles": [
        "Flight dynamics",
        "Launch vehicle",
        "Aircraft performance"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is it useful to decompose the total aerodynamic force on a vehicle into lift and drag, and how does that decomposition explain why increasing wing aspect ratio reduces induced drag for a fixed required lift?",
      "options": {
        "A": "Because lift and drag arise from the exact same local pressure distribution mechanism, so separating them is arbitrary; any design change affects both equally, and a higher aspect ratio therefore increases induced drag.",
        "B": "Because lift is linked to wing circulation and the downwash induced by that circulation, while drag (especially induced drag) represents energy lost into the wake; a higher aspect ratio produces less downwash (less vortex strength) per unit lift, so induced drag falls for the same lift.",
        "C": "Because only drag determines aircraft performance so lift can be ignored in optimization; decomposing forces is unnecessary since lift does not constrain speed or range.",
        "D": "Because decomposing forces shows that increasing angle of attack always reduces drag, implying that flying at higher angles of attack is always more efficient and therefore reduces induced drag."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and focused on key concepts; preserved technical terms (circulation, downwash, induced drag, aspect ratio). Distractors rewritten to be plausible but incorrect. Correct answer letter unchanged.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.8_vs_16",
    "pass_2_attempt": {
      "question": "A startup plans a reusable, runway-launched vehicle that accelerates to Mach 3 in the atmosphere, transitions to rocket propulsion to reach a 100 km suborbital apogee, then returns and lands on a runway. Which of the following integrated design strategies best reflects correct application of multidisciplinary aerospace engineering (aerodynamics, propulsion, materials, avionics, and testing), an understanding of lift and drag (as separate quantities governed by $L=\\tfrac{1}{2}\\rho V^2 S C_L$ and $D=\\tfrac{1}{2}\\rho V^2 S C_D$), and the expanded requirements introduced by adding spaceflight capability?",
      "options": {
        "A": "Adopt a combined-cycle propulsion (air-breathing turbo/ramjet for takeoff and Mach 3 cruise, then rocket for exoatmospheric ascent); use a low-aspect-ratio delta wing with high-lift devices for takeoff/landing and high-temperature leading edges for supersonic flight; select titanium alloys and ceramic-matrix composites plus an active thermal protection system; implement distinct atmospheric and orbital flight-control laws in avionics with seamless mode transition; validate with CFD, subsonic and supersonic wind-tunnel testing, thermal-vacuum and structural tests, and progressive flight-test campaigns. Explicitly size wing area S using $L=\\tfrac{1}{2}\\rho V^2 S C_L$ for takeoff and ensure low $C_D$ shape for ascent/heating considerations.",
        "B": "Use a high-bypass turbofan optimized for takeoff and cruise, then ignite a small rocket for the final ascent; equip a large high-aspect-ratio wing to reduce subsonic fuel burn; build primarily with conventional aluminum-lithium alloys to save cost; rely mainly on CFD and prototype flight tests (minimal wind-tunnel work); implement a single unified flight-control law. This minimizes program cost by avoiding specialized materials and exhaustive ground testing.",
        "C": "Design as a pure-rocket vehicle with stub wings sized only for landing (small wing area), use aluminum primary structure with passive ceramic tiles for re-entry, and implement flight-control based on ascent telemetry only; perform mostly full-scale flight testing to validate aerodynamics and handling. This concentrates development on propulsion while treating lift/drag as secondary since the rocket provides nearly all energy.",
        "D": "Choose a variable-sweep heavy wing to satisfy both low-speed and high-speed needs, powered by separate turbofans for takeoff and a single large conventional liquid-rocket engine for ascent; construct primary structure from standard carbon-fiber composites without specialized high-temperature materials; develop one flight-control law tuned by software updates during flight tests; rely on wind-tunnel testing only for low-speed aerodynamics and skip thermal-vacuum testing to save schedule time."
      },
      "correct_answer": "A",
      "generation_notes": "Created a runway-launched suborbital vehicle scenario requiring tradeoffs among aerodynamics (lift/drag equations), propulsion (combined-cycle + rocket), materials/thermal protection, avionics mode transitions, and a comprehensive test program; options present plausible but differentiated multidisciplinary strategies.",
      "concepts_tested": [
        "Multidisciplinary integration of aerodynamics, propulsion, materials, avionics, and testing",
        "Lift and drag as separate aerodynamic forces and their role in sizing and shaping wings",
        "Expansion from aeronautical to aerospace engineering: added thermal, vacuum, propulsion and avionics requirements for spaceflight"
      ]
    },
    "pass_2_reason": "readability_too_high_23.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does labeling non-Western music as \"world music\" function more as a marketing/classificatory device than a neutral descriptor, and what mechanism explains its impact on how artists produce music and how audiences perceive it?",
      "options": {
        "A": "Because industry gatekeepers define it to fit Western distribution channels, promoting exoticized or fusion sounds to reach global markets, which can standardize and reshape traditional identities.",
        "B": "Because it is a neutral descriptor that accurately encompasses all non-Western music without influencing production or audience perception.",
        "C": "Because its primary effect is to permanently separate \"world music\" from Western pop, ensuring pure traditional forms are preserved.",
        "D": "Because artists independently decide to present their music as \"world music\" solely to access funding, with no industry influence on marketing or reception."
      },
      "correct_answer": "A",
      "source_article": "World music",
      "x": 0.19537071883678436,
      "y": 1.5414490699768066,
      "concepts_tested": [
        "Concept 1: World music as a marketing/classificatory category shaped by industry forces and definitions",
        "Concept 2: Globalization and technology as mechanisms enabling cross-cultural exchange and crossover, with potential for both fusion and homogenization",
        "Concept 3: Tension between commercialization/promotion of world music and the preservation of traditional/local musical identities"
      ],
      "parent_concepts": [
        "Synthesis of diverse roots (blues, ragtime, European harmony, African rhythms, spirituals, marches) and how cross-cultural influences generate regional styles and stylistic evolution",
        "Concept 2: Cross-cultural synthesis as the origin of Qawwali (Amir Khusrow blending Persian, Arabic, Turkic, and Indian musical traditions) and how this fusion defines the form.",
        "Concept 3: The link between devotional origins and modern global exposure (from Sufi shrines and mehfil-e-sama to international stages and media promotion) and how context influences reach and audience."
      ],
      "parent_articles": [
        "Jazz",
        "Qawwali",
        "Qawwali"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is the label \"world music\" better understood as an industry marketing/classification strategy than a neutral descriptive term, and what mechanism explains how that labeling changes artists' production choices and audience perception?",
      "options": {
        "A": "Because record labels, distributors and media gatekeepers shape the category to fit Western distribution channels and consumer tastes, promoting exoticized or fusion sounds to sell internationally; this commercial framing tends to standardize and reshape traditional local identities.",
        "B": "Because \"world music\" is a neutral descriptor that accurately covers all non‑Western musical traditions and therefore has no systematic effect on how music is produced or heard.",
        "C": "Because its main effect is to segregate non‑Western music from Western pop and thereby protect and permanently preserve pure traditional forms from commercial influence.",
        "D": "Because artists alone decide to label their work \"world music\" only to obtain funding or niche audiences, and industry actors have no significant role in marketing or shaping reception."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording was shortened and clarified for undergraduate readers; emphasized industry gatekeepers and the mechanism (commercial framing leading to exoticization/fusion and standardization). All options kept plausible contrasts; correct answer unchanged.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.2_vs_16",
    "pass_2_attempt": {
      "question": "An independent British label in 1992 creates a curated series called \"World Fusion\": it packages field recordings of West African griots, North Indian raga performances, and Irish fiddling; commissions cross-genre remixes with Western pop producers; negotiates exclusive distribution in the UK and US; and publishes a chart and promotional leaflets aimed at mainstream radio. Based on the article's discussion of \"world music,\" which of the following outcomes best captures the likely combination of commercial, cultural, and technological effects?",
      "options": {
        "A": "The series will function mainly as an academic archive: museums and ethnomusicologists will treat the releases as definitive, and the marketed product will have negligible impact on the economic returns or on the everyday musical practices of the source communities.",
        "B": "The series will enable creative crossovers (fusion, remixes, new hybrid genres) through global circulation and recording technology, but because the label controls marketing, distribution, and copyright terms, visibility and profits will be concentrated with the label and mainstream markets—raising risks of stylistic homogenization and the marginalization or commodification of some local traditions.",
        "C": "The presence of recordings and travel will immediately and uniformly displace local traditions: within a few years the distinct regional practices will vanish as global pop styles fully replace them due to superior production values.",
        "D": "Mainstream audiences will refuse to engage with any marketed non-Western music, so the label's campaign will fail; cross-cultural exchange will therefore remain limited to in-person immigrant communities and not be affected by recording or distribution technologies."
      },
      "correct_answer": "B",
      "generation_notes": "Designed a concrete industry scenario that requires applying article concepts: industry-created marketing categories, technological facilitation of crossover, and commercialization vs. preservation tensions; options include plausible but incorrect extremes to test critical synthesis.",
      "concepts_tested": [
        "Industry shaping of world music as a marketing/classificatory category",
        "Role of technology and globalization in enabling cross-cultural exchange and potential homogenization",
        "Tension between commercialization (profits, copyright) and preservation of traditional/local musical identities"
      ]
    },
    "pass_2_reason": "readability_too_high_22.2_vs_16"
  },
  {
    "original_question": {
      "question": "In the framework of psychological egoism, which explanation most plausibly reconciles a costly helping act with the claim that all actions are ultimately self-interested?",
      "options": {
        "A": "The actor is driven by genuine concern for others, with no personal gain.",
        "B": "The actor is unaware of any self-benefit, identifying as morally ideal.",
        "C": "The actor derives an intrinsic benefit, such as personal satisfaction, guilt relief, or a sense of meaning, from helping.",
        "D": "The actor expects the action to be morally rewarding to others, which in turn benefits the actor socially."
      },
      "correct_answer": "C",
      "source_article": "Altruism",
      "x": 1.2485781908035278,
      "y": 1.0131746530532837,
      "concepts_tested": [
        "Concept 1: Altruism as a principle/definition — acting to benefit others or welfare independent of personal gain, with scope including non-human beings and future generations.",
        "Concept 2: Mechanisms and causes — altruistic actions involve costs to the actor and benefits to others, and may occur without reciprocity; psychological egoism offers a competing explanation that apparent altruism may be motivated by intrinsic self-benefit.",
        "Concept 3: Theoretical relationships — altruism can be framed as a deontological obligation or as a practical framework (effective altruism) that emphasizes evidence-based ways to maximize impact, contrasted with egoism."
      ],
      "parent_concepts": [
        "Concept 1: Volunteering as a voluntary, freely chosen act (principle of voluntariness and intrinsic motivation)",
        "Concept 1: Reciprocity and altruistic punishment as mechanisms that sustain cooperation within groups (direct/indirect reciprocity and costly punishment promote cooperative behavior)."
      ],
      "parent_articles": [
        "Volunteering",
        "Cooperation"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to psychological egoism (the view that all actions are ultimately self-interested), which explanation best reconciles a costly helping act with the claim that the act is still motivated by self-interest?",
      "options": {
        "A": "The actor is motivated by genuine concern for others and receives no benefit whatsoever.",
        "B": "The actor is unaware of any self-benefit and sincerely regards themselves as morally ideal.",
        "C": "The actor obtains an intrinsic benefit from helping (e.g., personal satisfaction, relief from guilt, or a sense of meaning).",
        "D": "The actor expects social rewards — for example, reciprocity, approval, or enhanced reputation from others — that will benefit them later."
      },
      "correct_answer": "C",
      "simplification_notes": "Clarified psychological egoism in the stem; shortened and made each option concise and distinct; emphasized intrinsic vs. social rewards to keep options plausible while preserving the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.7_vs_16",
    "pass_2_attempt": {
      "question": "Which of the following statements most accurately synthesizes the article's account of altruism, its biological characterization, and how competing explanations and normative frameworks relate to it?",
      "options": {
        "A": "Altruism is concern for the welfare of others expressed in actions that can extend to non-human beings and future generations; in biological terms it denotes behavior that benefits another while imposing a cost on the actor (e.g., reduced survival or reproductive prospects) and can occur without expectation of reciprocity; psychological egoism challenges the possibility of \"pure\" altruism by claiming apparent altruistic acts may yield intrinsic rewards for the actor (so the dispute hinges on whether such internal rewards count as benefits); normatively, altruism can be defended as a deontological obligation to benefit others, while effective altruism is a consequentialist-style approach that uses evidence and reason to prioritise actions that maximise benefit.",
        "B": "Altruism always requires self-harm or physical injury to the actor and therefore is rare in both human and non-human populations; psychological egoism is therefore irrelevant because altruism by definition cannot provide any reward to the actor; effective altruism rejects normative duties and instead argues altruism should be abandoned if it reduces the actor's wellbeing.",
        "C": "Altruism is best understood as any helping behaviour that improves others' welfare; because such acts inevitably produce personal feelings of satisfaction, psychological egoism conclusively shows that genuine altruism does not exist; biological accounts therefore mislabel cooperative strategies and altruism should be eliminated from moral theory in favour of rational egoism.",
        "D": "Altruism is strictly a religious or moral doctrine obliging people to sacrifice for others; biologically, actions labelled altruistic are simply mistakes or miscalculations that lower an individual's fitness; effective altruism is identical to deontological altruism because both prioritise duty over measurable outcomes."
      },
      "correct_answer": "A",
      "generation_notes": "Created a synthesis-style multiple-choice item combining definitional, biological, psychological, and normative (deontological vs effective altruism) aspects; distractors contain common misconceptions from the article.",
      "concepts_tested": [
        "Definition and scope of altruism (welfare of others, including non-humans and future generations)",
        "Biological mechanism and cost-benefit structure of altruistic acts and the psychological egoism challenge",
        "Normative frameworks: deontological altruism vs effective altruism (evidence-based prioritization)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.9_vs_16"
  },
  {
    "original_question": {
      "question": "How does the sequential process of information sharing → consultation → negotiation/conclusion → collective bargaining contribute to the legitimacy and effectiveness of social dialogue?",
      "options": {
        "A": "It enables participants to form quick, unilateral decisions without needing to discuss positions.",
        "B": "It builds mutual understanding and transparency through information sharing, enables informed exchange in consultation, yields legitimate and binding agreements in negotiation/conclusion, and implements these through collective bargaining.",
        "C": "It guarantees that only government authorities can decide outcomes after a brief consultation, making the process more efficient.",
        "D": "It replaces the need for independent organizations by centralizing all information within the government."
      },
      "correct_answer": "B",
      "source_article": "Social dialogue",
      "x": 1.244376540184021,
      "y": 0.8774164915084839,
      "concepts_tested": [
        "Concept 1: Bipartite vs. tripartite social dialogue as relational forms and their roles in influencing work-related policies.",
        "Concept 2: Enabling conditions (freedom of association, independent organizations, political will, institutional support) and why each is necessary for effective dialogue.",
        "Concept 3: Means/Processes (information sharing → consultation → negotiation/conclusion → collective bargaining) and how each step contributes to policy outcomes and social dialogue success."
      ],
      "parent_concepts": [
        "The distinction between collective and individual labour law (how rights are mediated through unions/collective action versus individual contracts).",
        "The mechanisms the labor movement uses (collective bargaining, sectoral bargaining, strikes, co-determination) to secure workers' interests."
      ],
      "parent_articles": [
        "Labour law",
        "Labour movement"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the sequence information sharing → consultation → negotiation/conclusion → collective bargaining enhance the legitimacy and effectiveness of social dialogue?",
      "options": {
        "A": "It enables participants to make quick, unilateral decisions without fully discussing their positions, speeding up outcomes.",
        "B": "It builds transparency and mutual understanding through information sharing, enables an informed exchange of views in consultation, produces legitimate and binding agreements in negotiation/conclusion, and implements and enforces them through collective bargaining.",
        "C": "It ensures that government authorities make final decisions after a brief consultation, which increases efficiency by centralizing authority.",
        "D": "It removes the need for strong independent worker and employer organizations by centralizing information and decision-making within the government."
      },
      "correct_answer": "B",
      "simplification_notes": "Question phrasing was shortened and clarified; the sequential steps were kept explicit; options were rewritten to be concise and plausible while preserving the original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.9_vs_16",
    "pass_2_attempt": {
      "question": "The Republic of Lumeria has convened a National Labour Forum composed of the Ministry of Labour, the Confederation of Employers, and two newly created workers' associations that lack formal legal recognition. The parties exchange labour-market statistics and hold several consultative meetings, but the government insists the Forum be purely advisory and the workers' associations are not authorized to sign legally binding agreements on behalf of workers. Which of the following best characterizes (1) the relational form of social dialogue in Lumeria, (2) the single most critical enabling condition that is missing given the facts, and (3) the specific step in the sequence of means/processes of social dialogue that is directly blocked and therefore prevents enforceable policy outcomes?",
      "options": {
        "A": "Tripartite; the fundamental right to freedom of association and collective bargaining is missing because worker associations are not legally recognized; the blocked step is negotiation/conclusion of binding conventions (and thus collective bargaining).",
        "B": "Bipartite; what is missing are strong, independent organizations with technical capacity because the worker groups are new; the blocked step is information sharing, since reliable data exchange is therefore undermined.",
        "C": "Tripartite; the missing element is political will on the part of social partners because the government treats the forum as advisory; the blocked step is consultation, because parties refuse to engage in substantive dialogue.",
        "D": "Tripartite; the missing enabling condition is appropriate institutional support (no formal procedures exist); the blocked step is collective bargaining, but only because institutions to register agreements are absent rather than because of rights restrictions."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete country vignette to require distinguishing bipartite vs. tripartite, identifying the specific enabling condition (freedom of association/collective bargaining) and mapping which process step (negotiation/binding convention → collective bargaining) is obstructed.",
      "concepts_tested": [
        "Bipartite vs. tripartite social dialogue",
        "Enabling conditions for effective social dialogue (freedom of association, organizational independence, political will, institutional support)",
        "Means/process sequence in social dialogue (information sharing → consultation → negotiation/conclusion → collective bargaining) and how blockage at one step prevents enforceable outcomes"
      ]
    },
    "pass_2_reason": "readability_too_high_22.0_vs_16"
  },
  {
    "original_question": {
      "question": "In the view of intelligence as the capacity to adapt to the environment through perception/inference, knowledge use, and problem-solving (adaptive behavior), why might a person perform very well on one set of tasks in a familiar setting but poorly on another set of tasks in a different setting, even though their underlying abilities are stable?",
      "options": {
        "A": "Because the underlying capacity is unitary and yields consistent performance across all contexts if measured accurately.",
        "B": "Because adaptive behavior depends on how well the current environmental cues map onto the appropriate perception-inference, knowledge, and problem-solving strategies; different settings demand different strategy uses, leading to variable performance.",
        "C": "Because all performance variation is due to measurement error and test reliability issues.",
        "D": "Because knowledge use is universal and determines all outcomes; if performance differs, it's due to changes in knowledge content alone."
      },
      "correct_answer": "B",
      "source_article": "Intelligence",
      "x": 1.278847336769104,
      "y": 1.0274244546890259,
      "concepts_tested": [
        "Concept 1: Intelligence as a multi-domain construct (competencies) rather than a single, unitary ability.",
        "Concept 2: Intelligence as the capacity to adapt to environment through perception/inference, knowledge use, and problem-solving (adaptive behavior).",
        "Concept 3: Variability and measurement of intelligence across occasions and domains, and the role of criteria in judging intellectual performance."
      ],
      "parent_concepts": [
        "Acceleration modalities (whole-grade skipping, telescoping, partial/subject acceleration) and the placement criteria (IQ vs. achievement testing) that guide them, along with the academic and social implications.",
        "Concept 2: The distinction and relationship between security intelligence (domestic threats) and foreign intelligence (information on foreign states) and how this separation shapes priorities and operations."
      ],
      "parent_articles": [
        "Gifted education",
        "Intelligence agency"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If intelligence is defined as the capacity to perceive or infer information, retain and use knowledge, and solve problems to adapt to an environment, why might someone do very well on one set of tasks in a familiar context but perform poorly on different tasks in a new context even though their underlying cognitive abilities remain stable?",
      "options": {
        "A": "Because intelligence is a single, unitary capacity that should produce consistent performance across contexts if tests are properly designed.",
        "B": "Because adaptive performance depends on how well the current environmental cues map onto the appropriate perception–inference processes, stored knowledge, and problem-solving strategies; different contexts require different strategy uses, producing variable outcomes.",
        "C": "Because all observed performance differences are attributable to measurement error or low test reliability rather than real differences in adaptive behaviour.",
        "D": "Because differences in performance reflect only variation in knowledge content; if someone does worse, it is solely because they lack the specific knowledge for that context."
      },
      "correct_answer": "B",
      "simplification_notes": "Rewrote the stem to be more concise and academic while keeping the definition of intelligence (perception/inference, knowledge use, problem-solving). Removed extraneous historical detail and preserved the core explanatory choices. Options were phrased to remain plausible and distinct.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_26.7_vs_16",
    "pass_2_attempt": {
      "question": "A university research team studies three professionals: (1) Maya, a theoretical physicist who consistently scores very highly on standardized IQ tests and solves abstract problems; (2) Jamal, a paramedic who quickly perceives changing cues at accident scenes and improvises lifesaving procedures; and (3) Ana, a community organizer who reads social motives and negotiates resource-sharing among competing groups. On different days the same individuals show variable performance: Maya performs poorly on an unfamiliar social negotiation task, Jamal scores below Maya on a written analytic test, and Ana’s performance fluctuates across stressful field contexts. Which conclusion best synthesizes this pattern in light of contemporary psychological accounts of intelligence?",
      "options": {
        "A": "Intelligence is a single, unitary ability (the g factor) that a standardized IQ test fully captures; therefore Maya’s consistently high IQ implies she is the most intelligent across all tasks, and momentary fluctuations are measurement error.",
        "B": "Intelligence is a multidimensional set of competencies; it fundamentally involves perceiving/infering information, retaining and using knowledge for adaptive behaviour in specific environments, and an individual’s measured performance will vary across occasions, domains, and judging criteria.",
        "C": "Intelligence is essentially equivalent to learning and knowledge retention (being ‘book smart’); differences among Maya, Jamal, and Ana reflect differences in acquired factual knowledge rather than distinct cognitive competencies or adaptive capacities.",
        "D": "Intelligence primarily consists of social and emotional understanding, so Ana’s abilities in reading motives and negotiating are the core of intelligence while abstract reasoning and procedural improvisation are peripheral skills."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete three-person vignette mapping abilities (abstract reasoning, situational improvisation, social cognition) to test recognition that intelligence is multi-domain, linked to adaptive perception/inference and knowledge use, and that performance varies by domain/occasion and assessment criteria.",
      "concepts_tested": [
        "Intelligence as a multi-domain construct (competencies)",
        "Intelligence as adaptive capacity involving perception/inference and knowledge use",
        "Variability of measured intelligence across occasions, domains, and criteria"
      ]
    },
    "pass_2_reason": "readability_too_high_22.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does a holistic, multi-factor model of child protection, which considers social, economic, cultural, psychological, and environmental factors, tend to be more effective at preventing harm than approaches that focus only on the individual child or a single incident?",
      "options": {
        "A": "Because it helps identify and address underlying risk and protective factors across domains, enabling coordinated interventions across sectors that strengthen families and environments, reducing recurrence.",
        "B": "Because it shifts blame to communities and reduces accountability of state actors.",
        "C": "Because it reduces assessment to a single factor, making interventions simpler and faster.",
        "D": "Because it prioritizes medical treatment over social support."
      },
      "correct_answer": "A",
      "source_article": "Child protection",
      "x": 1.2019085884094238,
      "y": 0.8635296821594238,
      "concepts_tested": [
        "Holistic, multi-factor model of risk and protection (considers social, economic, cultural, psychological, and environmental factors)",
        "Multi-agency child protection systems with coordination and referral mechanisms (laws, policies, services across sectors, responsibilities shared across actors)",
        "Prevention-focused, rights-based approach (aims to strengthen families, reduce risk of separation/violence/exploitation, aligns with UNCRC and SDGs)"
      ],
      "parent_concepts": [
        "The relationship between caregiver actions and child welfare outcomes, and how mandatory reporting, definitions, and jurisdictional differences mediate protection/removal/prosecution."
      ],
      "parent_articles": [
        "Child abuse"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is a holistic, multi-factor child protection model—one that considers social, economic, cultural, psychological, and environmental factors—generally more effective at preventing harm than approaches that focus only on the individual child or a single incident?",
      "options": {
        "A": "Because it identifies and addresses underlying risk and protective factors across domains, enabling coordinated, multi‑sector interventions that strengthen families and environments and reduce recurrence.",
        "B": "Because it shifts responsibility away from state agencies and places the onus on communities, reducing formal accountability for failures in protection.",
        "C": "Because it simplifies assessment to a single causal factor, making interventions quicker and administratively easier to deliver.",
        "D": "Because it emphasizes medical treatment and clinical responses over social, economic, and community-based supports."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording shortened and clarified; retained key idea of multi-factor, multi-sector prevention and family/environment strengthening; distractors rewritten to be plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_25.0_vs_16",
    "pass_2_attempt": {
      "question": "Municipality X reports rising child labour, increasing school dropout, households affected by HIV/AIDS, and entrenched social norms that tolerate corporal punishment. As an advisor asked to design a child protection response that reflects (1) a holistic, multi‑factor model of risk and protection, (2) a coordinated multi‑agency child protection system with formal referral mechanisms, and (3) a prevention‑focused, rights‑based approach consistent with the UNCRC and the SDGs, which of the following proposals best matches those principles?",
      "options": {
        "A": "Pass a strengthened child protection law that centralizes authority in a single child welfare agency with expanded powers to investigate and remove children into state-run institutions; provide emergency shelters and increase prosecutions for perpetrators, with most interventions initiated only after allegations are reported.",
        "B": "Implement a conditional cash transfer (CCT) administered by the Ministry of Finance that pays families when children attend school, paired with a high‑visibility public awareness campaign on child rights, but with no mandated intersectoral referral protocols or formal coordination structures across health, education, and justice sectors.",
        "C": "Create an integrated child protection system: enact rights‑based legislation; establish an intersectoral coordination body linking social welfare, education, health, security and justice; define routine referral pathways and data‑sharing protocols; scale up family‑strengthening measures (targeted cash support, parenting programmes, access to free quality education) and community child protection committees focused on prevention and early identification, with monitoring aligned to UNCRC/SDG indicators.",
        "D": "Contract an international NGO to implement a Western model emphasizing individual case management and rapid statutory removal into foster care, delivered centrally without adapting to local cultural practices or investing in community prevention or multisectoral referral networks."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a concrete municipal scenario and created four plausible policy options contrasting reactive/statutory, single‑sector prevention, integrated multi‑agency prevention, and exported Western model. Option C aligns with holistic, coordinated, prevention and rights‑based principles.",
      "concepts_tested": [
        "Holistic multi‑factor risk and protection model (social, economic, cultural, psychological, environmental)",
        "Multi‑agency child protection systems with coordination and referral mechanisms",
        "Prevention‑focused, rights‑based approach aligned with UNCRC and SDGs"
      ]
    },
    "pass_2_reason": "readability_too_high_21.8_vs_16"
  },
  {
    "original_question": {
      "question": "In the social-constructionist and performative view of gender, why is gender understood as something people “do” rather than something they “are,” and how does this account explain cross-cultural variation in gender norms?",
      "options": {
        "A": "Because biological sex dictates universal gender roles that everyone must perform.",
        "B": "Because gender is produced through repeated performances of social norms, which are culturally shaped, allowing different cultures to enact different gender scripts.",
        "C": "Because gender identity arises solely from conscious self-inquiry, independent of social cues or norms.",
        "D": "Because once a gender script is adopted, it becomes a fixed biological trait that cannot adapt to new cultural contexts."
      },
      "correct_answer": "B",
      "source_article": "Gender studies",
      "x": 1.1445822715759277,
      "y": 0.9615119695663452,
      "concepts_tested": [
        "Social construction and performativity of gender (gender as social/cultural constructs and practices, not solely biological determinants)",
        "Intersectionality and relational analysis (how gender intersects with race, ethnicity, location, class, nationality, disability, and its role in political discourse)",
        "Psychoanalytic and theoretical influences on gender analyses (Freud, Lacan, Kristeva, Ettinger; concepts like sexuation and unconscious structures shaping gender identity)"
      ],
      "parent_concepts": [
        "The historical/evolutionary progression of development frameworks (WID → WAD → GAD) reflecting shifts from focusing on women as beneficiaries to analyzing gender relations and power structures in development.",
        "Concept 2: Representation and visibility of women in art history and practice, including collective, dialogic methods (e.g., consciousness-raising) to shift perception."
      ],
      "parent_articles": [
        "Gender and development",
        "Feminist art movement"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to social-constructionist and performative theories of gender, why is gender described as something people 'do' rather than something they 'are', and how does this view explain differences in gender norms between cultures?",
      "options": {
        "A": "Because biological sex determines universal gender roles that people must perform, so gender is simply the enactment of fixed biological functions.",
        "B": "Because gender is continually produced by repeated performances of socially learned norms; these performances are shaped by local cultures, so different societies develop different gender scripts.",
        "C": "Because gender identity comes only from individuals' conscious self-reflection and thus does not depend on social norms or cultural context.",
        "D": "Because once someone adopts a gender script it becomes a permanent biological trait, preventing gender norms from varying across cultures."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified the original question by using concise academic language, removed excess jargon, and made the link between performativity (repeated social performances) and cross-cultural variation explicit. Distractors were kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.0_vs_16",
    "pass_2_attempt": {
      "question": "A qualitative researcher conducts life-history interviews with three informants: (1) a cisgender Latino man who describes learning to 'act like a man' through childhood games and fatherly admonitions; (2) a Samoan fa'afafine who explains occupying a culturally recognized third-gender role involving particular dress, caregiving, and community rituals; and (3) a Black woman working in the informal sector who details how unpaid caregiving, racial stereotyping, and precarious employment constrain her choices. Which analytic strategy best integrates the social construction and performativity of gender, an intersectional relational analysis, and psychoanalytic concepts such as Lacanian sexuation and Ettinger's matrixial emphasis on maternal connectivity?",
      "options": {
        "A": "Use a multimodal qualitative framework that (i) conducts discourse and performativity analysis to trace how gendered acts are repeated and naturalized (Butler), (ii) applies an intersectional matrix to map how race, class, nationality and location differentially structure power and experience, and (iii) reads unconscious formations and early relational (sexuation/matrixial) dynamics to interpret how subjectivities and trans-subjective connections shape each informant's gendered self.",
        "B": "Adopt a political economy approach that reduces gender explanations to material class position and labor-market forces, arguing that gendered behaviours are epiphenomenal products of economic structures and therefore need no separate psychoanalytic or performative account.",
        "C": "Apply a biological-essentialist comparative method that treats each informant's account as downstream effects of innate sex differences (hormones, chromosomes), using cross-cultural frequency counts to claim universality of male/female dispositions rather than culturally specific performances.",
        "D": "Produce a thick ethnographic description that documents each informant's local meanings and practices without theorizing power relations, performativity mechanisms, or unconscious processes—emphasizing cultural specificity and avoiding cross-case theoretical synthesis."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete multi-informant vignette; correct option synthesizes Butlerian performativity, intersectionality, and psychoanalytic sexuation/matrixial theory; distractors represent plausible but inadequate analytic choices (economic reductionism, biological essentialism, descriptive cultural relativism).",
      "concepts_tested": [
        "Social construction and performativity of gender",
        "Intersectionality and relational analysis",
        "Psychoanalytic theoretical influences on gender identity (Lacan, Ettinger)"
      ]
    },
    "pass_2_reason": "readability_too_high_30.1_vs_16"
  },
  {
    "original_question": {
      "question": "How does integrating cultural diplomacy with public diplomacy influence the spread and legitimacy of cultural messages, and why is credibility of information essential for building mutual understanding through these exchanges?",
      "options": {
        "A": "Because cultural diplomacy can attract audiences through symbols alone, credibility of information is irrelevant and public diplomacy should keep messages separate to avoid policy concerns.",
        "B": "Integrating cultural diplomacy with public diplomacy creates a framework where cultural exchanges are backed by transparent information from credible institutions, ensuring audiences can interpret messages in a context aligned with the nation's institutions, thus fostering mutual understanding.",
        "C": "Credibility is only necessary for economic transactions; cultural exchanges operate purely on emotional appeal, so public diplomacy's role is to maximize exposure, not credibility.",
        "D": "Mutual understanding arises from competition rather than cooperation; thus public diplomacy should co-opt cultural diplomacy to dominate the narrative."
      },
      "correct_answer": "B",
      "source_article": "Cultural diplomacy",
      "x": 1.2328022718429565,
      "y": 0.9430787563323975,
      "concepts_tested": [
        "Concept 1: Soft power as the basis for cultural diplomacy and its ability to attract foreign audiences to a nation.",
        "Concept 2: Cultural diplomacy as a mechanism to increase mutual understanding through exchanges of culture, ideas, information, and people, and its integration with public diplomacy (including credibility of the information).",
        "Concept 3: The relationship between informal cross-cultural interactions and formal diplomatic effort (organic cultural flows vs. government intervention), and the notion that culture can be the central hinge (\"linchpin\") of public diplomacy."
      ],
      "parent_concepts": [
        "Concept 2: Sports as a medium of political propaganda and state exposure (how governments use sport to project power or legitimacy)"
      ],
      "parent_articles": [
        "Politics and sports"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does integrating cultural diplomacy with public diplomacy affect the dissemination and perceived legitimacy of cultural messages, and why is credible information necessary to build mutual understanding through these exchanges?",
      "options": {
        "A": "Because cultural diplomacy attracts audiences through symbols and popular culture alone, the factual credibility of information is irrelevant; public diplomacy should remain separate to avoid entanglement with specific policies.",
        "B": "Integration creates a coherent framework in which cultural exchanges are supported by transparent, credible information from legitimate institutions, helping foreign audiences interpret cultural signals in the context of a nation's institutions and thereby fostering mutual understanding.",
        "C": "Credibility matters mainly for economic or transactional interactions; cultural exchanges function primarily on emotional appeal, so public diplomacy's role is to maximize exposure rather than ensure informational credibility.",
        "D": "Mutual understanding is best achieved through contest and narrative dominance; public diplomacy should subsume cultural diplomacy to control and outcompete alternative interpretations."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording tightened to ask explicitly about dissemination, legitimacy, and the role of credible information; options were rewritten to be concise and academically phrased while preserving original meanings and plausibility.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.0_vs_16",
    "pass_2_attempt": {
      "question": "The Ministry of Foreign Affairs of the fictional country Arandia funds a network of cultural centres abroad, sponsors student exchanges, and subsidizes touring film festivals showcasing Arandian cinema; simultaneously, Arandian pop music spreads organically through online platforms and diasporic communities without state coordination. Which of the following best characterizes the theoretical role of cultural diplomacy in relation to (i) soft power, (ii) public diplomacy and credibility, and (iii) the interplay between organic cultural flows and formal state efforts?",
      "options": {
        "A": "Cultural diplomacy operates as a form of soft power that makes a country attractive through its culture and values; state-sponsored exchanges and cultural programming build mutual understanding which strengthens the credibility of public diplomacy, and formal diplomatic initiatives seek to channel and amplify pre-existing organic cultural flows—thus culture often functions as the linchpin of public diplomacy.",
        "B": "Cultural diplomacy is essentially transactional: the state buys favourable foreign opinion through funded cultural exports and payments; credibility of public diplomacy depends primarily on the visibility of government sponsorship rather than mutual cultural understanding, and organic cultural flows are irrelevant to formal diplomatic strategy.",
        "C": "Cultural diplomacy is primarily an instrument for short-term policy wins and direct behavioral change in foreign publics; since culture is ephemeral, state intervention can fully control cultural influence and credibility rests solely on official messaging rather than interpersonal cultural exchange.",
        "D": "Cultural diplomacy replaces public diplomacy because cultural activities alone suffice to achieve foreign-policy objectives; credibility in the information sphere comes from close alignment with government institutions, while organic cultural exchanges are generally obstacles that formal programs must suppress."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a concrete scenario (Arandia) to test links between soft power attraction, cultural exchanges enhancing credibility of public diplomacy, and the relationship between organic cultural flows and formal state efforts, with distractors reflecting common misunderstandings.",
      "concepts_tested": [
        "Soft power and attraction via culture",
        "Cultural diplomacy's role in building mutual understanding and credibility for public diplomacy",
        "Interaction between organic cross-cultural exchanges and state-led cultural diplomacy; culture as linchpin of public diplomacy"
      ]
    },
    "pass_2_reason": "readability_too_high_24.6_vs_16"
  },
  {
    "original_question": {
      "question": "How do allogenic and autogenic ecosystem engineers differ in the primary mechanism by which they alter opportunities for other species, and what underlying principle explains how their effects on biodiversity can differ?",
      "options": {
        "A": "Allogenic engineers modify the environment by changing materials into different forms or configurations, redistributing resources; autogenic engineers create new habitat space through their own body structures, so the primary effect is habitat creation rather than material transformation.",
        "B": "Allogenic engineers alter climate directly, while autogenic engineers change soil chemistry; this difference explains why one affects temperature and the other nutrient availability.",
        "C": "Allogenic engineers only influence trophic interactions through predation, whereas autogenic engineers only affect abiotic filters; this distinction is the basis for their labels.",
        "D": "Allogenic and autogenic engineers differ solely in reproductive rate, which determines their relative impact on community structure."
      },
      "correct_answer": "A",
      "source_article": "Ecosystem engineer",
      "x": 1.6483566761016846,
      "y": 0.9651830196380615,
      "concepts_tested": [
        "Concept 1: Ecosystem engineers modify habitat structure and resource distribution, influencing species richness and landscape heterogeneity.",
        "Concept 2: Two mechanisms of engineering: allogenic (changing materials/form) and autogenic (creating habitat via body structures).",
        "Concept 3: Relationship to keystone species: engineers can have large impacts but differ in their primary mode of influence (non-trophic/resource modification vs trophic effects)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do allogenic and autogenic ecosystem engineers differ in the main way they change opportunities for other species, and what general principle explains why their effects on biodiversity can differ?",
      "options": {
        "A": "Allogenic engineers alter the physical environment by transforming materials or structures into different forms or configurations (e.g., beavers building dams, caterpillars making leaf shelters), thereby redistributing resources and microhabitats; autogenic engineers create or change habitat through their own bodies or growth (e.g., trees, corals), so their primary effect is habitat provision and structural complexity. Because one primarily transforms materials/resources and the other primarily builds structural habitat, their impacts on species richness and landscape heterogeneity differ.",
        "B": "Allogenic engineers act mainly by altering climate variables (temperature, humidity) across a landscape, while autogenic engineers act mainly by changing soil chemistry and nutrient pools; this climate-versus-nutrients difference explains their distinct effects on biodiversity.",
        "C": "Allogenic engineers influence communities only via trophic interactions such as predation and consumption, whereas autogenic engineers act only by changing abiotic filters (light, substrate); this strict trophic-versus-abiotic division determines their biodiversity effects.",
        "D": "Allogenic and autogenic engineers differ primarily in reproductive rate: the species with higher reproductive output will always have the larger engineering effect and thus the greater influence on community structure."
      },
      "correct_answer": "A",
      "simplification_notes": "Shortened and clarified wording; explicitly stated the two mechanisms (material transformation vs habitat created by organism bodies) with examples; emphasized the underlying principle that differences in resource redistribution versus structural habitat production lead to different effects on species richness.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.9_vs_16",
    "pass_2_attempt": {
      "question": "A restoration ecologist studies a 100-ha temperate wetland and records effects of three focal species: (1) Rodent X that fells trees and constructs dams, flooding channels to form ponds and oxbows; (2) Emergent grass Y that grows dense standing stems and creates vertical and horizontal structure used by insects and birds; (3) Predator Z that consumes herbivorous fish and thereby reduces grazing on submerged plants. Presence of X increases pond–marsh patchiness and amphibian richness; Y increases habitat complexity and supports canopy-specialist insects; removal of Z causes loss of submerged vegetation via herbivore release. Which option best classifies X, Y and Z and correctly explains how ecosystem engineers differ from keystone, trophically-driven species?",
      "options": {
        "A": "X = allogenic ecosystem engineer; Y = autogenic ecosystem engineer; Z = keystone (trophic) species. Ecosystem engineers modify physical habitat or resource distribution (creating heterogeneity and novel microhabitats) and thereby influence species richness, whereas keystone species exert strong effects mainly through trophic interactions (predation or grazing).",
        "B": "X = autogenic engineer; Y = allogenic engineer; Z = ecosystem engineer. Ecosystem engineers are identified primarily because they directly provide living or dead tissue (food) to other species rather than by altering physical habitat.",
        "C": "X = allogenic engineer; Y = autogenic engineer; Z = keystone. Ecosystem engineers always affect other species via trophic cascades in the same manner as keystone predators, so their primary mode of impact is through food-web interactions.",
        "D": "X = keystone predator; Y = autogenic engineer; Z = allogenic engineer. Ecosystem engineers must be abundant to influence landscape heterogeneity, so only numerically dominant species qualify as engineers."
      },
      "correct_answer": "A",
      "generation_notes": "Built a concrete wetland scenario mapping dam-building (allogenic), structural plants (autogenic), and predators (keystone) to test distinctions: habitat/resource modification, mechanisms (allogenic vs autogenic), and difference from trophic keystone effects.",
      "concepts_tested": [
        "Ecosystem engineers modify habitat structure and resource distribution influencing species richness and landscape heterogeneity",
        "Distinction between allogenic and autogenic engineering mechanisms",
        "Difference between engineers and keystone trophic species (non-trophic resource modification vs trophic effects)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.4_vs_16"
  },
  {
    "original_question": {
      "question": "In codicology, why does adopting a lato sensu approach (broadly including palaeography, art history, and social context) often change conclusions about a manuscript’s character, value, and intended use compared to a stricto sensu approach (focused on materials and production techniques)?",
      "options": {
        "A": "Because stricto sensu analysis already accounts for social context, so there is no difference in conclusions.",
        "B": "Because lato sensu broadens the lens to connect physical features with reader practices, ownership, and cultural value, altering interpretations of use and significance.",
        "C": "Because stricto sensu focuses on social contexts while lato sensu focuses only on binding mechanics.",
        "D": "Because incorporating broad context always makes the manuscript appear more valuable regardless of evidence."
      },
      "correct_answer": "B",
      "source_article": "Codicology",
      "x": 2.5285232067108154,
      "y": 0.2341524362564087,
      "concepts_tested": [
        "The scope and boundaries of codicology and its relationships to related disciplines, including the distinction between stricto sensu and lato sensu approaches.",
        "How physical features (scribal work, script styles, marginalia, ownership, decoration) are analyzed to infer a codex’s character, value, date, and purpose.",
        "The impact of materials and manufacturing on the final codex form and status (e.g., choices among papyrus, parchment, paper; binding), showing a causal link between production and the finished object."
      ],
      "parent_concepts": [
        "Concept 3: The scope/principle that the discipline prioritizes form, production context, and relationships between texts over substantive content analysis (content is secondary)."
      ],
      "parent_articles": [
        "Palaeography"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does a lato sensu codicological approach (which adds palaeography, art history, and social/cultural context) often yield different conclusions about a manuscript’s character, value, and intended use than a stricto sensu approach focused only on materials and production techniques?",
      "options": {
        "A": "Because a stricto sensu analysis already incorporates social and cultural context, so adding broader disciplines changes nothing.",
        "B": "Because lato sensu widens the analytical frame, linking physical features to reader practices, ownership, decoration, and cultural meaning, which can change interpretations of use and significance.",
        "C": "Because stricto sensu is primarily concerned with social history while lato sensu treats only binding mechanics, reversing the emphases.",
        "D": "Because adding broader contextual evidence inevitably makes a manuscript seem more important or valuable regardless of the material evidence."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was shortened and clarified; disciplinary terms (stricto sensu, lato sensu, palaeography) were kept but defined briefly; options rewritten to be concise and plausible distractors while preserving the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.8_vs_16",
    "pass_2_attempt": {
      "question": "You are given a 13th-century codex with the following physical features: high-grade sheepskin parchment with clear hair/flesh-side asymmetry; quires predominantly quaterniones (four bifolia per quire) with uniform pricking and ruling; catchwords at quire ends; evidence of expensive ultramarine pigment and gold leaf illumination on opening folios; marginal glosses and ownership inscriptions added in later hands; and several paper flyleaves with a watermark stylistically datable to the late 15th century. Which one of the following research questions would fall outside the primary remit of stricto sensu codicology (the narrow, material-focused codicological approach)?",
      "options": {
        "A": "Can the manuscript’s original quire‑ordering and the production centre’s folding/sewing conventions be reconstructed from the quire format, pricking, ruling and catchwords?",
        "B": "Do the choice of high‑grade sheepskin, costly pigments, gold tooling and the presence of later paper flyleaves indicate that this was produced as a deluxe presentation copy and later adapted for continued use?",
        "C": "Can the marginal glosses’ theological arguments and variant readings be collated to establish the authorial intent and to produce an edited critical text of the work?",
        "D": "Can variations in script style and distinctive scribal abbreviations across foliations be used to identify multiple hands and to propose a relative dating/sequencing of the manuscript’s production stages?"
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a concrete manuscript scenario and asked which research question is not primarily covered by narrow (stricto sensu) codicology; distractors map to material/structural/palaeographic analyses that codicology (and allied palaeography) address, while textual editing belongs to philology/textual criticism.",
      "concepts_tested": [
        "scope and boundaries of codicology (stricto sensu vs allied disciplines)",
        "inference from physical features (materials, quire structure, decoration) to date, purpose, and production"
      ]
    },
    "pass_2_reason": "readability_too_high_25.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does applying the Laplace-Beltrami operator to the vertex positions of a surface mesh cause the geometry to become smoother over iterations?",
      "options": {
        "A": "It preserves all local features by enforcing exact neighbor equality, preventing any change.",
        "B": "It acts as a diffusion/low-pass operator that moves each vertex toward the average of its neighbors, damping high-frequency geometric variations and thereby smoothing.",
        "C": "It amplifies high-frequency details by boosting differences between a vertex and its neighbors, sharpening the mesh.",
        "D": "It performs a global rigid transformation that aligns vertices to minimize distance to a reference shape, indirectly smoothing."
      },
      "correct_answer": "B",
      "source_article": "Geometry processing",
      "x": 1.6748608350753784,
      "y": 1.1803791522979736,
      "concepts_tested": [
        "Concept 1: Geometry processing uses differential operators on surfaces (e.g., Laplace-Beltrami) to perform operations like smoothing, illustrating an operator-based approach to shape manipulation.",
        "Concept 2: Distinction between geometry and topology in shapes, with geometry involving positions, tangents, normals, curvature, and topology concerns like holes and orientability; and how these properties behave under smooth transformations.",
        "Concept 3: The life cycle of a shape in geometry processing (birth → analysis/edit → consumption/fabrication), including how acquisition, measurement, and editing decisions impact final use and outcomes."
      ],
      "parent_concepts": [
        "Data representations and texture: how distance data yields point clouds or meshes, and how color/texture information is captured and mapped."
      ],
      "parent_articles": [
        "3D scanning"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does applying the Laplace–Beltrami operator $\\Delta_{LB}$ to the vertex positions of a surface (triangle) mesh produce a smoother geometry after repeated iterations?",
      "options": {
        "A": "Because it enforces exact equality with neighbors, preserving every local feature and preventing any geometric change.",
        "B": "Because $\\Delta_{LB}$ behaves like a diffusion / low-pass operator: each vertex is moved toward an average of its neighboring vertices, which damps high-frequency geometric variations and thus smooths the surface.",
        "C": "Because it amplifies high-frequency detail by increasing the differences between each vertex and its neighbors, sharpening small geometric features.",
        "D": "Because it applies a global rigid alignment that reorients and translates the mesh to best match a reference shape, indirectly producing a smoother appearance."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the prompt for clarity at undergraduate level, introduced the symbol $\\Delta_{LB}$, made each option concise and plausible while preserving the original correct answer and core explanation (diffusion/low-pass smoothing).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.0_vs_16",
    "pass_2_attempt": {
      "question": "You have a noisy triangle mesh obtained by scanning a ceramic mug with a handle: vertex positions exhibit high‑frequency jitter, the mesh connectivity has small boundary holes near the rim, and you must prepare the model both for visual rendering and for 3D printing. Which of the following workflows best (1) uses an operator‑based surface smoothing that acts on geometry (not topology), (2) provides a robust diagnostic of the mesh's topological invariants, and (3) respects the lifecycle stages (birth → analysis/edit → consumption) by delaying any topology‑changing repairs until intentional fabrication preparation?",
      "options": {
        "A": "Compute per‑vertex normals and apply a Laplace–Beltrami (cotangent) smoothing (use the discrete cotangent Laplacian L and solve a linear system like (M+λL)f = \\bar{f}) to remove high‑frequency geometric noise while keeping the mesh connectivity fixed; compute the Euler characteristic χ = |V| − |E| + |F| to quantify holes/genus; only perform Poisson hole‑filling or remeshing as an explicit final fabrication step. (Correct)",
        "B": "Run aggressive Laplace–Beltrami smoothing until visible bumps disappear — this will automatically close small boundary holes and restore the correct genus; no separate topological analysis is needed because smoothing fixes topology as well as geometry.",
        "C": "Flatten the mesh with a Tutte or least‑squares conformal parameterization and then edit the 2D u,v coordinates to remove jitter; parameterization is the standard way to denoise geometry and is preferable to differential operators for preserving topological invariants.",
        "D": "Use the Generalized Winding Number to smooth the surface: compute wn(q) at each vertex and iteratively adjust vertex positions toward wn(q)=0.5 to eliminate noise and holes simultaneously; this both denoises and repairs topology before rendering or printing."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a practical scanning-to-fabrication scenario testing Laplace–Beltrami operator smoothing, Euler characteristic for topology, and lifecycle sequencing; included distractors that misattribute topology changes to smoothing, parameterization, or winding-number methods.",
      "concepts_tested": [
        "Operator‑based surface smoothing using Laplace–Beltrami / cotangent Laplacian",
        "Distinction between geometry (positions, normals, curvature) and topology (holes, Euler characteristic, orientability)",
        "Shape life cycle stages: acquisition (scan), analysis/edit (measurements, smoothing), and consumption/fabrication (rendering, Poisson reconstruction)"
      ]
    },
    "pass_2_reason": "readability_too_high_24.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the introduction of deductive reasoning and rigorous proofs constitute a defining mechanism that transformed mathematics from a collection of isolated results into a coherent, cumulative discipline?",
      "options": {
        "A": "Because proofs establish universal truths from general premises, enabling results to be derived, verified, and connected, which builds a coherent and expandable body of knowledge.",
        "B": "Because proofs primarily speed up calculations through symbolic shorthand.",
        "C": "Because deductive reasoning eliminates the role of observation and experiment in mathematics entirely.",
        "D": "Because it guarantees that every problem has a universal, finite algorithm to reach a solution."
      },
      "correct_answer": "A",
      "source_article": "History of mathematics",
      "x": 1.5779690742492676,
      "y": 1.1783866882324219,
      "concepts_tested": [
        "Concept 1: The shift to deductive reasoning and rigorous proofs as a defining mechanism of mathematical development (from Greek mathematics and the Pythagoreans).",
        "Concept 2: Cross-cultural transmission and transformation of mathematical notation and concepts (numeral systems, zero, and the flow of ideas from Hindu-Arabic to Islamic to European contexts).",
        "Concept 3: The relationship between practical needs (commerce, taxation, calendars/astronomy) and the advancement of mathematical methods and tools."
      ],
      "parent_concepts": [
        "Concept 2: The relationship between numerical integration and historical/geometric ideas (quadrature) and how this shapes terminology and conceptual framing."
      ],
      "parent_articles": [
        "Numerical integration"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How did the introduction of deductive reasoning and rigorous proof change mathematics from a collection of isolated results into a coherent, cumulative discipline?",
      "options": {
        "A": "Because proofs permit deriving universal conclusions from general premises, so results can be verified, connected, and built upon to form a coherent, expandable body of knowledge.",
        "B": "Because the main effect of introducing proofs was to speed up numerical calculation by providing concise symbolic shorthand for computations.",
        "C": "Because deductive reasoning removed the need for observation, experiment, or example in mathematical practice entirely.",
        "D": "Because rigorous proofs guarantee that every mathematical problem has a universal, finite algorithm that will always produce a solution."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording shortened and focused on core issue (role of deductive reasoning and proofs). Distractors were rephrased into concise, plausible misconceptions (calculation speed, elimination of empirical input, guarantee of universal algorithm). No essential content or the correct answer was changed.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "Each option below lists three historical episodes. Which option correctly pairs (i) a canonical example of the shift to deductive, axiomatic mathematical reasoning, (ii) a documented pathway by which a place‑value numeral system and the concept of zero were transformed and transmitted into European use, and (iii) a mathematical innovation whose origin is best explained by practical needs such as commerce, taxation, or calendrical/astronomical computation?",
      "options": {
        "A": "(i) Euclid's Elements codifying the axiomatic format of definition → axiom → theorem → proof; (ii) al‑Khwārizmī's Arabic treatment of the Hindu–Arabic numerals (including zero and place value) that via translations entered medieval Europe; (iii) Babylonian sexagesimal place‑value notation developed for astronomical tables, calendars and administrative accounting (basis of $60$ and $360^\\circ$).",
        "B": "(i) The Pythagorean school's mystical numerology presented as the definitive axiomatic system for geometry; (ii) the Maya zero symbol being adopted directly by European scholars immediately after Columbus; (iii) Roman numerals (I, V, X, ...) evolving into the modern decimal positional system because of merchant bookkeeping needs.",
        "C": "(i) Diophantus's Arithmetica as the foundational work that established the Euclidean axiomatic method; (ii) Chinese rod numerals developing directly into the Hindu–Arabic numeral glyphs used in Europe; (iii) the Rhind papyrus representing mathematical advances motivated solely by recreational puzzles rather than pragmatic tasks like surveying and grain accounting.",
        "D": "(i) Aristotle's logical treatises supplanting the need for mathematical proofs and thus marking the shift to deductive mathematics; (ii) al‑Kindi inventing decimal place‑value notation and transmitting it to Europe; (iii) the medieval quadrivium (Boethius) being the primary engine that produced the Hindu–Arabic numerals for commercial use in Europe."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a triplet‑matching MCQ where only option A correctly aligns Euclid with axiomatic/deductive proof, al‑Khwārizmī/Islamic transmission with the spread of Hindu–Arabic numerals and zero into Europe, and Babylonian sexagesimal/administrative astronomy with practical drivers (commerce/calendars). Other options contain historically plausible but incorrect pairings.",
      "concepts_tested": [
        "Deductive reasoning and axiomatic proofs in Greek mathematics (Euclid)",
        "Cross‑cultural transmission of numeral systems and concept of zero via Islamic scholars",
        "Practical drivers (commerce, taxation, calendars/astronomy) shaping mathematical innovation"
      ]
    },
    "pass_2_reason": "readability_too_high_21.6_vs_16"
  },
  {
    "original_question": {
      "question": "In participatory development, why does establishing equal partnership (primus inter pares) and ongoing dialogue among stakeholders increase the likelihood of sustainable outcomes?",
      "options": {
        "A": "It compels external actors to enforce predetermined goals on the community more effectively.",
        "B": "It enables primary stakeholders to co-define priorities and implement solutions that fit local constraints, drawing on tacit knowledge, which strengthens ownership and adaptive learning.",
        "C": "It short-circuits the design phase by skipping formal planning stages.",
        "D": "It reduces the need for monitoring by transferring all accountability to the community."
      },
      "correct_answer": "B",
      "source_article": "Participatory development",
      "x": 1.2666372060775757,
      "y": 0.9530637264251709,
      "concepts_tested": [
        "Concept 1: Empowerment and ownership as mechanisms in PD, including how dialogue and equal partnerships (primus inter pares) lead to joint decisions and potentially more sustainable outcomes.",
        "Concept 2: The Social Movement Perspective vs. the Institutional Perspective as competing frameworks that define the aims and methods of participation (empowerment vs. inputs-for-predefined-goals).",
        "Concept 3: The Institutional/Project-Based view that PD follows stages (Research, Design, Implementation, Evaluation) where stakeholder inputs are used to achieve externally defined goals, highlighting a cause-effect link between participation inputs and project outcomes."
      ],
      "parent_concepts": [
        "Relational capital and asset mapping as mechanism: importance of relationships, listening and asking for ideas, and tools like capacity/skill inventories to mobilize and coordinate community resources."
      ],
      "parent_articles": [
        "Asset-based community development"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In participatory development, why does making primary stakeholders equal partners (primus inter pares) and maintaining ongoing dialogue increase the chances of sustainable outcomes?",
      "options": {
        "A": "It enables external actors to impose and enforce their predetermined goals on the community more effectively.",
        "B": "It allows primary stakeholders to co‑define priorities and implement solutions suited to local constraints, using tacit knowledge; this builds ownership and enables adaptive learning, which supports sustainability.",
        "C": "It short‑circuits the project by skipping formal design and planning stages, so interventions are delivered faster and therefore last longer.",
        "D": "It transfers all monitoring and accountability to the community, reducing external oversight and thus ensuring long‑term success."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording made more concise and precise; retained technical term \"primus inter pares\"; options rewritten to be clear, plausible, and match original intent. Emphasized ownership, tacit knowledge, and adaptive learning in the correct option.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.1_vs_16",
    "pass_2_attempt": {
      "question": "An international NGO implements a community sanitation project in two comparable villages. In Village X the NGO follows an institutional (project‑based) approach: it sets an external target to reduce diarrheal incidence by \\(40\\%\\) in 3 years, conducts research with limited consultation, designs and implements the intervention, and evaluates success using the externally defined indicator. In Village Y the NGO adopts a social movement (empowerment) approach: facilitators support village members to identify problems, co‑design the intervention, make joint decisions (primary stakeholders act as primus inter pares), and agree on locally meaningful evaluation indicators. After 5 years Village X reached the \\(40\\%\\) reduction by year 2 but diarrheal rates returned toward baseline by year 5 because maintenance and local adoption lapsed; Village Y reached only \\(15\\%\\) reduction by year 2 but improved to \\(60\\%\\) reduction by year 5 with sustained local maintenance and broader behavioral change. Which explanation best accounts for these divergent outcomes in terms of participatory development concepts and project stages (Research, Design, Implementation, Evaluation)?",
      "options": {
        "A": "Village X's institutional approach produced quick, measurable gains because stakeholder inputs were used instrumentally to meet an externally defined goal, but ownership was limited so long‑term maintenance and sustainability declined; Village Y's social movement approach produced slower initial results but greater eventual gains because empowered stakeholders (primus inter pares) controlled decisions across Research–Design–Implementation–Evaluation and defined indicators that fostered ownership and sustained outcomes.",
        "B": "Village X underperformed in the long term because institutional approaches always produce inferior technical designs; Village Y outperformed because social movement approaches always deliver better technical solutions, independent of participation or stages of the project cycle.",
        "C": "The divergent trajectories are best explained by differences in monitoring rigor: Village X used objective external indicators so its early success was real, while Village Y manipulated locally chosen indicators to exaggerate later gains; participation style and ownership played no causal role.",
        "D": "Village X should have been more sustainable because external goal setting and centralized evaluation ensure accountability; Village Y regressed early because giving primary stakeholders full control (primus inter pares) delays implementation and creates weak technical outcomes despite apparent long‑term benefits."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete two‑village scenario comparing institutional vs social movement PD approaches, included staged project cycle and participatory evaluation to elicit causal reasoning about empowerment, ownership, and sustainability; options include plausible but incorrect alternatives.",
      "concepts_tested": [
        "Empowerment and ownership as mechanisms leading to sustainability",
        "Differences between Social Movement and Institutional perspectives in PD",
        "Role of project stages (Research, Design, Implementation, Evaluation) and participatory indicators in linking participation inputs to outcomes"
      ]
    },
    "pass_2_reason": "readability_too_high_20.6_vs_16"
  },
  {
    "original_question": {
      "question": "How does emphasizing embodied carbon alter the design strategy for sustainable architecture relative to focusing only on operational carbon?",
      "options": {
        "A": "It shifts attention away from material choices and toward occupant behavior modification.",
        "B": "It foregrounds upfront emissions from materials and construction, encouraging decisions about material selection, reuse, durability, and construction methods to lower total lifecycle emissions.",
        "C": "It makes cement emissions the sole determinant of a project's sustainability, since cement dominates all emissions.",
        "D": "It implies that once the building is in use, energy performance is the only remaining factor, so embodied carbon can be ignored."
      },
      "correct_answer": "B",
      "source_article": "Sustainable architecture",
      "x": 1.5338407754898071,
      "y": 0.8773955702781677,
      "concepts_tested": [
        "Concept 1: The principle of minimizing environmental impact through improved efficiency and moderation in materials, energy, development space, and the ecosystem.",
        "Concept 2: Sustainability as a relationship between architecture, nature, and culture, expanding beyond purely technical “green design” to a broader ecological and cultural framework.",
        "Concept 3: The embodied carbon versus operational carbon distinction and the implication that addressing embodied carbon (e.g., cement-related emissions) is essential for lifecycle sustainability."
      ],
      "parent_concepts": [
        "Climate-informed site analysis and design decisions (window placement/size, glazing type, shading, insulation) to optimize passive heating in winter and cooling in summer."
      ],
      "parent_articles": [
        "Passive solar building design"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does shifting emphasis from operational carbon (emissions during a building's use) to embodied carbon (emissions from materials, manufacturing, and construction) change the sustainable design strategy?",
      "options": {
        "A": "It redirects focus away from material choices and toward altering occupant behavior and usage patterns.",
        "B": "It brings upfront emissions from materials and construction into primary view, encouraging choices about material selection, reuse, durability, and construction methods to reduce total lifecycle emissions.",
        "C": "It makes cement emissions the single decisive measure of a project's sustainability, because cement dominates all construction emissions.",
        "D": "It implies that after occupancy the building's energy performance is the only remaining concern, so embodied carbon can be ignored."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified terms operational vs embodied carbon, shortened wording for clarity, retained original choices and the correct answer; ensured all options remain plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "A university must choose one of four design proposals for a new 10,000 m² campus building. Which proposal best embodies the following sustainable-architecture principles: (1) minimizing negative environmental impact by improving efficiency and moderating the use of materials, energy, development space and ecosystems; (2) treating sustainability as a cultural and ecological relationship between architecture and nature rather than only a technical ‘‘green’’ fix; and (3) addressing embodied carbon in addition to operational carbon (note: cement alone accounts for about $8\\%$ of global emissions)?\n\nProposal A: Retrofit the existing 6,000 m² masonry structure, reuse 80% of structural elements, replace insulation with recycled cellulose (embodied carbon cut by roughly $50\\%$), optimize passive solar orientation and daylighting (operational energy reduced by ~$40\\%$), and engage local craftspeople and regional materials to reflect cultural context.\n\nProposal B: Demolish and build a new concrete-framed building with super-insulation, ground-source heat pumps and rooftop PVs designed to achieve net-zero operational energy (operational carbon $\\downarrow 100\\%$), but using 5,000 tonnes of cement that increases embodied carbon relative to the retrofit by ~35\\%.\n\nProposal C: Build a sprawling single‑story timber and rammed‑earth complex on a 2‑hectare greenfield at the urban fringe using low‑carbon local materials (low embodied carbon) but substantially increasing commuting distances, land take and transport emissions.\n\nProposal D: Erect a high‑tech glazed building with imported low‑E glass and advanced HVAC that attains a high green rating, but incorporates exotic imported composite panels with very high embodied energy and little connection to local cultural or ecological systems.\n\nWhich proposal most closely aligns with all three principles above?",
      "options": {
        "A": "Proposal A — retrofit, high reuse, reduced embodied carbon, passive/low‑energy measures, and local cultural integration.",
        "B": "Proposal B — new concrete build with net‑zero operational energy but substantially higher embodied cement emissions.",
        "C": "Proposal C — low‑carbon natural materials but sprawling greenfield placement that increases transport and land‑use impacts.",
        "D": "Proposal D — high‑performance glazed new building with imported high‑embodied‑energy components and limited cultural/ecological integration."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete campus design scenario with quantified trade-offs (embodied vs operational carbon, site placement, cultural integration) to test lifecycle assessment thinking and the broader cultural/ecological framing of sustainability. Included cement global emissions stat to cue embodied carbon importance.",
      "concepts_tested": [
        "Minimizing environmental impact via efficiency and moderation of materials/energy/space/ecosystem",
        "Sustainability as a cultural and ecological relationship beyond technical ‘green’ fixes",
        "Distinction between embodied carbon and operational carbon and importance of addressing embodied emissions (e.g., cement)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.7_vs_16"
  },
  {
    "original_question": {
      "question": "Non-state actors and transnational networks (civil society organizations, federations, international movements) influence European integration not by formal veto power or simple funding, but primarily through mechanisms that shape governance across multiple levels. Which description best captures how they contribute to integration?",
      "options": {
        "A": "They have formal veto power over EU legislation when mobilized across borders.",
        "B": "They create and propagate shared norms and preferences across countries, forming transnational networks that signal legitimacy, monitor compliance, and diffuse practices that align national policies with supranational objectives.",
        "C": "They are solely concerned with funding national referenda and do not affect policy content.",
        "D": "They primarily generate anti-integration protests that push for opt-outs and slow convergence."
      },
      "correct_answer": "B",
      "source_article": "European integration",
      "x": 0.6203147768974304,
      "y": 0.6412255167961121,
      "concepts_tested": [
        "Concept 1: European integration as a multi-dimensional, multi-level process spanning political, legal, social, regional, and economic spheres, with centralisation through policy coordination.",
        "Concept 2: Theoretical frameworks for understanding integration (proto-integration, explaining integration, analyzing governance, constructing the EU) and how they categorize and explain the phenomenon.",
        "Concept 3: The role of non-state actors and transnational networks (civil society organizations, federations, international movements) in shaping and sustaining integration through relationships and commitments."
      ],
      "parent_concepts": [
        "Concept 3: Integrative approach linking cohesion policy with other EU objectives (climate change, energy, globalization) to achieve sustainable development and regional competitiveness"
      ],
      "parent_articles": [
        "Regional policy of the European Union"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Non-state actors and transnational networks (civil society organizations, federations, international movements) rarely have formal veto power in EU decision-making. Which description best explains how they mainly advance European integration across multiple governance levels?",
      "options": {
        "A": "They acquire formal veto power over EU legislation when sufficiently mobilized across borders.",
        "B": "They generate and spread shared norms and policy preferences through transnational networks that confer legitimacy, monitor compliance, and diffuse practices, thereby aligning national policies with supranational objectives.",
        "C": "They are primarily focused on financing national referenda and so influence only domestic votes, not policy content.",
        "D": "They mainly organize anti-integration protests that produce opt-outs and systematically slow down policy convergence."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the stem; emphasized that influence occurs without formal vetoes; preserved mechanisms (norm diffusion, networks, legitimacy, monitoring) and made all options plausible alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.5_vs_16",
    "pass_2_attempt": {
      "question": "A coalition of ten European states proposes a Treaty to integrate their electricity markets. During negotiations national ministers emphasize domestic fiscal impacts; after signature the European Commission establishes a supranational Agency for Trans‑European Energy to harmonize technical standards; well‑integrated industry sectors produce regulatory spillovers that expand the Agency’s remit; meanwhile regional governments and transnational NGOs form networks that lobby for consumer protections and run a pan‑European campaign framing affordable energy as a European social right. Which combination of integration theories best explains (i) the historical normative advocacy for a unified Europe, (ii) the institutional spillover leading to a supranational agency, (iii) national governments’ decisive role in negotiating the Treaty on the basis of domestic preferences, and (iv) the mobilization of subnational authorities and civil society networks including identity framing?",
      "options": {
        "A": "(i) Proto‑integration (federalism/functionalism); (ii) Neofunctionalism (spillover to supranational bodies); (iii) Liberal intergovernmentalism (state bargaining driven by domestic preferences); (iv) Multi‑level governance combined with constructivist approaches (subnational actors and identity construction).",
        "B": "(i) Neofunctionalism; (ii) Liberal intergovernmentalism; (iii) Neofunctionalism; (iv) Rational choice institutionalism (NGOs as interest‑aggregators).",
        "C": "A single neofunctionalist explanation suffices for all four: grassroots actors create pressures, spillovers produce supranational agencies, and states adapt their loyalties accordingly.",
        "D": "(i) Functionalism only; (ii) Realist power politics (states create agencies to secure advantage); (iii) Intergovernmentalism (power rivalry among governments); (iv) Ordinary hierarchical EU governance (civil society plays a marginal, derivative role)."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete electricity‑market integration scenario and mapped each empirical feature to the appropriate phase/theoretical family: proto‑integration (normative/federalist), neofunctionalism (spillover), liberal intergovernmentalism (state bargaining/domestic preferences), and MLG/constructivism (subnational/NGO networks and identity).",
      "concepts_tested": [
        "Multi-dimensional, multi-level nature of European integration",
        "Phases and theoretical frameworks of integration (proto‑integration, neofunctionalism, intergovernmentalism, MLG, constructivism)"
      ]
    },
    "pass_2_reason": "readability_too_high_28.3_vs_16"
  },
  {
    "original_question": {
      "question": "Why does branding—creating stable associations between a product and certain qualities in consumers’ minds—tend to influence long-term demand and loyalty rather than only triggering immediate sales?",
      "options": {
        "A": "Because branding primarily relies on price discounts and fleeting cues, producing only temporary demand spikes.",
        "B": "Because branding builds durable associations that function as cognitive shortcuts, lowering perceived risk and shaping expectations, which supports repeated purchases over time.",
        "C": "Because branding directly increases the product's physical quality, making it inherently better than competitors.",
        "D": "Because branding guarantees the product will be available in all retailers, ensuring constant access."
      },
      "correct_answer": "B",
      "source_article": "Advertising",
      "x": 1.3083736896514893,
      "y": 0.9707787036895752,
      "concepts_tested": [
        "Concept 1: Branding as a mechanism to create associations between a product and certain qualities in consumers’ minds, influencing long-term demand and loyalty.",
        "Concept 2: Distinction between branding and direct-response advertising, highlighting different goals, time horizons, and measures (brand equity vs. immediate sales).",
        "Concept 3: Advertising as a broader persuasive tool beyond commercial products (political, NGO, governmental) and its effect on credibility, perceptions, and stakeholder signaling."
      ],
      "parent_concepts": [
        "Concept 1: Radio formats as market segmentation tools that target specific audiences through a chosen mix of music, information, and other content."
      ],
      "parent_articles": [
        "Radio format"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does branding—forming stable associations between a product and particular qualities in consumers' minds—tend to drive long-term demand and customer loyalty rather than only causing immediate one-off sales?",
      "options": {
        "A": "Because branding mainly depends on price promotions and short-lived cues, so it produces only temporary demand spikes.",
        "B": "Because branding builds durable associations that act as cognitive shortcuts, lowering perceived risk and creating expectation patterns that encourage repeat purchases over time.",
        "C": "Because branding directly increases the product's physical quality, making it inherently superior to competitors' offerings.",
        "D": "Because branding guarantees the product will be stocked in all retailers, ensuring continual availability and immediate sales."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; emphasized 'stable associations' and 'long-term demand'. Option B restates the original rationale using 'cognitive shortcuts' and 'perceived risk'. Distractors made plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.6_vs_16",
    "pass_2_attempt": {
      "question": "A corporation runs three simultaneous campaigns: (A) a five-year celebrity-centred campaign that consistently pairs its logo and product with images of sophistication and community values; (B) a four-week email coupon drive offering a 20% discount redeemable online; (C) a national tourism board campaign that depicts the country as safe, modern, and welcoming. Which single statement best characterizes the primary goals, typical metrics, and stakeholder effects of these three campaigns respectively?",
      "options": {
        "A": "(A) Branding campaign: builds associative links in consumers' minds to increase long-term demand and brand equity (measured by awareness, preference, willingness-to-pay, brand equity indices); (B) Direct-response campaign: elicits immediate transactions and is measured by conversion rate, short-term ROI and cost-per-acquisition; (C) Non-commercial/governmental advertising: uses persuasion to shape public perceptions and can function as stakeholder signaling (credibility, soft-power, reassurance to citizens, tourists, and investors).",
        "B": "(A) Direct-response campaign: because celebrity exposure usually generates immediate purchases and should be evaluated by short-term sales lift; (B) Branding campaign: coupons create a long-term image of generosity and should be measured by brand equity; (C) Non-commercial advertising: purely informational with no effect on credibility or investor perceptions.",
        "C": "(A) Branding campaign: designed solely to confuse competitors and has no measurable effect on consumer preference; (B) Direct-response campaign: measured only by click-through rate and never by actual sales; (C) National tourism ads: primarily commercial product placement and do not function as political or reputational signals.",
        "D": "(A) Branding campaign: identical in objective to direct-response advertising and should be judged by immediate conversion rates; (B) Direct-response campaign: focused on long-term loyalty metrics like net promoter score; (C) Non-commercial advertising: cannot influence stakeholder perceptions because governments and NGOs lack credibility as advertisers."
      },
      "correct_answer": "A",
      "generation_notes": "Created a three-part scenario mapping a long-horizon celebrity branding campaign, a short-term coupon direct-response tactic, and a government tourism campaign; options contrast correct theory-based mappings with common misconceptions about metrics and stakeholder effects.",
      "concepts_tested": [
        "Branding creates associative links that build long-term demand and brand equity",
        "Difference between branding and direct-response advertising (time horizon and metrics), and advertising as a persuasive tool for non-commercial actors affecting credibility and stakeholder signaling"
      ]
    },
    "pass_2_reason": "readability_too_high_20.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does inclusion of students with disabilities into general education classrooms, when implemented with appropriate accommodations and inclusive practices, tend to reduce stigma and potentially improve academic achievement?",
      "options": {
        "A": "Because merely placing students in the general classroom without supports automatically changes peers' attitudes.",
        "B": "Because regular interaction with typical peers provides social and academic models, and when supports are in place, these interactions give access to the curriculum and can lessen stigma.",
        "C": "Because inclusion lowers standards for all students, making it easier to pass without mastering content.",
        "D": "Because inclusion eliminates the need for teacher collaboration and professional development, which paradoxically reduces disruptions."
      },
      "correct_answer": "B",
      "source_article": "Special education",
      "x": 1.247140884399414,
      "y": 0.9108685851097107,
      "concepts_tested": [
        "Individualized, systematically monitored instruction with adapted materials/equipment and accessible settings to meet individual differences",
        "Inclusion/integration into general education as a mechanism to reduce stigma and potentially improve academic achievement",
        "Distinction between special education and remedial/general education, and the use of accommodations and supportive environments to serve disabled learners"
      ],
      "parent_concepts": [
        "Concept 1: Individualized Education Program (IEP) as the mechanism to tailor education to a student’s unique needs."
      ],
      "parent_articles": [
        "Individuals with Disabilities Education Act"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does placing students with disabilities in general education classrooms, when accompanied by appropriate accommodations and inclusive practices, tend to reduce stigma and can improve academic outcomes?",
      "options": {
        "A": "Because merely seating students in the general classroom without additional supports automatically changes classmates' attitudes.",
        "B": "Because regular interaction with non-disabled peers provides social and academic role models, and when accommodations allow access to the curriculum these interactions both lessen stigma and support learning.",
        "C": "Because inclusion lowers standards for all students, so students with disabilities appear to succeed without mastering the material.",
        "D": "Because inclusion removes the need for teacher collaboration and extra training, which somehow makes the classroom function better."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; emphasized mechanism (peer modeling + curriculum access with accommodations); retained original answer and distractors rephrased to be plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.2_vs_16",
    "pass_2_attempt": {
      "question": "River Valley School District evaluates three students for educational planning. Which set of placements and services best reflects the principles described in the article — i.e., individualized and systematically monitored instruction with adapted materials/equipment and accessible settings; use of inclusion/LRE to reduce stigma and support achievement; and correct distinction between special education and remedial/general-education responses? \n\nStudents: \n- Mia (8): average IQ, persistent decoding and reading-comprehension deficits consistent with dyslexia; limited response to classroom instruction; benefits from multisensory, research-based reading programs, text-to-speech, and small-group explicit instruction. \n- Carlos (12): schooling interrupted by internal displacement for three years; assessments show curricular gaps but typical cognitive profile and rapid gains when given targeted catch-up tutoring. \n- Jamal (10): uses a wheelchair and has moderate intellectual disability; requires accessible facilities, an adapted curriculum with individualized annual goals, frequent related services (speech/OT), and a low student–teacher ratio.",
      "options": {
        "A": "Mia: an IEP specifying dyslexia-specific, research-based instruction (small-group/pull-out as needed), presentation/response accommodations (text-to-speech, extended time) and inclusion in general classes where appropriate; Carlos: remedial catch-up via targeted RTI/MTSS interventions (no IEP) with progress monitoring; Jamal: individualized special-education placement (self-contained or specialized school if LRE requires it), with adapted curriculum, assistive equipment, related services, and legally binding IEP goals.",
        "B": "Mia: assigned only to a remedial tutoring class without an IEP because IQ is average; Carlos: given an IEP because his unpreparedness is severe; Jamal: fully included in the general classroom without a specialized curriculum to maximize social interaction.",
        "C": "Mia: placed in a segregated special school because dyslexia requires separation; Carlos: left in general education with no additional supports since gaps reflect life disruption; Jamal: mainstreamed with a single aide but no individualized curriculum or adapted facilities.",
        "D": "Mia: kept in general education with a single accommodation (extended time) but no systematic dyslexia intervention; Carlos: provided formal special-education services because he is behind academically; Jamal: placed part-time in a resource room but the school makes no major environmental adaptations or related-service commitments."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a vignette with three distinct cases to require mapping of each to appropriate responses: IEP and accommodations for SLD/dyslexia; RTI/remedial for disrupted schooling; specialized placement and related services for moderate intellectual disability and physical access needs. Options include plausible but incorrect policy misapplications.",
      "concepts_tested": [
        "individualized IEP and adapted materials/equipment",
        "inclusion and Least Restrictive Environment (LRE) versus segregation",
        "distinction between special education (IEP-based) and remedial/RTI general-education interventions"
      ]
    },
    "pass_2_reason": "readability_too_high_20.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why do barrier removal and reasonable accommodations enable equal participation for disabled people in employment and education?",
      "options": {
        "A": "They lower performance standards for disabled people.",
        "B": "They modify the environment and processes so that individuals can perform essential tasks or participate in activities without changing the required outcomes.",
        "C": "They primarily shift responsibility to the individual to adapt themselves to existing systems.",
        "D": "They guarantee automatic funding and enrollment for all applicants regardless of need."
      },
      "correct_answer": "B",
      "source_article": "Disability rights movement",
      "x": 1.2180979251861572,
      "y": 0.8639861345291138,
      "concepts_tested": [
        "Barrier removal and reasonable accommodations as mechanisms to enable equal participation (employment, housing, education)",
        "Cross-disability coalition and alignment with broader civil rights movements as strategic relationships in advocacy",
        "Legal frameworks (e.g., the ADA) as instruments that transform rights into practical protections and access"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do barrier removal and reasonable accommodations enable people with disabilities to participate equally in employment and education?",
      "options": {
        "A": "By reducing performance standards or expectations for people with disabilities.",
        "B": "By modifying the physical environment, policies, or procedures so individuals can perform essential tasks and meet the same required outcomes without lowering standards.",
        "C": "By shifting the primary responsibility onto the individual with a disability to adapt themselves to existing inaccessible systems.",
        "D": "By guaranteeing automatic funding, admission, or placement for all applicants with disabilities regardless of qualifications or demonstrated need."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the original background into a single clear question; removed historical and legal detail but preserved the core concept that accommodations change environments/processes to allow equal participation; rewrote options to be concise and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.6_vs_16",
    "pass_2_attempt": {
      "question": "The student Disability Coalition at Midvale University—an institution that receives substantial federal research grants—has identified three interlocking barriers: (1) campus buildings lack elevators and tactile signage, (2) the university's hiring office routinely denies interview-stage accommodations for applicants with mobility and sensory disabilities citing \"undue burden,\" and (3) university-run vocational training funnels some students with intellectual and developmental disabilities into segregated sheltered workshops that pay sub-minimum wages. Drawing on strategies exemplified by the U.S. disability rights movement (including the independent living movement, Section 504 actions, and the Americans with Disabilities Act), which single strategy is most likely to produce legally enforceable, broad-based improvements in physical access, employment accommodations, and deinstitutionalization while also maximizing political leverage through cross-disability alliance-building?",
      "options": {
        "A": "File complaints invoking Section 504 (because the university receives federal funds) and the ADA to require barrier removal and reasonable accommodations, while organizing a cross-disability coalition and partnering with mainstream civil-rights groups to pressure the university and obtain regulatory enforcement.",
        "B": "Campaign for a university-administered quota that reserves a fixed percentage of new hires and vocational placements for people with disabilities, negotiated exclusively with the university administration and implemented through separate sheltered programs.",
        "C": "Launch a high-profile charity fundraising drive (e.g., benefit pageants and donor campaigns) to pay for ad hoc accessibility modifications and direct support services for a small number of students, keeping advocacy separate from legal action.",
        "D": "Focus advocacy on promoting medicalized interventions and research funding at the university aimed at curing underlying impairments, arguing that such research will ultimately eliminate access barriers by reducing disability prevalence."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a realistic university vignette requiring application of legal instruments (Section 504/ADA), barrier removal/reasonable accommodations, and cross-disability coalition tactics; distractors reflect historically relevant but ineffective approaches (quotas/sheltered programs, charity model, medical/cure model).",
      "concepts_tested": [
        "Barrier removal and reasonable accommodations as mechanisms for equal participation",
        "Cross-disability coalition-building and alignment with broader civil rights movements",
        "Use of legal frameworks (Section 504, ADA) to convert rights into enforceable protections"
      ]
    },
    "pass_2_reason": "readability_too_high_28.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why are staff officers essential to enabling bidirectional information flow in command and control, and how does their role influence the speed and quality of decision-making?",
      "options": {
        "A": "They curate, translate, and fuse information from subordinate units with the commander's intent, filtering noise and synchronizing actions so that upward and downward communications are timely and actionable.",
        "B": "They centralize all decision authority, eliminating subordinate input to accelerate conclusions.",
        "C": "They hoard information at the staff level and release it only after lengthy verification, to prevent misinformation.",
        "D": "They focus solely on administrative tasks, providing little to no impact on information flow or decisions."
      },
      "correct_answer": "A",
      "source_article": "Command and control",
      "x": 1.306001901626587,
      "y": 0.7774438858032227,
      "concepts_tested": [
        "The mechanism by which C2 coordinates personnel, equipment, facilities, and procedures to plan, direct, coordinate, and control operations toward mission accomplishment.",
        "The role of military staff in enabling bidirectional information flow between a commander and subordinate units to support timely, accurate decision-making.",
        "The importance of standardized terminology and joint doctrine to enable interoperability and coherent C2 across organizations."
      ],
      "parent_concepts": [
        "Concept 1: Centralized vs decentralized general staffs and their trade-offs (top-down control vs situational focus, speed, and OODA loop performance)."
      ],
      "parent_articles": [
        "Staff (military)"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a command-and-control (C2) context, why are staff officers essential for bidirectional information flow between a commander and subordinate units, and how does their work affect the speed and quality of command decisions?",
      "options": {
        "A": "They curate, translate, and fuse reports from subordinate units with the commander’s intent, filter irrelevant data, and synchronize actions so that upward and downward communications are timely and operationally useful.",
        "B": "They concentrate all decision authority at the staff level, excluding subordinate input so commanders can make faster decisions without delay.",
        "C": "They withhold information at the staff level and only release it after prolonged verification, prioritizing accuracy so slow but error-free decisions are produced.",
        "D": "They perform mainly administrative tasks and have little effect on information flow or on the timeliness and quality of command decisions."
      },
      "correct_answer": "A",
      "simplification_notes": "Question shortened and clarified to focus on C2 bidirectional information flow between commander and subordinates; technical phraseology (curate, translate, fuse, filter, synchronize) retained for precision; distractors made plausible yet incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.4_vs_16",
    "pass_2_attempt": {
      "question": "A multinational joint task force is preparing a complex amphibious operation that requires tight synchronization of naval gunfire, close air support, logistics convoys, and cyber-electronic suppression. The task force commander must make timely decisions and ensure subordinate units execute orders while also receiving situation reports and intelligence updates from deployed units. Which description best captures the command-and-control (C2) mechanism that will most effectively enable planning, directing, coordinating, and controlling these operations while preserving bidirectional information flow and interoperability across services and allies?",
      "options": {
        "A": "A comprehensive C2 arrangement that combines the commander’s lawful authority with a specialized military staff and an integrated arrangement of personnel, equipment, communications, facilities, and procedures, together with standardized terminology and joint doctrine to enable timely, accurate bidirectional information flow and coherent planning, direction, coordination, and control.",
        "B": "A high‑bandwidth, automated communications backbone and AI-enabled orchestration layer that autonomously synchronizes assets across services, removing the need for human staff functions or agreed terminology among allied units.",
        "C": "Sole reliance on the commanding officer’s legal authority to issue orders, expecting subordinate units to adapt locally without dedicated staff mediation, common procedures, or standardized joint doctrine.",
        "D": "A distributed approach where each service and allied unit operates with its own proprietary procedures and terminology, relying on ad hoc translators at unit interfaces to reconcile information and deconflict operations in real time."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete joint operation scenario to require integration of personnel, equipment, communications, facilities, procedures, military staff role for bidirectional information flow, and the necessity of standardized terminology for interoperability; provided four plausible alternatives emphasizing different C2 emphases.",
      "concepts_tested": [
        "Integrated C2 arrangement of personnel, equipment, communications, facilities, and procedures to plan, direct, coordinate, and control operations",
        "Role of military staff in enabling bidirectional information flow between commander and subordinate units for timely, accurate decision-making",
        "Importance of standardized terminology and joint doctrine for interoperability across organizations and allied forces"
      ]
    },
    "pass_2_reason": "readability_too_high_21.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why is mental-state attribution (inferring beliefs, desires, and intentions) considered the mechanism by which we predict and explain others' behavior, rather than simply relying on observed actions and surface cues?",
      "options": {
        "A": "Because inferring hidden mental states provides a generative model of action that generalizes across contexts and accounts for behavior when the observable situation changes or when beliefs differ from reality.",
        "B": "Because past actions always predict future actions with perfect accuracy if you observe enough data, making mental-state inference unnecessary.",
        "C": "Because only brain imaging can reveal true mental states, since behavior alone cannot indicate beliefs or desires.",
        "D": "Because language development alone determines how reliably we can predict others' actions, regardless of observed behavior."
      },
      "correct_answer": "A",
      "source_article": "Theory of mind",
      "x": 1.288814663887024,
      "y": 1.0267553329467773,
      "concepts_tested": [
        "Mental-state attribution as the mechanism for predicting and explaining others' behavior (how observing behavior leads to inferring beliefs, desires, and intentions)",
        "Neurocognitive basis of ToM (involvement of specific brain regions such as mPFC, pSTS, precuneus, amygdala; effects of lesions and neuroimaging findings)",
        "Developmental emergence and variability (ToM as an innate potential requiring social experience; maturation of the prefrontal cortex; influence of culture and language)"
      ],
      "parent_concepts": [
        "Concept 1: Anthropomorphism as an innate cognitive tendency to attribute human form and traits to non-human entities, enabling social understanding and prediction."
      ],
      "parent_articles": [
        "Anthropomorphism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is attributing others' beliefs, desires, and intentions (mental-state attribution) taken to be the mechanism we use to explain and predict other people's behavior, instead of relying only on observed actions and surface cues?",
      "options": {
        "A": "Because inferring hidden mental states gives a generative model of action that generalizes across contexts and can predict behavior when the observable situation changes or when others hold false beliefs.",
        "B": "Because with enough data on past actions, future actions can be predicted perfectly from surface behavior alone, making mental-state inference unnecessary.",
        "C": "Because only neuroimaging can reveal true mental states, so behavior by itself cannot indicate beliefs or desires reliably.",
        "D": "Because language development alone determines how reliably one can predict others' actions, irrespective of observed behavior."
      },
      "correct_answer": "A",
      "simplification_notes": "Reworded the prompt concisely for undergraduate readers, removed detailed neuroanatomical and developmental examples while keeping the central comparison between mental-state inference and surface-cue prediction; kept all four options plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.2_vs_16",
    "pass_2_attempt": {
      "question": "A cognitive neuroscientist runs a coordinated program of studies to test three claims about theory of mind (ToM): (1) people predict and explain others' behavior by attributing mental states (beliefs, desires, intentions); (2) ToM depends on specific neural substrates such as the medial prefrontal cortex (mPFC), posterior superior temporal sulcus (pSTS)/temporoparietal junction (TPJ), precuneus, and amygdala; and (3) ToM is an innate potential that requires social experience and neural maturation (prefrontal synaptic development) and is modulated by language and culture. Which pattern of empirical findings would best support all three claims simultaneously?",
      "options": {
        "A": "Four-year-old children reliably pass explicit false-belief tasks while 2-year-olds fail; fMRI during false-belief stories shows right-lateralized activation in rTPJ, mPFC, pSTS and precuneus; patients with focal lesions in TPJ or frontal lobes perform poorly on false-belief tasks but normally on matched physical control tasks; longitudinal data show ToM gains parallel synaptic maturation of prefrontal cortex and increase with family conversational exposure to mental-state words; children from collectivist cultures show earlier mastery of knowledge-access tasks but later mastery of diverse-belief tasks compared with individualistic-culture peers.",
        "B": "Infants younger than 2 years routinely pass explicit Sally–Anne false-belief tests; PET and fMRI show diffuse increases across dorsolateral prefrontal cortex (DLPFC) but no selective activation in TPJ, pSTS, or mPFC during mental-state attribution; adults with TPJ lesions are unimpaired on false-belief tasks; cross-cultural comparisons show identical developmental order and timing of all ToM milestones regardless of language input.",
        "C": "Nine-month-old infants preferentially look longer at unexpected social outcomes, 4-year-olds pass explicit false-belief tasks, fMRI shows selective activation of mPFC, rTPJ/pSTS, precuneus and amygdala for mental-state versus physical control tasks, TPJ and frontal lesion patients exhibit deficits in mental-state but not in perceptual control tasks, longitudinal studies correlate increases in ToM performance with prefrontal maturation and amount of child–caregiver mental-state discourse, and bilingual or language-rich environments are associated with earlier acquisition of mental-state vocabulary and better ToM scores, while collectivist cultures emphasize knowledge-access earlier than appreciation of diverse beliefs.",
        "D": "Adults perform ToM tasks automatically and show no age-related decline; mirror-neuron regions in premotor cortex fully account for ToM task activation while temporoparietal and medial prefrontal areas are never implicated; individuals from different cultures show random variability in ToM milestones with no systematic relation to language exposure; patients with prefrontal lesions show enhanced ToM performance due to disinhibition."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a multi-method vignette requiring integration of behavioral false-belief results, selective neuroimaging and lesion evidence implicating mPFC/TPJ/pSTS/precuneus/amygdala, and developmental/modulatory influences of prefrontal maturation, language, and culture. Distractors include plausible but inaccurate patterns (mirror-neuron-only, diffuse activation, premature infant explicit performance, or contradictory lesion effects).",
      "concepts_tested": [
        "Mental-state attribution as mechanism for predicting/explaining behavior",
        "Neurocognitive basis of ToM (mPFC, pSTS/TPJ, precuneus, amygdala; lesion and fMRI evidence)",
        "Developmental emergence and variability (innate potential requiring social experience, prefrontal maturation, language and cultural modulation)"
      ]
    },
    "pass_2_reason": "readability_too_high_25.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the ecological, biocultural framework in medical anthropology explain health outcomes as emerging from interactions among biological, cultural, social, health-care, and environmental factors rather than from biology alone?",
      "options": {
        "A": "Because genes alone determine health outcomes, and context is irrelevant.",
        "B": "Because health results from dynamic interactions among biology, culture, social structure, health-care systems, and environment; these interactions shape meanings, behaviors, access, exposures, and physiological processes, producing diverse health outcomes.",
        "C": "Because biology and culture are completely separable and can be studied independently without loss of explanatory power.",
        "D": "Because cultural beliefs override all biological processes, making biology irrelevant for health outcomes."
      },
      "correct_answer": "B",
      "source_article": "Medical anthropology",
      "x": 1.2163106203079224,
      "y": 0.9946538209915161,
      "concepts_tested": [
        "Concept 1: The relationship and historical interaction between medicine and anthropology, including how hospital-based clinical education and the “clinical gaze” affected the status and use of ethnography in medicine and contributed to the field's evolution.",
        "Concept 2: The emergence and development of medical anthropology in the 1960s–1970s, including debates and the role of professional identity in distinguishing it from, yet relating to, medicine.",
        "Concept 3: The core theoretical stance of medical anthropology—an ecological, multidimensional, biocultural framework that analyzes how culture, society, health care systems, health, and illness are interconnected."
      ],
      "parent_concepts": [
        "Concept 1: Culture as a determinant of psychiatric classifications and their social uses (the idea that diagnoses are culturally constructed and not universally fixed)."
      ],
      "parent_articles": [
        "Cross-cultural psychiatry"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does the ecological, biocultural framework in medical anthropology explain health outcomes as emerging from interactions among biological, cultural, social, health-care, and environmental factors rather than from biology alone?",
      "options": {
        "A": "Because genes alone determine health outcomes, and social or cultural context has no effect.",
        "B": "Because health emerges from dynamic interactions among biology, culture, social structure, health-care systems, and the environment; these interactions shape meanings, behaviors, exposures, access, and physiological processes, producing diverse health outcomes.",
        "C": "Because biology and culture are entirely separable, so studying them independently provides a complete explanation of health outcomes.",
        "D": "Because cultural beliefs alone determine illness and biological processes can be ignored when explaining health."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the original question for clarity and concision; removed extended historical detail while keeping the core theoretical claim that health arises from biocultural and ecological interactions. Options were made concise and kept plausible alternatives.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.8_vs_16",
    "pass_2_attempt": {
      "question": "Consider this historical vignette: a 1920s medical faculty reorganizes training around hospital-based clinical instruction and laboratory experimentation, privileging the ‘clinical gaze’ and Claude Bernard–style experimental methods. Ethnographic reports and medical geographies produced by rural practitioners increasingly lose institutional standing. By the 1960s–1970s anthropologists consolidate a subfield called medical anthropology. Which of the following statements best explains how the institutional shift to hospital clinical education produced the later form and theoretical stance of medical anthropology?",
      "options": {
        "A": "The ascendancy of hospital clinical education and experimental methodology marginalized practitioners’ ethnographic knowledge within medicine, but ethnography persisted in primary care, rural medicine and public health; social anthropology then adopted ethnography as a marker of professional identity and diverged from medicine while maintaining ties, and in the 1960s–1970s medical anthropology emerged as a coherent field that uses an ecological, multidimensional biocultural framework to analyze how culture, society and health-care systems shape health and illness.",
        "B": "The dominance of the clinical gaze caused a complete and permanent split between medicine and anthropology, eliminating any ethnographic influence in health; medical anthropology therefore arose in the 1960s–1970s as a purely philosophical critique with no methodological continuity to earlier ethnographic work and restricted its study to non‑Western medical systems only.",
        "C": "Because hospital-based experimentalism proved inadequate, medicine reabsorbed ethnography immediately after the 1920s and transformed biomedicine into an explicitly biocultural discipline; medical anthropology was simply the new name physicians gave to this integrated approach during the interwar period rather than a distinct anthropological subfield consolidated in the 1960s–1970s.",
        "D": "The shift to laboratory and hospital training led practitioners to formalize folk and popular medicine into biomedical theory, producing a unified global medical system; medical anthropology developed in the 1960s–1970s primarily to document this homogenization and to catalog universal nosological categories across cultures."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a vignette linking hospital clinical training and experimental methods to marginalization of ethnography, then asked which option correctly connects that history to the professionalization and biocultural, ecological theoretical stance of medical anthropology formed in the 1960s–1970s.",
      "concepts_tested": [
        "historical relationship between clinical medicine and ethnography",
        "emergence and professionalization of medical anthropology in the 1960s–1970s",
        "biocultural, ecological, and multidimensional theoretical framework of medical anthropology"
      ]
    },
    "pass_2_reason": "readability_too_high_20.0_vs_16"
  },
  {
    "original_question": {
      "question": "How does a regulatory architecture that combines designated authorities with self-regulatory organizations enhance the capacity to monitor, enforce, and inform financial markets?",
      "options": {
        "A": "It reduces the need for public disclosures, making markets more private and efficient.",
        "B": "It allows self-regulation to fully replace formal oversight, eliminating government rules.",
        "C": "It uses formal rule-making and supervision by designated authorities to set standards, while SROs provide ongoing, industry-specific monitoring and timely enforcement, improving information flow to investors.",
        "D": "It concentrates control in a single institution, eliminating cross-checks among agencies."
      },
      "correct_answer": "C",
      "source_article": "Financial regulation",
      "x": 1.3133965730667114,
      "y": 0.8685344457626343,
      "concepts_tested": [
        "Concept 1: Regulation is justified by systemic risk and information asymmetry, which justify constraining certain contracts and supervising financial activity.",
        "Concept 2: The regulatory architecture (designated authorities and self-regulatory organizations) and mechanisms (trading acts, disclosure requirements) function to monitor, enforce, and inform the market.",
        "Concept 3: The aims of regulation (market confidence, financial stability, consumer protection, reducing financial crime) are connected to achieving a safer, more transparent financial system."
      ],
      "parent_concepts": [
        "Concept 2: The expansion and variation of definitions/regulations across jurisdictions—money laundering as broader than cash transactions, including any illicitly generated assets, and the differing legal views (e.g., US vs. UK) and regulatory approaches.",
        "Concept 2: Deposit insurance as a component of the financial safety net, interacting with fractional-reserve banking and bank solvency risk.",
        "Regulation and financial stability: the relationship between banking regulation, capital requirements, and maintaining stability in the economy.",
        "Concept 3: The regulatory/supervisory role of central banks in maintaining financial stability and preventing bank runs, and the relationship to commercial banks."
      ],
      "parent_articles": [
        "Money laundering",
        "Deposit insurance",
        "Bank",
        "Central bank"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does a regulatory framework that combines designated public authorities with self-regulatory organizations (SROs) strengthen the monitoring, enforcement, and information available in financial markets?",
      "options": {
        "A": "By reducing public disclosure requirements and shifting more transactions into private arrangements, which makes markets more efficient but less transparent.",
        "B": "By allowing SROs to fully replace statutory oversight, removing the need for formal government supervision and rule-making.",
        "C": "By having designated authorities set standards and supervise broadly, while SROs provide continuous, industry-specific monitoring and timely enforcement, thereby improving disclosures and information for investors.",
        "D": "By centralizing control in a single institution, eliminating overlapping checks between agencies and simplifying enforcement lines."
      },
      "correct_answer": "C",
      "simplification_notes": "Question rephrased to clearly state the combined roles of designated authorities and SROs; language simplified and condensed; retained focus on monitoring, enforcement, and information flow; all options made plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.3_vs_16",
    "pass_2_attempt": {
      "question": "A national regulator is assessing a newly designed leveraged derivative that banks plan to sell through independent financial advisors. The product creates significant interbank counterparty exposure (raising systemic risk) and is highly complex for nonprofessional clients (creating information asymmetry and principal–agent concerns). Which regulatory package best reflects the justifications for regulation (systemic risk and information asymmetry), the described supervisory architecture (designated authorities and possible SRO delegation), and the stated aims of regulation (market confidence, financial stability, consumer protection, reduction of financial crime)?",
      "options": {
        "A": "Prohibit the product outright for all buyers nationwide to eliminate systemic exposure; assign enforcement to a newly created SRO with no further obligations on banks or advisors.",
        "B": "Restrict sales to qualified institutional investors only, require banks to hold higher capital/resilience buffers tied to notional exposures, mandate standardized disclosure and suitability assessments for any permitted sales, and retain primary supervision with the national financial authority while permitting an SRO to assist with market monitoring.",
        "C": "Allow unrestricted retail distribution provided firms attach a short, plain‑language brochure and label the product as 'high risk'; rely primarily on market practices and ex post case law to resolve disputes.",
        "D": "Delegate full oversight to an industry SRO that issues nonbinding conduct guidelines and requires firms to offer internal ethics training for advisors, without formal disclosure or capital requirements."
      },
      "correct_answer": "B",
      "generation_notes": "Created a concrete scenario requiring selection of regulatory measures that address systemic risk and information asymmetry, incorporate designated authority + SRO roles, and advance aims (stability, confidence, consumer protection).",
      "concepts_tested": [
        "Systemic risk as justification for public-interest constraints",
        "Information asymmetry and limits on freedom of contract for retail/principal–agent problems",
        "Regulatory architecture: designated authorities and SRO delegation, trading/disclosure mechanisms",
        "Aims of regulation: market confidence, financial stability, consumer protection, reducing financial crime"
      ]
    },
    "pass_2_reason": "readability_too_high_23.4_vs_16"
  },
  {
    "original_question": {
      "question": "How do scaffold properties influence the coordination between cells and signaling factors to form functional tissue, and why is scaffold-mediated control of signaling important?",
      "options": {
        "A": "The scaffold's porosity only affects mechanical stability; signaling factors diffuse independently of scaffold cues.",
        "B": "The scaffold acts as a reservoir and conduit for signaling factors, shaping local concentration gradients and presenting physical cues that direct cell fate and organization; without such scaffold-mediated cues, cells may proliferate without forming coherent, functional tissue.",
        "C": "Signaling factors are unnecessary when cells are seeded on a scaffold, because the scaffold's extracellular matrix alone determines all cell behaviors.",
        "D": "The scaffold's chemical composition alone dictates tissue outcome, while cell type and signaling factors play a negligible role."
      },
      "correct_answer": "B",
      "source_article": "Tissue engineering",
      "x": 1.9266200065612793,
      "y": 1.1176197528839111,
      "concepts_tested": [
        "The triad of components: cells, scaffolds (matrix), and signaling factors work together to form functional tissue.",
        "Scaffold/biomaterial design provides mechanical structure and cues that guide tissue growth and function (biomimetic environments, extracellular matrices).",
        "The field as an interdisciplinary application of engineering principles to biology with goals to restore, maintain, or replace tissue function, and its relation to regenerative medicine (including the emphasis on stem/progenitor cells)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do engineered scaffolds influence the interaction between cells and biochemical signaling to produce organized, functional tissue, and why is scaffold-mediated control of signals important?",
      "options": {
        "A": "Scaffold porosity only changes mechanical stability; biochemical signals diffuse and act independently of scaffold structure.",
        "B": "Scaffolds function as reservoirs and conduits for signaling molecules and provide physical cues that shape local concentration gradients and cell behavior, directing cell fate and spatial organization; without these scaffold-mediated signals cells may proliferate but fail to form coherent, functional tissue.",
        "C": "Biochemical signaling is unnecessary once cells are placed on a scaffold because the scaffold’s extracellular-matrix–like structure alone determines all cell behaviors and tissue outcome.",
        "D": "The scaffold’s chemical composition alone determines the tissue outcome; the specific cell type and signaling factors have little influence."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded for clarity and concision, emphasized scaffold roles (reservoir, gradient formation, physical cues) and the consequence of lacking scaffold-mediated signaling; kept original scientific concepts and correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.1_vs_16",
    "pass_2_attempt": {
      "question": "You are designing a 3-cm diameter, load-bearing articular cartilage implant to repair a focal knee defect. Which experimental construct best exemplifies the tissue-engineering triad (cells, scaffold/matrix, signaling/physicochemical cues), employs biomimetic scaffold design to provide mechanical support and instructive extracellular-matrix (ECM) cues, and aligns with regenerative-medicine emphasis on stem/progenitor cells for durable tissue restoration?",
      "options": {
        "A": "Autologous mature chondrocytes expanded in monolayer and seeded onto a dense, non-porous polycaprolactone (PCL) mesh; culture medium supplemented with TGF-β1 but no mechanical conditioning or controlled pore architecture.",
        "B": "Autologous bone-marrow-derived mesenchymal stem cells (MSCs) seeded into a biodegradable collagen–hyaluronic acid hydrogel reinforced with aligned PLGA fibers to achieve structural stiffness, engineered porosity of $100$–$300\\,\\mu\\text{m}$, sustained TGF-β3 delivery, and cyclic compressive loading in a bioreactor prior to implantation.",
        "C": "Allogeneic dermal fibroblasts seeded onto a decellularized cortical bone scaffold (non-optimized for cartilage ECM) with VEGF supplementation to promote vascular ingrowth and no chondrogenic growth factors.",
        "D": "iPSC-derived chondrocytes plated onto a thin, non-biodegradable silicone sheet with insulin-like growth factor (IGF-1) in static culture; silicone provides long-term mechanical support but is not remodeled by host tissue."
      },
      "correct_answer": "B",
      "generation_notes": "Created a realistic cartilage-repair scenario comparing four constructs that differ in cell source, scaffold biomimicry/degradability/porosity, and signaling/mechanical conditioning; option B integrates the triad, biomimetic ECM cues, mechanical competence, and MSC-based regenerative-medicine emphasis.",
      "concepts_tested": [
        "tissue-engineering triad (cells, scaffold, signaling)",
        "scaffold biomimicry and mechanical/physicochemical cues guiding tissue formation",
        "interdisciplinary/regenerative medicine emphasis on stem/progenitor cells and bioreactor conditioning"
      ]
    },
    "pass_2_reason": "readability_too_high_22.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the fit principle in ergonomics—designing the job, equipment, and environment to match human capabilities and limitations—tend to reduce errors and injuries?",
      "options": {
        "A": "By increasing task speed to outpace fatigue, which paradoxically lowers error likelihood.",
        "B": "By reducing the need for compensatory movements and overexertion caused by mismatches between user and task, thereby lowering biomechanical strain and cognitive load.",
        "C": "By standardizing equipment for everyone, so all users perform identically regardless of size or strength.",
        "D": "By transferring all safety risk to training rather than to design improvements that accommodate human variation."
      },
      "correct_answer": "B",
      "source_article": "Ergonomics",
      "x": 1.4136414527893066,
      "y": 1.0607210397720337,
      "concepts_tested": [
        "The fit principle: fitting the job, equipment, and environment to human capabilities/limitations to reduce errors and injuries.",
        "System-level optimization: designing to optimize human well-being and overall system performance through human–equipment–environment interactions.",
        "Multidisciplinary integration: leveraging psychology, physiology, biomechanics, design, and related fields to study behavior and inform design decisions."
      ],
      "parent_concepts": [
        "Concept 1: Separation of studio spaces (studio floor, PCR, CAR) to manage noise, heat, and workflow, and the resulting impact on production efficiency and safety.",
        "Concept 3: Role of ergonomic design in reducing usability barriers and improving safe, correct PPE usage",
        "Concept 2: Genre- and ergonomics-driven design principles (why certain controllers or features—like steering wheels for driving games or shoulder triggers—are favored for specific game types, reflecting design-for-use principles)."
      ],
      "parent_articles": [
        "Television studio",
        "Personal protective equipment",
        "Game controller"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to the ergonomics 'fit' principle—designing the job, equipment, and environment to match human capabilities and limitations—why does this approach reduce human errors and work-related injuries?",
      "options": {
        "A": "By increasing task speed so workers complete tasks before fatigue develops, which supposedly lowers error rates.",
        "B": "By reducing the need for compensatory movements and overexertion caused by mismatches between user and task, thereby lowering biomechanical strain and cognitive load.",
        "C": "By standardizing equipment for everyone so all users perform identically regardless of differences in size, strength, or ability.",
        "D": "By shifting safety responsibility onto worker training and procedures rather than changing design to accommodate human variation."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; technical phrase 'fit principle' explained; options made concise and plausible while preserving the original concepts and correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.0_vs_16",
    "pass_2_attempt": {
      "question": "An automotive assembly plant has a rising incidence of repetitive strain injuries (RSIs) and an increase in assembly errors attributed to worker fatigue and confusing machine displays. Management is considering four intervention plans. Which plan best exemplifies the ergonomics principles of \"fit\" (matching job, equipment, and environment to human capabilities/limitations), system-level optimization of human well‑being and overall performance, and multidisciplinary integration of psychology, biomechanics, design and organizational change?",
      "options": {
        "A": "Purchase new ergonomic chairs and anti‑fatigue floor mats for all workstations and require workers to use them during shifts.",
        "B": "Redesign the machine operator interface with larger icons, add color coding for alerts, and provide a one‑hour training session on the new interface.",
        "C": "Perform a job and task analysis; retrofit stations with height‑adjustable fixtures sized from anthropometric data; redesign displays to reduce cognitive load; reorganize task pacing and rotation to limit repetitive exertions; implement participatory ergonomics and training; and monitor injury and productivity metrics to iteratively refine the system.",
        "D": "Install automated sensors that halt production when an error is detected and enforce a disciplinary policy for operators identified as responsible for repeated errors."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a workplace scenario with four plausible interventions: A (physical-only), B (cognitive-only), C (integrated multidisciplinary/system-level solution — correct), D (technology + punitive organizational change). The question tests recognition of the fit principle, system optimization, and multidisciplinary integration.",
      "concepts_tested": [
        "Fit principle: matching job/equipment/environment to human capabilities and limitations",
        "System-level optimization: designing for human well‑being and overall system performance",
        "Multidisciplinary integration: applying psychology, biomechanics, design, and organizational ergonomics"
      ]
    },
    "pass_2_reason": "readability_too_high_20.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the transnational, liminal nature of maritime security—where threats like piracy and territorial disputes cross boundaries and involve multiple jurisdictions—shape why coordinated, multi-stakeholder responses are necessary for protecting global supply chains?",
      "options": {
        "A": "Because a single nation's naval power can unilaterally secure all sea areas and shipping lanes without cooperation.",
        "B": "Because threats can move across borders and legal regimes, requiring harmonized standards, cross-border information sharing, and joint operations to close enforcement gaps and safeguard trade.",
        "C": "Because maritime threats are confined to coastal waters and do not affect international shipping once past a country's territorial waters.",
        "D": "Because port facilities can operate security in isolation, making international cooperation unnecessary."
      },
      "correct_answer": "B",
      "source_article": "Maritime security",
      "x": 1.5133302211761475,
      "y": 0.8340768218040466,
      "concepts_tested": [
        "Concept 1: Evolution of maritime security as a cross-disciplinary, cross-jurisdictional framework that links national security with economic development, environment, and human security.",
        "Concept 2: International mechanisms and standards (e.g., ISPS Code, SOLAS Chapter XI-2) that operationalize and regulate maritime security across ports, ships, and facilities.",
        "Concept 3: The transnational, liminal nature of maritime security, illustrating how threats like piracy and territorial disputes involve multiple jurisdictions and affect global supply chains and regional stability."
      ],
      "parent_concepts": [
        "Concept 2: Modern piracy tactics and defense mechanisms (how attackers operate with small boats and firearms and how guards, water cannons, radar, etc., mitigate risk)"
      ],
      "parent_articles": [
        "Piracy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Given that maritime security is transnational and liminal—threats such as piracy, trafficking, and territorial disputes cross borders and involve multiple legal jurisdictions—why are coordinated, multi‑stakeholder responses (states, navies, ports, industry, and international regimes such as the ISPS Code and SOLAS Chapter XI‑2) necessary to protect global supply chains?",
      "options": {
        "A": "Because a single nation's naval power can unilaterally secure all sea areas and commercial routes without outside cooperation.",
        "B": "Because threats traverse borders and legal regimes, so harmonized standards, cross‑border information sharing, and joint operations are needed to close enforcement gaps and safeguard trade.",
        "C": "Because maritime threats are confined to coastal waters and stop affecting international shipping once vessels pass a state's territorial sea.",
        "D": "Because individual port facilities can fully manage security in isolation, making international coordination unnecessary."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the original long question into a concise undergraduate level prompt, retained key terms (transnational, liminal, ISPS Code, SOLAS Chapter XI‑2) and the logic linking cross‑jurisdictional threats to the need for coordinated multi‑actor responses; options were made succinct and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_28.2_vs_16",
    "pass_2_attempt": {
      "question": "Country A is a littoral state whose Exclusive Economic Zone (EEZ) experiences a surge in piracy, illegal fishing, and periodic disruption of commercial shipping because of a disputed maritime boundary with neighboring Country B. A multinational shipping consortium asks for a comprehensive, lawful security strategy that preserves trade flow, protects the marine environment and crew welfare, and recognises the cross-jurisdictional nature of the problem. Which of the following strategies best reflects the contemporary, transnational conception of maritime security and correctly applies international mechanisms and standards?",
      "options": {
        "A": "Adopt and implement the ISPS Code through SOLAS Chapter XI-2 for port and ship security; establish regional Maritime Domain Awareness (MDA) and an Information Sharing Centre under a Djibouti/ReCAAP-style arrangement; harmonize domestic criminal laws in line with UNCLOS and relevant UN Security Council resolutions to enable prosecution; permit Privately Contracted Armed Security Personnel (PCASP) only under ISO 28007-certified rules and explicit flag‑state Rules for Use of Force (RUF); and coordinate capacity‑building and joint patrols with neighbouring states.",
        "B": "Prioritise unilateral naval sea‑denial and frequent military patrols to assert control of disputed waters, supplemented by expanded coastal artillery and no‑fishing exclusion zones enforced solely by Country A’s navy, with minimal engagement of international law or regional partners.",
        "C": "Focus only on hardening port infrastructure and cargo inspection (expanded ISPS physical measures and container scanning) while leaving on‑water responses to shipping companies and insurers, without establishing regional information sharing or legal harmonisation.",
        "D": "Privatise maritime security entirely by contracting multiple private armed security firms to protect all transiting vessels, allowing them to operate without prior flag‑state authorisation to maintain maximum operational flexibility, and rely on market mechanisms (higher insurance premiums) to deter illegal actors."
      },
      "correct_answer": "A",
      "generation_notes": "Created a scenario combining piracy, IUU fishing, and a boundary dispute to require solutions spanning legal, regulatory, operational, and cooperative measures; options contrast comprehensive international/regulatory approaches with unilateral, narrowly focused, or privatized responses.",
      "concepts_tested": [
        "Evolution of maritime security as cross-disciplinary and cross-jurisdictional (linking national security, economic development, environment, human security)",
        "International mechanisms and standards operationalizing maritime security (ISPS Code, SOLAS Chapter XI-2, UNCLOS, ISO 28007, regional agreements)",
        "Transnational/liminal nature of maritime security requiring regional cooperation, maritime domain awareness, harmonised laws and coordination across flag, coastal and port states"
      ]
    },
    "pass_2_reason": "readability_too_high_20.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does conceptualizing statecraft as an integrated art—combining science (systematic knowledge), art (judgment and tact), and virtue (moral character)—enable a statesman to govern with a universal scope that covers both internal affairs and international relations?",
      "options": {
        "A": "Because reliance on scientific analysis alone yields general laws that are always directly transferable to every country, ignoring local variability.",
        "B": "Because artistic intuition alone can respond to changes but cannot provide consistent, principled constraints or verify outcomes.",
        "C": "Because virtue alone ensures legitimacy but cannot coordinate complex policies and long-term planning across domestic and foreign arenas.",
        "D": "Because the three elements reinforce each other: science provides reliable methods, art translates methods to context, virtue supplies legitimacy and restraint, enabling unified action across internal and external demands."
      },
      "correct_answer": "D",
      "source_article": "Statecraft",
      "x": 1.0059576034545898,
      "y": 0.7277348637580872,
      "concepts_tested": [
        "Statecraft as an integrated art: combines science, art, and virtue, with a universal scope as discussed by Plato and More.",
        "Narrow vs broad conceptions: narrow view focusing on managing interstate relations for one’s country vs broad view encompassing the study and governance of states and societies.",
        "Informal influence and mechanisms: elder statesmen and informal politics as mechanisms that extend influence beyond official office."
      ],
      "parent_concepts": [
        "Economic diplomacy as statecraft: using economic tools (incentives, sanctions) to achieve foreign policy objectives."
      ],
      "parent_articles": [
        "Economic diplomacy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does treating statecraft as an integrated art—combining science (systematic knowledge), art (judgment and tact), and virtue (moral character)—allow a statesman to govern with a universal scope that covers both internal affairs and international relations?",
      "options": {
        "A": "Because relying only on scientific, systematic analysis produces general laws that can be applied unchanged to every country, making judgment and moral qualities unnecessary.",
        "B": "Because artistic intuition and practical judgment alone can adapt to changing situations but cannot by themselves create stable, verifiable principles or ensure consistent outcomes.",
        "C": "Because moral virtue alone gives a leader legitimacy and trust, but cannot by itself design, coordinate, or implement complex domestic and foreign policies.",
        "D": "Because the three elements reinforce one another: science supplies reliable methods and knowledge, art translates and applies those methods to specific contexts, and virtue provides legitimacy and restraint, enabling coherent action across both internal and external demands."
      },
      "correct_answer": "D",
      "simplification_notes": "Question shortened and clarified; the three components were defined in parentheses; options were rephrased to be concise and academically precise while keeping all four plausible; historical references (Plato, More) were omitted for brevity but the conceptual content was preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.7_vs_16",
    "pass_2_attempt": {
      "question": "A newly elected prime minister assembles an advisory council to address a compound crisis (economic contraction, rising civil unrest, and hostile trade restrictions). Four contributions are made: (1) the Chief Economist proposes a program of evidence-based institutional reform and predictive modeling as the \"science of governance\"; (2) the Foreign Secretary advocates concentrating resources on managing bilateral relations and tactical advantage in international negotiations; (3) a respected retired president offers to act as an unofficial mediator and moral exemplar, advising behind the scenes; (4) the Political Director argues for adaptive rhetoric, coalition-building, and discretionary policycraft as the \"art of ruling.\" Which combination of these contributions best exemplifies (a) the Platonic–Morean integrated view of statesmanship (science + art + presupposed personal virtue), (b) the broad conception of statecraft that covers building and running states both internally and externally, and (c) recognition of informal mechanisms of influence exercised by elder statesmen?",
      "options": {
        "A": "Contributions (1) and (4) only — emphasizing science and art of governance but excluding explicit interstate management and elder informal influence.",
        "B": "Contributions (1), (3), and (4) — combining institutional science, the art of ruling, and the informal moral/advisory role of an elder statesman, but not prioritizing interstate tactics.",
        "C": "Contributions (2) and (4) only — prioritizing tactical interstate management and political craft while omitting the institutional science and elder statesman role.",
        "D": "Contributions (1), (2), (3), and (4) — integrating institutional science, tactical interstate management, the art of ruling, and the informal advisory/moral role of an elder statesman."
      },
      "correct_answer": "D",
      "generation_notes": "Constructed a policy-crisis scenario with four concrete advisory roles; asked which combination captures Platonic/Morean tripartite statesmanship, the broad internal/external scope of statecraft, and elder-statesman informal influence. Correct choice is the all-inclusive option.",
      "concepts_tested": [
        "Platonic-Morean integrated conception of statesmanship (science, art, virtue)",
        "Narrow versus broad conceptions of statecraft",
        "Informal political influence of elder statesmen"
      ]
    },
    "pass_2_reason": "readability_too_high_28.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why can a country condemn a specific illegal act by a state (such as occupation) without denying that state's overall status as a sovereign state, and what principle does this illustrate about diplomatic recognition?",
      "options": {
        "A": "Because recognition of states and recognition of governments are distinct judgments; a state’s sovereignty can be acknowledged while criticising or rejecting particular actions by its government.",
        "B": "Because condemnation of an act automatically revokes recognition of the state itself.",
        "C": "Because UN membership requires uniform recognition of both the state and its government, so opposing an act still implies non-recognition of the state.",
        "D": "Because non-recognition of any act by a state always implies non-recognition of the state's existence as a state."
      },
      "correct_answer": "A",
      "source_article": "Diplomatic recognition",
      "x": 0.6563746929168701,
      "y": 0.5087937712669373,
      "concepts_tested": [
        "Concept 1: Implicit vs explicit recognition and the signaling role of actions (treaties, state visits) in establishing recognition, including de facto vs. de jure and partial recognition.",
        "Concept 2: The relationship between recognition and international organization membership, including how broad recognition can enable entry and how UN voting can serve as an implicit form of recognition.",
        "Concept 3: Distinction between recognizing states and recognizing governments, and the idea that non-recognition of specific acts does not automatically negate recognition of the state, reflecting policy considerations in diplomatic practice."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why can a state condemn a specific illegal act by another state (for example, an occupation) without denying that entity's status as a sovereign state, and what principle of diplomatic recognition does this illustrate?",
      "options": {
        "A": "Recognition of a state is distinct from approval of particular acts or of its government; a state can acknowledge another's statehood while protesting or refusing to accept a specific illegal action.",
        "B": "Condemning an illegal act automatically revokes recognition of the offending state, so protest equals derecognition.",
        "C": "Because United Nations membership requires uniform recognition of both a state's government and every act it takes, opposing an act necessarily means not recognizing the state.",
        "D": "Refusal to recognize an individual act by a state always implies denial of the state's existence and sovereignty."
      },
      "correct_answer": "A",
      "simplification_notes": "Wording made more concise and focused on the core legal principle: separation between recognising a state's existence and condemning specific acts or governments. Removed lengthy examples and procedural detail while keeping the tested distinction intact.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.5_vs_16",
    "pass_2_attempt": {
      "question": "Freedonia unilaterally declared independence from Oldland after an armed uprising and has effective control over most of the territory. In Year 1 the following actions occurred: Country X concluded a bilateral trade treaty with Freedonia and received a ministerial delegation; Country Y voted in the UN General Assembly in favour of Freedonia's admission to an international organization restricted to states; Country Z hosted a Freedonian head of state on a state visit but simultaneously issued a public statement that the visit “does not constitute recognition”; Country W issued an explicit declaration of de jure recognition; and Country V publicly condemned Freedonia's annexation of a small neighbouring district as illegal but maintained diplomatic ties. In Year 3 Freedonia's government was overthrown in a coup. According to the principles of diplomatic recognition in international law, which of the following summaries is most accurate?",
      "options": {
        "A": "X's treaty and ministerial visit amount to implicit de facto recognition; Y's favourable UN vote is an implicit recognition; Z's state visit automatically constitutes recognition despite the disclaimer; W's de jure recognition is legally stronger than de facto recognition; V's condemnation of the annexation implies it does not recognise Freedonia as a state; the coup in Year 3 automatically terminates all prior recognition of Freedonia.",
        "B": "X's treaty denotes full de jure recognition; Y's UN vote does not imply recognition because UN membership is separate from statehood; Z's visit with a disclaimer prevents any form of recognition; W's de jure recognition is merely political and no different from de facto; V's protest of the annexation is equivalent to derecognition of the state; after the coup other states cannot recognise the new government until the UN approves.",
        "C": "X's treaty and ministerial contact are persuasive evidence of implicit recognition, normally at least de facto; Y's affirmative UN vote functions as an implicit recognition by Y; Z's state visit accompanied by an explicit disclaimer allows Z to avoid implying recognition; W's explicit de jure recognition is a stronger, formal acknowledgement than de facto recognition; V's objection to the annexation does not necessarily negate its recognition of Freedonia as a state; after the coup prior recognition of the state normally persists, though other states may choose whether to recognise the new government separately.",
        "D": "X and Z both implicitly recognised Freedonia because any treaty or visit is automatic recognition regardless of statements; Y's UN vote is irrelevant to recognition; W's de jure recognition is weaker than de facto in practice; V's condemnation of the annexation means V must withdraw diplomatic relations; recognition of a government always equals recognition of the state and is irrevocable even after a coup."
      },
      "correct_answer": "C",
      "generation_notes": "Created a concrete multi-actor scenario (Freedonia) to test implicit vs explicit recognition (treaties, visits), de facto vs de jure, UN voting as implicit recognition, and distinction between state recognition and government recognition including effects of illegal acts and coups.",
      "concepts_tested": [
        "Implicit vs explicit recognition (treaties, state visits) and de facto vs de jure",
        "UN voting and international organisation membership as a form of implicit recognition; partial/non-recognition consequences",
        "Distinction between recognising a state and recognising its government; non-recognition of specific acts not equating to non-recognition of the state"
      ]
    },
    "pass_2_reason": "readability_too_high_21.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why does civilian oversight and transparency function as an accountability mechanism for the security sector, and through what mechanism does it influence security actors' behavior?",
      "options": {
        "A": "It clarifies lines of authority but leaves incentives intact, so actors continue to act as before.",
        "B": "It reduces information gaps and exposes misconduct, altering risk-reward calculations and increasing the likelihood of compliance through public scrutiny and potential sanctions.",
        "C": "It primarily diverts resources to oversight bodies, reducing operational effectiveness and accountability.",
        "D": "It guarantees full, real-time transparency for all security actions, ensuring perfect accountability."
      },
      "correct_answer": "B",
      "source_article": "Security sector governance and reform",
      "x": 1.2202918529510498,
      "y": 0.8768582940101624,
      "concepts_tested": [
        "Concept 1: Applying general governance principles (rule of law, accountability, transparency) to the security sector through SSR/SSG.",
        "Concept 2: Oversight and transparency as mechanisms to ensure accountability within the security sector (e.g., oversight of armed forces, transparency of intelligence agencies).",
        "Concept 3: The relationship between SSR/SSG and broader outcomes, such as stability, post-conflict recovery, and democratization."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do civilian oversight and transparency serve as accountability mechanisms for the security sector, and how do they change security actors' behavior?",
      "options": {
        "A": "They clarify chains of command and formal authority but leave incentives unchanged, so actors continue to behave as before.",
        "B": "They reduce information asymmetries and expose misconduct, altering security actors' risk–reward calculations so public scrutiny and possible sanctions make compliance more likely.",
        "C": "They mainly reallocate resources to oversight bodies, which reduces operational effectiveness and thus weakens, rather than strengthens, accountability.",
        "D": "They guarantee complete, real-time disclosure of all security actions, producing perfect accountability and eliminating misconduct."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was made more concise and direct; preserved the mechanism that oversight/transparency reduces information gaps and changes incentives via scrutiny and sanctions. Distractors were kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "In the fictional post-conflict state of Azania, the transitional government must design a security sector reform (SSR) program intended to produce good security sector governance (SSG) and support democratization and long-term stability. Which of the following policy packages best operationalizes the core SSG principles—rule of law, accountability and transparency—and is therefore most likely to strengthen public trust and stabilize Azania?",
      "options": {
        "A": "Grant the executive broad emergency powers to centralize command of all security institutions, classify intelligence operations as entirely secret to protect national security, and rapidly contract private military and security companies (PMSCs) to secure borders and infrastructure.",
        "B": "Enact clear, publicly accessible legislation defining the lawful uses of force; establish a civilian parliamentary oversight committee with budgetary review and complaint-handling powers; create an independent inspector-general to receive intelligence agency reports under legal safeguards; and implement DDR, vetting and training programs co-led by local authorities.",
        "C": "Immediately halve the armed forces to reduce militarization, but transfer oversight responsibility exclusively to international donor agencies for five years to accelerate reform, while postponing passage of domestic oversight legislation.",
        "D": "Retain existing security institutions but create internal military tribunals and closed disciplinary boards to handle civilian complaints, and publish annual force strength figures without disclosing budgets or operational mandates."
      },
      "correct_answer": "B",
      "generation_notes": "Designed a concrete post-conflict scenario and four plausible reform packages; correct option (B) integrates rule of law (public laws on use of force), oversight and transparency (civilian parliamentary committee, independent inspector-general reporting), DDR and local ownership—matching SSR/SSG objectives linked to stability and democratization.",
      "concepts_tested": [
        "Applying governance principles (rule of law, accountability, transparency) to the security sector",
        "Oversight and transparency mechanisms for holding security institutions accountable (parliamentary oversight, inspector-general, public laws)",
        "Relationship between SSR/SSG and outcomes like stability, post-conflict recovery and democratization"
      ]
    },
    "pass_2_reason": "readability_too_high_20.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why does participant observation enable ethnographers to document both social interaction and participants’ perspectives more effectively than distant observation?",
      "options": {
        "A": "Because it focuses on counting observable actions without interpreting motives.",
        "B": "Because it relies on structured surveys to capture roles, ensuring consistency across observers.",
        "C": "Because actively participating in the setting allows the researcher to experience daily practices, language, and shared meanings, enabling interpretation from within the participants’ frame (emic) while still watching interactions as they unfold.",
        "D": "Because it removes the researcher’s influence by maintaining complete detachment and objectivity in the field."
      },
      "correct_answer": "C",
      "source_article": "Ethnography",
      "x": 1.2571492195129395,
      "y": 1.004560947418213,
      "concepts_tested": [
        "Participant observation as the central ethnographic method and its role in documenting social interaction and participants’ perspectives.",
        "Holistic, context-rich approach (including environment like terrain and climate) and the emphasis on understanding phenomena from the insider’s viewpoint (emic perspective).",
        "The historical development of ethnography as a science and its relationship to ethnology and other disciplines, including adaptations like netnography."
      ],
      "parent_concepts": [
        "Concept 1: Travel writing as a vehicle for recording geographical/topographical information and knowledge across cultures."
      ],
      "parent_articles": [
        "Travel literature"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does participant observation let ethnographers both record social interactions and understand participants' own perspectives better than observing from a distance?",
      "options": {
        "A": "Because it emphasizes counting visible actions and behaviors without interpreting participants' meanings.",
        "B": "Because it depends on structured surveys and fixed role-coding to produce consistent data across observers.",
        "C": "Because by actively joining the setting the researcher experiences daily practices, language, and shared meanings, gaining an insider (emic) perspective while observing interactions as they occur.",
        "D": "Because it eliminates researcher influence by keeping the researcher detached and fully objective in the field."
      },
      "correct_answer": "C",
      "simplification_notes": "Question wording shortened and clarified; retained technical term 'emic' and 'participant observation'; distractors rewritten as plausible methodological misconceptions.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.4_vs_16",
    "pass_2_attempt": {
      "question": "You are advising a graduate student planning an ethnographic study of ritual fishing among an island community. Which of the following research plans best exemplifies core ethnographic principles—centrality of participant observation for documenting social interaction and participants’ perspectives, a holistic/context-rich (including terrain and climate) emic approach, and a historically informed openness to disciplinary adaptations such as netnography?",
      "options": {
        "A": "Live in the community for 12 months in a marginal participant role, record detailed field notes focused on social interactions and members’ own explanations of rituals, include a chapter on the island’s history, terrain, climate, and subsistence ecology, and supplement fieldwork with analysis of the community’s online forum (netnography); situate methods in the lineage of ethnography as a distinct discipline while noting its use across fields.",
        "B": "Spend two weeks attending ceremonies and administering a structured questionnaire to every household to produce prevalence estimates you will generalize nationally, and write a short summary of the island’s climate without engaging the community’s own explanations.",
        "C": "Participate in fishing activities for 6 months, collect thick description of rituals and terrain, but code participants’ responses into fixed categories and emphasize statistical generalization to other islands rather than presenting emic meanings.",
        "D": "Rely exclusively on archival documents and taped interviews conducted remotely (no in-person participation), describe the island’s environment from maps only, and treat ethnography as identical to classical ethnology with no reference to digital adaptations."
      },
      "correct_answer": "A",
      "generation_notes": "Provided a single-best plan combining participant observation, emic/holistic documentation (terrain, climate, history), and recognition of ethnography’s historical development and contemporary adaptations (netnography); distractors violate one or more core principles.",
      "concepts_tested": [
        "participant observation and emic perspective",
        "holistic/context-rich ethnographic approach including terrain/climate",
        "historical development of ethnography and adaptations such as netnography"
      ]
    },
    "pass_2_reason": "readability_too_high_23.1_vs_16"
  },
  {
    "original_question": {
      "question": "How does the liberal notion of a social contract justify limiting governmental authority, and which institutional mechanism most effectively maintains that limit when popular demands threaten expansion of state power?",
      "options": {
        "A": "By grounding authority in hereditary rule; mechanism: monarchic succession",
        "B": "By basing legitimate authority on consent and protecting natural rights; mechanism: separation of powers and the rule of law",
        "C": "By mandating majority rule with no protection for minority rights; mechanism: plebiscitary democracy",
        "D": "By conceding that the state may suspend rights to achieve order; mechanism: emergency decrees"
      },
      "correct_answer": "B",
      "source_article": "Liberalism",
      "x": 1.105027198791504,
      "y": 0.8622553944587708,
      "concepts_tested": [
        "Concept 1: Social contract and natural rights as the basis for legitimate government and limits on state power.",
        "Concept 2: How liberal principles translate into institutions and freedoms (rule of law, private property, civil rights, democracy, market economies).",
        "Concept 3: Historical diffusion and evolution of liberalism through revolutions, reforms, and its interactions with competing ideologies (fascism, Marxism-Leninism) and reform movements (Tanzimat, Al-Nahda)."
      ],
      "parent_concepts": [
        "Concept 1: Liberal socialism as a synthesis of liberal freedom with socialist emancipation, realized through a mixed economy that combines social ownership and private property to secure liberty.",
        "The balance between individual freedom and government intervention to achieve social justice (mixed economy/welfare state)",
        "Concept 1: Reformist, gradualist, democratic approach to achieving social equality within capitalism."
      ],
      "parent_articles": [
        "Liberal socialism",
        "Social liberalism",
        "Social democracy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to liberal social‑contract theory, on what basis is governmental authority justified and limited, and which institutional mechanism best maintains those limits when popular demands push to expand state power?",
      "options": {
        "A": "Authority is justified by hereditary rule; mechanism: orderly monarchic succession and dynastic legitimacy",
        "B": "Authority is justified by the consent of the governed and the protection of natural rights; mechanism: separation of powers together with the rule of law",
        "C": "Authority is justified solely by majority rule with no special safeguards; mechanism: direct plebiscitary democracy",
        "D": "Authority is justified by the need to preserve order even if rights are suspended; mechanism: executive emergency decrees"
      },
      "correct_answer": "B",
      "simplification_notes": "Question shortened and clarified: emphasised 'consent of the governed' and 'natural rights' as the liberal justification, and specified 'separation of powers' plus 'rule of law' as the institutional safeguard. Distractors were kept plausible but made concise.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "Four newly independent states (A–D) each adopt distinctive constitutional arrangements and policy trajectories after decolonization. Which state's sequence best exemplifies the liberal tradition described by Locke and later developments in liberalism — i.e., a social‑contract foundation in natural rights that produces institutional protections (rule of law, private property, civil liberties, representative government), followed by a 19th–20th century evolution toward social/liberal reforms (welfare provision, Keynesian responses to depression), and exposure to competing ideologies (fascism, Marxism–Leninism) and influence on non‑Western reform movements?",
      "options": {
        "A": "The constitution declares sovereignty vested in a hereditary monarch by divine sanction; property rights are subordinate to royal prerogative; political dissent is criminalized. In the late 20th century the regime liberalizes markets but retains monarchical control and restricts suffrage.",
        "B": "The founding charter states that legitimate government derives from the consent of the governed and protects life, liberty and property; it establishes an independent judiciary, free press, representative parliament and abolishes aristocratic privileges. During industrialization it expands suffrage, later introduces public education and welfare provisions and uses Keynesian stimulus in an economic crisis; in the interwar period it faces organized fascist and communist movements and its legal‑constitutional model inspires reformers in a neighbouring multiethnic empire.",
        "C": "The new state enshrines absolute individual property rights and immediately privatizes all security and adjudication to competing firms (no standing public police or courts). It rejects representative institutions, relying instead on voluntary contracts; it resists welfare provision and is critiqued by Marxists and classical anarchists alike.",
        "D": "The republic proclaims formal equality and civil liberties but reserves legislative authority to a state religion; it nationalizes key industries, imposes heavy trade barriers, and after a crisis pursues neoliberal deregulation without creating broad social protections; an authoritarian party later mobilizes nationalist rhetoric to suppress pluralist institutions."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed four historical vignettes mapping constitutional language and policy choices to liberal theory (Lockean social contract, institutional translations) and historical evolution (welfare/Keynesianism, ideological challenges, influence on non‑Western reforms); B aligns with the described liberal trajectory.",
      "concepts_tested": [
        "Social contract and natural rights as basis for legitimate government",
        "Translation of liberal principles into institutions and freedoms (rule of law, private property, civil rights, representative democracy, market economy)",
        "Historical diffusion and evolution of liberalism through revolutions, reforms, welfare state development, and interactions with competing ideologies (fascism, Marxism‑Leninism) and non‑Western reform movements"
      ]
    },
    "pass_2_reason": "readability_too_high_22.5_vs_16"
  },
  {
    "original_question": {
      "question": "In a supramolecular system driven by several weak, non-covalent interactions, why does the assembly exhibit selectivity for a particular structure and remain reversible, and how does the balance between interaction strength and thermodynamic parameters govern which structure forms?",
      "options": {
        "A": "Because each interaction is effectively covalent and prevents rearrangement, locking the system into a single arrangement irrespective of external conditions.",
        "B": "Because many weak, directional interactions collectively lower the free energy of a complementary arrangement, but only if their combined enthalpic gain and entropic costs are optimized; this balance allows reversibility and error correction.",
        "C": "Because solvent completely stabilizes all possible interactions, leading to random assembly that ignores geometry.",
        "D": "Because increasing temperature always strengthens non-covalent bonds, so the strongest ensemble always dominates regardless of structure."
      },
      "correct_answer": "B",
      "source_article": "Supramolecular chemistry",
      "x": 1.9336888790130615,
      "y": 1.0863032341003418,
      "concepts_tested": [
        "Concept 1: Non-covalent interactions enable reversible, selective assembly and spatial organization, balancing strength and energy parameters to govern structure formation.",
        "Concept 2: Molecular recognition and host–guest chemistry as mechanisms for selective, size- and shape-dependent assembly.",
        "Concept 3: Dynamic covalent chemistry and mechanically interlocked architectures as adaptive, reconfigurable assembly strategies that allow error correction and complex topologies."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a supramolecular system held together by many weak, non‑covalent interactions, why does the system select a particular assembled structure yet remain reversible, and how does the balance of interaction strength and thermodynamic factors determine which structure forms?",
      "options": {
        "A": "Because each weak interaction effectively behaves like a covalent bond and fixes the components into a single, irreversible arrangement regardless of external conditions.",
        "B": "Because many weak, directional interactions act cooperatively to lower the overall free energy for a complementary arrangement; the net enthalpic gain and entropic cost (via $\\Delta G=\\Delta H-T\\Delta S$) determine the thermodynamically preferred structure while keeping the assembly reversible and allowing error correction.",
        "C": "Because the solvent fully stabilizes all potential interactions equally, producing essentially random assembly that does not depend on geometry or specific complementarity.",
        "D": "Because increasing temperature always strengthens non‑covalent bonds, so the structure with the individually strongest interactions always dominates regardless of the overall thermodynamic balance."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the question; introduced thermodynamic notation $\\Delta G=\\Delta H-T\\Delta S$; rewrote all options to be concise and plausible while preserving the original concepts.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.2_vs_16",
    "pass_2_attempt": {
      "question": "You are tasked with synthesizing a [2]catenane (two interlocked macrocycles) from the following available components: (i) a dialdehyde building block M and a diamine linker N that form imine bonds reversibly under mildly acidic conditions, (ii) a metal ion T that coordinates to pyridine sites and can act as a template, and (iii) bulky stopper groups S that can be attached covalently to a linear thread. Which of the following synthetic strategies is most consistent with supramolecular principles to maximize selective formation, allow thermodynamic error correction, and produce a stable interlocked product?",
      "options": {
        "A": "First perform irreversible covalent macrocyclization of M and N (e.g., via a non-reversible coupling) to make two closed macrocycles, then attempt to interlock them mechanically by forcing them through each other; finally install stoppers. This minimizes dependence on non-covalent templating.",
        "B": "Use the reversible imine condensation between M and N in the presence of template T so that metal coordination pre-organizes components into the threaded topology under thermodynamic control (allowing error correction); once the interlocked topology predominates, chemically reduce the imines to stable amines (covalent lock) and then remove or exchange T as needed.",
        "C": "Assemble two preformed macrocycles using only weak non-covalent interactions (H-bonding and π–π stacking) hoping they will entangle into a catenane; no template or post-assembly covalent locking is performed to keep the system fully reversible.",
        "D": "Use strong metal–ligand coordination exclusively to form both macrocycles and rely on the permanence of the metal coordination geometry to produce and retain the interlocked topology, avoiding any covalent modification or reduction steps."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete synthetic-planning scenario that contrasts reversible dynamic covalent assembly + metal templating followed by covalent locking (correct) against strategies that lack error correction or final stability; tests interplay of non-covalent templating, molecular recognition, dynamic covalent chemistry, and mechanically interlocked architectures.",
      "concepts_tested": [
        "Non-covalent templating and molecular recognition for selective assembly",
        "Dynamic covalent chemistry (reversible imine formation) enabling error correction under thermodynamic control",
        "Use of post-assembly covalent locking to convert reversible assemblies into stable mechanically interlocked architectures"
      ]
    },
    "pass_2_reason": "readability_too_high_23.6_vs_16"
  },
  {
    "original_question": {
      "question": "In a parliamentary system, the head of state is typically ceremonial while the head of government (the prime minister) is responsible for day-to-day policy and is accountable to the legislature. Why is this division advantageous for balancing national representation and democratic accountability?",
      "options": {
        "A": "The ceremonial head of state provides a nonpartisan symbol of unity, while the head of government, chosen by the legislature, directs daily policy and remains answerable to it, preserving continuity of representation without enabling unchecked executive power.",
        "B": "The ceremonial head of state has the power to veto legislation, ensuring checks on the government.",
        "C": "The head of government and head of state being the same person guarantees decisive leadership and avoids gridlock.",
        "D": "The division amplifies political polarization by separating symbol and policy."
      },
      "correct_answer": "A",
      "source_article": "Head of state",
      "x": 0.662197470664978,
      "y": 0.5170685648918152,
      "concepts_tested": [
        "Concept 1: Division of executive power between head of state and head of government across systems (ceremonial vs. executive roles; separation vs. fusion of roles).",
        "Concept 2: Constitutional model classifications (standard model, non-executive model, semi-presidential, presidential) and how each model allocates the head of state’s authority.",
        "Concept 3: How constitutional design shapes actual power and symbolism (e.g., the head of state as embodiment of the nation or as a party-led executive in one-party states)."
      ],
      "parent_concepts": [
        "Concept 2: Distinction between a ceremonial head of state and a politically accountable head of government, including the idea of reserve powers."
      ],
      "parent_articles": [
        "Westminster system"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a parliamentary system the head of state is typically a largely ceremonial national symbol, while the head of government (the prime minister) directs policy and is accountable to the legislature. Why does this institutional separation help balance national representation and democratic accountability?",
      "options": {
        "A": "A nonpartisan ceremonial head of state embodies national unity and continuity, while a prime minister chosen with legislative support manages day-to-day policy and can be removed by the legislature, preventing concentration of unchecked executive power.",
        "B": "The ceremonial head of state retains a veto over legislation and thus provides a strong independent check on the government.",
        "C": "Making the same person both head of state and head of government guarantees decisive leadership and avoids gridlock between symbolic and policy roles.",
        "D": "Separating the symbolic head of state from policy leadership increases political polarization by creating two competing centres of legitimacy."
      },
      "correct_answer": "A",
      "simplification_notes": "Removed lengthy historical examples and legal citations; condensed wording; defined roles (ceremonial head of state vs prime minister) and framed the question around representation and accountability while keeping the original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.3_vs_16",
    "pass_2_attempt": {
      "question": "The Republic of Freedonia's 2020 Constitution provides: the President is directly elected for a five‑year term and may appoint and dismiss the Prime Minister; however, the Prime Minister and cabinet must enjoy the confidence of the National Assembly and can be removed by a vote of no confidence. The President chairs the National Defence Council, negotiates and signs treaties (subject to parliamentary ratification), and may, under narrowly defined conditions, dissolve the National Assembly. In practice, when the President's party lacks a legislative majority, Presidents appoint Prime Ministers from the opposition and concentrate on foreign and security policy, while the Prime Minister runs domestic and economic policy (a phenomenon frequently described as \"cohabitation\"). Which constitutional model best describes Freedonia, and which statement most accurately characterises the head of state's formal and practical authority?",
      "options": {
        "A": "Semi‑presidential model — the head of state shares executive authority with a head of government: formally both exercise key executive functions (President stronger in foreign/security affairs; PM responsible for domestic governance), and in practice power shifts depending on parliamentary majorities (cohabitation). The President therefore combines national symbolism with significant independent executive powers.",
        "B": "Presidential model — the head of state is the sole, independent chief executive whose cabinet is exclusively answerable to the President and not to the legislature; the President controls both domestic and foreign policy regardless of parliamentary composition.",
        "C": "Parliamentary non‑executive model — the head of state is essentially a ceremonial symbol who appoints the Prime Minister only as a formality on the legislature's advice and has no independent role in foreign or defence policy or the dissolution of parliament.",
        "D": "Single‑party (Marxist–Leninist) model — the formal head of state is constitutionally dominant but in practice is a mere figurehead because real executive authority is vested in the ruling party's General Secretary, not in the constitutionally defined President."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic constitutional vignette with key features (direct election, appointment power, parliamentary confidence, defence/foreign competences, dissolution power, and cohabitation) to distinguish semi‑presidential from presidential, parliamentary non‑executive, and single‑party models; options pair model label with the correct account of formal vs practical authority.",
      "concepts_tested": [
        "Division of executive power between head of state and head of government (ceremonial vs executive roles)",
        "Constitutional model classification (standard/non‑executive/semi‑presidential/presidential) and allocation of authority",
        "Effect of constitutional design and political practice (e.g., party majorities, cohabitation, or party leadership) on actual power and symbolism of the head of state"
      ]
    },
    "pass_2_reason": "readability_too_high_20.7_vs_16"
  },
  {
    "original_question": {
      "question": "How does recognizing two broad experiential modalities within mysticism (ecstatic unitive experiences and insights into ultimate truths or altered states) help explain why scholars reinterpret mysticism beyond any single experience type?",
      "options": {
        "A": "It implies that the transformative potential is identical across all practices, making diversity irrelevant.",
        "B": "It shows that mysticism can be a process of personal transformation realized via multiple experiential routes, allowing cross-tradition reinterpretation beyond one type of experience.",
        "C": "It suggests that only one modality is genuine and all others are misinterpretations.",
        "D": "It demonstrates that etymology determines which experiences count as mysticism."
      },
      "correct_answer": "B",
      "source_article": "Mysticism",
      "x": 1.0905263423919678,
      "y": 1.0438334941864014,
      "concepts_tested": [
        "Concept 1: Mysticism as a process of personal transformation expressed through various religious traditions and practices (not tied to a single experience type).",
        "Concept 2: The relationship and distinction between different experiential concepts (ecstatic unitive experiences vs. insights into ultimate truths and altered states like samadhi) and how scholars reinterpret mysticism beyond a single type of experience.",
        "Concept 3: Etymology and historical evolution of the term mysticism and how shifts in meaning (from ancient Greek roots to early modern broadening) shape current understanding."
      ],
      "parent_concepts": [
        "Concept 3: Illusion vs enlightenment — the Gnostic aim is to move from illusion of the material world to enlightenment through experiential knowledge of the divine.",
        "Concept 2: The mechanism by which gnosis operates in Gnosticism (experiential/spiritual knowledge that liberates the divine spark from earthly constraints)."
      ],
      "parent_articles": [
        "Gnosticism",
        "Gnosis"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does recognizing two broad experiential modalities in mysticism—(a) ecstatic unitive experiences and (b) intuitive insights into ultimate truths or altered states—help explain why scholars reinterpret 'mysticism' beyond any single type of experience?",
      "options": {
        "A": "It implies the transformative outcome is identical for all practices, so the variety of experiences is irrelevant to defining mysticism.",
        "B": "It indicates mysticism is a process of personal transformation that can be realized by multiple experiential routes, supporting reinterpretation across different traditions rather than tying mysticism to one type of experience.",
        "C": "It means only one of the two modalities is genuine and the other modality represents misinterpretations or distortions.",
        "D": "It demonstrates that the historical etymology of the term (e.g., Greek μύω/μυστήριον) rigidly determines which experiences should be labeled mysticism."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the original question to a single clear sentence; kept the two experiential modalities explicit; rewrote options to be concise and plausible while preserving the original correct choice (B).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.1_vs_16",
    "pass_2_attempt": {
      "question": "A comparative religion researcher compiles three case studies: (1) a Sufi who describes fana following prolonged dhikr as 'extinction of the individual self' and subsequent greater communion with God; (2) a Rinzai Zen practitioner reporting a sudden kenshō insight into Buddha‑nature during intensive zazen; (3) a medieval Christian monk describing contemplatio in the Eucharist as an experiential awareness of God's presence. Based on contemporary scholarly reassessments of mysticism and the historical evolution of the term (from Greek μύω/μυστήριον through medieval contemplatio to early modern and modern usages), which interpretation best reflects the article's account of mysticism?",
      "options": {
        "A": "These three cases exemplify mysticism conceived as a process of personal transformation situated within distinct religious matrices; scholars argue the term is historically contingent and pluralistic — not reducible to a single ecstatic 'union' model but encompassing unitive ecstasy, intuitive insight (e.g. prajña, kenshō), and altered states (e.g. samadhi) — a sense shaped by etymological roots in μύω and later medieval and early modern shifts.",
        "B": "All genuine mysticism is essentially the same phenomenon: an ecstatic unitive experience of becoming one with God or the Absolute; therefore only the Sufi and Christian cases are properly mystical, while the Zen kenshō is a quasi‑psychological insight but not mysticism.",
        "C": "Mysticism is primarily a modern psychological category invented after the Enlightenment to label unusual mental states; the historical and etymological connections to Greek mystery cults and medieval contemplatio are irrelevant to its present meaning.",
        "D": "Because μυστήριον originally meant ‘secret rite’ in Classical Greece, mysticism should be restricted to ancient mystery‑religion initiatory practices; later contemplative or insight experiences (Sufi fana, Zen kenshō, Christian contemplatio) fall outside the proper definition."
      },
      "correct_answer": "A",
      "generation_notes": "Created a comparative case vignette to require synthesis of (1) mysticism as transformative process across traditions, (2) distinction between unitive ecstasy, insight, and altered states, and (3) etymological and historical shifts in the term's meaning.",
      "concepts_tested": [
        "Mysticism as a process of personal transformation across religious traditions",
        "Distinction between ecstatic unitive experiences, insight/enlightenment, and altered states; scholarly broadening of definition",
        "Etymology (Greek μύω/μυστήριον) and historical evolution shaping contemporary understandings"
      ]
    },
    "pass_2_reason": "readability_too_high_26.6_vs_16"
  },
  {
    "original_question": {
      "question": "How does using aid as a diplomatic signal shape the incentives of a recipient government to allocate effort toward short-term compliance versus long-term institutional reform?",
      "options": {
        "A": "It consistently aligns short-term gestures with durable, systemic reforms, ensuring both immediate compliance and long-run capacity building.",
        "B": "It creates a tension where governments may prioritize meeting donor signals to retain aid flows over pursuing deep, long-term reforms, potentially delaying genuine development.",
        "C": "It has no effect on incentives because aid is ultimately a neutral transfer of resources that recipients can use freely for growth.",
        "D": "It guarantees that aid flows will be unconditional and fully transparent, thereby strengthening governance institutions."
      },
      "correct_answer": "B",
      "source_article": "Aid",
      "x": 1.218583345413208,
      "y": 0.8395318984985352,
      "concepts_tested": [
        "Concept 1: Aid as a strategic tool with multiple functions (diplomatic signaling, alliance reinforcement, incentives for behavior, access to resources, cultural influence) and the implications for donor-recipient relationships.",
        "Concept 2: The distinction and relationship between emergency aid and development aid (short-term relief vs long-term poverty alleviation) and how this affects purposes and outcomes.",
        "Concept 3: Official Development Assistance (ODA) criteria and measurement (concessionality and grant element) and how this standard shapes reporting, incentives, and evaluation of aid."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If donors use aid primarily as a diplomatic signal—rewarding visible, short-term actions by a recipient government—how will that shape the recipient's incentives to allocate effort between immediate compliance and deep, long-term institutional reform?",
      "options": {
        "A": "It reliably aligns incentives so recipients both perform visible short-term actions and carry out lasting institutional reforms.",
        "B": "It creates a tension: governments concentrate on visible short-term compliance to retain aid, which can delay or crowd out genuine, long-term institutional reform.",
        "C": "It has no systematic effect because aid is just a neutral transfer of resources that recipients can freely allocate toward long-term growth.",
        "D": "It guarantees that aid will be unconditional and transparent, which in turn strengthens governance institutions and ensures long-term reform."
      },
      "correct_answer": "B",
      "simplification_notes": "Rewrote the stem to clarify 'diplomatic signal' as donors rewarding visible short-term actions; kept the contrast between short-term compliance and long-term institutional reform and retained the focus on incentives. Removed extra background text and jargon while preserving the tested idea.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.7_vs_16",
    "pass_2_attempt": {
      "question": "Country B delivers the following package to developing Country A: (i) an immediate shipment of 50,000 tonnes of free food to relieve famine; (ii) a $100 million loan at 2% annual interest repayable in equal annual installments over 20 years; (iii) $10 million worth of military equipment delivered to Country A's armed forces; (iv) a team of donor‑paid doctors deployed for 3 years as technical assistance; (v) $20 million of direct budget support to Country A; and (vi) a condition that Country A grants donor firms long‑term mineral extraction rights and must procure 70% of project inputs from donor‑country suppliers. According to the DAC/OECD ODA definition (ODA must be administered with the promotion of economic development and welfare as its main objective and be concessional with a grant element ≥ 25% using a 10% discount rate) and the distinctions between emergency and development aid, which of the following best describes the correct classification and primary motive(s) of the components?",
      "options": {
        "A": "(i) Free food = emergency humanitarian aid and (as a 100% grant) counts as ODA. (ii) $100m loan at 2% over 20 years has a grant element ≈ 48% (discount rate 10%), so it is concessional, counts as ODA and is development aid. (iii) $10m military equipment is military aid, intended to reinforce an ally, and does not meet ODA criteria. (iv) Donor‑paid doctors and (v) $20m budget support are technical/development aid and count as ODA. (vi) The tied procurement + extraction‑rights clause is primarily a donor strategic/commercial access instrument and either disqualifies those components from ODA or makes their development objective secondary.",
        "B": "Only the free food (i) and the military equipment (iii) qualify as ODA because they are transfers of goods; the $100m loan is not ODA because loans cannot be concessional, and technical assistance, budget support, and the tied procurement/extraction clause are non‑ODA political conditionality.",
        "C": "All six components (i–vi) are ODA because they are official transfers from one government to another and therefore count toward the donor's ODA total regardless of intent, concessionality, or conditionality.",
        "D": "The free food (i) should be classified as development aid (not emergency); the $100m loan is non‑concessional and thus not ODA; military equipment (iii) and the tied procurement/extraction clause (vi) are strategic but both still count as ODA if delivered by an official agency; technical assistance and budget support are neither emergency nor development aid and do not meet ODA rules."
      },
      "correct_answer": "A",
      "generation_notes": "Case study combining a package of aid items; applied DAC/OECD ODA criteria including computation of grant element for the 2%/20y loan at 10% discount (~48%); required classifying items as emergency vs development and identifying strategic motives (military, tied procurement, resource access).",
      "concepts_tested": [
        "Aid as a strategic tool and donor motives (diplomatic signaling, military support, commercial access, conditionality)",
        "Distinction between emergency humanitarian aid and development aid (short‑term relief vs long‑term poverty alleviation)",
        "Official Development Assistance (ODA) measurement: concessionality and grant element (≥25% at 10% discount rate) and implications for what counts as reported aid"
      ]
    },
    "pass_2_reason": "readability_too_high_35.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why is the core objective of process safety framed as maintaining the integrity of hazardous operating systems across design, engineering, operations, and maintenance rather than focusing on a single phase?",
      "options": {
        "A": "Because the protective measures chosen in design automatically remain flawless regardless of later changes.",
        "B": "Because the causes of major accidents arise only from external events and not from internal system integrity.",
        "C": "Because the protective barriers are only effective if their performance is preserved through all lifecycle stages; degradation, modifications, or bypass in any phase can compromise safeguards and permit releases.",
        "D": "Because process safety is mainly about regulatory compliance and audits, which requires cross-stage attention."
      },
      "correct_answer": "C",
      "source_article": "Process safety",
      "x": 1.5411531925201416,
      "y": 0.8532975912094116,
      "concepts_tested": [
        "Concept 1: The relationship and distinction between process safety and occupational safety and health (OSH) in terms of scope, focus, and consequences.",
        "Concept 2: The core objective of process safety — preventing, controlling, mitigating, and recovering from releases of hazardous materials or energy to avoid major accidents.",
        "Concept 3: The principle of maintaining the integrity of hazardous operating systems and processes through design, engineering, operations, and maintenance to prevent events that could release hazardous materials or energy."
      ],
      "parent_concepts": [
        "Concept 1: Prevention/avoidance as a principle (eliminating ignition sources, inerting atmosphere, oxygen/content control) to prevent explosions from occurring.",
        "Concept 2: Constructional protection as a principle (reinforcement and predefined protective techniques to limit or zero damage if an explosion occurs).",
        "Concept 3: Safety-oriented SOP development through task analysis and hazard control, including readability considerations to ensure safe and correct execution."
      ],
      "parent_articles": [
        "Explosion protection",
        "Explosion protection",
        "Standard operating procedure"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does process safety emphasize maintaining the integrity of hazardous operating systems across design, engineering, operations, and maintenance rather than concentrating on a single phase?",
      "options": {
        "A": "Because protections installed during design are permanently reliable and need no further attention during later phases.",
        "B": "Because major accidents result only from external events (e.g., natural disasters, collisions) and not from failures in internal system integrity.",
        "C": "Because protective barriers only remain effective if their performance is preserved across the entire lifecycle; degradation, modifications, or bypass during any phase can compromise safeguards and allow hazardous releases.",
        "D": "Because process safety is mainly about regulatory compliance and audits, which necessarily require involvement across all stages."
      },
      "correct_answer": "C",
      "simplification_notes": "Question wording condensed to a single clear sentence referencing 'design, engineering, operations, and maintenance'. Distractor options were reworded to be plausible but incorrect. Core concept—that lifecycle preservation of barriers is required to prevent releases—was kept intact.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.1_vs_16",
    "pass_2_attempt": {
      "question": "Consider a petrochemical tank farm storing a flammable solvent. An engineering audit revealed recurring corrosion in the tank-to-transfer-pump piping and a practice where operators temporarily bypass a pressure interlock during peak demand. Which single bundle of actions best exemplifies process safety (distinct from routine occupational safety and health) by (1) focusing on preventing, controlling, mitigating, and recovering from hazardous-material releases that could escalate to a major accident, and (2) maintaining the integrity of hazardous operating systems through design, engineering, operations, and maintenance?",
      "options": {
        "A": "Replace the corroded piping with a specified corrosion-resistant alloy, install double block-and-bleed isolation valves on the transfer line, implement a management-of-change (MOC) procedure that requires engineering review and authorization before any interlock bypass, add a Safety Instrumented System (SIS) designed to the appropriate $SIL$ to prevent overpressure and uncontrolled releases, and perform a Quantified Risk Assessment (QRA) of credible release scenarios.",
        "B": "Require all operators to wear flame‑resistant clothing and gloves while on the tank farm, provide fall‑protection harnesses for tank-top access, conduct monthly ladder‑safety toolbox talks, and enforce immediate reporting of minor injuries to supervisors.",
        "C": "Increase housekeeping and cleanliness inspections around the pump rooms, provide ergonomic training to pump‑room technicians, and offer overtime incentives so more staff are available during peak transfer periods.",
        "D": "Stock additional first‑aid kits and fire extinguishers near the control room, train personnel in CPR and portable extinguisher use, and revise evacuation routes and muster points for faster personnel assembly in an emergency."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete tank‑farm scenario; options contrast process‑safety measures (engineering, SIS, MOC, QRA, integrity) with OSH and emergency response activities to test distinction, core objective, and integrity maintenance.",
      "concepts_tested": [
        "Distinction between process safety and occupational safety and health (OSH)",
        "Core objective of process safety: preventing, controlling, mitigating, and recovering from hazardous-material releases and major accidents",
        "Maintaining integrity of hazardous operating systems via design, engineering, operations, and maintenance (e.g., MOC, SIS, asset integrity)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.8_vs_16"
  },
  {
    "original_question": {
      "question": "How do synchronous versus asynchronous CMC modalities differently shape the timing and management of turn-taking, and why does this matter for collaborative problem-solving in text-based communication?",
      "options": {
        "A": "Synchronous real-time interaction lowers the cost of interruptions and supports rapid back-and-forth, enabling quick convergence on ideas, but can overwhelm participants; asynchronous decouples send/receive, allowing deliberate, planned responses that reduce interruptions but slow coordination and collective progress.",
        "B": "Synchronous reduces miscommunication by providing more cues; asynchronous eliminates all ambiguity and thus is always slower but perfect.",
        "C": "Synchronous and asynchronous have identical effects on turn-taking and response timing; modality doesn't matter.",
        "D": "Asynchronous always leads to better collaboration because it removes urgency entirely, while synchronous always degrades collaboration due to constant pressure."
      },
      "correct_answer": "A",
      "source_article": "Computer-mediated communication",
      "x": 1.2607483863830566,
      "y": 1.0097185373306274,
      "concepts_tested": [
        "Concept 1: Synchronous vs asynchronous modalities as fundamental mechanisms shaping communication dynamics and response behavior in CMC.",
        "Concept 2: Paralinguistic cues (emoticons, turn-taking rules, discourse organization) as essential mechanisms for conveying meaning and managing interaction in text-based CMC.",
        "Concept 3: CMC as embedded in everyday life and its impact on social relationships and collaboration across professional, social, and educational contexts."
      ],
      "parent_concepts": [
        "Concept 3: Technological evolution (e.g., Web 2.0) alters scope, speed, and applications of online communities, driving new forms of interaction and uses (e.g., real-time communication, marketing, conflict-alerting)."
      ],
      "parent_articles": [
        "Online community"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do synchronous versus asynchronous computer-mediated communication (CMC) formats alter the timing and management of turn-taking, and why does that difference matter for collaborative problem solving in text-based communication?",
      "options": {
        "A": "Synchronous (real-time) CMC lowers the cost of interruptions and enables rapid back-and-forth, which helps teams converge on ideas quickly but can overwhelm participants; asynchronous CMC decouples send/receive, allowing more deliberate, edited responses that reduce interruptions and social pressure but slow coordination and collective progress.",
        "B": "Synchronous CMC supplies temporal and presence cues that can reduce some miscommunication; asynchronous CMC lets participants reflect and revise messages, which reduces certain ambiguities but still slows coordination and does not guarantee perfect clarity.",
        "C": "Synchronous and asynchronous CMC have essentially the same effects on turn-taking and response timing; the modality itself does not meaningfully influence collaborative problem solving.",
        "D": "Asynchronous CMC always produces better collaboration because removing urgency lets people think more carefully, while synchronous CMC always harms collaboration because of constant pressure and interruptions."
      },
      "correct_answer": "A",
      "simplification_notes": "Condensed and clarified the original question; defined 'synchronous' and 'asynchronous' in context; emphasized effects on interruptions, editing/reflection, cognitive load, and coordination; kept the original contrast and retained option A as correct.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.2_vs_16",
    "pass_2_attempt": {
      "question": "A multinational research group uses three communication channels: (i) weekly scheduled video conferences, (ii) a Slack workspace with threaded channels and reaction emojis, and (iii) a moderated email listserv. The project lead observes the following patterns over two months: (1) Slack conversations often reach rapid apparent agreement via 'thumbs-up' reactions, but downstream task execution reveals frequent misunderstandings; (2) the listserv exchanges contain longer, more deliberated proposals and revisions, though replies are slow; (3) a junior researcher volunteers more personal difficulties in one-on-one Slack messages than she does during the video meetings. Which explanation most accurately accounts for these observations based on principles of computer-mediated communication?",
      "options": {
        "A": "The Slack 'thumbs-up' reactions function as paralinguistic/backchannel cues that facilitate quick coordination but can produce superficial consensus when message content is underspecified; the listserv’s asynchronous, persistent format promotes reflective, detailed deliberation despite low synchronicity; and text-based CMC (reduced nonverbal presence and greater perceived anonymity) often increases self-disclosure relative to synchronous, face-to-face-like video meetings.",
        "B": "Emoji reactions on Slack effectively convert it into a synchronous medium, so rapid 'thumbs-up' always indicates true shared understanding; the listserv’s delayed replies produce shallow exchanges because participants disengage; and video meetings foster greater self-disclosure than text because richer nonverbal cues make participants more comfortable sharing.",
        "C": "Slack’s rapid reactions eliminate the need for message persistence and therefore prevent misunderstandings; listservs are high-synchronicity channels that force immediate consensus; and junior researchers disclose more in video meetings due to the immediacy and social presence of live interaction.",
        "D": "Emoji reactions are equivalent to full nonverbal signaling and therefore remove ambiguity from text exchanges; listserv persistence causes participants to avoid personal disclosure, so email reduces self-disclosure the most; and synchronous video communication always leads to deeper, more candid personal disclosures than asynchronous text."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete multi-channel vignette requiring students to apply CMC concepts: synchronicity vs persistence, paralinguistic cues (emoticons/reactions, backchanneling), and effects on self-disclosure and collaboration in everyday professional contexts.",
      "concepts_tested": [
        "Synchronous vs asynchronous modalities (synchronicity, persistence)",
        "Paralinguistic cues in text-based CMC (emoticons, reaction emojis, backchanneling, turn-taking)",
        "CMC embedded in everyday life and its impact on social relationships, self-disclosure, and collaboration"
      ]
    },
    "pass_2_reason": "readability_too_high_22.1_vs_16"
  },
  {
    "original_question": {
      "question": "In adaptive, life-supporting natural resource management, decisions are continually informed by monitoring results and updated as ecological conditions change. Why are feedback loops from observed resource responses critical to this approach?",
      "options": {
        "A": "They prevent any changes in the plan and force adherence to initial assumptions.",
        "B": "They allow actions to be adjusted based on what monitoring shows about resource response, helping preserve the resource's life-supporting capacity.",
        "C": "They shift the focus to maximizing short-term yield regardless of ecological signals.",
        "D": "They rely on expert intuition alone rather than data to guide decisions."
      },
      "correct_answer": "B",
      "source_article": "Natural resource management",
      "x": 1.443706750869751,
      "y": 0.8834846019744873,
      "concepts_tested": [
        "Integrated, interdisciplinary approach: Natural resource management links ecology with social, cultural, economic, and political systems to achieve sustainability and stewardship.",
        "Adaptive, life-supporting management: Decisions are based on scientific understanding of resources and ecology, with an emphasis on maintaining the life-supporting capacity of resources and updating practices over time.",
        "Human–ecosystem relationships and governance: Livelihoods depend on landscape health, and ownership regimes/governance structures (e.g., property rights, catchment management) shape resource management outcomes."
      ],
      "parent_concepts": [
        "Groundwater as a renewable resource with limits: freshwater groundwater is renewable in principle, but overdrafting can lead to depletion and regional water scarcity.",
        "Concept 2: The relationship between resource extraction, environmental/human rights impacts, and governance frameworks (Sustainable Development Goals, circular economy) to mitigate negative outcomes.",
        "The role and mechanism of Natural Resource Damage Assessments (NRDA) and the function of trustees in quantifying injuries to natural resources and restoring ecosystem services.",
        "Concept 1: Multi-objective management that balances conservation, utilization, and mixed goals within ecological, economic, and social/legal contexts.",
        "Concept 1: Multiple-use management as a framework that balances timber production with biodiversity, water quality, recreation, and other ecosystem services.",
        "Concept 1: Ecosystem-based fisheries management (EBFM) as a comprehensive, ecosystem-focused approach that balances ecological health, productivity, and human needs, contrasted with traditional single-species management.",
        "Concept 2"
      ],
      "parent_articles": [
        "Water resources",
        "Natural resource",
        "Superfund",
        "Forest management",
        "Forestry",
        "Fisheries management",
        "Water resources"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In adaptive natural resource management that seeks to maintain a resource's life-supporting capacity, why are feedback loops from monitoring observed resource responses essential?",
      "options": {
        "A": "They lock managers into the original plan and prevent revision of initial assumptions.",
        "B": "They let managers adjust actions based on monitoring of how the resource actually responds, helping preserve its life-supporting capacity over time.",
        "C": "They reorient management toward maximizing short-term yields regardless of ecological signals.",
        "D": "They justify relying on expert intuition alone rather than empirical monitoring data to guide decisions."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was tightened to explicitly link 'feedback loops' to monitoring and 'life-supporting capacity'; options were rephrased to be concise and plausible while preserving the original distractors and correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.0_vs_16",
    "pass_2_attempt": {
      "question": "The River X catchment includes: (a) upstream private irrigation farms causing soil salinization and reduced environmental flows, (b) an Indigenous community with customary tenure that lacks full legal recognition, and (c) downstream state-owned wetlands that provide flood attenuation, habitat and an overexploited open-access fishery. A regional natural resource management plan must (1) preserve the catchment's life-supporting capacity, (2) integrate ecological, social, economic and political dimensions, and (3) operate across mixed ownership regimes while enabling learning and adjustment. Which of the following management strategies best exemplifies an integrated, adaptive natural resource management approach that recognises governance constraints?",
      "options": {
        "A": "A top-down regulatory ban issued by the state that immediately restricts irrigation withdrawals, criminalises illegal fishing in the wetlands, and levies heavy fines on non-compliant landowners, with enforcement handled solely by state agencies and no formal stakeholder participation or monitoring program.",
        "B": "A catchment-scale plan co-developed by state agencies, private landholders and the Indigenous community that legally recognises customary rights, sets catchment ecological indicators (e.g. flow thresholds, salinity targets, fish biomass), establishes regular monitoring and a plan–do–review–act adaptive cycle, uses GIS-based information for audits, and combines zoning, payments for ecosystem services and regulated community co-management of seasonal fishing.",
        "C": "A market-based scheme that allocates tradable water entitlements to private irrigators and industry to internalise scarcity signals, while the state retains ownership of the wetlands but does not change legal recognition of customary rights or introduce new ecological monitoring metrics.",
        "D": "A decentralised community-based programme that devolves full control to local villages and fishing cooperatives, emphasises local livelihood benefits and customary rules without state-backed legal recognition or a scientifically designed monitoring and adaptive review process."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete catchment scenario with mixed property regimes; options contrast top-down, market-only, community-only and integrated adaptive approaches. Correct answer emphasises co-development, legal recognition, indicators, monitoring and adaptive cycle consistent with NRM principles.",
      "concepts_tested": [
        "Integrated interdisciplinary management (ecological, social, economic, political)",
        "Adaptive management and maintaining life-supporting capacity (plan–do–review–act, indicators, monitoring)",
        "Human–ecosystem relationships and governance (property regimes, stakeholder co-management, legal recognition)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does theoretical physics emphasize a model's ability to produce novel, testable predictions rather than only reproducing existing observations, and how does this mechanism advance understanding?",
      "options": {
        "A": "Because novel, falsifiable predictions expose the model to potential disconfirmation, forcing refinement or rejection if new experiments contradict it, which drives progress and reveals underlying causal relations.",
        "B": "Because reproducing existing observations proves the model is universally true, making further testing unnecessary.",
        "C": "Because generating novel predictions is purely a mathematical exercise with no empirical consequence, ensuring internal consistency.",
        "D": "Because predictions can always be adjusted after experiments to maintain agreement, so they have no real diagnostic value."
      },
      "correct_answer": "A",
      "source_article": "Theoretical physics",
      "x": 1.7434008121490479,
      "y": 1.1117037534713745,
      "concepts_tested": [
        "Theoretical physics as predictive, empirical models: theories are judged by how well their predictions match observations and their ability to yield new testable predictions.",
        "Relationships between measurable quantities: a physical theory describes (and quantifies) how measurable quantities relate to one another, not just abstract axioms.",
        "Diverse theoretical approaches and aims: phenomenology, modeling, effective theories, unification, and reinterpretation represent different strategies for building, simplifying, or extending theories beyond current data."
      ],
      "parent_concepts": [
        "Concept 3: The status of SUSY as a testable theory, evidenced by ongoing experiments that have not yet found superpartners, highlighting the relationship between theoretical expectations and empirical verification."
      ],
      "parent_articles": [
        "Supersymmetry"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do theoretical physicists value a model's ability to make novel, testable predictions instead of only fitting existing observations, and how does that practice advance understanding?",
      "options": {
        "A": "Because novel, falsifiable predictions expose the model to possible refutation; when experiments disagree the model must be revised or rejected, which drives scientific progress and reveals underlying causal structure.",
        "B": "Because reproducing existing observations proves the model is universally true, so further testing is unnecessary.",
        "C": "Because generating novel predictions is primarily a mathematical exercise with no empirical consequence, useful only for checking internal consistency.",
        "D": "Because predictions can always be adjusted after experiments to preserve agreement, so they provide no genuine diagnostic value."
      },
      "correct_answer": "A",
      "simplification_notes": "Shortened and clarified the question to emphasize \"novel, testable predictions\" and the role of refutation in advancing understanding; retained the original core reasoning and contrasts.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.6_vs_16",
    "pass_2_attempt": {
      "question": "A collider experiment measures the decay width of a newly observed unstable particle as a function of its center-of-mass energy $E$. Three theoretical groups publish competing explanations: (i) a phenomenologist proposes a semi-empirical fit \\(\\Gamma(E)=aE^{2}+b\\) tuned to the measured points, (ii) a model-builder proposes a speculative extension of the particle spectrum and symmetry that predicts \\(\\Gamma(E)=\\alpha E^{3}\\) at all energies, and (iii) an effective-theory team constructs a low-energy effective Lagrangian and derives \\(\\Gamma(E)=cE^{2}+\\mathcal{O}\\big(\\frac{E^{4}}{\\Lambda^{2}}\\big)\\) valid for $E\\ll\\Lambda$, together with explicit error estimates and a defined domain of validity. Assuming all three descriptions fit the currently available data within experimental uncertainty, which of the following statements best reflects the standards and attitudes of theoretical physics described in the article?",
      "options": {
        "A": "The phenomenologist's semi-empirical fit will be preferred because agreement with existing measurements is the principal criterion; since it matches data and is simple, no further theoretical justification is required.",
        "B": "The model-builder's speculative \\(\\Gamma(E)=\\alpha E^{3}\\) will be favoured because mathematical unification and novel symmetry principles are sufficient for acceptance even before any new particles are observed.",
        "C": "The effective-theory approach is most scientifically robust because it (1) expresses a quantitative relationship between measurable quantities, (2) gives predictions with stated domain and errors that can be tested beyond current data, and (3) can serve as a bridge to deeper theories via correspondence at higher energies.",
        "D": "All three are equally acceptable as mainstream theories because multiple competing descriptions that fit current data are always regarded as equivalent until decisive experiments are done; theoretical economy and stated domains are secondary."
      },
      "correct_answer": "C",
      "generation_notes": "Constructed a collider decay-rate scenario comparing phenomenology, model-building, and effective theory; options test empirical adequacy, measurable-quantity relations, predictive power, domain of validity, and the role of unification/Occam's razor.",
      "concepts_tested": [
        "Theoretical physics judged by predictive agreement with observations and ability to make new testable predictions",
        "Physical theories describe quantitative relationships between measurable quantities",
        "Different theoretical approaches: phenomenology, model-building, effective theories and their scientific roles"
      ]
    },
    "pass_2_reason": "readability_too_high_23.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does modern taxonomy prioritize using shared derived characteristics to group organisms, and how does this approach accommodate extinct lineages when inferring evolutionary relationships?",
      "options": {
        "A": "Because convergent evolution can produce similar traits in unrelated groups, using shared derived traits that reflect common ancestry helps build classifications that correspond to the true evolutionary history, including both living and extinct lineages.",
        "B": "Because any observable similarity equally indicates relatedness, so classifications based on surface traits will always match evolutionary history.",
        "C": "Because the hierarchy is a fixed ladder where species must be classified only by their current morphology, ignoring extinct forms.",
        "D": "Because nomenclature rules require naming groups by their most ancient trait, regardless of ancestry."
      },
      "correct_answer": "A",
      "source_article": "Taxonomy (biology)",
      "x": 3.14780592918396,
      "y": 1.0505415201187134,
      "concepts_tested": [
        "Taxonomy as hierarchical classification using ranks (domain to species) based on shared characteristics.",
        "Modern objective of taxonomy: to reflect evolutionary relationships (phylogeny) among organisms, including extinct lineages.",
        "Relationship and distinction between taxonomy, systematics, and nomenclature, including ongoing definitional debates about what each field encompasses."
      ],
      "parent_concepts": [
        "Concept 2: Taxonomic reclassification dynamics and controversies (renaming Proteobacteria to Pseudomonadota) and how committee decisions influence scientific consensus.",
        "Concept 3: Different nomenclature codes (zoology: trinomen; botany: subsp.; bacteriology: emphasis on subspecies and infrasubspecific ranks) reflect how conceptual frameworks for infraspecific ranking vary across disciplines, shaping how subspecies are named and categorized.",
        "The barcode principle and barcoding gap: using short DNA regions whose interspecific variation exceeds intraspecific variation to reliably identify species.",
        "Concept 1: Monophyly and diagnostic dental morphology defining Canidae (e.g., bicuspid lower talonid, entoconid cusp) as evidence for the clade and its relationship to borophagines."
      ],
      "parent_articles": [
        "Pseudomonadota",
        "Subspecies",
        "DNA barcoding",
        "Canidae"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does modern taxonomy emphasize grouping organisms by shared derived characters (synapomorphies), and how does this practice allow extinct lineages to be incorporated when reconstructing evolutionary relationships?",
      "options": {
        "A": "Because convergent evolution can produce similar traits in unrelated groups, using shared derived traits that indicate common ancestry produces classifications that better reflect true evolutionary history and can include both extant and extinct lineages.",
        "B": "Because any observable similarity between organisms equally indicates relatedness, so grouping by superficial traits will reliably recover evolutionary relationships including fossils.",
        "C": "Because taxonomy treats the hierarchy as a fixed ladder, so species are classified only by their present morphology and extinct forms are excluded from evolutionary reconstructions.",
        "D": "Because the rules of nomenclature mandate naming groups by their most ancient trait, so classifications are determined by old characters regardless of actual ancestry."
      },
      "correct_answer": "A",
      "simplification_notes": "Rephrased the question to use the technical term ‘synapomorphies’ and made the wording more concise; retained focus on why shared derived characters are used and how fossils are included. Distractors were made plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.5_vs_16",
    "pass_2_attempt": {
      "question": "An international research team studies a group of archosaurs using fossil morphology and DNA. Their workflow includes: (1) inferring phylogenetic trees to test whether Dinosauria is monophyletic, (2) proposing that Aves be nested within Dinosauria to reflect common descent, (3) preparing formal diagnostic descriptions and designating holotypes for three newly discovered fossil species, (4) publishing new binomial names that conform to the International Code of Zoological Nomenclature (ICZN), and (5) updating a global database by placing the new taxa into ranks from family down to species. According to the distinctions and emphases described in the article, which assignment of these activities to systematics, taxonomy, and nomenclature is most accurate?",
      "options": {
        "A": "(1) and (2) = systematics; (3) and (5) = taxonomy; (4) = nomenclature.",
        "B": "(1) and (2) = taxonomy; (3) = systematics; (4) and (5) = nomenclature.",
        "C": "All five activities are strictly taxonomy, because taxonomy covers naming, description, and classification.",
        "D": "(1) = systematics; (2) = nomenclature; (3) = taxonomy; (4) = taxonomy; (5) = systematics."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete research workflow and asked students to map each activity to systematics (phylogenetic inference/evolutionary history), taxonomy (description, classification, types), or nomenclature (formal naming rules).",
      "concepts_tested": [
        "hierarchical taxonomic ranks and classification",
        "distinction between taxonomy, systematics, and nomenclature; modern taxonomy aiming to reflect phylogeny"
      ]
    },
    "pass_2_reason": "readability_too_high_21.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why is hypothalamic control of the anterior pituitary mediated by the hypothalamo-hypophysial portal system, and how does this arrangement affect the speed and specificity of signaling?",
      "options": {
        "A": "Because releasing factors are delivered in high local concentration directly to the anterior pituitary, enabling rapid, selective stimulation of pituitary cells with minimal dilution in the systemic circulation.",
        "B": "Because releasing factors are released into the systemic circulation and diluted, giving broad, slow, non-specific effects on multiple glands.",
        "C": "Because the anterior pituitary is innervated directly by hypothalamic neurons, bypassing the vascular route and delivering neurotransmitters systemically.",
        "D": "Because feedback hormones from the anterior pituitary are transported back to the hypothalamus exclusively via the portal system."
      },
      "correct_answer": "A",
      "source_article": "Neuroendocrinology",
      "x": 2.0155224800109863,
      "y": 1.1545934677124023,
      "concepts_tested": [
        "Hypothalamic control of the anterior pituitary via releasing factors and the hypothalamo-hypophysial portal system (mechanism and relationship)",
        "Distinct modes of pituitary signaling: anterior pituitary via portal circulation vs. posterior pituitary via direct neural innervation and systemic release (mechanism)",
        "Neuroendocrine integration as brain-driven regulation of broad physiological processes and homeostasis (principle)"
      ],
      "parent_concepts": [
        "Concept 1: The SAM axis and the HPA axis coordinate the acute stress response (fight-or-flight) and return to homeostasis, with adrenaline and cortisol as key mediators.",
        "Concept 2: Brain regions (limbic system, amygdala, prefrontal cortex, hypothalamus, stria terminalis) regulate the stress response by modulating the SAM and HPA axes, shaping physiological and cognitive outcomes."
      ],
      "parent_articles": [
        "Stress (biology)",
        "Stress (biology)"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does the hypothalamus use the hypothalamo-hypophysial portal circulation to control the anterior pituitary, and how does this arrangement affect the speed and specificity of hypothalamic signals?",
      "options": {
        "A": "Because hypothalamic releasing factors are delivered via the portal vessels to the anterior pituitary at high local concentration, producing rapid, selective stimulation of specific pituitary cells with minimal dilution into the systemic circulation.",
        "B": "Because hypothalamic releasing factors are released into the systemic circulation and become diluted, producing slower, less specific, and broader effects on multiple endocrine glands.",
        "C": "Because the anterior pituitary is directly innervated by hypothalamic neurons that bypass the vascular route and release neurotransmitters into the systemic circulation.",
        "D": "Because feedback hormones from the anterior pituitary are transported back to the hypothalamus exclusively through the portal vessels to regulate hypothalamic neurons."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording shortened and clarified for undergraduates; retained technical terms (hypothalamo-hypophysial portal circulation, releasing factors, anterior pituitary); options rephrased to be concise and plausible while preserving the original correct concept.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.6_vs_16",
    "pass_2_attempt": {
      "question": "You perform an experiment on an anesthetized rat measuring serum luteinizing hormone (LH; anterior pituitary product) and vasopressin (posterior pituitary product). The experiment has three sequential interventions: (1) electrical stimulation of hypothalamic GnRH neurons with all pituitary connections intact; (2) surgical transection of the hypothalamo-hypophysial portal vessels (median eminence veins) while leaving the neural stalk to the posterior pituitary intact, then repeat the same hypothalamic GnRH electrical stimulation; (3) after the portal transection, give an intravenous bolus of synthetic GnRH. For each intervention, indicate the expected immediate change in serum LH and vasopressin relative to the pre-intervention baseline.",
      "options": {
        "A": "1) LH increases, vasopressin no change. 2) After portal transection + GnRH stimulation: LH shows no increase (no change), vasopressin no change. 3) IV GnRH after transection: LH increases, vasopressin no change.",
        "B": "1) LH increases, vasopressin increases. 2) After portal transection + GnRH stimulation: LH decreases, vasopressin decreases. 3) IV GnRH after transection: LH shows no change, vasopressin increases.",
        "C": "1) LH increases, vasopressin no change. 2) After portal transection + GnRH stimulation: LH decreases, vasopressin no change. 3) IV GnRH after transection: LH shows no change, vasopressin no change.",
        "D": "1) LH shows no change, vasopressin increases. 2) After portal transection + GnRH stimulation: LH shows no change, vasopressin increases. 3) IV GnRH after transection: LH increases, vasopressin increases."
      },
      "correct_answer": "A",
      "generation_notes": "Designed an experiment contrasting anterior pituitary control via hypothalamo-hypophysial portal factors versus posterior pituitary direct neural release; included an IV GnRH step to test whether systemic hormone can access anterior pituitary independently of the portal vessels.",
      "concepts_tested": [
        "Hypothalamic control of anterior pituitary via releasing factors and the hypothalamo-hypophysial portal system",
        "Distinct signaling modes of anterior (portal-mediated) vs posterior (direct neural innervation) pituitary secretion and neuroendocrine integration"
      ]
    },
    "pass_2_reason": "readability_too_high_23.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why is the interplay between social structure and individual agency essential for understanding how everyday face-to-face talk varies across different contexts?",
      "options": {
        "A": "Because macro structures strictly determine behavior, leaving no room for individual influence in conversations.",
        "B": "Because macro structures constrain available communicative options, while individuals’ choices in interactions can reproduce or gradually transform those structures over time.",
        "C": "Because levels of analysis are completely independent, so micro-talk cannot affect macro-level patterns.",
        "D": "Because the content of messages alone, irrespective of norms or institutions, fully explains variation in talk across contexts."
      },
      "correct_answer": "B",
      "source_article": "Communication studies",
      "x": 1.2103904485702515,
      "y": 1.000815510749817,
      "concepts_tested": [
        "Concept 1: Levels of analysis in communication (from face-to-face/interpersonal to social/cultural systems) and the interplay between structure and agency.",
        "Concept 2: Methodological pluralism in communication studies (qualitative and quantitative methods; interpretive/hermeneutic approaches evolving toward analytical/computational techniques).",
        "Concept 3: Functions and purposes of communication (giving, receiving, exchanging information to persuade, seek/give information, and express emotions)."
      ],
      "parent_concepts": [
        "Concept 1: Film studies emphasizes analyzing cinema's narrative, artistic, cultural, economic, and political implications rather than focusing on film production skills."
      ],
      "parent_articles": [
        "Film studies"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is the relationship between social structures (institutions, norms) and individual agency necessary to explain why everyday face-to-face conversation differs across contexts?",
      "options": {
        "A": "Because macro-level structures fully determine conversational behavior, so individuals have no meaningful influence on how they talk.",
        "B": "Because macro-level structures constrain the communicative options people face, while individuals’ moment-to-moment choices can reproduce those structures or gradually change them over time.",
        "C": "Because micro-level interaction and macro-level structures are completely independent, so local talk cannot affect broader social patterns.",
        "D": "Because only the literal content of messages, separate from norms or institutions, explains why conversation varies across contexts."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified wording, emphasized 'social structures' and 'individual agency', removed extra methodological detail, and preserved the levels-of-analysis structure (micro vs. macro).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "A communication researcher investigates vaccine hesitancy in a multilingual metropolitan area. Their project includes (1) recording clinic consultations between clinicians and patients, (2) content-analyzing local news and social media campaigns, and (3) reviewing public-health agency policy documents and distribution infrastructures. Which of the following answer choices best describes how contemporary communication studies would conceptualize (a) the levels of analysis and the interplay of structure and agency in this project, (b) an appropriate methodological strategy, and (c) the communication functions being examined?",
      "options": {
        "A": "(a) The recordings address micro-level interpersonal interaction and individual agency, the media content addresses meso-to-macro cultural and institutional systems that shape but are also contested by individuals (structure–agency interplay); (b) a pluralistic mixed-methods design combining qualitative conversation analysis/ethnographic interviews for interpretive insight, surveys or experiments for population-level inference, and computational content/sentiment analysis or social-network analysis for large-scale media patterns; (c) functions studied include seeking/giving information, persuasion (vaccine uptake), and affective expression (fear, trust).",
        "B": "(a) All three data sources are treated as equivalent indicators of a single macro-level cultural system because culture is the primary determinant of behavior (structures wholly determine agency); (b) therefore a single large-scale quantitative content analysis of media is sufficient and preferable to qualitative work; (c) the only communication function of interest is persuasion (shifting public opinion).",
        "C": "(a) Clinic conversations are purely individual acts with no structural influence, while policies and media are separate structural forces that do not change in response to interaction (no interplay); (b) methods should be strictly interpretive (hermeneutics) for conversations and strictly archival for policy, avoiding any quantitative or computational techniques; (c) the project should focus exclusively on information exchange (seeking/giving), ignoring emotional or persuasive dimensions.",
        "D": "(a) Levels of analysis should be collapsed into the meso level (organizations and media) because interpersonal talk is inconsequential for public outcomes; (b) a purely qualitative case-study approach (participant observation and interviews) is the only valid method because quantitative methods cannot capture meaning; (c) primary function examined should be emotional expression since persuasion and information exchange are best measured by epidemiologists, not communication scholars."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a single applied scenario (vaccine hesitancy study) that requires mapping: micro/meso/macro levels and structure–agency interplay; justification for methodological pluralism (qualitative, quantitative, computational); and identification of communication functions (inform, persuade, express emotion). Option A integrates all three correctly; other options each violate one or more concepts.",
      "concepts_tested": [
        "Levels of analysis and structure–agency interplay",
        "Methodological pluralism in communication studies",
        "Functions and purposes of communication (information exchange, persuasion, emotional expression)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.0_vs_16"
  },
  {
    "original_question": {
      "question": "How do macroprudential measures alter the incentives of bank management to reduce system-wide risk, and why is this necessary beyond microprudential limits on individual institutions?",
      "options": {
        "A": "By making microprudential limits more stringent for all banks, which automatically reduces systemic risk.",
        "B": "By using macro-level penalties that punish any bank that takes too much risk, thus removing moral hazard entirely.",
        "C": "By internalizing the social costs of risk-taking through instruments like countercyclical capital buffers and systemic risk surcharges, aligning private incentives with system-wide stability and reducing the excess risk created by deposit insurance and implicit guarantees.",
        "D": "By expanding deposit insurance coverage to discourage banks from taking risk."
      },
      "correct_answer": "C",
      "source_article": "Macroprudential regulation",
      "x": 1.3223013877868652,
      "y": 0.8752950429916382,
      "concepts_tested": [
        "Concept 1: Macroprudential regulation as a mechanism to mitigate systemic risk and bridge macro policy with microprudential regulation.",
        "Concept 2: Principal–agent/moral hazard concerns in banking and how macroprudential aims to realign incentives to reduce system-wide risk.",
        "Concept 3: Externalities (pecuniary externalities) and the mood swings paradigm as theoretical foundations for macroprudential policy and its role in stabilizing the financial system."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do macroprudential policies change bank managers' incentives to limit system‑wide (systemic) risk, and why are such policies needed in addition to microprudential limits on individual institutions?",
      "options": {
        "A": "By simply tightening microprudential limits (for example, higher minimum capital ratios) uniformly across all banks, which by itself automatically reduces systemic risk.",
        "B": "By imposing macro‑level penalties that punish any bank taking excessive risk, thereby making banks fully internalize system costs and eliminating moral hazard.",
        "C": "By internalizing the social costs of risky behavior through tools such as countercyclical capital buffers and systemic‑risk surcharges, so managers bear part of the system‑wide cost of their actions and private incentives are better aligned with financial‑system stability.",
        "D": "By expanding deposit insurance and government guarantees to stabilize depositor expectations and thus reduce the likelihood of runs, which in turn discourages risky behavior by banks."
      },
      "correct_answer": "C",
      "simplification_notes": "Rephrased the question to be concise and undergraduate‑level, kept the theoretical rationale (moral hazard, externalities) and examples (countercyclical buffers, surcharges). Each option was kept plausible but only C preserves the correct mechanism.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.3_vs_16",
    "pass_2_attempt": {
      "question": "Country X has experienced a three‑year credit boom: private credit/GDP rose from 80% to 105%, national house prices increased by 50%, and banks financed rapid asset growth with a 45% share of non‑core (short‑term wholesale) liabilities. Deposit insurance is universal, and supervisors observe widespread optimistic underwriting. Which of the following macroprudential policy packages best mitigates systemic risk by (i) reducing moral‑hazard incentives created by deposit insurance (principal–agent concerns), (ii) internalizing pecuniary externalities that amplify overborrowing and asset‑price inflation, and (iii) moderating procyclical “mood swings” in credit supply?",
      "options": {
        "A": "Introduce a countercyclical capital buffer that raises banks' required common equity during the boom; impose caps on loan‑to‑value and debt‑to‑income ratios for mortgage lending; require higher loss‑absorbing capital (e.g., contingent convertible bonds) and a leverage cap to align manager incentives with long‑term solvency.",
        "B": "Intensify microprudential measures: increase the frequency of onsite inspections, raise minimum liquidity coverage ratios, and expand deposit insurance payouts to guarantee retail deposits fully during stress periods.",
        "C": "Rely primarily on conventional monetary tightening: raise the policy rate sufficiently to cool credit demand and restrict monetary aggregates, without changing bank capital rules or lending standards.",
        "D": "Tighten cross‑border capital controls and impose a uniform, time‑invariant increase in reserve requirements on all banks to reduce capital inflows and shorten funding maturities."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic three‑year credit boom vignette; offered four plausible policy packages. Option A bundles countercyclical capital, borrower constraints (LTV/DTI), and loss‑absorbing capital to address moral hazard, pecuniary externalities, and mood swings—matching macroprudential objectives. Other options emphasize microprudential, monetary, or static capital‑control responses and are therefore less aligned.",
      "concepts_tested": [
        "Macroprudential regulation as system‑wide risk mitigation and bridging macro policy with microprudential regulation",
        "Principal–agent problems and moral hazard in banking and how macroprudential tools realign incentives",
        "Pecuniary externalities and the mood‑swings paradigm as foundations for countercyclical macroprudential measures"
      ]
    },
    "pass_2_reason": "readability_too_high_20.8_vs_16"
  },
  {
    "original_question": {
      "question": "In a semi-direct democracy, how do the binding nature of the outcome and the procedural rules (such as signature thresholds and timeframes) differ between direct initiatives (put directly to a vote) and indirect initiatives (first to the legislature, then to a vote), and why does this matter for policy outcomes and minority protections?",
      "options": {
        "A": "Direct initiatives bypass the legislature and apply the voter's decision as law (if binding), making outcomes highly contingent on thresholds and timing, which can yield rapid policy change but may under-protect minorities if safeguards are weak; indirect initiatives route through the legislature, allowing debate, amendments, and delays that can stabilize policy and incorporate minority protections, though they may dilute direct popular will.",
        "B": "Direct initiatives always require supermajorities and are more deliberative than indirect initiatives, which are binding and fast.",
        "C": "Indirect initiatives are merely symbolic and have no real effect on policy.",
        "D": "The procedural rules are identical for both and thus the difference lies only in terminology."
      },
      "correct_answer": "A",
      "source_article": "Direct democracy",
      "x": 1.1780319213867188,
      "y": 0.8639399409294128,
      "concepts_tested": [
        "Concept 1: The shift of decision-making locus from elected representatives to citizens through mechanisms such as referendums, initiatives, and recalls, i.e., direct legislation versus representative governance.",
        "Concept 2: The variety of direct-democracy mechanisms (compulsory vs. popular vs. citizen-initiated referendums; direct vs. indirect initiatives) and how their binding/advisory nature and procedural rules (signature requirements, timeframes) shape policy outcomes.",
        "Concept 3: The relationship between direct democracy and broader frameworks (participatory and deliberative democracy) and how semi-direct models preserve sovereign citizen involvement while delegating day-to-day governance to representatives."
      ],
      "parent_concepts": [
        "Concept 3: Terminology and cross-context differences — how terms like referendum and plebiscite are related but may carry different legal meanings and consequences in different countries (e.g., Australia’s distinction)."
      ],
      "parent_articles": [
        "Referendum"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a semi-direct democracy, how do direct initiatives (placed immediately on the ballot) differ from indirect initiatives (first presented to the legislature, then possibly sent to a public vote) in terms of whether outcomes are binding and how procedural rules (signature thresholds, timeframes) operate — and why do these differences matter for the speed of policy change and protections for minorities?",
      "options": {
        "A": "Direct initiatives bypass the legislature and, if designed as binding, become law when approved by voters; their practical effect therefore depends heavily on signature thresholds and petition timeframes, which can produce rapid policy change but risk weaker minority protections if safeguards are low. Indirect initiatives are first routed to the legislature, which allows debate, amendments, and delays that can stabilize policy and add protections for minorities, though this process can dilute the immediate popular will.",
        "B": "Direct initiatives typically require higher approval thresholds and involve more formal deliberation than indirect initiatives, whereas indirect initiatives are generally faster and automatically binding without legislative input.",
        "C": "Indirect initiatives are mostly symbolic: they are submitted to the legislature but rarely result in substantive policy change or a public vote, so they have little effect on outcomes or minority protections.",
        "D": "Procedural rules (binding vs. advisory outcome, signature requirements, timeframes) are essentially identical for direct and indirect initiatives; 'direct' and 'indirect' refer only to the path taken, not to differences in effect on policy speed or minority safeguards."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording condensed and clarified; preserved technical terms (direct/indirect initiative, binding, thresholds, timeframes); removed extraneous historical detail; options rewritten to remain plausible while keeping original correct answer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_29.6_vs_16",
    "pass_2_attempt": {
      "question": "The constitution of the hypothetical country Novalia provides the following institutional rules: (1) any constitutional amendment proposed by the legislature must be submitted to a binding compulsory referendum; (2) citizens can trigger a popular referendum to suspend a recently enacted law by collecting signatures equal to $3\\%$ of registered voters within $6$ months, with at least $0.5\\%$ of registered voters signing in each of Novalia's $10$ regions; (3) citizens may propose statutory reforms by petitioning with $5\\%$ of registered voters; if such a petition is presented to the legislature and the legislature takes no acceptable action within $90$ days, the question proceeds to a ballot (an indirect initiative); and (4) a recall can be initiated with petitions equal to $10\\%$ of registered voters and, if a recall election is held, removal requires a majority vote and at least $40\\%$ turnout. Which one of the following statements best describes how these mechanisms differ from representative governance and how they shape policy outcomes in Novalia?",
      "options": {
        "A": "All statements are correct: the compulsory referendum submits elite-drafted constitutional changes to a binding popular decision; the popular referendum (with regional signature distribution) effectively grants citizens a veto that can suspend legislation pending a vote; the $5\\%$ citizen proposal is an indirect initiative giving the legislature first opportunity to act before the proposition goes to a binding ballot if it fails to do so within $90$ days; the recall permits removal before term end but may fail because of the $40\\%$ turnout quorum. Together these instruments exemplify a semi-direct democracy: representatives administer day-to-day governance while citizens remain sovereign through direct legislation instruments; deliberative referendums can be designed to increase public discussion but may be binding or advisory depending on rules.",
        "B": "Correct: the popular referendum described is purely advisory and cannot veto legislation, while the indirect initiative bypasses the legislature and places proposals immediately on the ballot; compulsory referendums on constitutional amendments are non-binding consultative devices; the recall threshold and turnout rules are symbolic only. Therefore Novalia functions mainly as a participatory democracy in which citizens make routine policy choices without meaningful representative control.",
        "C": "Incorrect: because constitutional amendments must face a compulsory referendum, legislators in Novalia are constitutionally forbidden from proposing amendments; the $5\\%$ petition is a direct initiative (not indirect), so any successful petition is placed on the ballot immediately without legislative consideration; the regional distribution requirement for popular referendums is incompatible with equality principles and would nullify the petition. These structural features indicate Novalia is closer to deliberative democracy than a semi-direct model.",
        "D": "Incorrect: Novalia's rules mean that any citizen proposal that reaches the signature threshold can overrule existing laws at will and representatives retain no sovereign role; the $90$-day legislative window is merely advisory and does not delay the citizen proposal from being enacted without a popular vote. Consequently Novalia is a pure direct democracy identical in practice to ancient Athenian assembly rule."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete institutional scenario with numeric thresholds ($3\\%$, $0.5\\%$, $5\\%$, $10\\%$, $40\\%$) and asked students to identify correct descriptions of compulsory vs. popular vs. indirect initiative vs. recall, and to relate these to semi-direct vs. representative and deliberative/participatory frameworks.",
      "concepts_tested": [
        "Shift from representative to citizen decision-making via referendums, initiatives, and recalls (direct legislation vs representative governance)",
        "Differences among referendum/initiative types (compulsory, popular, citizen-initiated; direct vs indirect) and how procedural rules (signature thresholds, regional distribution, timeframes, turnout quorums) alter policy power",
        "Relation of direct-democracy instruments to semi-direct, participatory, and deliberative democracy models"
      ]
    },
    "pass_2_reason": "readability_too_high_27.6_vs_16"
  },
  {
    "original_question": {
      "question": "How does modularity operationalize separation of concerns to manage system complexity, and what mechanism primarily enables independent evolution of parts while keeping integration as a separate concern?",
      "options": {
        "A": "By duplicating logic across modules to reduce cross-module dependencies.",
        "B": "By encapsulating a module's implementation behind a stable interface, so other parts of the system depend only on the interface; changes inside a module stay isolated, and the integration of modules is treated as a separate concern.",
        "C": "By forcing all modules to be updated simultaneously for any change to ensure consistency.",
        "D": "By removing interfaces and relying on a single global object to coordinate all modules."
      },
      "correct_answer": "B",
      "source_article": "Separation of concerns",
      "x": 1.444859266281128,
      "y": 1.0780398845672607,
      "concepts_tested": [
        "Concept 1: Separation of concerns as a design principle that enables focusing on one aspect of a problem at a time to manage complexity.",
        "Concept 2: Modularity as a concrete realization of SoC, allowing module details to be addressed in isolation and treating integration as a separate concern.",
        "Concept 3: View-based architecture (e.g., the 4+1 model) as an application of SoC, using separate perspectives to address different architectural concerns."
      ],
      "parent_concepts": [
        "Model–View–Controller (MVC) separation: decoupling the user interface from application logic to enable flexible, customizable interfaces and easier evolution.",
        "Concept 1: Division of labor in web development (front-end, back-end, full-stack) and the rationale for this specialization (client-side visuals vs server-side logic; integration of these layers)."
      ],
      "parent_articles": [
        "Graphical user interface",
        "Web development"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does modularity implement separation of concerns to manage system complexity, and what mechanism primarily allows modules to evolve independently while keeping integration a separate concern?",
      "options": {
        "A": "By duplicating logic across modules to reduce cross-module dependencies.",
        "B": "By encapsulating each module's implementation behind a stable interface so other parts depend only on the interface; changes inside a module stay isolated, and integration of modules is treated as a separate concern.",
        "C": "By requiring all modules to be updated simultaneously for any change so consistency is preserved.",
        "D": "By removing interfaces and relying on a single global object to coordinate and control all modules."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the question to be shorter and clearer (replaced 'operationalize' with 'implement'); emphasized encapsulation and stable interfaces as the mechanism; preserved the original answer and distractors.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.2_vs_16",
    "pass_2_attempt": {
      "question": "A software architect is designing a distributed e-commerce platform that must satisfy correctness, performance, maintainability, and security. Which of the following architectural approaches best exemplifies (a) the separation of concerns principle so engineers can focus on one aspect at a time, (b) modularity that lets module internals be developed and reasoned about in isolation while treating integration as a separate concern, and (c) a view-based separation of concerns (for example Kruchten's 4+1) to address different stakeholder perspectives?",
      "options": {
        "A": "Decompose the system into well-defined modules (catalog, ordering, payment, authentication, logging) with explicit module interfaces and an independent integration layer responsible for orchestration; document the architecture using multiple views (logical, development, process, physical, and scenarios) so each stakeholder can focus on the relevant concerns; handle cross-cutting concerns (security, logging) via aspects or separate infrastructure services.",
        "B": "Organize the codebase by feature teams where each team implements all aspects (UI, business rules, persistence) for their feature in a single repository; rely on continuous integration to catch integration problems and avoid producing separate architectural views or formal module contracts.",
        "C": "Adopt a large set of small microservices but allow each service to implement its own logging and security ad hoc; do not create a separate integration strategy or stakeholder views—treat integration as incidental and rely on runtime monitoring to reveal problems.",
        "D": "Model the system as a strict layered protocol stack (presentation, transport, routing) inspired by network protocol separation (e.g., TCP/IP) and place all policy decisions in the top layer; produce only a single developer-oriented diagram showing layers and internal APIs."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete distributed e-commerce scenario and presented four plausible architectural strategies; option A explicitly maps SoC, modularity with separate integration, and the 4+1 view-based documentation, while alternatives violate one or more target concepts.",
      "concepts_tested": [
        "Separation of concerns as focus-on-one-aspect principle",
        "Modularity and treating integration as a separate concern",
        "View-based architecture (Kruchten's 4+1) for stakeholder-specific concerns"
      ]
    },
    "pass_2_reason": "readability_too_high_23.5_vs_16"
  },
  {
    "original_question": {
      "question": "In medicinal chemistry optimization, why does pursuing higher potency for a screening hit frequently create trade-offs with metabolic stability and oral bioavailability?",
      "options": {
        "A": "Increasing potency always improves all pharmacokinetic properties, so there is no trade-off.",
        "B": "Increasing potency often involves increasing lipophilicity or introducing bulky groups, which can enhance target binding but also raise susceptibility to metabolic enzymes and reduce aqueous solubility and permeability, leading to poorer metabolic stability and oral bioavailability.",
        "C": "Potency is determined solely by receptor affinity and is independent of how a compound is metabolized or absorbed.",
        "D": "Metabolic stability is determined only by the presence of metabolic enzymes and is unaffected by changes made to improve potency."
      },
      "correct_answer": "B",
      "source_article": "Drug discovery",
      "x": 2.014341115951538,
      "y": 1.08462655544281,
      "concepts_tested": [
        "Concept 1: The shift from classical pharmacology and serendipitous discovery to reverse pharmacology and high-throughput screening as a mechanism for identifying therapeutic targets.",
        "Concept 2: Medicinal chemistry optimization of screening hits, focusing on increasing affinity and selectivity, potency, metabolic stability, and oral bioavailability, and understanding the interdependencies/trade-offs among these properties.",
        "Concept 3: The drug development pipeline (clinical trials and regulatory approval) and the broader funding, governance, and policy context (investors, government funding, orphan drug incentives) that shape how discoveries become marketable therapies."
      ],
      "parent_concepts": [
        "Concept 1: Drug effects arise from target-specific molecular interactions (binding to enzymes/receptors) guided by chemical structure and affinity.",
        "Structure-activity relationship (SAR) as a causal link: identifying which chemical groups in a molecule drive a target biological effect and how changing structure alters activity or potency.",
        "Ethnopharmacology workflow: From identification/ethnotaxonomy and traditional preparation to bio-evaluation and assessment of clinical potential, illustrating how traditional knowledge can lead to pharmacological discovery.",
        "Concept 3: Empirical/conceptual evidence that validates polypharmacology approaches (e.g., SAMT and cdODN strategies) as demonstrations that simultaneous multi-target modulation can be feasible and advantageous."
      ],
      "parent_articles": [
        "Mechanism of action",
        "Structure–activity relationship",
        "Ethnomedicine",
        "Polypharmacology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In medicinal chemistry optimization, why does increasing a screening hit's potency often cause trade-offs with metabolic stability and oral bioavailability?",
      "options": {
        "A": "Increasing potency inherently improves all pharmacokinetic properties, so optimizing potency does not create trade-offs.",
        "B": "Improving potency is often achieved by increasing lipophilicity or adding bulky substituents, which can strengthen target binding but also increase metabolic clearance and reduce aqueous solubility and membrane permeability, worsening metabolic stability and oral bioavailability.",
        "C": "Potency is determined solely by receptor affinity and is independent of how a compound is metabolized or absorbed.",
        "D": "Metabolic stability depends only on the presence and activity of metabolic enzymes and is unaffected by chemical changes made to improve potency."
      },
      "correct_answer": "B",
      "simplification_notes": "Question shortened and focused on the medicinal chemistry trade-off between potency and ADME; language clarified to state common structural changes (increased lipophilicity, bulky groups) and their effects on metabolic clearance, solubility, and permeability. Distractor options kept plausible but concise.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.3_vs_16",
    "pass_2_attempt": {
      "question": "A small university spin-out has discovered a compound that rescues motor-neuron degeneration in a zebrafish phenotypic screen. The hit shows sub-nanomolar activity in the phenotypic assay but, when profiled, has high off-target activity against several GPCRs, low metabolic stability (rapid hepatic clearance), poor oral bioavailability, and a molecular weight of 540 Da. The company lacks capital for large Phase II/III trials and is considering next steps. Which integrated strategy best applies principles from modern drug discovery (shift from phenotypic to target-based approaches, medicinal chemistry optimization with trade-offs among potency/selectivity/stability/bioavailability, and realistic funding/regulatory pathways)?",
      "options": {
        "A": "Proceed immediately to HTS against the zebrafish model in larger libraries to find a lower-molecular-weight analogue, then increase lipophilicity to improve membrane permeability and oral bioavailability; secure venture capital to fund Phase III and bypass orphan-drug incentives because broader indication will be more profitable.",
        "B": "Perform target deconvolution on the phenotypic hit to identify and validate the molecular target (enabling reverse-pharmacology assays), then use medicinal-chemistry SAR to reduce off-target GPCR binding and metabolic clearance (for example, block metabolic hotspots and lower cLogP to improve half-life and selectivity, while considering prodrug approaches to restore permeability); simultaneously apply for orphan-drug designation (prevalence $1:50{,}000$) and seek government and philanthropic grants or a small-pharma partner to fund early clinical development before engaging VC for later phases.",
        "C": "Discard the phenotypic hit because its molecular weight ($>500$ Da) violates Lipinski’s Rule of Five, and instead license an existing marketed drug for repurposing; rely on the faster route to market through off-label use rather than filing an NDA or pursuing clinical trials.",
        "D": "Abandon experimental chemistry optimisation and instead perform virtual high-throughput docking of the hit against all human GPCR structures to computationally redesign the molecule into a highly rigid, highly aromatic scaffold (increasing chirality and aromaticity) to guarantee selectivity; use quantum-computing platforms to accelerate discovery and self-fund Phase III from initial licensing revenue."
      },
      "correct_answer": "B",
      "generation_notes": "Designed an integrated scenario requiring: move from phenotypic hit to target deconvolution and reverse pharmacology, medicinal chemistry trade-offs (reduce cLogP, block metabolic hotspots, prodrug), and funding/regulatory strategy (orphan designation, gov/philanthropic early funding, partner/VC later). Four plausible but distinct strategic options created; B is factually aligned with article.",
      "concepts_tested": [
        "shift from phenotypic/classical to reverse pharmacology and target deconvolution",
        "medicinal chemistry optimization trade-offs (affinity, selectivity, metabolic stability, oral bioavailability)",
        "drug development pipeline and funding/regulatory context (clinical phases, NDA, orphan-drug incentives, government/VC funding)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.2_vs_16"
  },
  {
    "original_question": {
      "question": "How does the ideology of linguistic pluralism shape the design and legitimacy of language planning decisions within a speech community, as opposed to an assimilation ideology?",
      "options": {
        "A": "It pushes planners to promote a single dominant language for all official domains to maximize economic efficiency.",
        "B": "It motivates establishing formal recognition, regulators, and standardization efforts for multiple languages, legitimizing planning that supports linguistic diversity.",
        "C": "It leads planners to abandon any standardization, treating all languages as equally informal and interchangeable.",
        "D": "It causes planners to rely solely on voluntary use of languages without any institutional support."
      },
      "correct_answer": "B",
      "source_article": "Language planning",
      "x": 1.2382885217666626,
      "y": 1.0812742710113525,
      "concepts_tested": [
        "Concept 1: The relationship among language planning, language policy, and language management — how deliberate actions by authorities to influence language form, use, or acquisition shape a speech community.",
        "Concept 2: The role of language ideologies (internationalization, linguistic assimilation, linguistic pluralism, vernacularization) in guiding and legitimating planning decisions.",
        "Concept 3: Mechanisms and consequences of planning (establishment of regulators/institutions; creation of orthography/grammar/dictionaries; potential economic or political outcomes for minorities) as a cause–effect framework."
      ],
      "parent_concepts": [
        "Concept 1: Standardization as an institutional mechanism (government recognition, schooling, grammars, dictionaries) that designates what counts as a \"standard\" dialect and influences language use."
      ],
      "parent_articles": [
        "Dialect"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the ideology of linguistic pluralism shape which language‑planning measures are designed and regarded as legitimate in a speech community, compared with an assimilation ideology?",
      "options": {
        "A": "It encourages planners to promote a single dominant language for all official domains to maximize economic efficiency and social unity.",
        "B": "It motivates formal recognition of multiple languages, the creation of regulatory bodies and standardization efforts, and planning (corpus and acquisition) that legitimizes policies supporting linguistic diversity.",
        "C": "It leads planners to abandon any standardization, treating all languages as equally informal and interchangeable without official norms.",
        "D": "It causes planners to rely solely on voluntary, community use of languages and to avoid institutional or legal support for language promotion."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified to contrast pluralism with assimilation; retained key mechanisms (recognition, regulators, standardization, corpus and acquisition planning) and used precise sociolinguistic terms.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.4_vs_16",
    "pass_2_attempt": {
      "question": "In the hypothetical state of Tiranoa the government does the following: it designates the indigenous language Mino as a regional official language in three provinces; it funds a National Language Academy charged with creating a standardized orthography and a dictionary for Mino; and it mandates Mino-medium instruction for primary schools in those provinces — while simultaneously declaring English the official language for international trade. Which interpretation best characterizes (1) the relationship among language policy, language planning and language management in these actions, (2) the dominant language ideology motivating the domestic measures for Mino, and (3) the principal mechanisms and likely sociopolitical consequences for the Mino-speaking minority?",
      "options": {
        "A": "This is a coherent example of language policy (legal status decisions) implemented through language planning and explicit language management: the state’s declarations set the policy, the Academy and education mandates enact planning (corpus planning — graphization/standardization — and acquisition planning), and managers (government and Academy) carry out observable interventions. The dominant ideology for Mino is vernacularization (restoration/officialization of an indigenous language). Mechanisms include creation of a regulator, standard orthography and bilingual curricula; likely consequences are strengthened local literacy and cultural revitalization but limited national/international economic advantage and possible political marginalization because English is privileged for trade.",
        "B": "These measures primarily illustrate linguistic assimilation: by funding the Academy and schooling in Mino the state is attempting to replace minority identities with the national language, and management is coercive enforcement. The ideology is assimilation; mechanisms are compulsory education and legal banishment of minority forms. Consequences are rapid convergence to the national norm and loss of Mino distinctiveness.",
        "C": "The actions reflect pure linguistic pluralism: the government equally valorizes all languages so no single ideology guides planning. Mechanisms are symbolic recognition only (status allocation) without corpus or acquisition work; consequences are uniform socioeconomic benefits for all groups and elimination of language-based inequalities.",
        "D": "This is an instance of internationalization: because English is chosen for trade, the state’s primary objective is to promote a non-indigenous global language. The domestic steps for Mino are token status planning with no substantive management; the ideology is internationalization and the mechanism is privileging foreign-language competence to maximize economic returns, with cultural outcomes considered secondary."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete policy scenario (Tiranoa) that requires students to map policy/planning/management relations, identify vernacularization ideology, and link mechanisms (regulator, graphization, acquisition planning) to likely sociopolitical outcomes for a minority language.",
      "concepts_tested": [
        "relationship among language planning, language policy, and language management",
        "language ideologies (vernacularization vs other ideologies) guiding planning",
        "mechanisms (regulators, corpus and acquisition planning) and consequences for minorities"
      ]
    },
    "pass_2_reason": "readability_too_high_29.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does treating security as a multi-domain phenomenon (including military power, economics, environment, human security, and non-state actors) alter the way policymakers must prioritize trade-offs, compared with focusing solely on military threats?",
      "options": {
        "A": "Because the expanded view reduces the number of relevant threats, enabling a single policy instrument to address all risks.",
        "B": "Because non-military domains are independent of each other, allowing separate policies for each domain without cross-effects.",
        "C": "Because threats emerge from interactions across domains, making security outcomes depend on economic, environmental, and social factors, which forces balancing civil liberties, development, and resilience with deterrence.",
        "D": "Because military capability remains the sole determinant of security, so expanding domains does not change policy priorities."
      },
      "correct_answer": "C",
      "source_article": "International security",
      "x": 1.1824250221252441,
      "y": 0.9010751247406006,
      "concepts_tested": [
        "Concept 1: The expansion of security from traditional military power to a comprehensive, multi-domain framework (including economics, environment, human security, and non-state actors) and its policy implications.",
        "Concept 2: Security as a normative, subjective concept—the idea that different states have different security definitions and expectations, shaping their policies and actions.",
        "Concept 3: The trade-offs in pursuing security—the notion that achieving security can require sacrificing other values or engaging in measures that affect civil liberties and other priorities."
      ],
      "parent_concepts": [
        "Concept 3: Transnational and cross-jurisdictional nature of maritime security (liminality, cross-border governance, multi-actor coordination)."
      ],
      "parent_articles": [
        "Maritime security"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does treating security as a multi-domain phenomenon (military power, economics, environment, human security, and non-state actors) change the way policymakers must prioritize trade-offs, compared with focusing only on military threats?",
      "options": {
        "A": "Because the broader view somehow reduces the number of relevant threats, letting a single policy tool solve most risks.",
        "B": "Because non-military domains are essentially independent, so policymakers can design separate, non-interacting policies for each domain.",
        "C": "Because threats arise from interactions across domains, so security outcomes depend on economic, environmental, and social factors; policymakers must therefore balance civil liberties, development and resilience with traditional deterrence.",
        "D": "Because military capability still determines overall security, so adding other domains does not change policy priorities."
      },
      "correct_answer": "C",
      "simplification_notes": "Question language shortened and clarified; the list of domains was kept; background rationale and policy trade-off idea condensed; preserved normative and interactional aspects.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.5_vs_16",
    "pass_2_attempt": {
      "question": "The coastal state of Lantania faces three simultaneous problems over the next decade: (1) accelerated sea-level rise displacing coastal communities, (2) a sharp decline in export revenues from a single commodity, and (3) transnational cyber-attacks by an organized non-state group that steal financial data. The Lantanian government must design a security strategy that reflects contemporary international security thinking: it should move beyond a purely military response, recognize that 'security' may mean different things to different domestic constituencies, and acknowledge trade-offs between measures that enhance security and other values (e.g., civil liberties, development spending). Which of the following policy packages best embodies (i) the expansion of security into multiple domains (economic, environmental, cyber, human), (ii) sensitivity to the subjective/normative character of security across groups in Lantania, and (iii) explicit management of trade-offs in means used to pursue security?",
      "options": {
        "A": "Adopt an integrated policy: invest in coastal defenses and planned relocations while allocating $20\\%$ of targeted development funds to livelihood retraining; diversify the export base through tax incentives and regional trade agreements; form public–private cyber-defense partnerships and sign mutual assistance pacts with neighboring states and IGOs; strengthen domestic oversight by creating judicial review of surveillance measures, sunset clauses on emergency powers, and participatory local consultations so security priorities reflect diverse social groups.",
        "B": "Return to a traditional state-centric approach: increase defense spending by 40% to guard borders and maritime approaches, erect stricter immigration controls to deter migrants from flooded coasts, and centralize decision-making in the executive to allow rapid, unilateral action against cyber actors — treating security primarily as protection of territory and state institutions.",
        "C": "Implement a purely human-security reallocation: cut all military and coast-guard budgets to zero and divert the entire amount to universal basic income, public health, and community-led adaptation projects; accept open borders for displaced persons; rely exclusively on NGOs for cyber-security aid, with no state-led coordination.",
        "D": "Prioritize hard security and control: declare a prolonged state of emergency allowing mass surveillance, suspension of certain civil liberties, and emergency contracting of private security firms to protect critical infrastructure; delay economic restructuring and avoid costly adaptation measures to focus resources on immediate suppression of non-state cyber threats."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a realistic policy scenario requiring evaluation of multi-domain security, normative differences in threat perception, and trade-offs (liberties vs security). Option A integrates UNDP-like human development allocation ($20\\%$), international cooperation, and safeguards; other options map to traditional, extreme human-security, and authoritarian trade-off models.",
      "concepts_tested": [
        "Expansion of security from military to multi-domain frameworks (economic, environmental, cyber, human)",
        "Security as a normative and subjective concept shaping policy choices",
        "Trade-offs between security measures and other values (civil liberties, development priorities)"
      ]
    },
    "pass_2_reason": "readability_too_high_23.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the core objective of universal health care—providing access to health services without financial hardship—conceptually connect access to health outcomes and equality of opportunity?",
      "options": {
        "A": "By removing or reducing out-of-pocket costs at the point of care, more people can seek preventive and timely care and adhere to treatments, which tends to improve health outcomes and reduce SES-based disparities, linking access to outcomes and opportunity.",
        "B": "Because when services are free, everyone will automatically have the best possible health outcomes, regardless of behavior or environmental factors.",
        "C": "Because access alone guarantees uniform health outcomes, irrespective of how health services are financed or organized.",
        "D": "Because financing arrangements don't influence utilization or outcomes; wait times and quality are the only determinants."
      },
      "correct_answer": "A",
      "source_article": "Universal health care",
      "x": 1.2099275588989258,
      "y": 0.8406901955604553,
      "concepts_tested": [
        "Concept 1: The three critical dimensions of universal health care (who is covered, what services are covered, how much of the cost is covered) as a framework for understanding and evaluating UHC.",
        "Concept 2: The core objective of UHC to provide access to health services without financial hardship, linking access to health outcomes and equality of opportunity.",
        "Concept 3: The organizational mechanisms underpinning UHC (government-funded vs. private insurance-based models) and how these funding structures shape access and service provision."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does the core aim of universal health coverage—ensuring access to health services without financial hardship—logically link improved access to better health outcomes and greater equality of opportunity?",
      "options": {
        "A": "By reducing or eliminating out-of-pocket costs at the point of care, more people can obtain preventive and timely care, adhere to treatments, and avoid postponing needed services; this tends to improve population health and reduce socioeconomic disparities, thereby linking access to outcomes and equal opportunity.",
        "B": "Because if health services are free, everyone will automatically attain the best possible health outcomes regardless of behavior, environment, or genetics.",
        "C": "Because simply providing access guarantees uniform health outcomes for all people, no matter how health services are financed or organized.",
        "D": "Because financing arrangements do not influence utilization or outcomes; only factors like wait times and clinical quality determine health results."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording was shortened and clarified for undergraduates; retained the link between out-of-pocket costs, service use (preventive/timely care, adherence), and reduced socioeconomic disparities. Distractors were kept as plausible misconceptions about access, financing, and outcomes.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.8_vs_16",
    "pass_2_attempt": {
      "question": "Caledonia is a middle-income country where 60% of residents currently have health insurance, the publicly funded package covers primary care only, and the public system reimburses about $70\\%$ of the cost of covered services, leaving significant out-of-pocket (OOP) payments that push many households into financial hardship. The government wants to move toward Universal Health Coverage (UHC) as defined by the WHO and the three critical dimensions: who is covered, what services are covered, and how much of the cost is covered. Which of the following reform packages would most comprehensively align Caledonia’s system with the core objective of UHC (access to needed health services without financial hardship) and the three critical dimensions?",
      "options": {
        "A": "Mandate that all residents purchase private insurance from regulated insurers; provide a sliding-scale subsidy that covers 50\\% of premiums for the poorest 20\\%; the basic insurance package remains limited to primary care and maternity services, and insurers are allowed to use medical underwriting for supplementary plans.",
        "B": "Implement a single-payer, tax-financed national health fund that automatically enrolls all residents, defines a comprehensive essential benefit package (primary, specialist, hospital, and selected medications), and reduces point-of-service OOP payments so that the system reimburses 90\\% of the cost for covered services.",
        "C": "Expand employer-based mandatory sickness funds that cover employees and their immediate families, increase reimbursement rates to cover 80\\% of costs for enrollees, but leave informal sector workers and the unemployed to purchase voluntary private plans with no subsidy.",
        "D": "Introduce a voucher program that gives uninsured households a fixed annual amount to spend on accredited private providers; vouchers cover up to $200 per person per year, while other services remain available through the existing limited public package with the same OOP cost structure."
      },
      "correct_answer": "B",
      "generation_notes": "Created a country scenario with baseline coverage, services, and OOP; presented four reform packages contrasting funding models and coverage dimensions; selected the option that best meets the three UHC dimensions and WHO goal.",
      "concepts_tested": [
        "Three critical dimensions of UHC (who, what, cost)",
        "Funding/organizational models and their effect on access and financial protection"
      ]
    },
    "pass_2_reason": "readability_too_high_20.1_vs_16"
  },
  {
    "original_question": {
      "question": "Why is data mining best understood as a coordinated workflow involving pre-processing, modeling, post-processing, visualization, and metrics of interestingness, rather than a single isolated analysis step, and how does this illustrate its interdisciplinary nature?",
      "options": {
        "A": "Pre-processing and visualization are redundant because raw data already reveals patterns; modeling alone suffices to produce actionable insights.",
        "B": "Each stage serves a purpose: pre-processing aligns data quality and representation for meaningful pattern extraction by models; modeling discovers patterns; post-processing and visualization translate results into interpretable, actionable insights; metrics guide evaluation and selection of useful patterns; together they reflect the integration of database management (data preparation), machine learning/statistics (pattern discovery), and decision-support visualization and evaluation.",
        "C": "Post-processing is the only critical phase; other phases do not affect the final insights.",
        "D": "Data mining is purely a statistical hypothesis testing task that doesn't rely on data management or software engineering aspects."
      },
      "correct_answer": "B",
      "source_article": "Data mining",
      "x": 1.5020320415496826,
      "y": 1.099518895149231,
      "concepts_tested": [
        "Concept 1: Data mining as the analysis step within KDD and its boundaries (what is included vs excluded, e.g., not data collection or reporting).",
        "Concept 2: The types of patterns data mining discovers (clusters, anomalies, associations, sequential patterns) and their role as summaries used for further analysis and predictive analytics.",
        "Concept 3: The interdisciplinary nature and workflow relationships (interaction of machine learning, statistics, databases; role of pre-processing, post-processing, visualization, and metrics of interestingness)."
      ],
      "parent_concepts": [
        "Concept 1: The transformation pipeline that converts unstructured text into structured data (parsing, feature derivation, database insertion) and then derives patterns, followed by evaluation and interpretation.",
        "Concept 2: Clustering is an iterative, user-involved process driven by choices of distance/density measures and preprocessing, not an automatic or purely algorithmic task.",
        "Concept 2: Use of embeddings and similarity-based retrieval to compare items/documents and identify the most relevant matches for a user."
      ],
      "parent_articles": [
        "Text mining",
        "Cluster analysis",
        "Recommender system"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is data mining better described as a coordinated workflow—including pre-processing, modeling, post-processing, visualization, and measures of interestingness—rather than a single isolated analysis step, and how does this illustrate its interdisciplinary character?",
      "options": {
        "A": "Pre-processing and visualization are unnecessary because raw data already contains obvious patterns; modeling alone is sufficient to produce actionable insights.",
        "B": "Each stage has a distinct role: pre-processing ensures data quality and appropriate representation for models; modeling discovers patterns (e.g., clusters, anomalies, associations); post-processing and visualization make the results interpretable and actionable; and metrics of interestingness guide evaluation and selection of useful patterns. Together these stages integrate database management (data preparation), machine learning/statistics (pattern discovery and evaluation), and decision-support/visualization, illustrating data mining's interdisciplinary workflow.",
        "C": "Post-processing is the only critical phase for producing insight; the prior phases (pre-processing, modeling, visualization, metrics) do not materially affect the final results.",
        "D": "Data mining is essentially just statistical hypothesis testing and thus does not depend on database management, data preparation, or software-engineering considerations."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording shortened and clarified the functional role of each stage; preserved technical terms (pre-processing, modeling, post-processing, metrics, visualization) and the interdisciplinary link among databases, machine learning/statistics, and decision-support. Kept the original correct option (B).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_26.0_vs_16",
    "pass_2_attempt": {
      "question": "A retail analytics team follows a KDD workflow to improve demand forecasting. They (1) extract point-of-sale records into a data warehouse, (2) impute missing prices, remove duplicates, and aggregate transactions by customer, (3) run a k-means clustering to segment customers, mine association rules to find frequently co‑purchased items, run anomaly detection to flag possible fraud, and mine sequential purchase patterns, (4) train a regression model that predicts next‑month spend using cluster IDs and association‑rule features, and (5) produce visual dashboards and a written report for managers. Which of the following statements best describes what belongs to the \"data mining\" step (as opposed to other KDD stages) and correctly characterizes the types and uses of patterns discovered?",
      "options": {
        "A": "The data mining step consists of the automated/semi‑automated analyses in step (3): clustering, association‑rule and sequential‑pattern mining, and anomaly detection. These produce summaries or patterns (groups, dependencies, unusual records) that can be used as features for predictive models (step (4)). Data collection/warehousing (1), pre‑processing (2), and final reporting/interpretation (5) are part of the broader KDD process but not the core data mining analysis; the work relies on methods from machine learning, statistics and database systems and uses interestingness metrics to evaluate patterns.",
        "B": "Data mining primarily covers steps (1) and (5): gathering the POS records into the warehouse and creating dashboards/reports, because mining is about extracting and presenting data to stakeholders; the clustering and association analyses in (3) are considered data collection activities rather than the mining step.",
        "C": "Only supervised predictive tasks such as the regression in (4) count as data mining; unsupervised tasks like clustering, association rules and anomaly detection are preprocessing steps whose outputs are not considered mined patterns and cannot meaningfully be used in downstream predictive models.",
        "D": "Data mining is restricted to visualization and post‑processing (step (5)); patterns like clusters and association rules are merely human interpretable summaries produced after mining and have no role as inputs to machine‑learned predictors, which must be trained directly on raw, untransformed data collected in (1)."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete retail KDD pipeline scenario to test boundaries of the data mining step, the types of patterns produced (clusters, anomalies, associations, sequential patterns), and their role as summaries/features for predictive analytics as well as interdisciplinary method dependencies.",
      "concepts_tested": [
        "Data mining as the analysis step within KDD and its boundaries",
        "Types of patterns discovered (clusters, anomalies, associations, sequential patterns) and their use as summaries/features for predictive models",
        "Interdisciplinary nature and workflow relationships (machine learning, statistics, databases; role of pre-processing and post-processing)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.8_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the dean of the diplomatic corps serve as the representative of the corps on matters of privilege and protocol, given that within the corps precedence is determined by the date credentials were presented?",
      "options": {
        "A": "The dean holds formal legal authority to make protocol decisions on behalf of all ambassadors.",
        "B": "The role is a convention based on seniority, providing a stable, non-political channel for the corps to present shared interests.",
        "C": "The dean can legally alter the order of precedence whenever their own country requests it.",
        "D": "The dean automatically attains higher diplomatic rank and immunity, enabling them to negotiate privileges for others."
      },
      "correct_answer": "B",
      "source_article": "Diplomatic rank",
      "x": 0.5854713916778564,
      "y": 0.5014365911483765,
      "concepts_tested": [
        "Concept 1: Precedence and the Dean of the Diplomatic Corps — how order of precedence is determined by the date credentials were presented and the role of the dean in representing the corps.",
        "Concept 2: Rank–Mission Relationships — how ranks map to types of missions (ambassador vs minister vs chargé d'affaires) and how changes (e.g., post-WWII standardization to embassies) shaped current practice.",
        "Concept 3: Regulatory Framework and Historical Evolution — how the Vienna Convention (1961) standardized modern ranks and the historical progression from earlier systems (Congress of Vienna 1815, Aix-la-Chapelle 1818) to explain why the system exists."
      ],
      "parent_concepts": [
        "Roles and relationships in diplomatic hierarchy: the ambassador’s highest rank, the distinction from chargé d'affaires, and how embassies facilitate government-to-government relations."
      ],
      "parent_articles": [
        "Ambassador"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If precedence in the diplomatic corps is determined by the date ambassadors presented their credentials, why does the longest-serving ambassador (the dean) act as the corps' representative on matters of diplomatic privilege and protocol?",
      "options": {
        "A": "Because the dean has formal legal authority to decide protocol and privileges for all ambassadors.",
        "B": "Because it is a convention based on seniority that provides a neutral, stable, non‑political channel for the corps to present shared concerns.",
        "C": "Because the dean can legally alter the order of precedence whenever their own government requests it.",
        "D": "Because the dean automatically attains a higher diplomatic rank and greater immunity, enabling them to negotiate privileges for others."
      },
      "correct_answer": "B",
      "simplification_notes": "Question and options shortened and clarified to undergraduate level; preserved the key point that precedence is by credential date and that the dean's role is a convention of seniority providing a neutral representative. Removed extended historical and legal detail.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.9_vs_16",
    "pass_2_attempt": {
      "question": "In the Catholic Republic of San Cordoba the following diplomats are accredited to the head of state: (1) Ambassador Alvarez (Country A) presented credentials on 10 March 2015; (2) Papal Nuncio Ruiz (Holy See) presented credentials on 1 July 2016; (3) Chargé d'affaires en pied Morita (Country C) was accredited by their foreign minister to San Cordoba's foreign minister on 1 January 2014; and (4) Envoy/Minister Petrov (Country D) still styles himself as a \"minister\" from a legation appointed in 1980. According to contemporary diplomatic practice and the historical evolution codified by the Vienna Convention (1961), which of the following statements is CORRECT about order of precedence and the status of these representatives?",
      "options": {
        "A": "Papal Nuncio Ruiz will serve as dean of the diplomatic corps in San Cordoba because in many Catholic countries the nuncio is accorded that role; ambassadors (including the nuncio and Ambassador Alvarez) take precedence over chargés, and among ambassadors precedence (aside from the nuncio exception) is determined by the date credentials were presented; the title \"minister\" as head of a legation is effectively obsolete after WWII and was superseded by the embassy/ambassador system formalized by the Vienna Convention (1961).",
        "B": "Chargé Morita, having been accredited the earliest (1 January 2014), is the dean of the diplomatic corps because precedence and the dean are always determined by the earliest accreditation date regardless of rank; ministers from legations rank above ambassadors because they represent their sovereigns directly under the 1815 Congress of Vienna rules.",
        "C": "Ambassador Alvarez automatically outranks the papal nuncio because precedence among ambassadors is solely determined by the presentation date of credentials (so 2015 precedes 2016), and the Vienna Convention (1961) restored the 1815 Congress of Vienna hierarchy that gives precedence to secular ambassadors over ecclesiastical representatives.",
        "D": "Envoy Petrov retains primacy because historical practice allows ministers (envoys extraordinary and ministers plenipotentiary) to keep precedence over chargés and ambassadors appointed later; under modern practice the Vienna Convention (1961) left ministers as a parallel but equally valid head-of-mission rank."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete accreditation timeline in a Catholic country to test: (1) the papal nuncio-dean exception and ambassador vs chargé precedence; (2) credential-date seniority within rank; (3) the obsolescence of minister/legation after WWII and codification by the Vienna Convention (1961).",
      "concepts_tested": [
        "Precedence and Dean of the Diplomatic Corps (credential dates and nuncio exception)",
        "Rank–Mission Relationships (ambassador vs chargé; minister/legation obsolescence)",
        "Regulatory Framework and Historical Evolution (Congress of Vienna, Aix-la-Chapelle, Vienna Convention 1961)"
      ]
    },
    "pass_2_reason": "readability_too_high_28.2_vs_16"
  },
  {
    "original_question": {
      "question": "How does the constitutive perspective explain that everyday talk and interactions do more than reflect organizational life—they actively shape its structure, processes, and identity?",
      "options": {
        "A": "By acting as a one-way transmitter of pre-existing roles from leadership to staff.",
        "B": "By generating, negotiating, and stabilizing shared meanings that become norms, routines, and identities.",
        "C": "By being a distraction that has little to do with actual organizing.",
        "D": "By enforcing fixed roles that cannot adapt to changing circumstances."
      },
      "correct_answer": "B",
      "source_article": "Organizational communication",
      "x": 1.2827348709106445,
      "y": 0.9974921345710754,
      "concepts_tested": [
        "The constitutive role of communication in organizing (how communication creates and sustains organizational structures, processes, and identities)",
        "Power, discourse, and organizational life (how discourses can oppress or liberate members, and how rhetorical practices shape organizational outcomes)",
        "Evolution of theoretical frameworks (the shift from a solely functional view to interpretive/critical perspectives influenced by globalization and postmodern thought)"
      ],
      "parent_concepts": [
        "Balancing the message, the media channel, and the audience as a core mechanism to achieve long-term organizational goals."
      ],
      "parent_articles": [
        "Strategic communication"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to the constitutive perspective, how do everyday conversations and interactions do more than describe organizational life and instead actively create and sustain an organization's structures, processes, and identity?",
      "options": {
        "A": "They act as a one-way transmission of predefined roles and orders from leaders to staff.",
        "B": "They generate, negotiate, and stabilize shared meanings and practices that become organizational norms, routines, and collective identities.",
        "C": "They are peripheral noise or distraction with little real effect on how the organization is structured or operates.",
        "D": "They merely enforce fixed, unchanging roles and procedures that prevent adaptation."
      },
      "correct_answer": "B",
      "simplification_notes": "Question phrasing shortened and clarified; kept the term 'constitutive perspective' and preserved theoretical focus. Options made more concise and plausible without altering the correct option.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.2_vs_16",
    "pass_2_attempt": {
      "question": "GlobeSoft, a multinational technology firm, announces a merger and the CEO issues a series of memos and town-hall speeches that frame the merger as a necessary step toward “strategic alignment and agile innovation.” HR circulates formal efficiency metrics, while informal employee networks circulate counter-narratives about layoffs and the marginalization of minority teams. Which theoretical interpretation best explains how the CEO’s rhetoric both helps bring the merged organization into being (shaping roles, identities, and procedures) and simultaneously legitimizes managerial authority while suppressing alternative voices — an understanding that reflects the field’s shift from a purely functional view to interpretive/critical, discursive perspectives influenced by postmodern thought?",
      "options": {
        "A": "A functional/transactional perspective: communication is chiefly a vehicle for transmitting information to coordinate tasks and reduce uncertainty, so the CEO’s memos function to provide clear directives and efficiency metrics guide organizational action.",
        "B": "A constitutive, interpretive/critical perspective: the CEO’s rhetoric constitutes the merged organization by producing organizational identities, norms, and procedures; that discourse also operates as a form of power (in the Foucauldian sense), legitimizing managerial authority and marginalizing dissenting narratives.",
        "C": "A human-relations/cultural perspective: the messages are primarily about employee morale and cultural integration, so the emphasis is on using narratives to increase belonging and satisfy psychological needs rather than on creating organizational structures or exercising power.",
        "D": "A systems/ecological perspective: the merger should be analyzed as an input–throughput–output process in a complex environment where communication is one adaptive subsystem among many, not primarily as constitutive discourse or power enactment."
      },
      "correct_answer": "B",
      "generation_notes": "Designed a concrete merger scenario to contrast functional, constitutive/critical, human-relations/cultural, and systems lenses; correct choice links constitutive role of discourse with power and postmodern/interpretive evolution.",
      "concepts_tested": [
        "constitutive role of communication in organizing",
        "power and discourse in organizational life",
        "evolution from functional to interpretive/critical (discursive) frameworks"
      ]
    },
    "pass_2_reason": "readability_too_high_23.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does categorization into social groups, coupled with evaluation of those groups, tend to produce prejudice through overgeneralization about individuals?",
      "options": {
        "A": "Once a category is activated, people rely on category-level schemas to interpret ambiguous information, automatically applying group-level attributes to individuals and forming unfavourable judgments even when a specific person differs from the stereotype.",
        "B": "Individuals are always evaluated on their own merits, so category labels never influence judgments.",
        "C": "Prejudice only arises from conscious beliefs and never from automatic cognitive shortcuts like categorization.",
        "D": "Group categorization inherently reduces cognitive load and thus makes people more open to individual variation."
      },
      "correct_answer": "A",
      "source_article": "Prejudice",
      "x": 1.2326685190200806,
      "y": 0.9811652898788452,
      "concepts_tested": [
        "Concept 1: Categorization and evaluation as a mechanism for prejudice (categorical thinking leading to unfavourable judgments based on perceived group membership; includes overgeneralization).",
        "Concept 2: Cognitive/psychological processes such as symbolic transfer and resistance to change (transfer of value onto a category and then individuals; persistence despite evidence).",
        "Concept 3: Social consequences/relationships (prejudice contributing to scapegoating, violence, and perceived global security threats)."
      ],
      "parent_concepts": [
        "Animalistic vs mechanistic dehumanization as distinct psychological mechanisms that deny either uniquely human traits or warmth/agency, shaping how victims are perceived and treated.",
        "In-group/out-group conflict as the relational basis for xenophobia"
      ],
      "parent_articles": [
        "Dehumanization",
        "Xenophobia"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does sorting people into social categories and then evaluating those categories often produce prejudice by causing overgeneralizations about individual members?",
      "options": {
        "A": "Once a category is activated, people use category-level schemas to interpret ambiguous information, automatically applying group-level attributes to individuals and forming unfavourable judgments even when a specific person differs from the stereotype.",
        "B": "People are judged only on their individual merits, so category labels do not influence evaluations of specific persons.",
        "C": "Prejudice arises only from deliberate, conscious beliefs and never from automatic cognitive shortcuts such as categorization.",
        "D": "Because categorization reduces cognitive load, it makes people more likely to attend to individual variation and therefore decreases overgeneralization."
      },
      "correct_answer": "A",
      "simplification_notes": "Rewrote the stem to be concise and academically phrased for undergraduates; preserved technical terms (e.g., \"category-level schemas\") and the mechanism of automatic application of group attributes. Options were reworded to be plausible alternatives and kept one correct answer (A).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.3_vs_16",
    "pass_2_attempt": {
      "question": "In the town of Greendale, a single widely publicized fraud conviction by a member of the minority Parkside community produced a cascade of social reactions: local residents began to describe all Parkside people as dishonest; newspapers used value-laden headlines linking 'Parkside culture' to corruption; politicians framed Parkside immigration as a threat to national values; and vigilante attacks against Parkside neighbourhoods increased, prompting international human-rights concerns. Which explanation best integrates the psychological mechanisms that produced and sustained the prejudice and the subsequent social consequences in this scenario?",
      "options": {
        "A": "Initial categorical thinking produced an overgeneralized negative evaluation of the entire Parkside category; symbolic transfer occurred when value-laden cultural meanings were attached to the Parkside category and applied to individuals; resistance to change kept the negative belief despite counterevidence; political scapegoating amplified hostility and produced collective violence, creating a broader security threat.",
        "B": "An authoritarian personality in most Greendale residents caused an immediate hostile attitude towards Parkside people; mass media simply reflected this pre-existing pathology, and the political rhetoric had little causal role in escalating violence or international concern.",
        "C": "Realistic conflict over scarce economic resources was the primary driver: competition for jobs after an economic downturn led residents to blame Parkside people, independently of categorical overgeneralization or symbolic framing.",
        "D": "Intergroup contact failure alone explains the sequence: lack of interpersonal contact increased anxiety and ignorance, so prejudice emerged directly from this absence without involvement of symbolic transfer or political scapegoating."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete multi-step scenario illustrating categorization/overgeneralization, symbolic transfer and resistance to change, and social consequences (scapegoating, violence, security risk); options contrast integrated mechanism with single-factor alternatives.",
      "concepts_tested": [
        "Categorization and overgeneralization as mechanisms of prejudice",
        "Symbolic transfer and resistance to change in maintaining prejudice",
        "Prejudice leading to scapegoating, collective violence, and security consequences"
      ]
    },
    "pass_2_reason": "readability_too_high_25.5_vs_16"
  },
  {
    "original_question": {
      "question": "How do virtualization and backend resource pooling enable scalable, on-demand provisioning in utility computing?",
      "options": {
        "A": "It standardizes hardware to ease upgrades and ensure compatibility across devices.",
        "B": "It decouples software from physical hardware, allowing many virtual instances to share a pool of resources and be allocated or deallocated quickly as demand changes.",
        "C": "It guarantees each customer a dedicated physical server to maintain fixed performance regardless of demand.",
        "D": "It eliminates the need for hardware by running everything entirely in software without any physical backend."
      },
      "correct_answer": "B",
      "source_article": "Utility computing",
      "x": 1.4544990062713623,
      "y": 1.0850242376327515,
      "concepts_tested": [
        "Concept 1: Metered, pay-per-use provisioning as the mechanism that enables low upfront costs and scalable usage.",
        "Concept 2: Virtualization and distributed/resource pooling (back-end clusters) that enable scalable, on-demand provisioning.",
        "Concept 3: The relationship to and influence on broader models (grid computing, cloud computing, software as a service) and the idea of bundling resources across participants to deliver utility services."
      ],
      "parent_concepts": [
        "Dependency on IaaS/PaaS to provide scalable, on-demand infrastructure and rapid provisioning"
      ],
      "parent_articles": [
        "Software as a service"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a utility computing (pay-per-use) model, how do virtualization and backend resource pooling enable scalable, on-demand provisioning of compute and storage?",
      "options": {
        "A": "They enforce standardized hardware configurations to simplify upgrades and ensure compatibility across all devices.",
        "B": "They decouple software from physical hardware so many virtual instances can share a common pool of servers and storage, allowing instances to be allocated or released quickly as demand changes.",
        "C": "They guarantee each customer a dedicated physical server to maintain fixed performance irrespective of changing demand.",
        "D": "They remove hardware constraints by running services entirely as software abstractions, eliminating any need for a physical backend."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was tightened for clarity; technical terms (virtualization, resource pooling) were kept. Options were rephrased to be concise and plausible while preserving the original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.4_vs_16",
    "pass_2_attempt": {
      "question": "Company Alpha must run variable, occasionally large computational workloads but wants minimal upfront capital, rapid elasticity, and pay-for-what-you-use pricing. It evaluates three offerings: (1) Vendor U — virtual machines provisioned on pooled back-end server clusters, billed per-minute, customers spin instances up/down on demand and can buy bundled third‑party compute/storage; (2) Vendor V — dedicated physical servers leased on multi‑year contracts with flat monthly fees and no virtualization; (3) Community Grid — volunteer-owned PCs coordinated by a central server, contributors unpaid and availability unpredictable. Which statement best explains why Vendor U exemplifies utility computing (per the article) and how it differs from Vendor V and Community Grid?",
      "options": {
        "A": "Vendor U matches utility computing because it provides metered, pay‑per‑use provisioning with low upfront cost and on‑demand scalability; it uses virtualization and pooled back‑end clusters to oversubscribe resources and deliver elasticity, and it can bundle resources (marketplace) — whereas Vendor V is capital‑intensive dedicated hosting and Community Grid lacks commercial metering and reliable QoS.",
        "B": "Vendor U is essentially identical to Vendor V because both provide dedicated compute capacity to customers; the presence of virtualization only affects billing granularity and does not influence upfront costs or scalability, while Community Grid is the only true utility because it aggregates many nodes.",
        "C": "Vendor U is not utility computing because it charges per minute; true utility computing requires free or volunteer contributions (like Community Grid) and fixed monthly billing, while Vendor V's long leases best ensure predictable performance and thus are the utility model.",
        "D": "Vendor U resembles Community Grid more than Vendor V because both use pooled, heterogeneous resources; utility computing is defined by geographic distribution of nodes (grid computing) rather than by metered billing or virtualization, so Vendor V cannot be utility despite its commercial terms."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete procurement scenario comparing three concrete deployment models; options contrast metered pay‑per‑use, virtualization/pooling, and bundling versus dedicated leases and volunteer grids to test understanding of utility computing features and distinctions.",
      "concepts_tested": [
        "Metered pay‑per‑use provisioning enabling low upfront cost and elasticity",
        "Virtualization and pooled back‑end clusters enabling on‑demand scaling",
        "Relationship to grid/cloud/SaaS and bundling/marketplace of resources"
      ]
    },
    "pass_2_reason": "readability_too_high_22.7_vs_16"
  },
  {
    "original_question": {
      "question": "How does the shift from purely descriptive botanical identification to molecular/metabolomic approaches change how pharmacognosy explains the link between natural product origin, structure, and therapeutic effect?",
      "options": {
        "A": "It reveals that therapeutic effects often arise from networks of multiple metabolites interacting with biological targets, so understanding mechanism requires systems-level reasoning rather than single-compound causality.",
        "B": "It proves that only the most abundant metabolite is responsible for activity, making structural complexity irrelevant.",
        "C": "It shows that origin and taxonomy alone fully predict activity, obviating the need for molecular data.",
        "D": "It implies that metabolomic data replace the need to consider ecological roles or biosynthetic pathways in mechanism."
      },
      "correct_answer": "A",
      "source_article": "Pharmacognosy",
      "x": 2.062110424041748,
      "y": 1.0623505115509033,
      "concepts_tested": [
        "Concept 1: Natural product molecules (secondary metabolites) as the basis for medicinal and functional properties, highlighting the relationship between chemical structure, natural origin, and biological effects.",
        "Concept 2: Evolution of pharmacognosy from descriptive, botanical identification of crude drugs to molecular/metabolomic approaches, illustrating how advances in science expand the conceptual framework of the field.",
        "Concept 3: The role of quality control, pharmacopoeial protocols, and regulatory frameworks in standardizing and ensuring the safety and efficacy of natural product-derived medicines."
      ],
      "parent_concepts": [
        "Ethnopharmacology workflow: From identification/ethnotaxonomy and traditional preparation to bio-evaluation and assessment of clinical potential, illustrating how traditional knowledge can lead to pharmacological discovery."
      ],
      "parent_articles": [
        "Ethnomedicine"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "When pharmacognosy moved from mainly descriptive botanical identification to molecular and metabolomic approaches, how did its explanation of the link between a natural product's origin, chemical structure, and therapeutic effect change?",
      "options": {
        "A": "It shows therapeutic effects often arise from networks of multiple metabolites interacting with biological targets, so understanding mechanism requires systems-level reasoning rather than single-compound causality.",
        "B": "It proves that only the most abundant metabolite is responsible for activity, making structural complexity irrelevant.",
        "C": "It shows that origin and taxonomy alone fully predict biological activity, removing the need for molecular data.",
        "D": "It implies metabolomic profiling replaces the need to consider ecological roles or biosynthetic pathways when explaining mechanism."
      },
      "correct_answer": "A",
      "simplification_notes": "Reworded the stem to be concise and clear for undergraduates, clarified 'molecular/metabolomic' as methods, preserved the core comparison between descriptive botanical versus systems-level molecular explanations; distractors were phrased as plausible but incorrect interpretations.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_22.0_vs_16",
    "pass_2_attempt": {
      "question": "A biotech company has obtained a crude ethanolic extract from Plant X used in traditional medicine; preliminary in vitro assays show anti-inflammatory activity. As the lead pharmacognosist you must design a development pathway that (1) follows the modern evolution of pharmacognosy from botanical identification to molecular/metabolomic characterization, (2) identifies the secondary metabolite(s) responsible for activity, and (3) generates the quality-control data required for a pharmacopoeial-style monograph and regulatory submission. Which one of the following development plans best satisfies these requirements?",
      "options": {
        "A": "Document the plant provenance and perform botanical/macroscopic and microscopic identification (including leaf constants) to prevent adulteration; perform bioassay-guided fractionation of the crude extract to isolate active secondary metabolite(s); use LC–MS/MS-based metabolomic profiling to develop a chemical fingerprint and identify marker compounds; develop validated analytical assays (e.g., HPLC) to quantify the marker(s), set specification limits (identity, assay, purity, contaminants, microbial limits), generate stability and toxicology data, and assemble a pharmacopoeial-style monograph for regulatory submission.",
        "B": "Isolate compounds using a single acid–base extraction targeted at alkaloids, purify the first major alkaloid obtained, and proceed directly to human efficacy trials because the compound was isolated and in vitro active; skip broader metabolomic profiling and formal quality specifications since isolation proves the active principle.",
        "C": "Rely on the traditional use record and supply whole crude extract capsules with botanical identification only (macroscopy and supplier certificates), arguing that long-term ethnomedical use obviates the need for chemical characterization, bioassay-guided fractionation, or regulatory monographs.",
        "D": "Perform untargeted metabolomics to produce a complex chemical fingerprint and select several correlated metabolites as markers without performing bioassay-guided fractionation or isolation; standardize batches solely by multivariate fingerprint similarity without developing validated single-compound assays or toxicology data, then file for regulatory approval based on fingerprinting alone."
      },
      "correct_answer": "A",
      "generation_notes": "Created a realistic drug-development scenario that requires integration of traditional botanical methods, bioassay-guided fractionation, metabolomic profiling, analytical validation, and pharmacopoeial/regulatory quality control; distractors omit one or more critical elements.",
      "concepts_tested": [
        "Role of secondary metabolites in biological activity",
        "Transition from descriptive botanical methods to molecular/metabolomic approaches in pharmacognosy",
        "Quality control, pharmacopoeial monographs, and regulatory requirements for natural product-derived medicines"
      ]
    },
    "pass_2_reason": "readability_too_high_21.9_vs_16"
  },
  {
    "original_question": {
      "question": "How does treating neural networks as knowledge representation formalisms illuminate the challenge of combining symbolic reasoning with subsymbolic learning, and what mechanism explains why a direct, rule-based engine struggles with perceptual tasks?",
      "options": {
        "A": "Neural networks encode knowledge in distributed, continuous internal representations that capture statistical regularities, which symbolic inference engines struggle to operate on directly; bridging requires learnable mappings or hybrid representations to translate perceptual input into symbolic structures.",
        "B": "Neural networks store knowledge as explicit, discrete facts that can be directly manipulated by logical inference, so no bridging is necessary.",
        "C": "If neural networks are knowledge representations, then symbolic reasoning can simply be replaced by a single large network, making hybrid systems unnecessary.",
        "D": "All KR formalisms are recursively isomorphic, so any integration approach works equally well regardless of representation."
      },
      "correct_answer": "A",
      "source_article": "Knowledge representation and reasoning",
      "x": 1.4133981466293335,
      "y": 1.1244450807571411,
      "concepts_tested": [
        "Concept 1",
        "Concept 2",
        "Concept 3",
        "Concept 1: The linkage between structured knowledge representation and automated reasoning mechanisms (e.g., inference engines, theorem provers) and how the choice of representation influences what can be reasoned about.",
        "Concept 2: The idea that many mainstream KR formalisms are recursively isomorphic, implying theoretical equivalence in expressive power and shared fundamental challenges across formalisms.",
        "Concept 3: The interdisciplinary nature of KR, drawing on psychology and logic and extending to machine learning, including viewing neural networks as knowledge representation formalisms, which supports integrating symbolic and subsymbolic approaches."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "If we treat neural networks as knowledge-representation formalisms, how does that clarify the difficulty of combining symbolic reasoning with subsymbolic learning, and what explains why a direct rule-based inference engine struggles with perceptual tasks?",
      "options": {
        "A": "Neural networks encode knowledge in distributed, continuous internal representations that capture statistical regularities; symbolic inference engines cannot operate directly on these representations, so bridging requires learnable mappings or hybrid representations that translate perceptual input into symbolic structures.",
        "B": "Neural networks store knowledge as explicit, discrete facts that can be directly manipulated by logical inference, so no bridging between subsymbolic and symbolic systems is necessary.",
        "C": "Viewing neural networks as knowledge representations implies symbolic reasoning can simply be replaced by a single, sufficiently large network, eliminating the need for hybrid systems.",
        "D": "Because all mainstream knowledge-representation formalisms are recursively isomorphic, any method of integration will work equally well regardless of whether the representation is symbolic or subsymbolic."
      },
      "correct_answer": "A",
      "simplification_notes": "Condensed the original two-part question into a single clear sentence for undergraduates; retained technical terms (distributed representations, symbolic inference, hybrid mappings); shortened options while keeping them plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.9_vs_16",
    "pass_2_attempt": {
      "question": "You are designing a medical-diagnosis system and must choose among three knowledge-representation formalisms applied to the same domain: (1) an OWL/frame-based ontology with a classifier, (2) a MYCIN-style rule-based system with forward/backward chaining and truth-maintenance, and (3) a trained transformer neural network that maps patient records to diagnoses. Which single statement best captures (i) how choice of representation constrains the available automated reasoning mechanisms, (ii) the practical meaning of the claim that mainstream KR formalisms are recursively isomorphic, and (iii) the interdisciplinary nature of KR that brings together psychology, formal logic, and machine learning (symbolic and subsymbolic)?",
      "options": {
        "A": "The representation determines the natural reasoning engine: classifiers operate on subsumption, inheritance and consistency checking in ontologies; rule systems naturally support forward/backward chaining and truth‑maintenance; neural networks provide approximate, data‑driven inference without native symbolic proofs. Recursive isomorphism means these formalisms are theoretically inter-translatable (so they have equivalent expressive power) but such encodings impose practical costs in efficiency, comprehensibility and usability. This reflects KR’s interdisciplinary character: frame/prototype ideas from psychology shape representations, logic provides formal semantics and mechanized inference, and ML (e.g., neural nets) supplies parameterized, subsymbolic encodings that can be hybridized with symbolic methods.",
        "B": "Because mainstream KR formalisms are recursively isomorphic, the choice of representation is irrelevant: any reasoning engine (classifier, rule engine, or theorem prover) runs identically on any formalism, and neural networks are merely another implementation with no special tradeoffs. Psychology and logic are historical curiosities with no practical impact on modern KR and ML integration.",
        "C": "Ontologies and rule systems are equivalent in both representation and runtime behaviour, so a classifier is simply a special case of forward chaining; neural networks cannot be considered knowledge representations because they lack logical semantics. The recursive‑isomorphism result therefore only applies to symbolic formalisms; interdisciplinary inputs are limited to logic and software engineering.",
        "D": "The choice of formalism only affects surface syntax and tooling; any formalism can directly provide both deductive proofs and approximate pattern matching without encoding overhead. Recursive isomorphism implies perfect interoperability in practice, and psychology contributes only metaphors rather than concrete design constraints on KR systems."
      },
      "correct_answer": "A",
      "generation_notes": "Constructed a concrete medical-diagnosis scenario contrasting ontology+classifier, rule-based system, and neural network; formulated one option that links representation→reasoning, explains recursive isomorphism as theoretical equivalence with practical tradeoffs, and notes interdisciplinary integration of psychology, logic, and ML.",
      "concepts_tested": [
        "linkage between representation and automated reasoning mechanisms",
        "recursive isomorphism and practical implications of expressive equivalence",
        "interdisciplinary nature of KR including psychology, logic, and machine learning"
      ]
    },
    "pass_2_reason": "readability_too_high_26.6_vs_16"
  },
  {
    "original_question": {
      "question": "Why does codifying domain concepts, properties, and relations into an ontology enhance interoperability between heterogeneous data systems?",
      "options": {
        "A": "It imposes a strict dataset schema that all systems must mirror exactly to exchange data.",
        "B": "It provides a shared, machine-interpretable vocabulary and explicit semantics for concepts and their interrelations, allowing disparate systems to map data to common terms and infer compatible meanings.",
        "C": "It eliminates the need for data transformation because all data can be stored in a single universal format.",
        "D": "It primarily focuses on philosophical debates about existence rather than practical data exchange."
      },
      "correct_answer": "B",
      "source_article": "Ontology (information science)",
      "x": 1.320481777191162,
      "y": 1.0980067253112793,
      "concepts_tested": [
        "Ontology as a structured representation of concepts, properties, and inter-entity relations within a domain",
        "The role of ontologies in enabling interoperability, data systems, and discoverability across disciplines",
        "The relationship between applied ontology and philosophy, including ontology engineering and normative vs. foundational debates (e.g., use of controlled vocabularies and tools like Protégé)"
      ],
      "parent_concepts": [
        "Formal representation of meaning through ontologies and metadata (using RDF/OWL to describe concepts, relationships, and categories)"
      ],
      "parent_articles": [
        "Semantic Web"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does encoding a domain's concepts, properties, and relationships in an ontology improve interoperability among heterogeneous data systems?",
      "options": {
        "A": "By enforcing a single rigid data schema that every system must replicate exactly to exchange information.",
        "B": "By supplying a shared, machine-interpretable vocabulary and explicit semantics for concepts and relations, enabling systems to map their local data to common terms and infer compatible meanings.",
        "C": "By removing the need for any data transformation because all systems store data in one universal format defined by the ontology.",
        "D": "By primarily addressing philosophical questions about existence rather than providing practical mechanisms for data exchange."
      },
      "correct_answer": "B",
      "simplification_notes": "Reworded the question for clarity and concision, retained technical terms (ontology, interoperability), removed extended background examples; kept the original correct answer and core concept intact.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.3_vs_16",
    "pass_2_attempt": {
      "question": "A university medical informatics team must integrate heterogeneous datasets: electronic health records, a proteomics database, and literature-mined term lists. They find ambiguous tokens such as \"CSF\" used in different senses, multiple overlapping class hierarchies, and inconsistent relation definitions across sources. Which strategy best applies the principles of applied ontology to maximize interoperability and discoverability while avoiding prolonged philosophical foundational debates?",
      "options": {
        "A": "Construct precise domain ontologies for each dataset, align and map them to a shared upper (foundation) ontology (e.g., BFO or an OBO Foundry component), formalize disambiguating axioms (so \"CSF\" has distinct identifiers for \"Cerebrospinal fluid\" vs \"Colony stimulating factor\"), and use an OWL-based tool such as Protégé for editing, validation and iterative ontology engineering.",
        "B": "Automatically extract an ontology from all texts and databases using only unsupervised ontology-learning algorithms, then perform direct dataset joins based on learned labels; this avoids manual modeling and philosophical arguments and will scale without human intervention.",
        "C": "Adopt a single flat controlled vocabulary (a long list of canonical terms) and integrate systems by string-matching normalized labels at ingest time; treat all deeper relations and attributes as implementation details to be ignored initially.",
        "D": "Postpone engineering work until domain experts resolve metaphysical questions (e.g., whether biomedical entities are best modeled as enduring objects or as processes); once foundational ontology issues are settled, encode the resulting essences into the system."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a concrete biomedical data-integration scenario that requires domain and upper ontologies, controlled vocabularies, formal axioms, and tooling (Protégé); distractors test automated learning, flat taxonomies, and philosophical foundationalism.",
      "concepts_tested": [
        "Ontology as structured representation of concepts, properties, and inter-entity relations",
        "Role of ontologies in enabling interoperability and discoverability across heterogeneous data systems",
        "Applied ontology practices versus philosophical foundational debates (ontology engineering, controlled vocabularies, and tools like Protégé)"
      ]
    },
    "pass_2_reason": "readability_too_high_20.3_vs_16"
  },
  {
    "original_question": {
      "question": "In a multi-stage data fusion architecture, why does performing fusion at lower levels (e.g., raw data or basic features) tend to produce outputs with higher information content but greater design complexity compared to higher-level fusion (e.g., decisions or situation assessments), and how does this choice influence system resources and human-in-the-loop considerations?",
      "options": {
        "A": "Lower-level fusion combines raw data into synthesized signals and propagates sensor-specific uncertainties, which can increase information content but require tight synchronization, calibration, and uncertainty management, thus raising processing load and design complexity; higher-level fusion uses already-processed evidence to make decisions, reducing data volume and latency but sacrificing traceability of evidence and robustness to missed signals.",
        "B": "Lower-level fusion always yields faster results because it processes more data, while higher-level fusion is slower because it discards information.",
        "C": "Higher-level fusion preserves all raw measurements and their uncertainties, making the system design easier and more robust in all scenarios.",
        "D": "The choice of fusion level has no impact on latency, interpretability, or human-in-the-loop requirements; it is purely a data organization preference."
      },
      "correct_answer": "A",
      "source_article": "Data fusion",
      "x": 1.5407698154449463,
      "y": 1.0884493589401245,
      "concepts_tested": [
        "Concept 1: The multi-level data fusion framework (JDL/DFIG) and how processing at different levels (data, object, situation, etc.) shapes outcomes and system design.",
        "Concept 2: The core principle that fusing information from multiple sources enhances accuracy, usefulness, and coherence compared to individual sources, including the idea of low-, intermediate-, and high-level fusion.",
        "Concept 3: Geospatial data fusion as data integration that yields a fused dataset with enriched attributes/metadata, not merely a simple union."
      ],
      "parent_concepts": [
        "Concept 3: Integration of multiple data sources (criminal history, education, employment, references, etc.) to inform hiring decisions (how combining checks leads to a holistic assessment)."
      ],
      "parent_articles": [
        "Background check"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a multi-stage data fusion system, why does fusing at lower levels (raw sensor data or basic features) tend to produce outputs with higher information content but greater design complexity than fusing at higher levels (processed evidence, decisions, or situation assessments), and how does that choice affect system resources and human-in-the-loop needs?",
      "options": {
        "A": "Lower-level fusion combines raw signals and preserves sensor-specific uncertainties, which increases information content but requires tight synchronization, calibration, and explicit uncertainty management; this raises processing load, data-rate and design complexity. Higher-level fusion combines already-processed evidence or decisions, reducing data volume, latency and resource demand but sacrificing traceability of original measurements, sensitivity to weak/missed signals, and the ability for humans to inspect low-level evidence.",
        "B": "Lower-level fusion always yields faster outputs because it processes more raw data in parallel, while higher-level fusion is slower because it discards detailed information before combining.",
        "C": "Higher-level fusion preserves all raw measurements and their uncertainties, making system design simpler and universally more robust than lower-level fusion.",
        "D": "The fusion level choice does not affect latency, interpretability, or human-in-the-loop requirements; it is only a matter of how data are organized within the system."
      },
      "correct_answer": "A",
      "simplification_notes": "Question text shortened and clarified; trade-offs (information content vs. complexity), resource effects (processing, latency, data volume), and human-in-the-loop issues (traceability, inspectability) were made explicit; technical terms retained.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_26.2_vs_16",
    "pass_2_attempt": {
      "question": "A municipal flood-monitoring system ingests raw river-gauge voltages, radar precipitation grids, mobile-phone GPS traces, and geotagged citizen photos. The pipeline performs these tasks in sequence: (1) sensor-calibration and time alignment of raw voltages; (2) interpolation and merging of gauge and radar measurements to produce a continuous water-level surface; (3) labeling and temporal tracking of road segments as “flooded” or “clear”; (4) combining road-status, forecasts, and population data to identify evacuation zones; (5) optimizing allocation of rescue teams. Which choice best maps these tasks to the JDL/DFIG levels (use $L_0,L_1,\\dots$), correctly characterizes the interpolation step as low/intermediate/high fusion, and accurately describes the nature of the resulting geospatial fused dataset?",
      "options": {
        "A": "(Correct) Calibration and time alignment = $L_0$ (Source Preprocessing). Interpolation/merging into a continuous water-level surface = low-level (data) fusion producing new raw/field data (e.g. $\u0000\\hat{h}(x)=\\sum_{i=1}^n w_i(x) h_i$ where weights $w_i$ come from sensor geometry/uncertainty). Road-segment labeling/tracking = $L_1$ (Object Assessment). Combining statuses/forecasts/population = $L_2$/$L_3$ (Situation and Impact Assessment). Resource allocation/optimization = $L_4$/$L_5$ (Process/Mission Refinement). The fused geospatial dataset is not a simple union: it contains all points with interpolated attributes and metadata (e.g. uncertainty, provenance) assigned to each location.",
        "B": "Calibration = $L_0$. Interpolation/merging into a continuous surface = high-level fusion (decision/symbolic), because it produces a single summary field; road labeling = $L_1$. The fused geospatial dataset is essentially the superset (union) of input points with no need for attribute interpolation; downstream analysis simply reads attributes from the nearest original sensor.",
        "C": "Calibration/time alignment = $L_1$ (Object Assessment). Interpolation/merging = intermediate-level fusion ($L_2$) because it combines disparate modalities. Road labeling/tracking is $L_3$ (Impact Assessment). Evacuation-zone identification and team allocation are still part of $L_3$. The fused dataset is a merged table in which original attribute columns are simply concatenated per coordinate without recalculating values.",
        "D": "Calibration = $L_0$. Interpolation step is decision fusion (sensors send binary flood/no-flood and the center fuses decisions) rather than data fusion. Road-segment labeling is therefore merely a majority-vote over sensor bits. The geospatial fused dataset must be larger than any input (fusion always increases data volume) and contains no uncertainty metadata unless explicitly requested."
      },
      "correct_answer": "A",
      "generation_notes": "Used a concrete flood-monitoring pipeline to map tasks to JDL/DFIG levels, distinguish low/intermediate/high fusion (interpolation as low-level), and emphasize geospatial fusion produces enriched attributes/metadata rather than a simple union.",
      "concepts_tested": [
        "JDL/DFIG multi-level mapping",
        "Low-/intermediate-/high-level fusion and benefits of fusion",
        "Geospatial data fusion producing enriched fused datasets (interpolation, metadata)"
      ]
    },
    "pass_2_reason": "readability_too_high_22.3_vs_16"
  },
  {
    "original_question": {
      "question": "Why does kinship function as a web of social relationships with functional roles (such as socialization, group formation, and obligations) beyond mere biological relatedness?",
      "options": {
        "A": "Because kinship ties are defined strictly by genetic distance, which directly prescribes moral duties.",
        "B": "Because kinship systems encode patterns of social roles, expectations, and obligations that persist through socialization and institutions, extending beyond biological ties.",
        "C": "Because kinship is solely a biological reproduction mechanism and has no impact on social organization.",
        "D": "Because kinship distance is purely a metaphor and does not influence real-world duties or group formation."
      },
      "correct_answer": "B",
      "source_article": "Kinship",
      "x": 1.2280857563018799,
      "y": 0.985235333442688,
      "concepts_tested": [
        "Kinship as a web of social relationships with functional roles (socialization, group formation, obligations) beyond mere biological relatedness.",
        "Descent versus affinity: how descent groups and affinal (marital) relationships create distinct kinship patterns and social obligations.",
        "Kinship terminologies and distance: how degrees of relationship and kinship distance organize social roles, duties, and ethical norms (e.g., filial piety)."
      ],
      "parent_concepts": [
        "Pedigree collapse and DNA relationships: how cousin or closer-relative marriages can produce pedigree collapse, altering autosomal-DNA match patterns and the perceived relatedness between relatives."
      ],
      "parent_articles": [
        "Endogamy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does kinship operate as a network of social relationships with practical functions (socializing children, forming economic/political/religious groups, and creating obligations) rather than being only about biological relatedness?",
      "options": {
        "A": "Because kinship ties are determined strictly by genetic distance, and genes directly prescribe who has moral duties to whom.",
        "B": "Because kinship systems encode patterns of roles, expectations, obligations and categories (e.g. descent and affinity) that are transmitted by socialization and institutions, producing social groups and duties that extend beyond mere biological ties.",
        "C": "Because kinship is simply a biological reproduction mechanism and therefore does not structure social organization or obligations.",
        "D": "Because kinship distance is merely a metaphorical concept with no real effect on people's duties, social roles, or group formation."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; retained key terms (descent, affinity, socialization, obligations); distractors reframed as plausible misconceptions (genetic determinism, purely biological, metaphor-only).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.6_vs_16",
    "pass_2_attempt": {
      "question": "An anthropologist documents the following features in Village A: descent is matrilineal (children belong to the mother's lineage and key inheritance passes from a mother's brother to his sister's sons); marriages are regularly arranged between two specific lineages creating enduring political alliances between those lineages; people refer to a mother's sister by the same term used for 'mother' while distinguishing a father's brother with a different term; and primary child socialization occurs in the maternal household, with stronger normative obligations expressed toward maternal kin than toward paternal kin. Which interpretation most accurately reflects the concepts of kinship discussed in the article?",
      "options": {
        "A": "Kinship here is a socially constituted web of relations: matrilineal descent organizes group membership and inheritance, affinal ties from repeated bride-exchange produce political alliances, and the classificatory kin terminology (treating a mother's sister as 'mother') encodes socially salient roles and obligations—showing kinship is not reducible to genetic relatedness alone.",
        "B": "These patterns indicate kinship is primarily biological: stronger obligations to maternal kin must reflect higher genetic relatedness on the mother's side, and terminology simply mirrors accurate genealogical closeness; marriage alliances are incidental to kinship structure.",
        "C": "Because the community uses the same term for a mother's sister and for mother, their kinship terminology is purely descriptive and genealogically precise, implying that sociocultural roles do not influence who is counted as kin or who inherits.",
        "D": "Affinal ties (marriage) in this village cannot produce long-term social organization; only descent groups determine political alliances and obligations, so the observed bride-exchange is unlikely to affect lineage-level relations."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete ethnographic vignette illustrating matrilineal descent, affinal alliance via bride-exchange, and classificatory terminology; options contrast biologistic and social-constructivist readings to test understanding of descent vs affinity and kinship as social roles/obligations.",
      "concepts_tested": [
        "Kinship as socially constituted web of relationships (beyond biology)",
        "Descent versus affinity and their social functions",
        "Kinship terminologies (descriptive vs classificatory) and kinship-based obligations"
      ]
    },
    "pass_2_reason": "readability_too_high_27.7_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the collectively enforced structure of rights and obligations within an institution produce reliable expectations that help govern behavior, beyond the mere content of the rules themselves?",
      "options": {
        "A": "Because enforcement by multiple actors creates credible expectations of punishment for violations, reducing strategic uncertainty and encouraging consistent cooperation.",
        "B": "Because it makes rules strictly formal and eliminates informal norms from affecting behavior.",
        "C": "Because it guarantees universal compliance without any costs or effort.",
        "D": "Because it makes behavior entirely dependent on one central authority, ignoring local incentives."
      },
      "correct_answer": "A",
      "source_article": "Institution",
      "x": 1.2605985403060913,
      "y": 0.9792935848236084,
      "concepts_tested": [
        "Institutions as humanly devised constraints that shape social interaction and economic performance through costs of exchange and production.",
        "Institutions consist of mutually related rights and obligations and are collectively enforced, creating reliable expectations that govern behavior.",
        "The spectrum from informal to formal institutions (including primary/meta-institutions) and how formality and organizational complexity influence persistence and the scope of social order."
      ],
      "parent_concepts": [
        "Concept 1: Organization vs. institution – organizations contain internal institutions that govern interactions, clarifying the relationship and distinction between the two."
      ],
      "parent_articles": [
        "Organization"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does collective enforcement of an institution’s mutually related rights and obligations produce dependable expectations that govern behavior beyond the written rules themselves?",
      "options": {
        "A": "Because when multiple actors reliably enforce the rules they create credible threats of sanction and reduce strategic uncertainty, which encourages consistent cooperation and compliance.",
        "B": "Because collective enforcement turns all rules into strictly formal laws and removes the influence of informal norms or culture on behavior.",
        "C": "Because collective enforcement guarantees universal compliance at no cost, so people always obey without incentives or enforcement effort.",
        "D": "Because collective enforcement concentrates control in a single central authority, making local incentives and multiple enforcers irrelevant."
      },
      "correct_answer": "A",
      "simplification_notes": "Rewrote the question in clearer academic language, emphasized 'collective enforcement' and 'credible expectations'; preserved the institutional concepts (rights/obligations, enforcement, expectations). Distractor options kept plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.5_vs_16",
    "pass_2_attempt": {
      "question": "In the country of Veridia, rural land has long been allocated by clan elders according to unwritten customary rules that confer de facto rights and obligations enforced by communal sanctions. The national government passes a law creating a formal land-titling registry that confers legal deeds transferable through courts, but the registry offices are understaffed and local courts are slow and unpredictable. Which of the following predictions best synthesizes the institutional concepts that (1) institutions are humanly devised constraints that affect transaction costs and economic performance, (2) institutions consist of mutually related rights and obligations that are collectively enforced to create reliable expectations, and (3) institutions lie on a spectrum from informal to formal with formality and enforcement affecting persistence and scope of social order?",
      "options": {
        "A": "Formal land titling will rapidly replace customary allocation, eliminate uncertainty, and immediately lower the costs of exchange because written law always supersedes local practice; therefore investment will rise regardless of enforcement capacity.",
        "B": "If the formal registry is made low-cost and reliably enforced, registered deeds will reduce transaction costs and stimulate investment; if enforcement remains weak and costly, the customary, collectively enforced rules will persist and continue to govern most transactions, illustrating the formal–informal spectrum, the role of rights/obligations and the importance of enforcement for institutional effectiveness.",
        "C": "Because institutions are merely cultural conventions, replacing customary rules with formal titles will have no systematic effect on transaction costs or investment; economic performance depends only on individual preferences, not on institutional form or enforcement.",
        "D": "Customary, informal rules cannot generate dependable expectations because they lack written laws; only the formal titling law creates genuine rights and thus will determine all future land transactions, even if courts are slow."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete land-titling scenario to test students' understanding of institutions as humanly devised constraints affecting transaction costs and economic performance, the necessity of collective enforcement and rights/obligations, and the formal–informal spectrum affecting persistence.",
      "concepts_tested": [
        "Institutions as humanly devised constraints affecting transaction costs and economic performance",
        "Collective enforcement of mutually related rights and obligations and the formal–informal spectrum of institutions"
      ]
    },
    "pass_2_reason": "readability_too_high_23.4_vs_16"
  },
  {
    "original_question": {
      "question": "Why does pairing a data visualization with concise, supporting text and keeping the visual design uncluttered improve viewers' comprehension and reduce the risk of misinterpretation?",
      "options": {
        "A": "Because humans remember more from vivid color and decoration, so decoration alone conveys the message.",
        "B": "Because verbal text provides precise anchoring, labels, and context, while simple visuals reduce extraneous cognitive load, allowing the viewer to map the data to the intended relationships.",
        "C": "Because adding text distracts from the visual data, so clutter helps focus attention on the main message.",
        "D": "Because only the text matters; visuals are optional if the text is clear."
      },
      "correct_answer": "B",
      "source_article": "Data and information visualization",
      "x": 1.4180324077606201,
      "y": 1.0718567371368408,
      "concepts_tested": [
        "Concept 1: The primary goal of data/information visualization is to add value by improving viewers' comprehension and enabling insights and informed decisions.",
        "Concept 2: Effective visualization relies on deliberate design choices (visual encoding, color/shape use, simplicity, context, accuracy) and pairing visuals with supporting text to avoid clutter and misinterpretation.",
        "Concept 3: The comprehension of visuals emerges from the relationship between verbal and graphical components and the needs/knowledge level of the target audience."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does pairing a data visualization with concise supporting text and keeping the visual design uncluttered improve viewers' comprehension and reduce the risk of misinterpretation?",
      "options": {
        "A": "Because vivid colors and decorative elements make the graphic more memorable, so decoration alone is sufficient to convey the message.",
        "B": "Because concise verbal text supplies precise anchors, labels and context, while an uncluttered visual reduces extraneous cognitive load so viewers can map visual encodings to the intended relationships.",
        "C": "Because adding explanatory text distracts from the visual, and a busier, more decorated design helps focus attention on the main message.",
        "D": "Because the text is the only thing that matters; as long as the text is clear, the visualization itself can be optional or arbitrary."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was tightened for clarity; technical terms (e.g., \"extraneous cognitive load\", \"anchors\", \"visual encodings\") were retained to keep conceptual precision. Options were rephrased to remain plausible alternatives while preserving the original core idea.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "A city health department must present weekly COVID-19 vaccination progress to two distinct audiences: (1) the general public, who need a concise, actionable understanding; and (2) city policymakers, who require detailed evidence to make resource-allocation decisions. The dataset contains weekly totals, percentage vaccinated of the eligible population, age-group breakdowns, and 95% confidence intervals for sampling error. Which of the following visualization strategies best fulfills the primary goal of data/information visualization (adding value by improving comprehension and enabling informed decisions), while following effective-design principles (deliberate visual encoding, simplicity, contextualization, accuracy) and optimizing the verbal–graphical relationship for each audience's needs?",
      "options": {
        "A": "Produce two coordinated displays: for the general public, a simple time-series line chart of weekly percent vaccinated (with clear axis labels, a high-contrast color for the trend, annotated inflection points, a brief caption explaining the trend and recommended actions, and no decorative chartjunk); for policymakers, an interactive dashboard exposing raw counts, age-group breakdowns, drill-down filters, and 95% confidence-interval error bands, with linked views and an executive summary explaining data sources, update cadence, and recommended thresholds (e.g., reach $70\\%$ coverage). Ensure all data are accurate and up-to-date.",
        "B": "Create a single, highly polished infographic combining a multicolored map, a 3D pie chart of age-group shares, ornate decorative elements to attract attention, and a paragraph of technical methodology in small font. Use the same visual for both audiences to maintain brand consistency, relying primarily on visual appeal to communicate significance.",
        "C": "Publish the full dataset in a sortable table and a downloadable CSV file; include no charts. Add a one-paragraph methodological note stating accuracy and update frequency. Let users draw conclusions themselves; this preserves accuracy by avoiding any potential graphical distortion.",
        "D": "Design an advanced multivariate visualization (parallel coordinates and a correlation matrix) that encodes all variables and uncertainty simultaneously. Present this single complex graphic to both audiences with minimal explanatory text to avoid biasing interpretation; assume users will infer relationships through exploration."
      },
      "correct_answer": "A",
      "generation_notes": "Created a realistic public-health dashboard scenario requiring application of visualization goals, design principles, and audience tailoring. Option A integrates comprehension, deliberate encoding, accuracy, simplicity, contextual text, and audience-specific displays; other options violate one or more principles.",
      "concepts_tested": [
        "Primary goal of visualization: add value by improving comprehension and enabling insights/decisions",
        "Effective design: deliberate visual encoding, simplicity, context, accuracy, and use of supporting text",
        "Audience tailoring and the verbal–graphical relationship for comprehension"
      ]
    },
    "pass_2_reason": "readability_too_high_24.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why do the enabling conditions of support, leadership, and a forum function together in collaborative governance to enable policy-making that no single sector could achieve alone?",
      "options": {
        "A": "Support identifies the policy problem; leadership mobilizes diverse actors; and the forum provides a structured, ongoing space for joint problem identification and policy development.",
        "B": "Leadership concentrates power in one sector, bypassing input from others.",
        "C": "A forum alone is sufficient; support and leadership are unnecessary.",
        "D": "These conditions primarily delay decisions and reduce legitimacy of policy choices."
      },
      "correct_answer": "A",
      "source_article": "Collaborative governance",
      "x": 1.2734761238098145,
      "y": 0.9221179485321045,
      "concepts_tested": [
        "Concept 1: Collaborative governance as a relational, multi-sector approach that seeks to achieve more than any single sector could accomplish on its own.",
        "Concept 2: Enabling conditions and mechanisms (support, leadership, and a forum) that organize problem identification and collaborative policy-making.",
        "Concept 3: Practical forms (Consensus Building and Collaborative Network) as mechanisms to align needs, strategies, resources, and to build social capital for policy implementation."
      ],
      "parent_concepts": [
        "Concept 1: Multistakeholder governance model as the mechanism for Internet governance (involves governments, private sector, civil society, technical communities; decentralized, international)."
      ],
      "parent_articles": [
        "Internet governance"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do the three enabling conditions—support, leadership, and a forum—work together in collaborative governance to produce policies that no single sector could achieve by itself?",
      "options": {
        "A": "Support identifies the policy problem; leadership mobilizes and convenes diverse actors; and the forum provides a structured, ongoing space for joint problem definition and policy development.",
        "B": "Leadership centralizes authority in one sector, allowing decisions to be made quickly by bypassing input from other sectors.",
        "C": "A well-designed forum alone is sufficient to generate multi-sector policy outcomes; explicit support and leadership are unnecessary.",
        "D": "These conditions mainly introduce delays, create confusion among participants, and reduce the legitimacy of resulting policy choices."
      },
      "correct_answer": "A",
      "simplification_notes": "Reworded the stem for clarity; made each option concise and plausible; preserved the original explanation of each enabling condition and their combined role in collaborative governance.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "Harborville, a mid-sized coastal city, faces increasingly frequent storm surges and tidal flooding. The mayor's office formally convenes the Harbor Resilience Council: representatives from the municipal planning department, the state environmental agency, two private engineering firms, neighborhood associations, the port authority, and a regional funder. The council meets in scheduled deliberative sessions, works toward consensus on an integrated adaptation plan, allocates shared resources for pilot infrastructure projects, and establishes an inter-agency monitoring network to track outcomes. Which of the following best explains why the Harbor Resilience Council exemplifies collaborative governance and identifies the enabling conditions and mechanisms at work?",
      "options": {
        "A": "This is collaborative governance because a public agency initiated a formally organized, multi-sector forum in which non-state actors participate in deliberative, consensus-oriented decision making to address a public problem (flooding). The enabling conditions—support (clear problem identification), leadership (mayor’s office convening stakeholders), and a forum (the formal council)—are present, and the council demonstrates both consensus-building and a collaborative network to align strategies, resources, and social capital.",
        "B": "This is not collaborative governance because the presence of private engineering firms and neighborhood associations makes the process adversarial; the mayor’s office can still impose policy unilaterally, so the arrangement is best described as hierarchical policy implementation rather than a collaborative network or consensus-building process.",
        "C": "This is collaborative governance but lacks necessary enabling conditions because only government agencies can initiate governance forums; since private firms and community groups are involved the council must be a public–private contract rather than a deliberative forum with consensus aims.",
        "D": "This is not collaborative governance because participants are likely only being consulted for technical input; true collaborative governance requires that all participants have formal veto power over policy, so a mayor-initiated council cannot meet the Ansell and Gash criteria even if it is formally organized."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete coastal-flooding scenario illustrating multi-sector participation; tested identification of collaborative governance by matching Ansell & Gash criteria (public initiation, formal forum, deliberative consensus) and linked enabling conditions (support, leadership, forum) plus mechanisms (consensus building, collaborative network).",
      "concepts_tested": [
        "Collaborative governance as multi-sector relational approach",
        "Enabling conditions: support, leadership, forum",
        "Practical mechanisms: consensus building and collaborative network"
      ]
    },
    "pass_2_reason": "readability_too_high_20.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why does the DNA damage response (DDR) yield different cellular outcomes (senescence, apoptosis, or uncontrolled proliferation) in response to DNA lesions, and how does repair capacity influence which outcome occurs?",
      "options": {
        "A": "The DDR outcome depends solely on the quantity of lesions; more lesions automatically trigger cancer due to replication stress.",
        "B": "The DDR integrates damage severity, cell type, and repair capacity to decide between temporary arrest, permanent senescence, or apoptosis; higher repair capacity reduces cancer risk by preventing mutation accumulation, while insufficient repair can lead to senescence, apoptosis, or cancer depending on whether checkpoints are bypassed.",
        "C": "The DDR always triggers apoptosis for any detectable lesion, regardless of context.",
        "D": "The DDR outcome is determined only by whether lesions occur in coding regions of essential genes, dictating whether the cell can survive."
      },
      "correct_answer": "B",
      "source_article": "DNA repair",
      "x": 2.0751657485961914,
      "y": 1.1471434831619263,
      "concepts_tested": [
        "The DNA repair system identifies and corrects damage to preserve genome integrity, and when repair fails, a DNA damage response can lead to senescence, apoptosis, or uncontrolled cell division (cancer).",
        "Repair capacity is context-dependent, varying with cell type, age, and environment, which modulates cellular fate and genome stability.",
        "The impact of DNA damage depends on the location of lesions (e.g., critical genes) and the effectiveness of repair, influencing cancer risk and tumor heterogeneity."
      ],
      "parent_concepts": [
        "Concept 1: The mechanistic sequence of homologous recombination, including resection of 5' ends, 3' strand invasion into a homologous template, and the choice between DSBR and SDSA pathways, with a tendency toward non-crossover repair in DNA repair."
      ],
      "parent_articles": [
        "Homologous recombination"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does the DNA damage response (DDR) produce different cell fates—temporary cell‑cycle arrest, irreversible senescence, apoptosis, or uncontrolled proliferation (tumorigenesis)—after DNA lesions, and how does a cell’s DNA repair capacity influence which fate is chosen?",
      "options": {
        "A": "The DDR outcome depends only on the total number of lesions: a higher lesion load always leads to replication stress and inevitably to cancerous proliferation.",
        "B": "The DDR integrates lesion severity, cell type (and age), checkpoint status, and repair capacity to select among transient arrest, permanent senescence, or apoptosis; robust repair reduces mutation accumulation and cancer risk, whereas inadequate repair can cause senescence or apoptosis, or cancer if checkpoints are bypassed.",
        "C": "The DDR uniformly triggers apoptosis for any detectable DNA lesion, independent of lesion type, cell context, or repair ability.",
        "D": "The DDR outcome is determined solely by whether lesions fall in coding regions of essential genes: lesions in such genes decide cell survival and thus the fate."
      },
      "correct_answer": "B",
      "simplification_notes": "Condensed the original multipart question into a single clear sentence and clarified the key variables the DDR integrates (lesion severity, cell type/age, checkpoint status, repair capacity). Retained original answer structure and core concept that repair capacity modulates risk of senescence, apoptosis, or cancer.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_24.7_vs_16",
    "pass_2_attempt": {
      "question": "Researchers expose equal numbers of two human cell populations—(1) rapidly dividing colonic epithelial stem cells, and (2) terminally differentiated cortical neurons—from both young and aged donors to an ionizing radiation dose that produces approximately $10^{4}$ DNA lesions per cell. Which predicted outcome best integrates the roles of lesion location, repair capacity (which varies with cell type and age), and the DNA damage response in determining short- and long-term consequences?",
      "options": {
        "A": "Rapidly dividing epithelial stem cells with only moderate repair capacity are prone to replicate over unrepaired lesions, producing mutations that can clonally expand if they confer growth advantage (increasing cancer risk and tumor heterogeneity), whereas post‑mitotic neurons accumulate unrepaired damage leading primarily to functional decline, senescence or apoptosis; aged cells in both compartments with reduced repair capacity exacerbate these outcomes.",
        "B": "Because neurons are long‑lived, unrepaired lesions in cortical neurons are more likely to generate malignant tumours than lesions in rapidly dividing epithelial stem cells; therefore the dominant risk after radiation exposure is neuro‑oncogenesis rather than epithelial cancer.",
        "C": "The principal determinant of outcome is lesion count alone (here $10^{4}$ lesions); lesion location and cell type are negligible, so all exposed cells will have equal probabilities of senescence, apoptosis, or malignant transformation regardless of repair capacity or age.",
        "D": "Any cell sustaining a total lesion load near $10^{4}$ will immediately trigger apoptosis via the DNA damage response, so neither mutations nor senescence or cancer will occur in either cell type regardless of lesion location or repair efficiency."
      },
      "correct_answer": "A",
      "generation_notes": "Created a concrete radiation-exposure scenario comparing dividing stem cells and nondividing neurons, included lesion count ($10^{4}$) to ground the question; options contrast correct integration of location, repair capacity, and DDR with common misconceptions (neurons→cancer, lesion count-only, obligatory apoptosis).",
      "concepts_tested": [
        "DNA repair preserves genome integrity and its failure leads to senescence, apoptosis, or cancer",
        "Repair capacity depends on cell type and age and influences cellular fate",
        "Impact of lesion location (critical genes) and repair effectiveness on cancer risk and tumor heterogeneity"
      ]
    },
    "pass_2_reason": "readability_too_high_21.5_vs_16"
  },
  {
    "original_question": {
      "question": "How does the distribution of political power in a hybrid regime shape governance outcomes, compared to clear democracies or clear autocracies?",
      "options": {
        "A": "It tends to combine rapid policy decisions with broad electoral accountability, yielding quick reforms and strong legitimacy.",
        "B": "It creates a mixed distribution of authority that both constrains rulers through institutional checks and blurs accountability, leading to inconsistent policy and contested legitimacy.",
        "C": "It guarantees equal influence for all actors, ensuring uniformly stable policies across the state.",
        "D": "It concentrates power in a single office, maximizing decisiveness and making legitimacy unchallengeable."
      },
      "correct_answer": "B",
      "source_article": "Government",
      "x": 1.1327046155929565,
      "y": 0.794884204864502,
      "concepts_tested": [
        "Concept 1: Separation of powers and governance structure (legislature, executive, judiciary) as the mechanism by which policies are enforced and determined.",
        "Concept 2: Power acquisition and legitimacy (electoral contest vs hereditary succession) as foundations for government authority and policy direction.",
        "Concept 3: Regime classification and hybridity (democracies, totalitarian/authoritarian regimes, mixed systems) and how differing distributions of power shape governance."
      ],
      "parent_concepts": [
        "Concept 3: Sources and instruments of executive power (decrees/executive orders, control of bureaucracy) and how they interact with legislative and judicial oversight and with policy areas like economics and foreign policy.",
        "Concept 1"
      ],
      "parent_articles": [
        "Executive (government)",
        "Local government in Nepal"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a \"hybrid\" regime that mixes democratic and authoritarian elements, how does the mixed distribution of political power typically affect policy-making and legitimacy compared with clear democracies or autocracies?",
      "options": {
        "A": "It often pairs rapid, centralized decision-making with meaningful electoral accountability, producing quick reforms and robust legitimacy.",
        "B": "It creates a mixed allocation of authority where some institutional checks constrain rulers but lines of accountability are blurred, producing inconsistent or uneven policies and contested legitimacy.",
        "C": "It guarantees equal influence for all political actors, leading to uniformly stable and predictable policies across the state.",
        "D": "It concentrates power in a single office, maximizing decisiveness and producing largely unchallengeable legitimacy."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified \"hybrid regime\" as mixing democratic and authoritarian features; shortened phrasing; preserved technical terms (institutional checks, accountability, legitimacy, policy consistency); removed historical examples and added direct comparison with clear democracies/autocracies.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_23.0_vs_16",
    "pass_2_attempt": {
      "question": "The fictional country of Azura has the following institutional features: a hereditary monarch who constitutionally retains a legislative veto and appoints the prime minister without a formal requirement of legislative confidence; a popularly elected legislature whose electoral law produces a seat distribution disproportionate to vote shares; a judiciary that is formally independent but whose senior judges are appointed for life by the monarch; regular multiparty elections occur but campaign finance rules and media access heavily favor pro-monarch parties; the military holds statutory emergency powers and has intervened to block specific reforms. Which of the following best characterizes Azura with respect to (1) separation of powers and governance structure, (2) how political authority is acquired and legitimized, and (3) regime classification?",
      "options": {
        "A": "A functioning constitutional monarchy and liberal democracy: clear separation of powers among legislature, executive and judiciary, with political authority primarily produced and legitimized by competitive elections and constitutional constraints on the monarch.",
        "B": "A hybrid authoritarian (electoral/competitive authoritarian) regime: formal branches (legislature, executive, judiciary) exist but separation of powers is weak in practice because the hereditary monarch controls key appointments and vetoes; political authority combines hereditary legitimacy with constrained electoral legitimacy, producing authoritarian rule with democratic trappings.",
        "C": "A totalitarian regime: a single ruling party monopolizes all political, social and economic life; authority is acquired exclusively through party mechanisms rather than hereditary succession or periodic elections, and the judiciary and legislature are mere instruments of the party.",
        "D": "A federal republic with strong separation of powers: sovereignty rests with elected representatives, the monarch is effectively ceremonial, and legitimacy is derived primarily from free and fair electoral contests independent of hereditary influence."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete hybrid-regime scenario (hereditary monarch with veto/appointments, skewed elections, judiciary dependence, military powers) to test recognition of weak separation of powers, mixed sources of legitimacy (hereditary + electoral), and classification as electoral/competitive authoritarianism rather than pure democracy, totalitarianism, or federal republic.",
      "concepts_tested": [
        "Separation of powers and governance structure (legislature, executive, judiciary)",
        "Power acquisition and legitimacy (hereditary succession versus electoral contest)",
        "Regime classification and hybridity (democracy, authoritarianism, competitive/electoral authoritarianism)"
      ]
    },
    "pass_2_reason": "readability_too_high_33.1_vs_16"
  },
  {
    "original_question": {
      "question": "In human ecology, the principle of bidirectional human–environment influence explains why communities facing the same drought can experience different long-term outcomes. How does this bidirectional relation account for those differences?",
      "options": {
        "A": "The drought will have the same biophysical impact regardless of human context, so social variation is irrelevant.",
        "B": "Cultural norms, social institutions, and technology mediate how people respond (e.g., water use, storage, governance), which in turn changes ecological feedbacks and future resilience.",
        "C": "Ecological outcomes are entirely determined by climate, so human actions cannot alter them.",
        "D": "Economic development automatically resolves stressors by providing resources."
      },
      "correct_answer": "B",
      "source_article": "Human ecology",
      "x": 1.4952070713043213,
      "y": 0.9450026154518127,
      "concepts_tested": [
        "Interconnected human–environment relationships and bidirectional influence (how culture, social structures, and technology shape ecological interactions)",
        "Interdisciplinary integration as a core mechanism for understanding human ecology (combining biology, social sciences, and humanities to study adaptation and sustainability)",
        "Ecosystem services/natural capital as a framework for linking ecological processes to human outcomes and policy (how ecosystems provide value and sustain human societies)"
      ],
      "parent_concepts": [
        "Exosomatic adaptation: culture defined as the outside-the-body means of environmental adaptation, tying culture to environmental constraints rather than solely to internal human traits."
      ],
      "parent_articles": [
        "Processual archaeology"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "According to human ecology's idea of bidirectional (two-way) human–environment interactions, why can two communities exposed to the same drought have different long-term outcomes?",
      "options": {
        "A": "The drought's biophysical effects are the same everywhere, so variation in social systems does not change outcomes.",
        "B": "Cultural norms, social institutions, and technologies shape how people use and manage water (e.g., extraction, storage, governance); those human responses change ecological feedbacks and thus affect resilience and future outcomes.",
        "C": "Ecological outcomes are determined solely by climate and biophysical forces, so human actions cannot alter them.",
        "D": "Economic development automatically resolves resource stress by supplying the needed capital and infrastructure."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the question; explained 'bidirectional' as two-way interactions; kept technical terms (institutions, ecological feedbacks, resilience); made distractors plausible but incorrect.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized coastal town experiences a rapid decline in wild shellfish beds, recurrent harmful algal blooms, and falling fisher incomes. A municipal team must design a recovery program that both restores ecological function and sustains local livelihoods. Which of the following proposals best exemplifies a human ecology approach that (a) treats human and environmental systems as bidirectionally coupled, (b) integrates disciplinary perspectives (biological monitoring, social institutions, economics, and appropriate technology), and (c) uses ecosystem services or natural capital as a basis for policy?",
      "options": {
        "A": "Declare a 20-year no-take marine reserve enforced by external patrols and provide fishers with a fixed unconditional cash stipend during the closure; scientific monitoring of shellfish is funded independently but not linked to community decisions.",
        "B": "Establish a co-management scheme in which local fishers and ecologists jointly set seasonal harvest limits informed by population models and traditional ecological knowledge; fund seagrass and estuary restoration through a payments-for-ecosystem-services (PES) program financed by a tourism levy; deploy water-quality sensors for adaptive management and provide training in low-impact aquaculture as alternative livelihoods.",
        "C": "Privatize shellfish production by auctioning long-term leases to industrial aquaculture firms, incentivize intensive cage culture via tax breaks, and phase out small-scale wild harvesters without mechanisms to account for coastal habitat impacts.",
        "D": "Commission a macroeconomic study to quantify the GDP loss from reduced landings, then invest in port and cold-chain infrastructure to boost per-unit export value of whatever catch remains, leaving harvest rules and coastal habitat management unchanged."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a concrete coastal collapse scenario; options contrast single-discipline fixes with an integrated human-ecology solution. Correct choice (B) combines ecological monitoring, traditional knowledge, institutional co-management, PES/natural-capital valuation, adaptive technology, and livelihood diversification to test all target concepts.",
      "concepts_tested": [
        "bidirectional human–environment interactions",
        "interdisciplinary integration (biology, social sciences, economics, technology)",
        "ecosystem services / natural capital informing policy"
      ]
    },
    "pass_2_reason": "readability_too_high_20.8_vs_16"
  },
  {
    "original_question": {
      "question": "How does the shift toward online fundraising alter the marginal cost and reach of donor acquisition, and what strategic implication does that have for an organization's fundraising mix?",
      "options": {
        "A": "Online fundraising lowers marginal costs per donor and expands reach through network effects, which incentivizes adding digital channels alongside traditional methods to pursue growth and diversification.",
        "B": "Online fundraising increases all costs and reduces reach, so organizations should abandon it in favor of traditional methods.",
        "C": "Online fundraising has no impact on cost or reach and should be treated purely as a branding exercise with no strategic implication.",
        "D": "Online fundraising automatically ensures ethical compliance and removes policy concerns from fundraising strategy."
      },
      "correct_answer": "A",
      "source_article": "Fundraising",
      "x": 1.361373782157898,
      "y": 0.9198783040046692,
      "concepts_tested": [
        "Mechanisms and evolution of fundraising methods (traditional face-to-face vs online/grassroots; reasons for adopting new methods)",
        "Relationships between fundraising and organizational goals across sectors (non-profits, religious groups, political campaigns; donor influence and ethical/policy considerations)",
        "Organizational structure and strategy of fundraising (development/advancement roles; distinctions between annual fund appeals and major campaigns)"
      ],
      "parent_concepts": [
        "Concept 1: The fundraising mechanism of charity records — how proceeds and royalties are allocated to charities (e.g., UNICEF), illustrating a financial relationship between music releases and philanthropy.",
        "Concept 3: The historical evolution and impact of charity records — how successful campaigns catalyze further initiatives and shape fundraising trends across regions and decades."
      ],
      "parent_articles": [
        "Charity record",
        "Charity record"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does a shift from face-to-face to online fundraising affect the marginal cost of acquiring a new donor and the geographic/social reach of donor acquisition, and what strategic change should an organization therefore make to its fundraising mix?",
      "options": {
        "A": "Online fundraising typically lowers the marginal cost per acquired donor and expands reach through digital and network effects, so organizations should add digital channels to traditional methods to pursue growth and diversification.",
        "B": "Online fundraising generally raises costs and narrows reach, so organizations should abandon online methods and concentrate solely on traditional, in-person fundraising.",
        "C": "Online fundraising produces no meaningful change in marginal cost or reach and is mainly a branding activity, so it requires no strategic change to the fundraising mix.",
        "D": "Online fundraising automatically resolves ethical and policy issues in fundraising and therefore eliminates the need for governance or compliance measures."
      },
      "correct_answer": "A",
      "simplification_notes": "Question compressed and clarified: \"marginal cost\" and \"reach\" defined in plain terms; phrasing made concise while preserving domain terms (digital channels, network effects, fundraising mix). Options kept plausible and technically framed.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.7_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized private university needs to raise $50 million for a new science building (a capital expenditure) while ensuring its annual operating budget (Opex) remains stable and that donor influence does not compromise academic independence. The university currently has a small development staff, a modest annual fund, and a donor base concentrated in a few large donors whose gifts sometimes come with programmatic restrictions. The board is considering several proposals: (1) hire third‑party professional fundraisers paid on a percentage of funds raised, (2) launch an integrated capital campaign with a private solicitation phase targeting major and principal gifts while simultaneously expanding online recurring giving and planned giving programs, (3) convert most fundraising to street fundraising and automatic monthly withdrawals to build a broad small‑donor base quickly, or (4) run a series of high‑visibility pledge drives and accept large corporate restricted gifts in exchange for naming rights. Which proposal best aligns with the university’s need to raise major capital, preserve operating stability, strengthen donor retention and stewardship, and minimize undue donor influence on academic priorities?",
      "options": {
        "A": "Hire third‑party fundraisers compensated by a percentage of funds raised to rapidly access experienced solicitors and secure large gifts, using the proceeds to cover both the capital project and operating shortfalls.",
        "B": "Launch a comprehensive capital campaign with a private phase focused on cultivation and solicitation of major and planned gifts by trained development officers, emphasize multi‑year pledges and endowment components for long‑term Opex support, expand online recurring giving for donor acquisition, and adopt stewardship and conflict‑of‑interest policies to limit restrictive donor conditions.",
        "C": "Shift most resources to street fundraising and automatic monthly withdrawal programs to rapidly build a broad base of small recurring donors, using the volume of micro‑donations to fund both the building and ongoing operations.",
        "D": "Run frequent public pledge drives and actively solicit large corporate restricted gifts with naming rights to secure immediate capital, while allowing donors to specify programmatic uses to attract bigger contributions."
      },
      "correct_answer": "B",
      "generation_notes": "Created a concrete university scenario combining capital vs operating needs, donor concentration risks, and choices among professional fundraisers, capital campaigns, street fundraising, and corporate restricted gifts; correct answer integrates development roles, campaign phases, stewardship, planned giving, and ethical safeguards.",
      "concepts_tested": [
        "Evolution and selection of fundraising methods (capital campaigns, online recurring giving, street fundraising)",
        "Organizational fundraising strategy and structure (development officers, private campaign phase, pledges, planned giving)",
        "Donor relations, stewardship and ethical considerations (donor restrictions, conflict‑of‑interest policies, minimizing undue influence)"
      ]
    },
    "pass_2_reason": "readability_too_high_24.2_vs_16"
  },
  {
    "original_question": {
      "question": "Why do postcolonial critiques argue that the claim of universal progress within modernity cannot be disentangled from imperial power relations, and how does this reveal the mechanism by which modernity achieves its global reach?",
      "options": {
        "A": "The universal-progress narrative relies on a single standard of rationality and social order that imperial networks enforce through coercive exchange and domination; postcolonial critiques show this standard is imposed and silences diverse knowledges, making \"modernity\" a project of power, not a neutral achievement.",
        "B": "The universal-progress claim arises from voluntary cultural exchange and mutual advantage; postcolonial critiques support this rosy view of empire.",
        "C": "Imperial power is unrelated to modernization; postcolonial critiques focus on cultural differences rather than power.",
        "D": "Modernity's reach is explained entirely by economic resources; postcolonial critiques claim culture has no role."
      },
      "correct_answer": "A",
      "source_article": "Modernity",
      "x": 0.5379313826560974,
      "y": 0.9840644001960754,
      "concepts_tested": [
        "Concept 1: Modernity as an interrelated set of processes (secularization, liberalization, modernization, capitalism, urbanization) that collectively transform society and culture.",
        "Concept 2: Modernity as both a normative idea and analytical framework linked to Enlightenment and modernist thought, with debates about progress and critiques from postmodernism.",
        "Concept 3: Global power dynamics and imperial/colonial dimensions of modernity, and how postcolonial and anti-modernization critiques address these relationships."
      ],
      "parent_concepts": [
        "Concept 3: The socialization of risk (environmental and other risks become central to everyday life, biographical norms, power relations, and governance)."
      ],
      "parent_articles": [
        "Risk society"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why do postcolonial critiques argue that the modernity claim of \"universal progress\" cannot be separated from imperial power relations, and how does this explain the way modernity attains global reach?",
      "options": {
        "A": "Because the universal-progress narrative depends on a single, Eurocentric standard of reason and social order that imperial networks enforce through coercion, economic domination, and cultural suppression; postcolonial critics show this standard is imposed and silences alternative knowledges, so modernity spreads as a project of power rather than a neutral achievement.",
        "B": "Because the universal-progress claim simply reflects voluntary cultural exchange and mutual benefit between societies; postcolonial critiques therefore affirm a benign, cooperative model of empire.",
        "C": "Because imperial power is unrelated to processes of modernization; postcolonial critiques are primarily concerned with cultural diversity and not with domination or power dynamics.",
        "D": "Because modernity spreads entirely through the distribution of economic resources and technology; postcolonial critiques argue that cultural and political mechanisms play no significant role."
      },
      "correct_answer": "A",
      "simplification_notes": "Question wording condensed and clarified for undergraduates; removed lengthy historical detail and examples while preserving the core claim that postcolonial critiques link universal-progress narratives to imperial enforcement and the mechanism of cultural imposition.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.5_vs_16",
    "pass_2_attempt": {
      "question": "Country Z underwent rapid industrialization: large-scale rural-to-urban migration, expansion of capitalist markets and wage labor, legal reforms enshrining individual rights, and a decline in institutional religious authority. Intellectual elites celebrated this as evidence of human progress rooted in Enlightenment reason, while indigenous communities and postcolonial scholars argued that much of the material advance depended on earlier imperial extraction and that cultural traditions were being eroded. Which interpretation most accurately captures the concept of modernity as described in the article?",
      "options": {
        "A": "Modernity is best understood as an interrelated ensemble of processes—secularization, liberalization, modernization, capitalism and urbanization—that both function as an analytical framework linked to Enlightenment ideals of progress and as a normative project contested by postmodern and postcolonial critiques emphasizing imperial/colonial power dynamics.",
        "B": "Modernity is essentially a neutral technological and scientific advance (rationalization) whose principal effect is improved efficiency and objective knowledge; normative or political critiques about imperialism and culture are secondary and outside the concept.",
        "C": "Modernity refers solely to a Western historical epoch (the modern era) and therefore cannot be applied analytically to accounts like Country Z’s; such developments outside Europe are merely imitations of European modernity.",
        "D": "Modernity is primarily an artistic period (c. 1860–1970) and should be interpreted mainly through changes in aesthetic styles and the role of the urban flâneur, rather than through socio-economic or political transformations."
      },
      "correct_answer": "A",
      "generation_notes": "Presented a concrete national example combining socio-economic, political, and intellectual changes; options isolate single aspects (technology, Eurocentrism, art) to test recognition of modernity as a plural, contested ensemble tied to Enlightenment norms and postcolonial critique.",
      "concepts_tested": [
        "Modernity as interrelated socio-cultural processes (secularization, capitalism, urbanization, liberalization)",
        "Modernity as both normative idea and analytical framework linked to Enlightenment and contested by postmodern critique",
        "Imperial/colonial dimensions of modernity and postcolonial critiques"
      ]
    },
    "pass_2_reason": "readability_too_high_21.7_vs_16"
  },
  {
    "original_question": {
      "question": "Why does coupling interactive visual representations with underlying analytical processes enable higher-level reasoning and sense-making in visual analytics?",
      "options": {
        "A": "It ensures that all decisions are made automatically by algorithms, removing cognitive load from the analyst.",
        "B": "It creates a bidirectional feedback loop where the visual interface makes computational results perceptible and the analyst's interactions steer the analytical methods, enabling hypothesis testing and interpretation that integrate evidence and context.",
        "C": "It minimizes the need to understand the data by presenting glossy visuals that look informative.",
        "D": "It fragments the data into isolated views so analysts can focus on single metrics without considering broader context."
      },
      "correct_answer": "B",
      "source_article": "Visual analytics",
      "x": 1.3747557401657104,
      "y": 1.0470938682556152,
      "concepts_tested": [
        "Concept 1: Coupling interactive visual representations with underlying analytical processes to enable higher-level reasoning and sense-making.",
        "Concept 2: Human–computer collaboration in visual analytics, guided by cognitive, perceptual, and design principles to support analytical reasoning.",
        "Concept 3: The relationships and boundaries among scientific visualization, information visualization, and visual analytics, including how visual analytics integrates techniques from visualization with data analysis methods."
      ],
      "parent_concepts": [
        "Concept 2: Visualization exploits relationships between heterogeneous data (e.g., code, metrics, traces, evolution) to reveal anomalies and correlations that are not obvious in raw data."
      ],
      "parent_articles": [
        "Software visualization"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does coupling interactive visual representations with underlying computational analysis enable higher-level reasoning and sense-making in visual analytics?",
      "options": {
        "A": "Because it makes all decisions automatic by algorithms, removing the analyst's cognitive workload.",
        "B": "Because it creates a bidirectional feedback loop: the visual interface makes computational results perceptible (so analysts see patterns), while analyst interactions (selection, filtering, hypothesis generation) steer the analytic methods, enabling iterative hypothesis testing and interpretation that integrates evidence and context.",
        "C": "Because attractive or polished visuals reduce the need to understand the data or the analysis methods.",
        "D": "Because it fragments the data into isolated views so analysts can focus on single metrics without considering broader context."
      },
      "correct_answer": "B",
      "simplification_notes": "Shortened and clarified the original question; preserved technical terms (e.g., \"bidirectional feedback loop\", \"hypothesis testing\"); added brief examples of interactions (selection, filtering) to make option B clearer; kept all four options plausible and maintained the original correct choice.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_25.5_vs_16",
    "pass_2_attempt": {
      "question": "A national CERT (Computer Emergency Response Team) is evaluating four prototype tools for analyzing large-scale network intrusion data. For each prototype a brief description is given. According to the definition and scope of visual analytics in the article — specifically the emphasis on coupling interactive visual representations with underlying analytical processes to support higher-level reasoning and sense-making, and on human–computer collaboration informed by cognitive, perceptual, and design principles — which single prototype best qualifies as a genuine visual analytics system?",
      "options": {
        "A": "A real-time dashboard that displays precomputed anomaly scores as a 2D heatmap; users can click cells to view raw logs, but all statistical models and clustering are trained offline nightly and cannot be adjusted in-session. The dashboard uses standard color scales and numerical summaries.",
        "B": "An immersive 3D rendering of packet flows over an inferred network geometry where volumetric glyphs represent throughput; users can rotate and zoom the scene but no algorithmic analytics (e.g., clustering, classification) run on-demand. The representation leverages the data's natural geometric layout.",
        "C": "An interactive graph-based environment that shows devices as nodes and connections as edges, where analysts can apply on-demand clustering, outlier detection, and hypothesis tests that immediately update the visualization. The system supports iterative hypothesis generation, allows analysts to adjust algorithm parameters via visual controls, and uses color, position, and preattentive encodings designed to reduce search and enhance pattern recognition.",
        "D": "A periodically produced PDF report containing a set of carefully designed static charts (time series, histograms, and a network summary) and expert commentary; the graphics follow good visual design principles but cannot be manipulated or linked to live analytical procedures."
      },
      "correct_answer": "C",
      "generation_notes": "Created a concrete SOC scenario with four plausible prototypes; correct choice embodies coupling of interactive visualization and on-demand analytics, human-in-the-loop hypothesis iteration, and perceptual/design principles. Distractors exemplify information visualization (A,D) or scientific visualization (B) or lack tight coupling.",
      "concepts_tested": [
        "Coupling interactive visual representations with analytical processes for sense-making",
        "Human–computer collaboration guided by cognitive and perceptual design principles",
        "Differences and boundaries among scientific visualization, information visualization, and visual analytics"
      ]
    },
    "pass_2_reason": "readability_too_high_21.5_vs_16"
  },
  {
    "original_question": {
      "question": "How does micro-level self-interested behavior lead to macro-level unintended consequences via emergent system dynamics?",
      "options": {
        "A": "By simple additive effects that accumulate without altering the environment or incentives.",
        "B": "By generating feedback loops where individuals' optimizations change the environment, which then changes incentives and subsequent actions, producing nonlinear, emergent outcomes.",
        "C": "By ensuring that every action is perfectly aligned with the overall system goal, eliminating any discrepancy.",
        "D": "By isolating actions so they do not influence others, making macro outcomes predictable."
      },
      "correct_answer": "B",
      "source_article": "Unintended consequences",
      "x": 1.2931785583496094,
      "y": 0.9745080471038818,
      "concepts_tested": [
        "Concept 1: Unintended consequences arise when actions produce outcomes that were not anticipated or foreseen.",
        "Concept 2: Three types of unintended consequences—unexpected benefits, unexpected drawbacks, and perverse results (where a solution worsens the problem).",
        "Concept 3: Emergent macro-level effects can arise from micro-level actions through mechanisms like self-interest and feedback, illustrating how individual decisions can lead to broader, unplanned outcomes."
      ],
      "parent_concepts": [
        "Concept 3: Trade-offs and unintended consequences (the balance between security measures and civil liberties; potential negative outcomes of CT policies)"
      ],
      "parent_articles": [
        "Counterterrorism"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How can self-interested actions by individuals (micro-level) produce unintended large-scale (macro-level) consequences through emergent system dynamics?",
      "options": {
        "A": "By simple additive effects that merely accumulate without changing the environment or incentives.",
        "B": "By creating feedback loops: individuals' optimizations alter the environment, which changes incentives and future actions, producing nonlinear, emergent outcomes.",
        "C": "By guaranteeing every individual action is perfectly aligned with the system's overall goal, so no discrepancies occur.",
        "D": "By keeping actions isolated so they do not influence others, making aggregate outcomes straightforward and predictable."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified for undergraduates; preserved technical terms like 'feedback loops' and 'emergent outcomes'; options rewritten to be concise and plausible while keeping original correct answer (B).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_20.2_vs_16",
    "pass_2_attempt": {
      "question": "A city government establishes a program that pays residents $5 per kilogram for collected plastic waste to reduce litter in public spaces. After 12 months the following outcomes are observed: (i) visible litter in parks declines by 30% (the intended effect); (ii) several small enterprises open as aggregation centers that buy plastics from informal collectors and sell to recyclers; (iii) some low‑cost manufacturers begin producing larger volumes of single‑use plastic packaging because it becomes profitable to sell scrap back into the collection system; (iv) an informal labor market of independent collectors emerges. Which of the following best classifies these results as unintended consequences and explains the mechanism by which micro‑level actions produced the macro‑level pattern?",
      "options": {
        "A": "Outcomes (ii) and (iv) are unexpected benefits (new economic activity and jobs); outcome (iii) is a perverse result because the policy created a profit motive that increased the underlying production of single‑use plastics, worsening the systemic problem; these effects collectively illustrate an emergent macro‑level consequence arising from individual self‑interest and feedback through price incentives.",
        "B": "All observed outcomes (ii)–(iv) are unexpected drawbacks: the new enterprises and collectors are negative side effects that reduce program efficiency, and manufacturer behavior is merely another drawback; there is no emergent market mechanism—only administrative failure.",
        "C": "None of the outcomes are unintended consequences because the creation of a collection market and changes in producer behavior were foreseeable; the program simply achieved predictable supply‑chain adjustments rather than producing any perverse or beneficial side effects.",
        "D": "All observed outcomes constitute perverse results: the program uniformly made the litter problem worse by encouraging more plastic use and commodifying waste; the emergence of collectors and aggregation centers is part of the same perverse dynamic rather than a benefit."
      },
      "correct_answer": "A",
      "generation_notes": "Designed a concrete municipal policy scenario to require students to identify unintended consequences, classify them into unexpected benefits vs perverse results, and explain emergent macro effects produced by micro-level incentives and feedback.",
      "concepts_tested": [
        "Unintended consequences as unanticipated outcomes",
        "Three types: unexpected benefits, unexpected drawbacks, perverse results",
        "Emergent macro-level effects from micro-level incentives/feedback (self-interest and price signals)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.5_vs_16"
  },
  {
    "original_question": {
      "question": "Why does preserving soil biodiversity and maintaining habitats for beneficial organisms on a farm contribute to sustainable productivity over the long term?",
      "options": {
        "A": "It reduces the need for crop diversification by focusing on a single high-yield variety.",
        "B": "It enhances multiple ecosystem services (pollination, natural pest suppression, and nutrient cycling) that support crop yields while reducing reliance on synthetic inputs.",
        "C": "It ensures immediate peak production by maximizing external inputs.",
        "D": "It eliminates ecological interactions, making the system more predictable and isolated from environmental changes."
      },
      "correct_answer": "B",
      "source_article": "Sustainable agriculture",
      "x": 1.7177519798278809,
      "y": 0.9235531091690063,
      "concepts_tested": [
        "Concept 1: Farming practices and ecosystem services are interdependent; sustainable agriculture aims to manage land, water, and biodiversity to maintain or enhance ecosystem services that support long-term productivity.",
        "Concept 2: Sustainable agriculture contributes to climate change mitigation/adaptation and must respond to changing environmental conditions while supporting a growing population.",
        "Concept 3: Sustainable agriculture integrates environmental, economic, and social objectives (site-specific practices, efficient resource use, on-farm ecological cycles, and farmer/community quality of life) rather than focusing on a single metric."
      ],
      "parent_concepts": [
        "Concept 1: Minimum soil disturbance (no-till) preserves soil minerals and organic matter, reduces erosion, and lowers production costs, illustrating a cause–effect relationship between tillage practices and soil/productivity outcomes.",
        "Concept 2: Permanent soil cover helps prevent water loss and erosion, contributing to soil moisture retention and long-term soil health."
      ],
      "parent_articles": [
        "Conservation agriculture",
        "Conservation agriculture"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How does preserving soil biodiversity and keeping habitats for beneficial organisms on a farm support long-term sustainable productivity?",
      "options": {
        "A": "It allows the farm to rely on a single high-yield crop variety and so reduces the need for crop diversification.",
        "B": "It strengthens multiple ecosystem services (e.g., pollination, natural pest suppression, nutrient cycling) that sustain crop yields and lower dependence on synthetic inputs.",
        "C": "It guarantees immediate peak production by enabling maximal use of external inputs like synthetic fertilizers and pesticides.",
        "D": "It removes complex ecological interactions, making the farm system more predictable and isolated from environmental variability."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording was shortened and clarified for undergraduate readers; technical terms (ecosystem services) were retained but illustrated with examples. Distractor options were kept plausible and aligned to common misconceptions.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.6_vs_16",
    "pass_2_attempt": {
      "question": "A 200‑ha semi‑arid mixed farm is experiencing declining soil fertility, increasing water scarcity, and community pressure to raise annual food output by 20% over the next decade while cutting net greenhouse gas (GHG) emissions. Which of the following intervention packages best embodies the principles of sustainable agriculture — managing land, water and biodiversity to sustain ecosystem services, contributing to climate mitigation/adaptation, and integrating environmental, economic and social objectives through site‑specific practices and on‑farm ecological cycles?",
      "options": {
        "A": "Intensify cereal production on the best 150 ha with high‑yielding hybrid varieties and synthetic N–P–K fertilizer to achieve a 25% yield increase, set the remaining 50 ha aside as a strictly protected reserve (land sparing), and sell outputs to distant markets to maximize farmer revenue.",
        "B": "Convert fields to an agroforestry design on marginal plots, institute legume cover crops and crop rotations to restore soil N via biological fixation, adopt AI‑controlled precision irrigation (reducing water use by ~30%), recycle livestock manure on‑farm, install solar panels for energy, and form a local cooperative for processing and local sale.",
        "C": "Switch all acreage to certified organic monoculture cash crops for export, relying on imported rock phosphate and composted amendments, eliminate synthetic pesticides, and lease mechanized services to maintain yields.",
        "D": "Build centralized climate‑controlled greenhouses and vertical hydroponic units that provide year‑round high yields with complete soil avoidance, heated and powered by grid electricity, and contract out labor to seasonal migrant workers."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a realistic farm scenario requiring trade‑offs; option B integrates ecosystem services (agroforestry, legumes, manure recycling), climate mitigation/adaptation (water savings, solar), and socio‑economic aims (cooperative, local processing), while distractors each omit one or more key sustainability pillars.",
      "concepts_tested": [
        "Interdependence of farming practices and ecosystem services (soil, water, biodiversity)",
        "Role of sustainable agriculture in climate change mitigation/adaptation and feeding growing populations",
        "Integration of environmental, economic, and social objectives in site‑specific, resource‑efficient, on‑farm ecological cycles"
      ]
    },
    "pass_2_reason": "readability_too_high_25.5_vs_16"
  },
  {
    "original_question": {
      "question": "In a community of practice, newcomers begin at the periphery and gradually move toward full participation. Why does this legitimate peripheral participation structure promote meaningful learning rather than merely accumulating isolated skills?",
      "options": {
        "A": "It ensures learners absorb isolated, decontextualized facts before applying them in real tasks.",
        "B": "It frames learning as social meaning-making embedded in authentic practice, where newcomers continuously renegotiate their interpretations and identity with experienced members as they participate.",
        "C": "It removes social context, enabling the learner to focus on internal cognitive processing in isolation.",
        "D": "It confines learning to passive observation of experts, with no active participation required."
      },
      "correct_answer": "B",
      "source_article": "Situated learning",
      "x": 1.2604354619979858,
      "y": 1.008870244026184,
      "concepts_tested": [
        "Concept 1: Learning is situated and takes place through participation in a community of practice within a specific social and physical context.",
        "Concept 2: Legitimate peripheral participation describes the process by which newcomers move toward full participation, involving ongoing negotiation of meaning and identity within the community.",
        "Concept 3: Knowledge is co-constructed through social interaction and practice; motivation and learning are embedded in social participation and evolving social relations."
      ],
      "parent_concepts": [
        "The supervised, real-clinic learning environment as a mechanism to transform trainees into practicing physicians"
      ],
      "parent_articles": [
        "Teaching hospital"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "In a community of practice, newcomers begin at the periphery and progressively move toward full participation (legitimate peripheral participation). Why does this trajectory generate meaningful, situated learning instead of just accumulating isolated skills?",
      "options": {
        "A": "Because it makes learners first master decontextualized facts and rules, which they later apply to real tasks.",
        "B": "Because it frames learning as social meaning-making embedded in authentic practice: newcomers co-construct knowledge and continually renegotiate meanings and their identities through participation with experienced members.",
        "C": "Because it removes social context so learners can concentrate on internal cognitive processing in isolation.",
        "D": "Because it restricts learners to passive observation of experts, so they acquire skills without active engagement."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; preserved technical term 'legitimate peripheral participation'; option B kept intact but made slightly more concise; all distractors rewritten to remain plausible and contrast social/situated vs. decontextualized, individual, or passive accounts.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_19.5_vs_16",
    "pass_2_attempt": {
      "question": "Which of the following workplace vignettes best exemplifies situated learning as described by Lave and Wenger — that is, learning that occurs through participation in a community of practice, progresses by legitimate peripheral participation toward full membership, and involves co-construction of knowledge and identity through social interaction?",
      "options": {
        "A": "A newly hired ward nurse initially shadows experienced nurses during rounds, listens to handovers, and performs low-risk tasks under supervision. Over months she begins to lead portions of the handover, offers interpretations of ambiguous symptoms that are discussed and adjusted by the team, and gradually assumes full responsibility for a patient caseload, adopting the occupational identity and norms of the ward.",
        "B": "A newly hired ward nurse studies the hospital protocols, completes an online module and a written test on procedures, and is certified competent after scoring above the threshold; afterwards she works independently following the protocols without consulting colleagues.",
        "C": "A newly hired ward nurse spends several weeks practicing procedures in an individual virtual-reality simulator that reproduces clinical situations. She repeats scenarios until she attains high proficiency scores but rarely interacts with other staff during this period.",
        "D": "A newly hired ward nurse attends a series of instructor-led classroom drills where she memorizes step-by-step checklists and repeats them in timed exercises judged solely on speed and accuracy, with little discussion of contextual judgment or team norms."
      },
      "correct_answer": "A",
      "generation_notes": "Designed four concrete workplace vignettes to contrast situated, social, participatory learning (A) with individualistic or decontextualized learning modes (B–D); A aligns with legitimate peripheral participation, co-construction of knowledge, and identity negotiation.",
      "concepts_tested": [
        "Learning as participation in a community of practice within a specific social/physical context",
        "Legitimate peripheral participation and progressive movement toward full participation and identity change",
        "Knowledge co-construction through social interaction and motivation embedded in evolving social relations"
      ]
    },
    "pass_2_reason": "readability_too_high_27.0_vs_16"
  },
  {
    "original_question": {
      "question": "Why is the exchange of finance for rights in intellectual property considered the irreducible core that drives the creative industries, and how does this arrangement sustain ongoing creativity?",
      "options": {
        "A": "It ensures all creative work becomes publicly funded, removing market risk and guaranteeing broad access to markets.",
        "B": "It aligns incentives by turning speculative creative effort into legally protected, monetizable assets, enabling investors to recoup costs and fund further innovation.",
        "C": "It eliminates the need for licensing or contracts because IP rights are automatically granted with any new idea.",
        "D": "It concentrates participation in large firms, restricting capital access to maintain market control."
      },
      "correct_answer": "B",
      "source_article": "Creative industries",
      "x": 1.2787827253341675,
      "y": 0.9673700332641602,
      "concepts_tested": [
        "The irreducible core and economic mechanism: exchange of finance for rights in intellectual property as the engine of the creative industries.",
        "Definitional boundaries and relationships: how “creative industries,” “cultural industries,” and “creative economy” overlap, differ, and shape which activities are included.",
        "Creativity as an economic resource: the claim that human creativity and knowledge generation are central to modern economic well-being and employment."
      ],
      "parent_concepts": [
        "Concept 3: The sportainment model influences and drives cross-industry development (leisure, hospitality, real estate, urban planning) through entertainment-centered venues and experiences."
      ],
      "parent_articles": [
        "Sports entertainment"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why is the exchange of finance for intellectual-property (IP) rights described as the \"irreducible core\" of the creative industries, and how does that arrangement sustain continued creative production?",
      "options": {
        "A": "Because it makes creative work entirely publicly funded, eliminating market risk and ensuring universal market access.",
        "B": "Because it converts speculative creative effort into legally protected, monetizable assets, aligning incentives so investors can recoup costs and finance further innovation.",
        "C": "Because it removes the need for contracts or licensing, since IP rights are automatically granted to any new idea without negotiation.",
        "D": "Because it centralizes control in large firms, restricting capital to a few players to preserve market dominance."
      },
      "correct_answer": "B",
      "simplification_notes": "Clarified phraseology, defined \"IP\" as intellectual property, condensed question to emphasize the economic mechanism and its effect on incentives and funding, and made all option statements concise and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.1_vs_16",
    "pass_2_attempt": {
      "question": "A mid-sized city's economic development office must adopt a classification and measurement policy for its “creative industries” to allocate grants and report economic contribution. Which of the following policy packages best reflects (1) the DCMS definition emphasizing activities that originate in individual creativity and whose value is realized through generation/exploitation of intellectual property (the \"irreducible core\"), (2) Caves’ insight that rights/IP exchange is the sector’s economic engine, and (3) the DCMS method for counting creative workers?",
      "options": {
        "A": "Adopt a DCMS-style sector list (advertising, architecture, crafts, design, film/TV/photography, IT/software, publishing, museums/galleries/libraries, music/performing and visual arts). For metrics, count (i) all workers employed in enterprises whose primary output is a listed creative product (including non-creative roles like security guards), and (ii) workers who are creatively occupied but employed outside those enterprises (e.g., a piano teacher at a school). Exclude antiques dealers and broad engineering fields unless the activity directly generates exploitable IP (patents, copyrighted software), while allowing extended inclusions (e.g., gastronomy, video games, R&D) under separate policy streams.",
        "B": "Define creative industries narrowly as only those producing reproducible cultural texts or artefacts (film, publishing, music, videogames) and exclude museums, libraries and most services. For measurement, count only workers with explicit creative job titles (artists, developers, writers), ignoring non-creative staff in creative firms. Include antique dealers and civil engineers because their outputs can be creative in practice.",
        "C": "Classify firms solely by who holds copyright according to WIPO-style chains: only firms or individuals owning copyrights are creative. For statistics, count only copyright owners and employees directly involved in copyrightable production; exclude all other workers in those firms (e.g., managers, cleaners). Engineers and R&D labs are included only if they hold copyrights; gastronomy and museums are excluded unless copyright is central.",
        "D": "Treat any small-scale, artisanal, or tourism-related activity as part of the creative industries (farmers’ markets, antique shops, neighbourhood bakeries, local heritage festivals). For metrics, count every such firm as one creative enterprise (irrespective of employee composition) and allocate funds equally per firm to stimulate grassroots creativity; do not prioritize IP generation or exploitation."
      },
      "correct_answer": "A",
      "generation_notes": "Created a policy-choice scenario testing knowledge of DCMS sector list and definition, Caves' 'irreducible core' about IP exchange, and the DCMS counting method (all workers in creative firms plus creatively occupied workers outside them). Options contrast WIPO-only, narrow core-text, and overly broad artisanal approaches.",
      "concepts_tested": [
        "Irreducible core: exchange of finance for rights in intellectual property as economic engine",
        "Definitional boundaries and overlap between creative industries, cultural industries, and creative economy",
        "Practical counting method for creative workers (DCMS approach) and implications for policy/economic measurement"
      ]
    },
    "pass_2_reason": "readability_too_high_24.5_vs_16"
  },
  {
    "original_question": {
      "question": "In applied mathematics, why is abstraction and model simplification considered central, and how does the trade-off between simplicity and realism influence a model's usefulness for solving real-world problems?",
      "options": {
        "A": "Abstraction makes the problem solvable by removing all nonlinearities, and any loss of detail always increases predictive generality.",
        "B": "Abstraction helps reveal the core mechanisms and relevant scales, allowing insights that generalize beyond specific cases; too much simplification can miss critical dynamics, while too much detail can obscure essential behavior and hinder analysis.",
        "C": "Abstraction is a way to avoid collecting data, so the model's usefulness does not depend on empirical validation.",
        "D": "Abstraction ensures the model perfectly captures reality if the equations are derived from first principles, guaranteeing accurate predictions."
      },
      "correct_answer": "B",
      "source_article": "Applied mathematics",
      "x": 1.5002483129501343,
      "y": 1.1100740432739258,
      "concepts_tested": [
        "The bidirectional relationship between applied mathematics and pure mathematics: practical applications motivate theory, and advances in pure mathematics can later become applicable.",
        "Modeling as the core activity: applied mathematics centers on formulating and studying mathematical models to solve real-world problems.",
        "Fluid boundaries and interdisciplinarity: there is no fixed set of branches, and distinctions between applied mathematics and the applications of mathematics blur as disciplines evolve and cross-pollinate (e.g., cryptography arising from number theory)."
      ],
      "parent_concepts": [
        "Concept 2: Many differential equations do not have closed-form solutions; properties can be studied analytically or approximated numerically when exact solutions are unavailable."
      ],
      "parent_articles": [
        "Differential equation"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why are abstraction and model simplification central in applied mathematics, and how does the balance between simplicity and realism affect a model's usefulness for real-world problems?",
      "options": {
        "A": "Abstraction makes problems solvable by removing all nonlinearities and complexities; any loss of detail always increases a model's predictive generality.",
        "B": "Abstraction isolates core mechanisms and relevant scales so models reveal insights that transfer beyond specific cases; too much simplification can omit critical dynamics, while too much detail can obscure essential behavior and hinder analysis or computation.",
        "C": "Abstraction is primarily a way to avoid empirical work, so a model's usefulness does not depend on data collection or validation.",
        "D": "When equations are derived from first principles, abstraction guarantees the model perfectly captures reality and thus yields accurate predictions."
      },
      "correct_answer": "B",
      "simplification_notes": "Wording was shortened and made more direct for undergraduates; retained focus on modeling, abstraction, and the trade-off between simplicity and realism; technical terms like 'mechanisms', 'scales', and 'dynamics' were preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_18.2_vs_16",
    "pass_2_attempt": {
      "question": "Consider these three concrete developments: (i) during an epidemic, epidemiologists use the SIR compartmental model with equations $\\frac{dS}{dt}=-\\beta\\frac{SI}{N}$ and $\\frac{dI}{dt}=\\beta\\frac{SI}{N}-\\gamma I$, and applied mathematicians refine the model and prove analytical results about its PDE or stochastic limits; (ii) number theorists prove deep results about elliptic curves that years later are used to build elliptic-curve cryptography; (iii) an ecologist fits a standard logistic population ODE to field data using existing parameter-estimation methods but does not develop new mathematics. Which statement best captures the role of applied mathematics and its relationship to pure mathematics and applications, given these examples?",
      "options": {
        "A": "Applied mathematics centers on formulating and studying mathematical models (as in the SIR example), has a bidirectional relationship with pure mathematics (practical problems motivate new theory and pure results such as elliptic-curve theory can later become applied), and has fluid boundaries with applications—an ecologist using existing models is applying mathematics, while mathematical biologists who pose new problems contribute to applied mathematics.",
        "B": "Applied mathematics is strictly the use of established mathematical techniques to solve practical problems; it does not generate new mathematical theory, so developments in pure number theory (elliptic curves) are unrelated to applied mathematics and only domain experts applying models count as applied mathematics.",
        "C": "Applied mathematics is confined to the classical areas that developed alongside physics (differential equations, numerical analysis, applied probability); newer connections such as number theory → cryptography or computational methods are outside applied mathematics, and modeling is primarily a tool of other sciences rather than of applied mathematics itself.",
        "D": "Applied mathematics is identical to the applications of mathematics by non-mathematicians; mathematicians who prove abstract existence or regularity results for models are doing pure mathematics, while only domain practitioners fitting models to data are engaged in applied mathematics."
      },
      "correct_answer": "A",
      "generation_notes": "Used three concrete examples (SIR model, elliptic-curve cryptography, ecological data fitting) to probe: modeling as central activity, bidirectional influence with pure math, and blurred interdisciplinary boundaries.",
      "concepts_tested": [
        "Bidirectional relationship between applied and pure mathematics",
        "Modeling as core activity of applied mathematics",
        "Fluid boundaries and interdisciplinarity between applied mathematics and applications"
      ]
    },
    "pass_2_reason": "readability_too_high_27.7_vs_16"
  },
  {
    "original_question": {
      "question": "How do geographic and environmental gradients—specifically a decline in energy availability with increasing latitude—mechanistically constrain the distribution of species and lead to a predictable drop in regional species richness toward higher latitudes?",
      "options": {
        "A": "The gradient directly accelerates mutation rates in tropical regions, producing more species.",
        "B": "Higher energy supports larger populations and more ecological niches, enabling more species to coexist; as energy declines with latitude, population sizes shrink and fewer niches are available, reducing species richness.",
        "C": "Energy availability has no effect on distributions; climate temperature alone determines species presence.",
        "D": "Isolation increases with latitude and prevents any dispersal, causing all regions to have the same richness."
      },
      "correct_answer": "B",
      "source_article": "Biogeography",
      "x": 1.6501022577285767,
      "y": 1.0585265159606934,
      "concepts_tested": [
        "Concept 1: Historical factors (speciation, extinction, continental drift, glaciation) drive patterns of species distribution over space and time.",
        "Concept 2: Geographic and environmental gradients (latitude, elevation, isolation, habitat area, energy availability) constrain distributions and produce predictable patterns.",
        "Concept 3: Biogeography integrates short-term ecological processes and long-term historical processes, using tools like GIS to analyze and predict distribution across scales."
      ],
      "parent_concepts": [
        "Endemism as a measure of biodiversity in a defined area and its link to extinction risk due to restricted geographic range.",
        "Endemism as a tool for informing conservation priorities and interpreting evolutionary history (how historical/environmental factors shape endemism).",
        "Latitudinal gradient of biodiversity and its drivers: Why is biodiversity greater in tropical regions, and how do climate and primary productivity contribute to this pattern?",
        "Concept 2: Key historical processes (vicariance, dispersal, migration, bottlenecks, population expansion) and how genetic data and coalescent-based approaches help infer their relative roles.",
        "Concept 1: Geographic isolation reduces gene flow between populations, enabling independent genetic divergence that can result in speciation.",
        "Scale and perspective in community ecology (local vs. regional, and the shift toward evolutionary biogeography) as a conceptual framework for understanding communities",
        "Fragmentation as a landscape-scale process that alters habitat configuration via five discrete phenomena (area reduction, interior-to-edge ratio change, isolation, breaking patches into smaller patches, and smaller average patch size).",
        "The conceptual distinction between habitat fragmentation and habitat loss, and how terminology reflects underlying processes and connectivity (i.e., fragmentation focusing on spatial arrangement, not solely reduced area).",
        "Concept 3: The geographic context of populations (sympatry vs allopatry) influences how and where isolation barriers arise and are maintained during speciation.",
        "Concept 1: Beta diversity as the relationship between regional (gamma) diversity and local (alpha) diversity, capturing differentiation or turnover across sites (β = γ/α and related formulations). Why/how: what the beta component represents and how it changes with site similarity.",
        "Concept 1: Plant distributions and abundances are governed by environmental factors and biotic interactions (e.g., competition, grazing), shaping community composition.",
        "Concept 3: Climate change (natural or human-induced) can modify habitats over seasonal to long timescales, leading to changes in species distribution, potential overpopulation, or extinction, illustrating cause-effect relationships between climate and biotic responses.",
        "Concept 3: Ecotones as drivers of biodiversity and ecosystem interactions (how mixing zones affect species richness, competition, and the presence/abundance of introduced species).",
        "Concept 3: Biogeographic origin and dispersal history of Canidae (origin in North America, later spread to Eurasia and South America) and how timing shapes evolution."
      ],
      "parent_articles": [
        "Endemism",
        "Endemism",
        "Biodiversity",
        "Phylogeography",
        "Allopatric speciation",
        "Community (ecology)",
        "Habitat fragmentation",
        "Habitat fragmentation",
        "Reproductive isolation",
        "Beta diversity",
        "Plant ecology",
        "Bioclimatology",
        "Ecotone",
        "Canidae"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Explain, in mechanistic terms, how an environmental gradient—specifically a decline in available ecosystem energy with increasing latitude—constrains species distributions and produces a predictable decrease in regional species richness toward higher latitudes.",
      "options": {
        "A": "The energy gradient directly raises mutation rates in low‑latitude populations, increasing speciation and thus more species in the tropics.",
        "B": "Greater available energy at lower latitudes supports larger population sizes and a wider variety of resource‑based niches, reducing local extinctions and allowing more species to coexist; as energy declines with latitude, populations shrink and fewer niches exist, so regional species richness falls.",
        "C": "Energy availability is irrelevant; only ambient temperature controls whether a species can occur along a latitudinal gradient.",
        "D": "Higher latitudes have greater geographic isolation and historical barriers to colonization, which reduce immigration and gene flow so fewer species establish or persist there, producing lower richness."
      },
      "correct_answer": "B",
      "simplification_notes": "Rewrote the prompt in clearer undergraduate academic language, focused on the energy–richness mechanism, and made all distractors plausible alternative mechanisms (mutation rate, temperature-only control, isolation/colonization limits).",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_25.8_vs_16",
    "pass_2_attempt": {
      "question": "You are studying an oceanic archipelago with three islands: Island A (large, high-elevation, close to the mainland; geological evidence indicates it was connected to the mainland by a landbridge during Pleistocene low sea levels), Island B (moderate area and isolation), and Island C (small, remote, low-elevation). Field surveys show: (1) several endemic plant and passerine bird taxa restricted to the montane cloud forest of Island A and genetically divergent from mainland conspecifics; (2) a suite of lowland plant species present on the mainland and Island A but absent from Island C despite apparently suitable lowland habitat there; (3) a few squamate reptiles on Island C that are genetically closest to taxa from a distant archipelago several hundred kilometres away. Which combination of processes best explains observations (1)–(3), and which research approach would most directly test these hypotheses and project future distributions under climate warming?",
      "options": {
        "A": "(Processes) (1) Pleistocene vicariance and subsequent allopatric speciation in high-elevation refugia on Island A driven by isolation and elevation gradients; (2) dispersal limitation and increased extinction risk on small, low-energy Island C (area–isolation effects of island biogeography) explaining absence of lowland taxa; (3) rare long-distance oceanic dispersal events (rafting/overwater dispersal) accounting for reptiles on Island C. (Approach) Integrate molecular phylogeography and paleogeographic reconstruction with GIS-based environmental niche modelling (ENM/SDM) to test origins and to project range shifts under warming.",
        "B": "(Processes) (1) Sympatric ecological speciation within Island A's cloud forest driven solely by niche partitioning; (2) competitive exclusion by a dominant colonist prevents lowland species from establishing on Island C despite available habitat; (3) tectonic rafting (continental drift) explains reptile affinities. (Approach) Intensive ecological competition experiments on each island without molecular or GIS analyses.",
        "C": "(Processes) (1) Ancient Gondwanan vicariance (plate-tectonic breakup) produced the endemic taxa on Island A; (2) soil edaphic specialization prevents lowland species from surviving on Island C; (3) human-mediated introduction explains reptiles on Island C. (Approach) Focus on fossil assemblages and historical shipping records exclusively to infer origins and distributions.",
        "D": "(Processes) (1) Recent human translocations created the endemic assemblage on Island A; (2) habitat suitability is identical across islands so stochastic local extinctions alone explain absence on Island C; (3) adaptive radiation on Island C produced reptiles similar to distant archipelago by convergent evolution. (Approach) Rely on species occurrence records alone (no genetic or spatial-environmental modelling) to infer processes and forecast changes."
      },
      "correct_answer": "A",
      "generation_notes": "Created a scenario-rich multiple-choice question linking Pleistocene vicariance, allopatric speciation, island area/isolation and dispersal limitations, plus oceanic long-distance dispersal; included an integrated methodological answer (molecular phylogeography + paleogeography + GIS/ENM) to test and project distributions under climate change.",
      "concepts_tested": [
        "Historical factors (speciation, extinction, continental/sea-level change, vicariance)",
        "Geographic and environmental gradients and island biogeography (latitude/elevation/isolation/area/energy)",
        "Integration of short-term ecological and long-term historical processes using molecular phylogeography and GIS/ENM to analyze and predict distributions"
      ]
    },
    "pass_2_reason": "readability_too_high_24.8_vs_16"
  },
  {
    "original_question": {
      "question": "How do understandable, individualized information and sufficient time in a clinical encounter translate into active patient involvement and better decision-making within participatory medicine?",
      "options": {
        "A": "They empower patients to override clinical judgment whenever they disagree.",
        "B": "They reduce information asymmetry and provide time for reflection, questions, and expressing preferences, enabling decisions aligned with the patient’s values.",
        "C": "They guarantee the patient will choose the medically optimal option for everyone, regardless of personal values.",
        "D": "They shift all responsibility to the patient, making the clinician's role unnecessary."
      },
      "correct_answer": "B",
      "source_article": "Patient participation",
      "x": 1.2945127487182617,
      "y": 0.9799059629440308,
      "concepts_tested": [
        "Concept 1: Principles underlying patient participation (transparency, individualization, recognition, respect, dignity, and choice) and how they shape patient autonomy and involvement in care.",
        "Concept 2: Mechanisms to enable participation (how factors like understandable information, education, sufficient time, inclusive processes, and provider attitudes translate into active patient involvement and better decision-making).",
        "Concept 3: Relationships and representational dynamics in participatory medicine (how democratic, statistical, and symbolic representation affect legitimacy, diversity, and power in patient engagement)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "How do providing understandable, individualized information and allowing sufficient time during a clinical encounter promote active patient involvement and better decision-making in participatory medicine?",
      "options": {
        "A": "They permit patients to override the clinician’s judgment whenever they disagree.",
        "B": "They reduce information asymmetry and create time for reflection, questions, and expression of preferences, enabling choices aligned with the patient’s values.",
        "C": "They guarantee the patient will choose the single medically optimal option for everyone regardless of individual values.",
        "D": "They shift full responsibility to the patient and render the clinician’s role unnecessary."
      },
      "correct_answer": "B",
      "simplification_notes": "Question wording shortened and clarified; technical phrase 'information asymmetry' retained; removed extended background examples but preserved mechanisms linking understandable information and time to patient-centered decisions. Options rewritten to be concise and plausible.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_25.2_vs_16",
    "pass_2_attempt": {
      "question": "A large urban hospital forms a Patient Advisory Council (PAC) to redesign its discharge process. The hospital wants the PAC to embody patient participation principles (transparency, individualization, recognition, respect, dignity, choice), use mechanisms that enable meaningful involvement (clear tailored information, education for patients and providers, sufficient time, inclusive processes, positive provider attitudes), and address representational challenges in participatory medicine (democratic, statistical, symbolic representation). Which of the following PAC designs best fulfills these aims?",
      "options": {
        "A": "Staff select volunteer patients known to them; PAC meets for 30 minutes monthly; members receive standard clinical reports full of medical terminology; no training for staff or patients; decisions about discharge workflows are made by clinicians after PAC meetings.",
        "B": "The hospital publishes a transparent charter emphasizing respect and choice; provides lay, individualized summaries and communication-skills training to patient members and shared-decision-making training to clinicians; schedules longer, well-supported meetings; recruits members via stratified sampling to reflect patient demographics while also electing a subset of patient representatives and including lived-experience leaders; discloses conflicts of interest, compensates participants, and evaluates impact regularly.",
        "C": "The hospital deploys an anonymized online survey and an AI-summarized feedback dashboard; it weights responses to approximate the hospital population (statistical representation) but holds no in-person deliberations, provides no provider training, and keeps all final policy authority with administrators.",
        "D": "The hospital invites several well-known patient advocates to speak at public forums (symbolic representation) and uses their testimony to guide changes; no systematic recruitment, no education for clinicians, and no mechanisms for patients to participate in decision-making between forums."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a vignette requiring synthesis of normative principles, enabling mechanisms, and types of representativeness; options contrast comprehensive, partial, and tokenistic implementations to test integrative understanding.",
      "concepts_tested": [
        "Principles of patient participation (transparency, individualization, recognition, respect, dignity, choice)",
        "Mechanisms enabling participation (tailored information, education, time, inclusive processes, provider attitude)",
        "Representational dynamics in participatory medicine (democratic, statistical, symbolic representation and legitimacy)"
      ]
    },
    "pass_2_reason": "readability_too_high_21.9_vs_16"
  },
  {
    "original_question": {
      "question": "Why does embedding CSR into a firm’s core strategy and aligning it with its brand and stakeholder networks tend to improve long-term performance, rather than treating CSR as a separate philanthropic activity?",
      "options": {
        "A": "Because this alignment transforms CSR into a strategic asset that creates value for customers, employees, and investors by delivering differentiated offerings, reducing risk, and enabling efficient resource use, which together boosts long-run performance.",
        "B": "Because CSR only increases charitable expenditures, which necessarily guarantees higher profits due to favorable tax treatment.",
        "C": "Because isolating CSR from core strategy prevents any effect on brand or stakeholder relations, so long-term performance is unaffected.",
        "D": "Because aligning CSR with the brand removes the need to monitor stakeholder concerns, simplifying decision-making."
      },
      "correct_answer": "A",
      "source_article": "Corporate social responsibility",
      "x": 1.3248459100723267,
      "y": 0.9167646765708923,
      "concepts_tested": [
        "Strategic CSR and its link to brand alignment, stakeholder integration, and long-term firm performance",
        "CSR as corporate self-regulation with regulatory/standards incentives (ESG reporting, mandatory schemes)",
        "Creating Shared Value as an extension of CSR that aligns social obligations with profitability"
      ],
      "parent_concepts": [
        "Stakeholder identification vs. stakeholder salience (normative vs. descriptive): how managers determine who counts as a stakeholder and which stakeholders matter, influencing decisions.",
        "Concept 3: The evolution of marketing definitions toward emphasizing relationships and societal value, reflecting a shift from mere exchange to ongoing stakeholder engagement.",
        "Concept 3: Naming rights can be donated to outside organizations (CSR), with implications for reputation and stakeholder relationships.",
        "Concept 3: Social mission and reinvestment of profits into communities (including multi-stakeholder and platform cooperative models) as drivers of societal impact and sustainability.",
        "Concept 2: Reinvestment of profits into sustainable development and services to align economic activity with social objectives."
      ],
      "parent_articles": [
        "Stakeholder theory",
        "Marketing",
        "Naming rights",
        "Cooperative",
        "Social economy"
      ]
    },
    "reason": "content_loss_both_passes",
    "pass_1_attempt": {
      "question": "Why does integrating corporate social responsibility (CSR) into a firm's core strategy and aligning it with the brand and stakeholder network typically improve long-term performance, instead of treating CSR as a separate philanthropic activity?",
      "options": {
        "A": "Because this alignment turns CSR into a strategic asset that creates value for customers, employees, and investors by differentiating offerings, reducing risk (legal and reputational), and improving resource efficiency, which together support stronger long-run performance.",
        "B": "Because CSR only increases charitable expenditures, which automatically guarantees higher profits due to favorable tax treatment and therefore improves long-term performance.",
        "C": "Because treating CSR as a separate activity has no spillover effects on brand reputation or stakeholder relations, so it neither helps nor harms long-term performance.",
        "D": "Because aligning CSR with the brand eliminates the need to monitor stakeholder concerns and external standards, simplifying management and thereby improving long-term performance."
      },
      "correct_answer": "A",
      "simplification_notes": "Question was shortened and clarified for undergraduates while keeping technical terms (core strategy, brand alignment, stakeholders). Options were kept plausible and the original correct answer (A) preserved.",
      "content_preserved": true
    },
    "pass_1_reason": "readability_too_high_21.6_vs_16",
    "pass_2_attempt": {
      "question": "A multinational consumer-packaged-goods firm, NaturaCo, faces rising regulatory pressure for ESG disclosure in its primary markets and declining consumer trust after supply-chain controversies. The CEO proposes a three-year program that will: (1) reconfigure procurement to source sustainably from smallholder farmers, paying a price premium while providing technical training to increase their yields; (2) develop a new product line branded explicitly around the sustainable-sourcing partnership; (3) publish audited ESG reports that follow international standards and publicly invite farmer cooperatives and consumer groups to participate in product design and impact measurement. Which description best characterizes this program in terms of CSR theory and practice?",
      "options": {
        "A": "A traditional philanthropic CSR initiative: the firm donates funds and services to farmer communities but keeps sourcing and branding unchanged; the program primarily seeks reputational benefits without altering core operations.",
        "B": "A strategic CSR program that operationalizes Creating Shared Value (CSV): it aligns brand and procurement strategy with stakeholder integration, creates measurable social and economic value for farmers and the firm, and prepares the company to meet/shape mandatory ESG reporting regimes, supporting long-term firm performance.",
        "C": "A regulatory-compliance CSR tactic: the firm focuses only on producing audited ESG reports to satisfy regulators and investors but avoids substantive changes in procurement or stakeholder engagement, leaving social outcomes unchanged.",
        "D": "An instance of greenwashing: the firm markets a new ‘sustainable’ product line while covertly maintaining exploitative supplier contracts and reporting only self-selected metrics to create a positive public image without enabling real farmer benefits."
      },
      "correct_answer": "B",
      "generation_notes": "Constructed a multi-faceted scenario requiring recognition of strategic CSR features (brand alignment, stakeholder integration, long-term performance), CSV (shared economic and social value), and link to ESG reporting/mandatory schemes; distractors reflect philanthropy, compliance-only reporting, and greenwashing.",
      "concepts_tested": [
        "Strategic CSR: brand alignment and stakeholder integration",
        "Creating Shared Value (CSV) aligning social obligations with profitability",
        "CSR as corporate self-regulation and ESG/mandatory reporting incentives"
      ]
    },
    "pass_2_reason": "readability_too_high_21.7_vs_16"
  }
]