{
  "metadata": {
    "generated_at": "2025-11-19T22:21:03.830294",
    "level": 4,
    "num_articles": 499,
    "num_concepts": 1290,
    "num_questions": 326,
    "model": "gpt-5-nano",
    "method": "hierarchical-expansion"
  },
  "questions": [
    {
      "question": "Why do emergent properties of the brain, such as certain patterns of learning or conscious experience, arise from the interactions among neurons, glia, and neural circuits rather than being localized in a single neuron?",
      "options": {
        "A": "Because the brain's components operate independently, so additivity of single-neuron outputs is sufficient to explain higher-level properties.",
        "B": "Because nonlinear interactions, feedback across multiple scales, and the network\u2019s topology generate new patterns that cannot be predicted from any single component alone.",
        "C": "Because information is stored exclusively in synaptic chemical signaling without regard to network dynamics or interactions.",
        "D": "Because emergent properties are fixed at development and do not depend on ongoing circuit activity or interactions."
      },
      "correct_answer": "B",
      "source_article": "Neuroscience",
      "x": 1.8032488822937012,
      "y": 1.1452748775482178,
      "concepts_tested": [
        "Emergence: How complex properties of brains and behavior arise from interactions among neurons, glia, and neural circuits.",
        "Multiscale/integrative approach: Connecting molecular, cellular, system, and cognitive levels using diverse disciplines and techniques.",
        "Brain\u2013behavior relationships: The links between neural mechanisms and learning, memory, perception, behavior, and consciousness."
      ],
      "parent_concepts": [
        "Concept 1: Neuronal signaling mechanisms (electrical impulses, chemical synapses, neurotransmitters; excitatory/inhibitory modulation)",
        "Concept 2: Distributed neural basis of executive functions (involvement of multiple brain regions, not solely the prefrontal cortex)"
      ],
      "parent_articles": [
        "Nervous system",
        "Executive functions"
      ]
    },
    {
      "question": "How does multilevel integration and communication across cells and tissues enable a coherent physiological response to a perturbation?",
      "options": {
        "A": "By relying solely on rapid electrical signals that reach every cell at the same time, ensuring uniform responses.",
        "B": "By engaging multiple modes of signaling (neural, endocrine, paracrine, and autocrine) so that the same perturbation information is interpreted contextually by different cells, coordinating local and systemic responses to produce a coherent outcome.",
        "C": "By restricting signaling to a single tissue so that each tissue can respond independently without needing feedback from other parts of the body.",
        "D": "By requiring identical receptor types across all tissues so every cell responds identically to the messenger, guaranteeing uniformity of response."
      },
      "correct_answer": "B",
      "source_article": "Physiology",
      "x": 1.9025288820266724,
      "y": 1.1100101470947266,
      "concepts_tested": [
        "Homeostasis: the regulatory mechanisms that maintain a stable internal environment.",
        "Structure\u2013Function relationship: how anatomical organization at molecular, cellular, and organ levels dictates and supports physiological function.",
        "Multilevel integration and communication: coordination of biophysical/biochemical processes through cell-to-cell signaling to achieve coherent organismal function."
      ],
      "parent_concepts": [
        "Concept 1: Neuronal signaling mechanisms (electrical impulses, chemical synapses, neurotransmitters; excitatory/inhibitory modulation)",
        "Endocrine regulation uses feedback loops to maintain homeostasis",
        "Concept 3: Endocrine regulation and negative feedback maintaining homeostasis (e.g., insulin regulating blood glucose levels)."
      ],
      "parent_articles": [
        "Nervous system",
        "Endocrinology",
        "Hormone"
      ]
    },
    {
      "question": "In systems theory, emergence and synergy describe system-wide properties that arise from interactions of parts and are not reducible to the components. Which explanation best captures how these emergent properties arise?",
      "options": {
        "A": "The components each carry hidden, pre-existing properties that only show up when combined.",
        "B": "Interactions among components generate nonlinear feedback and cooperative dynamics that create novel patterns not predictable from any single component.",
        "C": "Emergent properties occur because the system's boundaries prevent any information from flowing between components.",
        "D": "Emergent properties are simply the arithmetic average of component properties."
      },
      "correct_answer": "B",
      "source_article": "Systems theory",
      "x": 1.4896122217178345,
      "y": 1.0901458263397217,
      "concepts_tested": [
        "Emergence and synergy: systems exhibit properties that arise from interactions of parts and are not reducible to individual components.",
        "Boundaries, context, structure, function, and relations: how a system is defined and how its environment and internal organization shape behavior and interactions with other systems.",
        "Adaptation and equifinality: systems learn and adapt depending on engagement with their environment, and different paths can lead to the same end state."
      ],
      "parent_concepts": [
        "Levels of analysis and cross-scale integration: studying the nervous system from molecular/cellular scales to imaging and cognitive tasks, and how each scale contributes to understanding brain function.",
        "Concept 1: Security is a relationship that depends on the referent\u2019s environment and the referent\u2019s own capabilities, i.e., security emerges from interactions between a target, its surroundings, and its response options.",
        "Ends-ways-means relationship: strategy describes how goals are achieved with available resources, with resources constraining actions and the possibility of both intended and emergent strategy.",
        "Concept 1: Connectivity and cross-sphere interactions among the Earth\u2019s subsystems",
        "The micro-level vs macro-level scales of analysis and how phenomena at different levels relate",
        "Concept 1: Transformation and efficiency \u2014 Operations converts inputs (materials, labor, energy) into outputs (goods/services) with the goal of efficient resource use to meet customer requirements.",
        "Concept 1: Innate vs Adaptive immunity \u2014 their differences in specificity, how they learn/remember (adaptive), and how they coordinate responses.",
        "Concept 1: The three-component feedback control system (receptor, control center, effector) and their interactions in maintaining a variable within a maintenance range.",
        "Concept 2: Stability and performance criteria\u2014how delays, overshoot, steady-state error, and stability criteria influence controller design and system behavior.",
        "Concept 3: Modeling and design tools\u2014how block diagrams and transfer functions model input-output relationships, and how controllability/observability relate to the ability to control and estimate system states.",
        "Concept 1: Feedback forms a loop that creates circular causality, requiring system-wide analysis rather than linear cause-and-effect reasoning.",
        "Concept 3: Feedback can modify system gain and behavior (e.g., boosting amplification through regeneration) but may also cause instability or undesirable effects (e.g., howl) if not managed.",
        "Self-organization and adaptation: order and patterns arise without central control through local rules and feedback, enabling systems to adapt to their environment.",
        "Transdisciplinary foundations enabling cross-domain applicability of systems thinking",
        "Interdependence of hard infrastructure, soft infrastructure, and governance",
        "The four components of quality management (planning, assurance, control, improvement) form an integrated system to consistently meet intended performance.",
        "Concept 1: Mathematical modeling as the core means of describing real-world systems to enable analysis and decision support.",
        "Concept 3: Drivers of change and their interaction with change management processes (technology evolution, process reviews, crises, regulation, etc.), illustrating cause-effect relationships that trigger and shape change efforts.",
        "Concept 1: Iterative learning loop \u2014 monitoring informs learning, which updates models and then shapes future decisions.",
        "Emergent properties of groups: the idea that group behavior cannot be fully understood by studying individuals in isolation.",
        "IT system composition: hardware, software, and peripherals work together to process/store/retrieve/transmit information.",
        "Concept 1: Interdependence of social and ecological systems with feedback mechanisms",
        "Concept 1: Sustainability through balancing human needs with natural systems and ecological limits (cause/effect: how different approaches aim to achieve a sustainable balance).",
        "Concept 2: Decomposition of risk into sources, events, consequences, and likelihood (a cause\u2013effect\u2013probability framework)",
        "Concept 2: The relationship between management style and ecological resilience\u2014how ecosystem management contrasts with command-and-control approaches to improve resilience and sustainability.",
        "Concept 2: BPM lifecycle and mechanisms \u2014 modeling, automation/execution, control, measurement, and optimization as an interconnected set of activities.",
        "Concept 3: People\u2013technology\u2013process relationships \u2014 BPM is enabled by technology and involves the participation of people, highlighting how workflows and automation relate to organizational goals and performance.",
        "Concept 2: Composability as a mechanism that enables modules to be combined to build larger systems (e.g., in functional programming).",
        "Concept 2: Existence of both linear (designed) and non-linear (emergent, complex) relationships in sociotechnical interactions.",
        "Concept 3: The risk of optimizing one aspect in isolation and the rationale for integrated design of social and technical elements to avoid unintended, detrimental effects.",
        "Concept 1: Closed-loop feedback control mechanism (measurement, comparison to setpoints, corrective action) to maintain process within target parameters.",
        "Concept 3: Objective-driven design and benefits (using control theory principles to achieve energy efficiency, reduced waste, improved quality, and enhanced safety).",
        "Encoding predetermined decision criteria into machines (control logic) to automate processes and reduce human intervention",
        "Systems integration of multiple technologies (mechanical, hydraulic, electrical, electronic, computer) to enable complex automation and affect performance metrics (labor savings, waste reduction, quality, costs)"
      ],
      "parent_articles": [
        "Neuroscience",
        "Security",
        "Strategy",
        "Earth system science",
        "Sociology",
        "Operations management",
        "Immune system",
        "Homeostasis",
        "Control theory",
        "Control theory",
        "Feedback",
        "Feedback",
        "Complex system",
        "Systems science",
        "Infrastructure",
        "Quality management",
        "Operations research",
        "Change management",
        "Adaptive management",
        "Group dynamics",
        "Information technology",
        "Socio-ecological system",
        "Environmentalism",
        "Risk",
        "Ecosystem management",
        "Business process management",
        "Business process management",
        "Modularity",
        "Sociotechnical system",
        "Sociotechnical system",
        "Industrial process control",
        "Industrial process control",
        "Automation",
        "Automation"
      ]
    },
    {
      "question": "Why does emergence occur in a complex system where components interact via nonlinear local rules, producing global behaviors that cannot be inferred by examining the parts alone?",
      "options": {
        "A": "Because the global behavior is simply the additive sum of the individual behaviors.",
        "B": "Because nonlinear interactions create feedback and cross-scale couplings that generate new patterns and organizational levels not predictable from any single component.",
        "C": "Because averaging all component outputs collapses the system into a single simple trend.",
        "D": "Because increasing the number of components always linearizes the overall dynamics."
      },
      "correct_answer": "B",
      "source_article": "Complexity",
      "x": 1.5851572751998901,
      "y": 1.149272084236145,
      "concepts_tested": [
        "Emergence from interacting components: how non-linear, collective dynamics lead to higher-order behaviors not reducible to individual parts.",
        "Organized vs. disorganized complexity: different methodological approaches (probability/statistical mechanics vs. holistic, multi-factor analysis) applied to different types of complex phenomena.",
        "Relational regimes and state spaces as sources of complexity: complexity arises from the number and variety of distinguishable relationships and their possible states within a system."
      ],
      "parent_concepts": [
        "Levels of analysis and cross-scale integration: studying the nervous system from molecular/cellular scales to imaging and cognitive tasks, and how each scale contributes to understanding brain function."
      ],
      "parent_articles": [
        "Neuroscience"
      ]
    },
    {
      "question": "Why does weak emergence typically allow for reliable computer simulation of the emergent phenomenon, in contrast to strong emergence?",
      "options": {
        "A": "Because weak emergence implies the emergent property can be reduced to the properties of a single component.",
        "B": "Because weak emergence relies on the interacting components retaining their independence, so the collective behavior can be reproduced by simulating local interactions among components.",
        "C": "Because weak emergence claims the emergent property is entirely non-computable from micro-details.",
        "D": "Because weak emergence asserts the global property cannot be observed or tested experimentally."
      },
      "correct_answer": "B",
      "source_article": "Emergence",
      "x": 1.4476832151412964,
      "y": 1.132567286491394,
      "concepts_tested": [
        "Emergence as system-level properties not present in any component, arising from interactions within a wider whole.",
        "Weak vs. strong emergence, including implications for predictability, reduction, and the ability to simulate or analyze emergent phenomena.",
        "Philosophical/historical framing of emergence (etiology, categorial novum, poiein) and how threshold events or novel features arise in complex systems."
      ],
      "parent_concepts": [
        "Levels of analysis and cross-scale integration: studying the nervous system from molecular/cellular scales to imaging and cognitive tasks, and how each scale contributes to understanding brain function.",
        "Concept 1: Security is a relationship that depends on the referent\u2019s environment and the referent\u2019s own capabilities, i.e., security emerges from interactions between a target, its surroundings, and its response options.",
        "The micro-level vs macro-level scales of analysis and how phenomena at different levels relate",
        "Self-organization and adaptation: order and patterns arise without central control through local rules and feedback, enabling systems to adapt to their environment.",
        "Emergence and collective behavior: macroscopic properties arise from microscopic interactions in many-body systems.",
        "Emergent properties of groups: the idea that group behavior cannot be fully understood by studying individuals in isolation.",
        "Emergence from interacting components and non-linearity: how local rules and interactions give rise to global properties that are not reducible to the parts."
      ],
      "parent_articles": [
        "Neuroscience",
        "Security",
        "Sociology",
        "Complex system",
        "Condensed matter physics",
        "Group dynamics",
        "Complexity"
      ]
    },
    {
      "question": "Why does the view that cognition operates on internal representations via computational procedures help explain our ability to solve novel problems that we haven't been explicitly trained for?",
      "options": {
        "A": "Because internal representations encode abstract structure, allowing learned elementary procedures to be recombined to generate new solutions, enabling generalization beyond specific training examples.",
        "B": "Because cognition is purely reactive to stimuli, so novel problems cannot be solved without new training.",
        "C": "Because internal representations are tiny and can't support complex reasoning, so behavior is random.",
        "D": "Because all cognitive tasks reduce to direct copying of sensory input to motor response."
      },
      "correct_answer": "A",
      "source_article": "Cognitive science",
      "x": 1.2828636169433594,
      "y": 1.0253710746765137,
      "concepts_tested": [
        "Concept 1: The mind is best understood through representational structures and computational procedures that operate on them.",
        "Concept 2: Cognitive phenomena emerge from and can be analyzed across multiple levels, from neural circuitry to modular brain organization and behavior.",
        "Concept 3: Cognitive science is inherently interdisciplinary, integrating psychology, philosophy, AI, neuroscience, linguistics, and anthropology to model and explain cognition."
      ],
      "parent_concepts": [
        "Concept 3: Competing theoretical frameworks (classical computationalism, connectionism, representationalism/anti-representationalism) as models for explaining how cognition operates and represents information.",
        "Concept 1: Hierarchical organization of executive functions (basic processes enabling higher-order skills like planning and problem-solving)",
        "Concept 2: Distributed neural basis of executive functions (involvement of multiple brain regions, not solely the prefrontal cortex)",
        "Concept 3: Transfer as a continuum integrated with learning \u2014 transfer is not always a separate, discrete event but is connected to learning itself, with debates about its boundaries and conceptualization.",
        "Theoretical frameworks and interdisciplinarity: the variety of theories (referential, ideational, causal, truth-conditional, use, inferentialist) and how semantics interacts with disciplines like logic, computer science, and psychology.",
        "Concept 1: The information-processing framework (encoding, storage, retrieval, processing) as the mechanism by which social information is handled and subsequently influences perception and memory.",
        "Sensorimotor grounding of cognition: cognition is shaped by the body's motor and perceptual systems, not solely by abstract representations.",
        "Contextual embedding and situatedness: embodiment depends on biological, psychological, and cultural contexts, as well as interactions with the environment.",
        "Interdisciplinary integration of psychology/neuroscience with microeconomic theory to build behavioral models",
        "Concept 1: Imagination as a cognitive process that generates new ideas by manipulating mental images and integrating semantic and episodic memory, supporting problem-solving and learning.",
        "Concept 3: Radical behaviorism\u2019s inclusion of covert mental states under the same controlling variables and its relationships to applied behavior analysis and cognitive-behavioral therapies."
      ],
      "parent_articles": [
        "Cognition",
        "Executive functions",
        "Executive functions",
        "Transfer of learning",
        "Semantics",
        "Social cognition",
        "Embodied cognition",
        "Embodied cognition",
        "Behavioral economics",
        "Imagination",
        "Behaviorism"
      ]
    },
    {
      "question": "Why does the expected utility framework provide a normative (prescriptive) mechanism for rational choice under uncertainty, and how does separating beliefs from preferences contribute to its prescriptive role?",
      "options": {
        "A": "Because it prescribes choosing the option that maximizes the expected utility, defined as the probability-weighted sum of utilities across outcomes; this makes the decision depend only on the agent\u2019s utility function and beliefs about outcome probabilities, so updates to beliefs (e.g., Bayes\u2019 rule) change choices without altering underlying preferences.",
        "B": "Because it prescribes choosing the option with the highest raw utility, ignoring any probabilistic information about outcomes.",
        "C": "Because it selects options based on the most frequently occurring outcome, regardless of utilities.",
        "D": "Because it explains decision-making purely in terms of observed cognitive biases, treating norms as descriptive rather than prescriptive."
      },
      "correct_answer": "A",
      "source_article": "Decision theory",
      "x": 1.3975611925125122,
      "y": 1.0570943355560303,
      "concepts_tested": [
        "Expected utility theory as the mechanism for rational decision-making under uncertainty",
        "The normative vs. descriptive distinction and the role of decision analysis as a prescriptive tool",
        "The evolution of decision theory to incorporate behavioral insights (e.g., prospect theory, cognitive biases) and alternative frameworks (Bayesian decision theory, axiomatic/procedural approaches)"
      ],
      "parent_concepts": [
        "Concept 1: Distinction and relationship between uncertainty, risk, and variability, including how measurement treats them and when risk is considered separate from uncertainty.",
        "Utility maximization under constraints: rational choice with preferences, budget sets, and local non-satiation forming the basis of consumer theory.",
        "Concept 3: Constraints and feasible region shaping choice \u2014 financial, legal, social, physical, or emotional restrictions define the set of possible actions and influence the chosen option.",
        "Concept 2: Components of risk (risk sources, potential events, their consequences, and their likelihood) that together define risk.",
        "Ends-ways-means relationship: strategy describes how goals are achieved with available resources, with resources constraining actions and the possibility of both intended and emergent strategy.",
        "Ends-to-means alignment over a defined time horizon: how goals are achieved using resources and why timing matters.",
        "Concept 1: Modeling and quantitative analysis as central mechanisms for solving managerial problems and achieving (near) optimal decisions.",
        "Concept 1: Policy as guiding decisions to achieve rational outcomes, with different testability for subjective vs. objective decision-making.",
        "Concept 1: The risk assessment process as a flow of steps (hazard analysis -> risk assessment -> risk evaluation) and how each step informs risk management decisions.",
        "Concept 2: How risk results are interpreted and communicated, including cognitive biases and the role of decision aids in shaping decisions.",
        "Concept 2: Passive vs. active adaptive management \u2014 whether learning is valued only for decision quality or explicitly incorporated into the objective function to prioritize learning.",
        "EIA as a decision-support tool that requires accounting for environmental values and justification of decisions, rather than guaranteeing a predetermined environmental outcome.",
        "Present value, expectation, and decision making under uncertainty (time value of money and expected utility)",
        "Concept 1: Distributive vs. integrative negotiation as fundamental types, and how the negotiators\u2019 mindset and the situation determine which type occurs.",
        "Concept 1: Risk as the effect of uncertainty on objectives (how uncertainty can alter outcomes relative to goals)",
        "Concept 2: Risk aversion and the risk\u2013return trade-off drive portfolio choice; a rational investor prefers portfolios with better risk-adjusted returns and avoids dominated choices.",
        "Concept 1: Optimization as selecting the best element with respect to an objective function over a feasible set (objective + feasible region).",
        "Concept 3: TCO as a decision-making framework \u2014 TCO provides a cost basis that relates to investment analysis metrics (ROI, IRR, EVA) and helps gauge the viability and profitability of capital investments over time.",
        "Concept 1: Evaluation aims to determine effectiveness (doing what is intended) and efficiency (value for money) to inform decision-making."
      ],
      "parent_articles": [
        "Uncertainty",
        "Microeconomics",
        "Rational choice model",
        "Risk",
        "Strategy",
        "Strategic planning",
        "Management science",
        "Policy",
        "Risk assessment",
        "Risk assessment",
        "Adaptive management",
        "Environmental impact assessment",
        "Financial economics",
        "Negotiation",
        "Risk",
        "Modern portfolio theory",
        "Mathematical optimization",
        "Total cost of ownership",
        "Program evaluation"
      ]
    },
    {
      "question": "In an experimental study, participants are randomly assigned to treatment and control groups. Why does this randomization strengthen causal claims compared to an observational study where groups are formed by participants' preferences?",
      "options": {
        "A": "Randomization creates identical groups by design, guaranteeing the same outcomes in both groups.",
        "B": "Randomization helps ensure that both observed and unobserved confounders are balanced on average between groups, so observed outcome differences are more plausibly caused by the treatment.",
        "C": "Randomization eliminates the need for any statistical analysis because differences are automatically causal.",
        "D": "Randomization makes the sample perfectly representative of the population, ensuring generalization to all populations."
      },
      "correct_answer": "B",
      "source_article": "Statistics",
      "x": 1.5725957155227661,
      "y": 1.1284596920013428,
      "concepts_tested": [
        "Descriptive vs. inferential statistics and how sampling variation affects generalization from a sample to a population",
        "Hypothesis testing framework, including null hypothesis, alternative hypothesis, and Type I/Type II errors",
        "Experimental vs. observational study designs and the role of manipulation/randomization in establishing causal inferences and the importance of representative sampling"
      ],
      "parent_concepts": [
        "Concept 1: Distinction and relationship between uncertainty, risk, and variability, including how measurement treats them and when risk is considered separate from uncertainty.",
        "Concept 2: A core workflow in mathematical statistics involves selecting a model, checking its conditions/assumptions, and quantifying uncertainty (e.g., through confidence intervals).",
        "Concept 3: Descriptive statistics describes data, while inferential statistics uses probabilistic models to draw conclusions and test hypotheses, enabling secondary analyses and new studies.",
        "Concept 3: Measurement challenges and limitations in estimating the world economy (data quality, legality of markets, regulatory differences) and how they affect global comparisons.",
        "Cost-quality trade-offs in survey design and the goal of improving quality within cost constraints",
        "Concept 1: Official statistics are expected to be objective, accurate, and accessible, produced on a continuing basis to measure change.",
        "Concept 3: The impact of statistical tools (e.g., ANOVA, p-values, Fisher\u2019s exact test) on hypothesis testing and interpreting biological data.",
        "The parameter-to-distribution relationship: parameters influence the distribution of measured data, and estimation uses observed data to infer the parameters.",
        "The role of data samples and noise in estimation: a sample from a random vector provides information to form an estimator, acknowledging randomness in measurements.",
        "Concept 2: The probabilistic, \"most likely\" matching objective in pattern recognition, including handling statistical variation versus exact pattern matching.",
        "Concept 1: Learning from data and generalization to unseen data (the fundamental goal of ML and its ability to perform tasks without explicit instructions)"
      ],
      "parent_articles": [
        "Uncertainty",
        "Mathematical statistics",
        "Mathematical statistics",
        "World economy",
        "Survey methodology",
        "Official statistics",
        "Biostatistics",
        "Estimation theory",
        "Estimation theory",
        "Pattern recognition",
        "Machine learning"
      ]
    },
    {
      "question": "How does interdisciplinarity in environmental history, by integrating humanities and natural sciences across time and space, most effectively enable understanding of long-term human\u2013environment dynamics?",
      "options": {
        "A": "It standardizes methods so all data are reduced to a single metric for easy comparison.",
        "B": "It prioritizes quantitative data over qualitative insights to establish objective causality.",
        "C": "It combines multiple kinds of evidence and explanatory logics (narratives, ecological data, material records) to reveal how social actions and ecological processes co-evolve across different scales.",
        "D": "It confines analysis to present-day concerns to maintain relevance."
      },
      "correct_answer": "C",
      "source_article": "Environmental history",
      "x": 1.3189517259597778,
      "y": 0.9244641661643982,
      "concepts_tested": [
        "Concept 1: The reciprocal relationship between humans and the environment (environment influences human affairs and humans influence the environment).",
        "Concept 2: A three-part analytical framework for environmental history: (a) changes in nature itself, (b) how humans use nature and its environmental consequences, (c) human ideas/beliefs about nature and their influence on interactions with the natural world.",
        "Concept 3: The field\u2019s interdisciplinarity and broad scope across time and space (integration of humanities and natural sciences to study long-term, global human\u2013environment dynamics)."
      ],
      "parent_concepts": [
        "Concept 3: Historical drivers and mechanisms (how public awareness, environmental laws, and events like Silent Spring and major oil spills catalyzed the emergence and focus of environmental science)."
      ],
      "parent_articles": [
        "Environmental science"
      ]
    },
    {
      "question": "Why does targeting a single environmental problem through policy often produce spillover effects on other environmental issues?",
      "options": {
        "A": "Because many environmental problems share common sources or production processes, so reducing one problem often shifts incentives or technologies toward cleaner options that also lessen others, creating co-benefits.",
        "B": "Because each environmental problem is isolated and solved problems do not affect others, given distinct causes.",
        "C": "Because focusing on one issue narrows political attention and resources, leading to neglect and worsening of all other issues.",
        "D": "Because addressing one issue necessarily diverts resources away from others, guaranteeing worsening outcomes."
      },
      "correct_answer": "A",
      "source_article": "Environmental policy",
      "x": 1.368301272392273,
      "y": 0.8586468696594238,
      "concepts_tested": [
        "Concept 1: Interconnectedness of environmental problems and spillover effects of addressing one issue on others",
        "Concept 2: Policy instruments (laws, regulations, actions) as mechanisms to influence human activity to prevent environmental harm",
        "Concept 3: The broad, multi-dimensional scope of environmental policy (environment, social and economic dimensions) and its focus on sustainability for future generations"
      ],
      "parent_concepts": [
        "Concept 3: Historical drivers and mechanisms (how public awareness, environmental laws, and events like Silent Spring and major oil spills catalyzed the emergence and focus of environmental science)."
      ],
      "parent_articles": [
        "Environmental science"
      ]
    },
    {
      "question": "In science policy, why are knowledge networks and collaborations considered essential structures for shaping science production, particularly regarding the distribution of expertise, equipment, and tacit know-how?",
      "options": {
        "A": "They ensure every actor has equal access to all resources, eliminating any coordination costs.",
        "B": "They allow results to be determined purely by the most talented individual, independent of network structure.",
        "C": "They determine which problems are tackled and how quickly ideas spread, because diverse expertise and shared access to specialized equipment enable recombination and diffusion of tacit knowledge, while coordination, trust, and incentives influence efficiency.",
        "D": "They automatically produce fast breakthroughs because international networks overcome local limitations without any overhead."
      },
      "correct_answer": "C",
      "source_article": "Science policy",
      "x": 1.2675955295562744,
      "y": 0.9988622665405273,
      "concepts_tested": [
        "Concept 1: Resource allocation and funding as mechanisms to align science with public interest and economic development.",
        "Concept 2: Knowledge networks and collaborations as essential structures shaping how science is produced (distribution of expertise, equipment, and know-how).",
        "Concept 3: The multi-actor, international ecosystem (governments, firms, NGOs, universities) and its influence on science policy and global research agendas."
      ],
      "parent_concepts": [
        "Concept 3: Historical drivers and mechanisms (how public awareness, environmental laws, and events like Silent Spring and major oil spills catalyzed the emergence and focus of environmental science).",
        "Concept 3: Integration of science with governance \u2014 the role of stakeholders, openness, and institutional design in enabling adaptive management."
      ],
      "parent_articles": [
        "Environmental science",
        "Adaptive management"
      ]
    },
    {
      "question": "Why does a governance system typically rely on both formal rules and informal norms to guide decision-making and acceptable conduct?",
      "options": {
        "A": "Formal rules guarantee optimal outcomes for everyone, so informal norms are unnecessary and sometimes counterproductive.",
        "B": "Informal norms replace formal rules entirely, making the formal framework redundant.",
        "C": "Formal rules provide binding constraints and predictable procedures, while informal norms shape legitimacy and voluntary compliance, enabling coordination and adaptation when rules are interpreted or enforcement is insufficient.",
        "D": "Only one element is needed, and choosing between formal rules or informal norms depends solely on the size of the group."
      },
      "correct_answer": "C",
      "source_article": "Governance",
      "x": 1.2119635343551636,
      "y": 0.9210273027420044,
      "concepts_tested": [
        "The governance framework as a system of rules, laws, norms, and power dynamics that guide decision-making and acceptable conduct.",
        "The role and structure of governing bodies (formal and informal) in enforcing rules and overseeing group operations.",
        "Governance as the allocation and mobilization of resources and the setting of a collective direction to address needs and challenges."
      ],
      "parent_concepts": [
        "The policy cycle as a framework linking agenda setting, formulation, legitimation, implementation, and evaluation.",
        "Concept 3: Governance principles and regulatory frameworks (Cadbury/OECD/SOX) that guide governance practices beyond narrow context-specific rules.",
        "Concept 1: Spatial planning mediates between competing demands on land from the state, market, and local community.",
        "Regulation forms as mechanisms to influence behavior (command-and-control, incentive regulation, preferences shaping)",
        "Concept 1: Statecraft as an integrated art (combining science, art, and virtue) and its contested, hard-to-define nature.",
        "Concept 1: Politics as mechanisms of decision-making and resource/status distribution within power relations (negotiation, lawmaking, force) and how these mechanisms produce specific political outcomes.",
        "Concept 3: The relationship between political actors ( parties, governments) and processes (elections, policy changes), and the influence of foundational ideas from political thought on contemporary practice.",
        "Concept 3: The core aims of data governance are to maximize the value of data as a strategic asset while reducing risks from misuse or inaccuracy and ensuring regulatory, ethical, and business compliance.",
        "Concept 1: Policy as guiding decisions to achieve rational outcomes, with different testability for subjective vs. objective decision-making.",
        "Concept 1: Bureaucracy as a rational, hierarchical system that implements laws/regulations through trained non-elected officials using standardized procedures.",
        "Policy goals versus policy tools: the distinction between objectives (inflation, unemployment, growth) and instruments (taxation, spending, money supply, interest rates, tariffs) and the trade-offs involved in achieving those goals.",
        "Concept 3: Integration of science with governance \u2014 the role of stakeholders, openness, and institutional design in enabling adaptive management.",
        "Mechanisms and procedures that constrain power and safeguard citizens\u2019 rights, including minority protections",
        "Concept 3: The necessity of proper accounting practices and records management as preconditions for accountability (without accounting, accountability cannot exist).",
        "Concept 2: The formal\u2013informal spectrum of institutions and the role of enforcement in maintaining coordination and compliance (e.g., how varying levels of formality and third-party enforcement affect stability).",
        "Concept 3: Mutually related rights and obligations and collective enforcement as the basis of social order (e.g., how shared expectations and enforcement mechanisms sustain institutional functioning).",
        "Concept 2: Mechanisms to enable deliberation (random selection of lay citizens, resource/time allocation, deliberative polls, and the interplay of consensus vs. majority rule)",
        "Concept 1: Cultural policy as a framework of government actions, laws, and programs designed to regulate and support arts and culture, aiming to improve accessibility and promote diverse cultural expressions.",
        "Concept 2: Mechanisms of cultural policy include funding, tax/economic instruments, and institutional structures (ministries, endowments, galleries, museums) that implement cultural objectives.",
        "Concept 3: The relationship and distinction between cultural policy and arts policy, with cultural policy being broader and addressing representation and diversity beyond purely aesthetic concerns.",
        "Concept 3: Governance and roles (enterprise architects overseeing solutions architects) and their impact on aligning decisions across the organization with the strategic vision.",
        "Concept 3: Governance and definitional variability across organizations and governments, shaping what counts as an \"open standard\" and how standards are adopted globally.",
        "Concept 1: Localized decision-making with centralized intervention only when local capability is insufficient; the principle that tasks should be handled at the most immediate level capable of resolving them.",
        "Concept 1: Regulation-maps-to-behavior mechanism \u2014 Regulating land use is intended to change human behavior, which in turn is expected to produce social and environmental outcomes (noting that these outcomes may be context-dependent).",
        "Concept 1: The core mechanisms of administrative law (rulemaking, adjudication, enforcement) and how they structure accountability within executive agencies.",
        "Concept 1: Policy implementation as the mechanism by which politics becomes public programs (translation of politics into reality).",
        "Relationships among regime types: the idea that forms like democracies, authoritarian regimes, and hybrids are not strictly exclusive and can coexist or blur into mixed regimes, illustrating conceptual connections between theory and practice.",
        "Accountability mechanism: how citizens judge representatives and sanction them if they do not act in the represented's interests.",
        "Mechanisms of regulation: supervision, enforcement, and disclosure to achieve market confidence, financial stability, and consumer protection (how regulation operates)",
        "Regulatory structure and the role of different actors (government, regulatory authorities, and self-regulatory organizations) and how they interact to govern securities markets and banking supervision (relationships within the regulatory ecosystem)",
        "The policy process as a political system with diverse actors and potential co-production with communities"
      ],
      "parent_articles": [
        "Public policy",
        "Corporate governance",
        "Spatial planning",
        "Regulation",
        "Statecraft",
        "Politics",
        "Politics",
        "Data governance",
        "Policy",
        "Bureaucracy",
        "Economic policy",
        "Adaptive management",
        "Constitutionalism",
        "Accountability",
        "Institution",
        "Institution",
        "Deliberative democracy",
        "Cultural policy",
        "Cultural policy",
        "Cultural policy",
        "Enterprise architecture",
        "Open standard",
        "Subsidiarity",
        "Land-use planning",
        "Administrative law",
        "Public administration",
        "Government",
        "Political representation",
        "Financial regulation",
        "Financial regulation",
        "Public policy"
      ]
    },
    {
      "question": "How do social structures and individual/collective actors interact to produce political institutions, and what mechanism explains both stability and potential change?",
      "options": {
        "A": "Structures completely determine outcomes; agency is irrelevant.",
        "B": "Agency alone shapes outcomes; structures are epiphenomenal.",
        "C": "Institutions emerge from iterative interactions where structures constrain choices and, via strategic action, agents can alter rules, leading to path-dependent stability with possible critical junctures.",
        "D": "Changes in institutions occur only through external shocks; neither structure nor agency matters."
      },
      "correct_answer": "C",
      "source_article": "Political science",
      "x": 1.213088035583496,
      "y": 0.9449244141578674,
      "concepts_tested": [
        "Normative vs. positive political science: differences in aims, methods, and what counts as explanation vs. evaluation.",
        "Structure and agency in political analysis: how social structures and individual/aggregate actors interact to shape political institutions and behavior.",
        "Disciplinary boundaries and interdisciplinarity: how political science emerged from and relates to philosophy, history, economics, sociology, and law, and what this means for methods and questions."
      ],
      "parent_concepts": [
        "The policy cycle as a framework linking agenda setting, formulation, legitimation, implementation, and evaluation.",
        "Concept 1: Statecraft as an integrated art (combining science, art, and virtue) and its contested, hard-to-define nature.",
        "Concept 3: Organizational structure and processes (envoys/ambassadors, diplomatic missions, foreign ministries) enabling negotiation and treaty formation",
        "Concept 3: The relationship between political actors ( parties, governments) and processes (elections, policy changes), and the influence of foundational ideas from political thought on contemporary practice.",
        "Concept 1: Policy implementation as the mechanism by which politics becomes public programs (translation of politics into reality).",
        "Relationships among regime types: the idea that forms like democracies, authoritarian regimes, and hybrids are not strictly exclusive and can coexist or blur into mixed regimes, illustrating conceptual connections between theory and practice.",
        "Concept 3: Classification and interaction of political systems (democracies, totalitarian regimes, authoritarian regimes, hybrids, monarchies) and the idea that forms can be mixed or non-mutually exclusive.",
        "The policy process as a political system with diverse actors and potential co-production with communities"
      ],
      "parent_articles": [
        "Public policy",
        "Statecraft",
        "Diplomacy",
        "Politics",
        "Public administration",
        "Government",
        "Government",
        "Public policy"
      ]
    },
    {
      "question": "In a systems view of education, why might addressing only one determinant (such as providing universal access to educational technology) fail to close achievement gaps between socioeconomic groups?",
      "options": {
        "A": "Because technology alone determines learning, so other factors are irrelevant to outcomes.",
        "B": "Because educational outcomes arise from interdependent factors (motivation, family support, teacher quality, curriculum relevance, resources) that interact and reinforce each other; changing one factor without addressing the rest yields limited impact.",
        "C": "Because students will not use the technology effectively unless teachers are replaced by automated systems.",
        "D": "Because policy changes automatically solve all structural barriers once technology is provided."
      },
      "correct_answer": "B",
      "source_article": "Education",
      "x": 1.2670472860336304,
      "y": 0.9651527404785156,
      "concepts_tested": [
        "Concept 1: Education as a mechanism of socialization and skill development mediated by formal, non-formal, and informal structures, and its effects on individuals and society.",
        "Concept 2: The aims of education and the tension between fostering critical thinking versus indoctrination, and how these aims influence policy, assessment, and practice.",
        "Concept 3: Determinants and disparities in educational success, including psychological factors (motivation, intelligence, personality), social factors (socioeconomic status, ethnicity, gender), and structural factors (access to technology, teacher quality, parental involvement) and how they interact to produce outcomes."
      ],
      "parent_concepts": [
        "Education, power, and equality: how states or societal structures influence education (e.g., coercion to attend school) and issues of discrimination and wealth distribution affecting educational access and outcomes.",
        "The relationship between pedagogy, learning, and learner development within social/political/cultural contexts (how pedagogy influences and is influenced by development).",
        "Curriculum theory as symbolic representation (Pinar) and how viewing curriculum as representation changes analysis and policy implications.",
        "Concept 2: Transition from clerical/religious control to secular, mass, state-supported schooling as a mechanism of modernization.",
        "Concept 3: Education policy as a tool for social transformation and political objectives (military obedience, literacy campaigns, universal compulsory education)."
      ],
      "parent_articles": [
        "Philosophy of education",
        "Pedagogy",
        "Curriculum theory",
        "History of education",
        "History of education"
      ]
    },
    {
      "question": "How do norms of allocation and structural factors jointly shape who gains access to social goods and rights, and why does this mechanism tend to reproduce social inequality over time?",
      "options": {
        "A": "They encode rules that determine eligibility and distribute power through institutions, thereby channeling resources to certain groups and embedding unequal outcomes across generations.",
        "B": "They merely reflect existing inequality but do not causally shape access.",
        "C": "They are only relevant in kinship-oriented societies and disappear in modern economies.",
        "D": "They do not affect access; individual effort and talent alone decide outcomes."
      },
      "correct_answer": "A",
      "source_article": "Social inequality",
      "x": 1.2012434005737305,
      "y": 0.9159548878669739,
      "concepts_tested": [
        "Concept 1: Norms of allocation and structural factors determine who gains access to social goods and rights.",
        "Concept 2: Cultural narratives and social identities (e.g., deserving/undeserving) influence beliefs about inequality and help justify or perpetuate it.",
        "Concept 3: Variations in societal organization (egalitarian, ranked, stratified; kinship-oriented vs. materially oriented) affect the level and progression of inequality."
      ],
      "parent_concepts": [
        "Education, power, and equality: how states or societal structures influence education (e.g., coercion to attend school) and issues of discrimination and wealth distribution affecting educational access and outcomes.",
        "Concept 2: Schooling patterns Reflecting and reinforcing social stratification (class, race, gender) rather than challenging it.",
        "Concept 2: Stratification can be based on multiple factors (wealth, income, race, education, ethnicity, gender, occupation, social status, power) and can also arise from kinship, clan, tribe, or caste, showing diverse bases for forming strata.",
        "Stickiness and structural constraints: how limited resources or opportunities at the ends of the ladder affect individual mobility and long-term outcomes."
      ],
      "parent_articles": [
        "Philosophy of education",
        "Sociology of education",
        "Social stratification",
        "Social mobility"
      ]
    },
    {
      "question": "In universalist political philosophy, what mechanism justifies applying the same basic political rights across all cultures, and why does cultural relativism challenge this mechanism?",
      "options": {
        "A": "It derives core rights from a universalizable rational capacity shared by all humans, which yields cross-cultural justification; cultural relativism challenges this by insisting normative claims must be anchored in local cultural norms, undermining universal validity.",
        "B": "It derives rights from the most powerful culture\u2019s legal code, which ensures efficiency; cultural relativism challenges by advocating minority protections.",
        "C": "It relies on historical variance to show that rights are context-dependent; cultural relativism supports this by claiming no universal norm exists.",
        "D": "It uses empirical observation of cross-cultural practices to posit universal rights; cultural relativism counters by noting variability and interpretation."
      },
      "correct_answer": "A",
      "source_article": "Political philosophy",
      "x": 1.1842470169067383,
      "y": 0.9559603929519653,
      "concepts_tested": [
        "Normative vs empirical study in political inquiry: why political philosophy emphasizes what ought to be (values like justice, equality, liberty) and how this contrasts with empirical political science.",
        "Ideological foundations and justification of political action: how different ideologies (anarchism, liberalism, conservatism, socialism) tie their core values to views on state power, legitimacy, and social order.",
        "Methodological approaches to political knowledge: foundationalist vs particularist methods; universalist vs cultural relativist claims, and how these frameworks shape the construction and critique of political theories."
      ],
      "parent_concepts": [
        "Education, power, and equality: how states or societal structures influence education (e.g., coercion to attend school) and issues of discrimination and wealth distribution affecting educational access and outcomes.",
        "Concept 1: The distinction between natural rights and legal rights, including their bases (human nature vs. law) and implications for universality and context-dependence.",
        "Concept 1: Politics as mechanisms of decision-making and resource/status distribution within power relations (negotiation, lawmaking, force) and how these mechanisms produce specific political outcomes.",
        "The dual nature of ideology, where practical elements are as prominent as theoretical ones, linking beliefs to policy, action, and governance.",
        "Distributive norms as governing allocations (Equality, Equity, Power, Need, Responsibility)",
        "Concept 1: Direct democracy vs. representative democracy, and the institutional mechanisms (constitution and supreme court) that constrain majority power to protect minority rights.",
        "Concept 2: Mechanisms to enable deliberation (random selection of lay citizens, resource/time allocation, deliberative polls, and the interplay of consensus vs. majority rule)"
      ],
      "parent_articles": [
        "Philosophy of education",
        "Rights",
        "Politics",
        "Ideology",
        "Distributive justice",
        "Democracy",
        "Deliberative democracy"
      ]
    },
    {
      "question": "In explaining the persistence of social stratification in a modern, complex society, how do action theory and conflict theories differ, and what mechanism does each theory emphasize as maintaining or challenging stratification?",
      "options": {
        "A": "Action theory claims persistence stems from coercive institutions enforcing rigid roles; the mechanism is external force that keeps people in place, while conflict theory emphasizes voluntary acceptance of roles to maintain order.",
        "B": "Action theory contends persistence arises from internalized norms and expected social roles that guide daily behavior, maintaining social order; the mechanism is socialization and shared meanings. Conflict theory contends persistence arises from unequal control of resources and power, with social institutions reproducing inequality; the mechanism is structural advantage and ongoing class conflict.",
        "C": "Action theory claims persistence is due to genetic differences; mechanism is biology. Conflict theory claims persistence disappears with universal education; mechanism is expanded opportunity.",
        "D": "Action theory says persistence is random; mechanism is luck. Conflict theory says persistence is due to technological change; mechanism is innovation."
      },
      "correct_answer": "B",
      "source_article": "Social stratification",
      "x": 1.2176662683486938,
      "y": 0.94220370054245,
      "concepts_tested": [
        "Concept 1: Stratification as a hierarchical system driven by inequalities of status and access to resources, and its correlation with societal complexity.",
        "Concept 2: Bases of stratification (wealth, income, race, education, ethnicity, gender, occupation, social status, power, kinship/caste) that determine individuals\u2019 positions and privileges within the hierarchy.",
        "Concept 3: Theoretical perspectives on stratification (action theory vs. conflict theories/Marxism) and their explanations for social order, mobility, and resource distribution."
      ],
      "parent_concepts": [
        "Concept 2: Schooling patterns Reflecting and reinforcing social stratification (class, race, gender) rather than challenging it.",
        "Stickiness and structural constraints: how limited resources or opportunities at the ends of the ladder affect individual mobility and long-term outcomes."
      ],
      "parent_articles": [
        "Sociology of education",
        "Social mobility"
      ]
    },
    {
      "question": "How does meritocracy attempt to separate advancement from hereditary privilege, and what common systemic limitation can still undermine true equality of opportunity?",
      "options": {
        "A": "It assigns positions randomly, which eliminates privilege.",
        "B": "It bases advancement on demonstrated ability and performance, but unequal access to resources (education, preparation, mentorship) means not everyone can demonstrate ability equally, undermining equality of opportunity.",
        "C": "It guarantees equal funding to education for all, ensuring everyone can demonstrate ability equally.",
        "D": "It completely eliminates any family influence by law, ensuring equal outcomes."
      },
      "correct_answer": "B",
      "source_article": "Meritocracy",
      "x": 1.2255743741989136,
      "y": 0.9673568606376648,
      "concepts_tested": [
        "Concept 1: Merit as measured by demonstrated ability and performance (examinations, IQ, credentials) and its role as the mechanism for advancement",
        "Concept 2: Relationship to equality of opportunity and anti-nepotism/hereditary privilege (meritocracy as a pathway to fair advancement vs. nepotism/aristocracy)",
        "Concept 3: Historical and conceptual complexities (origins of the term, satirical critique, evolving broader usage, and philosophical connections such as Ethos)"
      ],
      "parent_concepts": [
        "Concept 2: Schooling patterns Reflecting and reinforcing social stratification (class, race, gender) rather than challenging it."
      ],
      "parent_articles": [
        "Sociology of education"
      ]
    },
    {
      "question": "How does an increase in saving influence investment and long-run economic growth, and through what mechanism does this relationship operate?",
      "options": {
        "A": "It directly funds additional consumption, raising current demand and encouraging firms to invest to meet higher sales.",
        "B": "It raises the supply of loanable funds in financial markets, lowering real interest rates and making borrowing cheaper for firms, which stimulates capital investment and, over time, raises the economy's productive capacity and growth.",
        "C": "It reduces total production because saved resources are unavailable for immediate use, causing a contraction and lower investment.",
        "D": "It has no effect on investment because saving and investment occur in different markets."
      },
      "correct_answer": "B",
      "source_article": "Economics",
      "x": 1.224186658859253,
      "y": 0.9389249682426453,
      "concepts_tested": [
        "Concept 1: Micro vs. Macro analysis as different levels of economic interactions (agents/markets vs. systemic production/distribution/consumption and related variables).",
        "Concept 2: Interactions among production, distribution, consumption, savings, and investment, and how factors of production (labor, capital, land, enterprise) and macro factors (inflation, growth, public policy) shape economic outcomes.",
        "Concept 3: The distinction between positive (what is) and normative (what ought to be) economics and the existence of different theoretical frameworks (rational vs. behavioral, mainstream vs. heterodox)."
      ],
      "parent_concepts": [
        "Utility maximization under constraints: rational choice with preferences, budget sets, and local non-satiation forming the basis of consumer theory.",
        "Historical development of environmental economics and its foundational ideas (Condorcet, Smith, Malthus) shaping the analysis of environmental policy effects.",
        "Concept 1: Capital generates a flow of productive services over multiple production cycles due to its durability.",
        "Information asymmetry and contract design: how incomplete information between parties leads to market failures and how mechanism design can elicit information-sharing and welfare-enhancing outcomes.",
        "Concept 1: The rules of exchange and allocation procedures are central to market design, and designing them is meant to fix or create markets with desirable properties.",
        "Concept 2: The forms of socialism (non-market vs market socialism) and their distinct mechanisms for organizing the economy (planning and price signals vs continued use of monetary prices and markets) and the implications for efficiency and profit.",
        "The fiscal policy mechanism: how government spending and taxation (fiscal stance) influence aggregate demand and macroeconomic stabilization, including deficits/surpluses as indicators.",
        "Concept 2: Economic value and modeling of attention; treating attention as a scarce commodity and applying economic theory to information management and \"free\" goods.",
        "Concept 1: Comparative advantage and international specialization lead to more efficient resource allocation and higher productivity in global production.",
        "Present value, expectation, and decision making under uncertainty (time value of money and expected utility)",
        "Concept 1: Economic efficiency as a criterion for evaluating legal rules and predicting which rules will be promulgated",
        "Concept 1: Labor supply as a rational choice balancing wage, leisure, and other constraints, including substitution and income effects.",
        "Concept 1: Rational labor supply decision \u2014 workers choose how much to work based on wage, leisure, and utility to maximize lifetime utility.",
        "Concept 1: Comparative advantage as the mechanism by which free trade can raise economic welfare through efficient resource allocation.",
        "Concept 3: The normative nature of ecological economics and critiques of standard methods (e.g., cost-benefit analysis) with alternative approaches (e.g., positional analysis) and connections to justice and care.",
        "Money\u2019s functions and their policy implications (medium of exchange, store of value, unit of account; why these roles matter for macro outcomes)",
        "Concept 3: How government intervention, regulation, and antitrust policy shape industry structure, welfare, and the governance of economic activity.",
        "Interdisciplinary integration of psychology/neuroscience with microeconomic theory to build behavioral models"
      ],
      "parent_articles": [
        "Microeconomics",
        "Environmental economics",
        "Capital (economics)",
        "Information economics",
        "Market design",
        "Socialism",
        "Economic policy",
        "Attention economy",
        "International business",
        "Financial economics",
        "Law and economics",
        "Labour economics",
        "Labour economics",
        "Free trade",
        "Ecological economics",
        "Monetary economics",
        "Industrial organization",
        "Behavioral economics"
      ]
    },
    {
      "question": "In a system with stochastic arrivals and dynamic interactions (e.g., an emergency department), suppose you need to compare several staffing policies under realistic variability. Why would you choose a simulation-based evaluation over a purely deterministic optimization model as the core analysis method?",
      "options": {
        "A": "Because deterministic optimization models can be limited to fixed inputs and simplified dynamics, whereas simulation captures stochastic variability and system interactions, enabling realistic policy comparison across many scenarios.",
        "B": "Because simulation guarantees finding the globally optimal staffing policy without requiring data.",
        "C": "Because optimization always requires less computation than simulation.",
        "D": "Because simulation eliminates uncertainty by averaging away random fluctuations."
      },
      "correct_answer": "A",
      "source_article": "Operations research",
      "x": 1.6620818376541138,
      "y": 0.7664583921432495,
      "concepts_tested": [
        "Concept 1: Mathematical modeling as the foundation of OR\u2014constructing models to describe the system in order to analyze and improve decisions.",
        "Concept 2: Optimization objective\u2014OR aims to maximize or minimize real-world objectives (profit, cost, risk, etc.) to achieve best outcomes.",
        "Concept 3: Method selection workflow\u2014choosing and applying techniques (simulation, optimization, stochastic models, etc.) based on system nature, goals, and computational constraints."
      ],
      "parent_concepts": [
        "Concept 3: Constraints and feasible region shaping choice \u2014 financial, legal, social, physical, or emotional restrictions define the set of possible actions and influence the chosen option.",
        "Concept 1: Transformation and efficiency \u2014 Operations converts inputs (materials, labor, energy) into outputs (goods/services) with the goal of efficient resource use to meet customer requirements.",
        "Ends-to-means alignment over a defined time horizon: how goals are achieved using resources and why timing matters.",
        "Concept 1: Modeling and quantitative analysis as central mechanisms for solving managerial problems and achieving (near) optimal decisions.",
        "Cost-quality trade-offs in survey design and the goal of improving quality within cost constraints",
        "Concept 1: Optimization as selecting the best element with respect to an objective function over a feasible set (objective + feasible region).",
        "Concept 2: BPM lifecycle and mechanisms \u2014 modeling, automation/execution, control, measurement, and optimization as an interconnected set of activities.",
        "Resource leveling as a mechanism to smooth demand and supply, including data inputs (demands, resource configurations, supply forecasts) and trade-offs (service level vs. cost)."
      ],
      "parent_articles": [
        "Rational choice model",
        "Operations management",
        "Strategic planning",
        "Management science",
        "Survey methodology",
        "Mathematical optimization",
        "Business process management",
        "Resource management"
      ]
    },
    {
      "question": "Why does natural selection change allele frequencies in a population over generations, assuming some heritable variation affects fitness?",
      "options": {
        "A": "Because changes in allele frequencies occur only when mutations occur and introduce new alleles, which then spread by selection.",
        "B": "Because individuals carrying advantageous alleles tend to leave more offspring, and those alleles are heritable, so their frequencies rise in the gene pool.",
        "C": "Because the environment directly edits the DNA sequences of individuals with advantageous alleles, increasing their frequency.",
        "D": "Because allele frequencies drift by random sampling of gametes in small populations, regardless of fitness differences."
      },
      "correct_answer": "B",
      "source_article": "Evolutionary biology",
      "x": 1.8226794004440308,
      "y": 1.1126964092254639,
      "concepts_tested": [
        "Concept 1: Evolutionary mechanisms (natural selection, mutation, genetic drift, gene flow) and how they alter allele frequencies and population genetics.",
        "Concept 2: The Modern Synthesis as an interdisciplinary framework that integrates genetics, ecology, systematics, and paleontology to explain evolutionary change.",
        "Concept 3: Evolutionary developmental biology (evo-devo) and how developmental processes link genetics to evolution, expanding the scope of explanatory mechanisms."
      ],
      "parent_concepts": [
        "Concept 1: Genetic load as a measure of reduced mean fitness relative to a reference high-fitness genotype, linking individual genotype fitness to population-level outcomes.",
        "Concept 3: The modeling assumption (ignoring frequency-dependent selection) and its implications for applying the genetic load concept and understanding its limitations.",
        "Concept 1: Phylogenetic inference uses observable, heritable data to reconstruct evolutionary relationships and yields a phylogenetic tree as a diagram of inferred history.",
        "Concept 2: The interaction of inheritance, variation, and struggle for existence under environmental pressures governs microevolution, macroevolution, and potentially speciation.",
        "Concept 1",
        "Concept 1: Rooted vs unrooted trees and the root as the most recent common ancestor; edge lengths can reflect time estimates.",
        "Concept 2: Evolutionary rates vary across genes, sites, and lineages, influenced by purifying and directional selection; frameworks like the neutral theory and the molecular clock help interpret divergence times and rate consistency."
      ],
      "parent_articles": [
        "Genetic load",
        "Genetic load",
        "Phylogenetics",
        "Natural selection",
        "Cooperation",
        "Phylogenetic tree",
        "Molecular evolution"
      ]
    },
    {
      "question": "Why does a strictly falsification-based account of the scientific method fail to explain how scientists actually respond to anomalous data and decide whether to revise or replace a theory?",
      "options": {
        "A": "It assumes data are theory-neutral and predictions can be tested independent of background assumptions.",
        "B": "It posits that a single failed prediction always falsifies a theory, which contradicts how scientists treat anomalies.",
        "C": "It shows that testing a theory depends on a network of auxiliary hypotheses and background assumptions; when anomalies occur, scientists often adjust these auxiliaries rather than abandon the core theory, so falsification alone cannot decide theory change.",
        "D": "It claims that progress comes only from simpler, more elegant theories, which conflicts with historical cases of complex, multi-parameter revisions."
      },
      "correct_answer": "C",
      "source_article": "Philosophy of science",
      "x": 1.1695892810821533,
      "y": 1.074671983718872,
      "concepts_tested": [
        "Concept 1: Demarcation and justification of scientific knowledge (distinguishing science from non-science; reliability/validity of theories; role of induction)",
        "Concept 2: The nature of scientific progress and theory change (paradigms, scientific revolutions, and how progress can be relative to historical frameworks)",
        "Concept 3: Competing justification frameworks and critique of a universal \"scientific method\" (logical positivism, falsification, coherence, and Feyerabend\u2019s methodological pluralism)"
      ],
      "parent_concepts": [
        "Concept 1: Method choice shapes evidence and conclusions (the relationship between methods and what can be claimed as knowledge).",
        "Concept 2: Distinctions between quantitative and qualitative research (their goals, methods, and appropriate contexts) and the value of integrating them through mixed-methods.",
        "Concept 1: Interdisciplinary relationships \u2014 physics intersects with fields like biophysics and quantum chemistry, and new physics ideas explain mechanisms in other sciences.",
        "Theory construction criteria: conditions like consistency, generality, parsimony, and conditionality that govern robust, testable social theories.",
        "Concept 1: Epistemological divide shaping research method (positivist vs interpretivist)",
        "Concept 2: The scientific method relies on empirical evidence and experiments, with hypotheses tested against observations rather than resting on a priori reasoning.",
        "Power-knowledge relationship and objectivity: knowledge and truth are shaped by power dynamics and social context, challenging the notion of pure objectivity.",
        "Concept 1: The relationship between method and knowledge claims \u2014 how the choice of method influences what counts as evidence and can lead to different conclusions from the same data.",
        "Systematic, bias-controlled inquiry as a core principle guiding how research is conducted",
        "Epistemology-driven variation in research approaches across disciplines (how different knowledge claims lead to different methods)",
        "Epistemology/ontology shaping design: researchers' beliefs about knowledge and reality influence the choice of design, methods, and measures.",
        "The historical development of science: transition from natural philosophy to natural science during the Scientific Revolution and its impact on how knowledge is acquired and validated.",
        "Concept 3: Scientific knowledge in anatomy advances via empirical observation and cross-species comparison, challenging authorities when discrepancies arise.",
        "Concept 2: Falsifiability and the provisional nature of scientific claims (impossibility assertions are highly probable but not proven; counterexamples can refute theories)",
        "Concept 3: The theory\u2013measurement\u2013law relationship (use of mathematics/logic to translate observations into measurable statements and predictive laws)",
        "Three conceptual orientations of industrial relations (science-building, problem solving, ethical) that guide research and practice.",
        "The criteria for a physical theory: agreement with empirical observations and the ability to make new, testable predictions.",
        "Different theoretical approaches in physics (phenomenologists, model-builders, effective theories) and their goals (fitting data, unification, abstraction) in creating and evaluating models.",
        "Concept 3: The relationship of social science to broader science and its historical evolution (from moral philosophy to empirical science; division between stricter and broader senses of science).",
        "Concept 2: The relationship and distinctions among branches of science (natural, social, formal, applied) and their underlying methodologies.",
        "Concept 3: The historical evolution of science (from natural philosophy to natural science) driven by methodological shifts and institutional development.",
        "Concept 2: Hierarchy of evidence (EBM pyramid) and how it shapes trust in different types of evidence."
      ],
      "parent_articles": [
        "Methodology",
        "Methodology",
        "Physics",
        "Social theory",
        "Social science",
        "Empiricism",
        "Critical theory",
        "Methodology",
        "Research",
        "Research",
        "Research design",
        "Science",
        "Comparative anatomy",
        "Natural science",
        "Natural science",
        "Industrial relations",
        "Theoretical physics",
        "Theoretical physics",
        "Social science",
        "Science",
        "Science",
        "Evidence-based medicine"
      ]
    },
    {
      "question": "Why is falsifiability essential for a hypothesis to be scientifically meaningful?",
      "options": {
        "A": "It guarantees that the hypothesis will produce a single inevitable result in every experiment.",
        "B": "It ensures the hypothesis yields predictions that could be contradicted by an observation, allowing it to be tested and possibly refuted.",
        "C": "It ensures that accumulating data will eventually prove the hypothesis true.",
        "D": "It constrains scientists to align the hypothesis with preexisting beliefs to maintain coherence."
      },
      "correct_answer": "B",
      "source_article": "Scientific method",
      "x": 1.3147547245025635,
      "y": 1.0706732273101807,
      "concepts_tested": [
        "Falsifiability and hypothesis-based testing: hypotheses must be testable with predictions; results can support, refine, or discard the hypothesis.",
        "Iterative, principle-based nature of scientific inquiry: the method is not a fixed step-by-step process; different fields vary, and steps may be omitted or reordered.",
        "Role of empirical observation and skepticism: careful observation and skepticism help prevent cognitive biases from distorting interpretation of data."
      ],
      "parent_concepts": [
        "Concept 1: Method choice shapes evidence and conclusions (the relationship between methods and what can be claimed as knowledge).",
        "Concept 2: Distinctions between quantitative and qualitative research (their goals, methods, and appropriate contexts) and the value of integrating them through mixed-methods.",
        "Theory construction criteria: conditions like consistency, generality, parsimony, and conditionality that govern robust, testable social theories.",
        "Concept 1: Epistemological divide shaping research method (positivist vs interpretivist)",
        "Concept 2: A core workflow in mathematical statistics involves selecting a model, checking its conditions/assumptions, and quantifying uncertainty (e.g., through confidence intervals).",
        "Systematic, bias-controlled inquiry as a core principle guiding how research is conducted",
        "Concept 3: Scientific knowledge in anatomy advances via empirical observation and cross-species comparison, challenging authorities when discrepancies arise.",
        "Concept 2: Falsifiability and the provisional nature of scientific claims (impossibility assertions are highly probable but not proven; counterexamples can refute theories)",
        "Concept 3: The theory\u2013measurement\u2013law relationship (use of mathematics/logic to translate observations into measurable statements and predictive laws)",
        "The criteria for a physical theory: agreement with empirical observations and the ability to make new, testable predictions.",
        "Different theoretical approaches in physics (phenomenologists, model-builders, effective theories) and their goals (fitting data, unification, abstraction) in creating and evaluating models.",
        "Concept 1: The research continuum from basic/bench science to preclinical to clinical/translational research, and how each stage connects to practical applications."
      ],
      "parent_articles": [
        "Methodology",
        "Methodology",
        "Social theory",
        "Social science",
        "Mathematical statistics",
        "Research",
        "Comparative anatomy",
        "Natural science",
        "Natural science",
        "Theoretical physics",
        "Theoretical physics",
        "Medical research"
      ]
    },
    {
      "question": "Why does defining sustainability science by the problems it addresses, rather than by the disciplines it employs, shape how research is designed and carried out?",
      "options": {
        "A": "It preserves disciplinary silos, reducing the need to integrate different kinds of knowledge.",
        "B": "It prompts researchers to frame concrete, real-world problems, assemble cross-disciplinary methods, involve stakeholders, and test solutions in governance and practice, thereby linking knowledge generation with actionable outcomes.",
        "C": "It biases research toward rapid, publishable results within a single discipline, at the expense of long-term impact.",
        "D": "It eliminates the need for empirical data because the focus is on normative goals rather than measurement."
      },
      "correct_answer": "B",
      "source_article": "Sustainability science",
      "x": 1.3597873449325562,
      "y": 0.8972792029380798,
      "concepts_tested": [
        "Concept 1: The field is defined by the problems it addresses rather than by its disciplines, and this shapes its research approach.",
        "Concept 2: A knowledge-action bridge that advances both understanding and practical action, linking theory with governance and practice.",
        "Concept 3: Interdisciplinary and global-local integration, drawing on natural and social sciences, engineering, and medicine, with perspectives from both north and south."
      ],
      "parent_concepts": [
        "The relationship between sustainability and sustainable development (sustainability as a long-term goal vs. sustainable development as the set of processes/pathways to achieve it)"
      ],
      "parent_articles": [
        "Sustainable development"
      ]
    },
    {
      "question": "In decision-making under uncertainty, why is second-order uncertainty often represented as a probability density over first-order outcome probabilities, and how does that representation affect how we compute expected losses for a chosen action?",
      "options": {
        "A": "It encodes uncertainty about what the true probability p is, allowing us to compute the marginal expected loss by integrating the conditional loss E[Loss|p] across p with weight f(p).",
        "B": "It assumes the true probability p is fixed; you should pick a single p and compute E[Loss|p], ignoring the density since second-order uncertainty is irrelevant to expectations.",
        "C": "It treats second-order uncertainty purely as sampling noise in outcomes, so the density over p is unnecessary; you should only use the observed frequencies.",
        "D": "It implies that all probabilities p in [0,1] are equally likely, which is the only consistent prior for a non-informative approach."
      },
      "correct_answer": "A",
      "source_article": "Uncertainty",
      "x": 1.5582027435302734,
      "y": 1.110785722732544,
      "concepts_tested": [
        "Concept 1: The distinction and relationship between uncertainty, risk, and variability (and how they are used differently in forecasting and decision-making).",
        "Concept 2: How uncertainty is measured using probability distributions and density functions, including the idea of first-order vs. second-order uncertainty (confidence over outcome probabilities).",
        "Concept 3: The role of risk as outcomes with potential losses and how it can be conceptually separate from pure uncertainty (balance between expected values, loss functions, and variability)."
      ],
      "parent_concepts": [
        "Concept 2: Components of risk (risk sources, potential events, their consequences, and their likelihood) that together define risk.",
        "Concept 1: Risk as the effect of uncertainty on objectives (how uncertainty can alter outcomes relative to goals)"
      ],
      "parent_articles": [
        "Risk",
        "Risk"
      ]
    },
    {
      "question": "In a cybernetic system, outputs feed back as inputs to influence future actions. How does negative feedback help maintain stable behavior within such a system?",
      "options": {
        "A": "By ignoring the feedback and keeping the input fixed, so outputs never change.",
        "B": "By comparing the current output to a reference and adjusting the input to reduce the error, dampening deviations.",
        "C": "By always amplifying the input whenever the output changes, causing rapid and uncontrolled shifts.",
        "D": "By removing all connections between outputs and inputs to prevent any feedback effects."
      },
      "correct_answer": "B",
      "source_article": "Cybernetics",
      "x": 1.2837657928466797,
      "y": 1.040154218673706,
      "concepts_tested": [
        "Circular causality and feedback loops as a mechanism by which a system\u2019s outputs influence future inputs to maintain or adjust behavior.",
        "Recursion and self-organization as processes that generate complex, adaptive behavior from simpler rules and information processing.",
        "The role of information, control, and communication as fundamental cross-domain functions linking systems in biology, machines, and society."
      ],
      "parent_concepts": [
        "Concept 1: Security is a relationship that depends on the referent\u2019s environment and the referent\u2019s own capabilities, i.e., security emerges from interactions between a target, its surroundings, and its response options.",
        "Interdependence, boundaries, and context: Why changing one component can affect the whole system and how boundaries and environmental context shape system behavior.",
        "Concept 1: The three-component feedback control system (receptor, control center, effector) and their interactions in maintaining a variable within a maintenance range.",
        "Concept 2: Negative feedback as the mechanism that reverses changes and stabilizes the system once the variable returns to the set point.",
        "Concept 2: Stability and performance criteria\u2014how delays, overshoot, steady-state error, and stability criteria influence controller design and system behavior.",
        "Concept 3: Modeling and design tools\u2014how block diagrams and transfer functions model input-output relationships, and how controllability/observability relate to the ability to control and estimate system states.",
        "Concept 1: Feedback forms a loop that creates circular causality, requiring system-wide analysis rather than linear cause-and-effect reasoning.",
        "Concept 2: Feedback acts as a regulatory mechanism by routing outputs back to inputs to control a process (e.g., water level via a float valve; speed via governors).",
        "Concept 3: Feedback can modify system gain and behavior (e.g., boosting amplification through regeneration) but may also cause instability or undesirable effects (e.g., howl) if not managed.",
        "Self-organization and adaptation: order and patterns arise without central control through local rules and feedback, enabling systems to adapt to their environment.",
        "Concept 1: Iterative learning loop \u2014 monitoring informs learning, which updates models and then shapes future decisions.",
        "Iterative query refinement: the feedback loop where user results influence subsequent querying to improve results.",
        "Concept 2: Existence of both linear (designed) and non-linear (emergent, complex) relationships in sociotechnical interactions.",
        "Concept 1: Closed-loop feedback control mechanism (measurement, comparison to setpoints, corrective action) to maintain process within target parameters.",
        "Concept 2: System architecture and data flow (sensors -> controllers like PLC/DCS -> actuators) and the role of the HMI.",
        "Encoding predetermined decision criteria into machines (control logic) to automate processes and reduce human intervention",
        "Systems integration of multiple technologies (mechanical, hydraulic, electrical, electronic, computer) to enable complex automation and affect performance metrics (labor savings, waste reduction, quality, costs)"
      ],
      "parent_articles": [
        "Security",
        "Systems theory",
        "Homeostasis",
        "Homeostasis",
        "Control theory",
        "Control theory",
        "Feedback",
        "Feedback",
        "Feedback",
        "Complex system",
        "Adaptive management",
        "Information retrieval",
        "Sociotechnical system",
        "Industrial process control",
        "Industrial process control",
        "Automation",
        "Automation"
      ]
    },
    {
      "question": "Mantle convection drives plate tectonics. Why does the surface respond with discrete plates and plate boundaries rather than as a single globally connected shell?",
      "options": {
        "A": "Because the mantle has uniform viscosity, so the entire mantle drags the lithosphere at the same rate, producing a uniform surface motion.",
        "B": "Because the lithosphere is a mechanically strong, nearly rigid shell over a weaker asthenosphere, so convection-induced stresses are transmitted mainly at boundaries, allowing differential motion between plates and the development of plate boundaries through processes like slab pull and ridge push.",
        "C": "Because erosion and sediment transport at the surface impart directional stresses that organize motion into plates.",
        "D": "Because mantle convection cannot generate horizontal shear at the lithosphere, so plates move only vertically."
      },
      "correct_answer": "B",
      "source_article": "Geodynamics",
      "x": 1.755396842956543,
      "y": 0.9678512215614319,
      "concepts_tested": [
        "Mantle convection as the driver of plate tectonics and related geologic phenomena",
        "Rock deformation modes (elastic, plastic, brittle) and how stress magnitude and relaxation times dictate deformation behavior",
        "Internal stress\u2013gravity\u2013density relationships and hydrostatic equilibrium, including the role of the equation of state to model density with depth"
      ],
      "parent_concepts": [
        "Mantle convection as the driver of plate tectonics, powered in part by radioactive decay heating the mantle."
      ],
      "parent_articles": [
        "Earth science"
      ]
    },
    {
      "question": "How do relative dating and absolute dating complement each other in constructing geological timelines, and what unique information does each method provide that the other cannot alone?",
      "options": {
        "A": "Relative dating provides exact numerical ages using fossil assemblages; absolute dating only establishes the sequence of events.",
        "B": "Absolute dating yields the actual ages for rocks, while relative dating is used to determine where those ages belong in the rock sequence.",
        "C": "Relative dating establishes the sequential order of events without numeric ages, while absolute dating provides numerical ages for specific rocks/events; together they give both order and time scale.",
        "D": "Both methods rely on radiometric decay and fossil content to give the same information, so they are redundant."
      },
      "correct_answer": "C",
      "source_article": "Geology",
      "x": 1.7272919416427612,
      "y": 0.9437747001647949,
      "concepts_tested": [
        "Concept 1: Geology as an integrative, evidence-based reconstruction of Earth's history using multiple methods (fieldwork, rock description, geophysics, chemistry, paleontology, etc.).",
        "Concept 2: Relative vs. absolute dating as complementary tools for building geological timelines (how each method contributes to dating rocks and events).",
        "Concept 3: Plate tectonics as a central unifying framework in geology, supported by rock records, fossils, and climate history, explaining the distribution and evolution of Earth\u2019s systems."
      ],
      "parent_concepts": [
        "Earthquakes as a consequence of lithospheric plate movement and interactions, particularly near convergent boundaries involving subduction.",
        "The sedimentary cycle: how weathering/erosion, transport, deposition, and diagenesis interact to form sedimentary rocks.",
        "Uniformitarianism and analog reasoning: using modern processes and structures to reconstruct past environments from the rock record."
      ],
      "parent_articles": [
        "Earth science",
        "Sedimentology",
        "Sedimentology"
      ]
    },
    {
      "question": "Why does ex-ante regulation sometimes yield better welfare outcomes than relying on ex-post liability when information about risk is incomplete and enforcement resources are scarce?",
      "options": {
        "A": "Ex-ante regulation constrains actions before harm is possible, lowering expected harm and reducing reliance on difficult post-harm detection and prosecution; ex-post liability depends on uncovering fault and harm, which is costly and uncertain when information is incomplete.",
        "B": "Ex-ante regulation achieves optimal outcomes by punishing wrongdoers after harm occurs, creating stronger incentives than pre-emptive rules.",
        "C": "Ex-ante regulation relies on private negotiations to align incentives; ex-post liability is redundant once contracts exist.",
        "D": "Ex-ante regulation and ex-post liability are effectively equivalent when risk is uncertain and enforcement is costly."
      },
      "correct_answer": "A",
      "source_article": "Regulation",
      "x": 1.2950986623764038,
      "y": 0.907724142074585,
      "concepts_tested": [
        "Concept 1: Ex-ante regulation vs ex-post liability \u2014 how information availability and expectations influence whether preventative rules or liability-based approaches produce better outcomes.",
        "Concept 2: Regulation mechanisms and their effects \u2014 how command-and-control, incentive-based, and norms/shaping preferences regulate behavior and achieve policy aims.",
        "Concept 3: Enforcement and monitoring as critical to effectiveness \u2014 why having the power to enforce and ongoing monitoring determines whether regulatory aims are realized, including the role of self-regulation vs government regulation."
      ],
      "parent_concepts": [
        "Concept 3: Governance principles and regulatory frameworks (Cadbury/OECD/SOX) that guide governance practices beyond narrow context-specific rules.",
        "Concept 3: Governance and regulatory mechanisms (ESG reporting, standards, incentives) that move CSR from voluntary actions to mandatory or incentivized practices, shaping corporate behavior and outcomes.",
        "Concept 1: Regulation-maps-to-behavior mechanism \u2014 Regulating land use is intended to change human behavior, which in turn is expected to produce social and environmental outcomes (noting that these outcomes may be context-dependent).",
        "Mechanisms of regulation: supervision, enforcement, and disclosure to achieve market confidence, financial stability, and consumer protection (how regulation operates)",
        "Regulatory structure and the role of different actors (government, regulatory authorities, and self-regulatory organizations) and how they interact to govern securities markets and banking supervision (relationships within the regulatory ecosystem)",
        "Precautionary principle: why it is used when there is scientific uncertainty and how it shapes regulatory action to prevent harm."
      ],
      "parent_articles": [
        "Corporate governance",
        "Corporate social responsibility",
        "Land-use planning",
        "Financial regulation",
        "Financial regulation",
        "Environmental law"
      ]
    },
    {
      "question": "In the policy cycle, how does feedback from the evaluation stage function as a mechanism to improve future policy design, and why is this feedback essential for iterative learning?",
      "options": {
        "A": "It ensures the same policy is repeated without changes to preserve political legitimacy.",
        "B": "It provides evidence about whether outcomes match aims, revealing where problem definitions, instrument choices, or resource allocations should be revised in the next cycle.",
        "C": "It shifts all responsibility for outcomes to external actors, thereby avoiding reforms.",
        "D": "It locks in the original problem framing so that future cycles do not reconsider objectives."
      },
      "correct_answer": "B",
      "source_article": "Public policy",
      "x": 1.2397558689117432,
      "y": 0.9195009469985962,
      "concepts_tested": [
        "The policy cycle as a framework (agenda setting, formulation, legitimation, implementation, evaluation) and the role of feedback in shaping future policy.",
        "The network of actors and co-production (politicians, civil servants, interest groups, experts, citizens) and how power dynamics and collaboration influence policy design and outcomes.",
        "The link between policy aims and instruments (how regulations, subsidies, taxes, and spending plans are selected and mapped to objectives like economic growth, inequality reduction, or environmental protection)."
      ],
      "parent_concepts": [
        "Concept 3: Governance principles and regulatory frameworks (Cadbury/OECD/SOX) that guide governance practices beyond narrow context-specific rules.",
        "Concept 3: Policy and economic policy shape health equity by distributing resources and opportunities, producing health disparities.",
        "Concept 3: Governance and regulatory mechanisms (ESG reporting, standards, incentives) that move CSR from voluntary actions to mandatory or incentivized practices, shaping corporate behavior and outcomes.",
        "Regulation forms as mechanisms to influence behavior (command-and-control, incentive regulation, preferences shaping)",
        "Integration of environmental, social, and economic dimensions in policy: environment, quality of life, health, resource management, and biodiversity as interconnected policy considerations.",
        "Concept 2: Digital privacy as an extension of the privacy right and the role of law and policy in protecting it amid technological change",
        "How the objectives of defense/security, economic benefit, and humanitarian aid are interconnected and influence policy decisions.",
        "How domestic considerations, the behavior of other states, and geopolitical strategies shape the formulation of foreign policy (cause-and-effect relationships).",
        "How diplomacy and the diplomatic corps, along with think tanks, function as mechanisms in developing, informing, and implementing long-term foreign policy.",
        "The fiscal policy mechanism: how government spending and taxation (fiscal stance) influence aggregate demand and macroeconomic stabilization, including deficits/surpluses as indicators.",
        "Policy goals versus policy tools: the distinction between objectives (inflation, unemployment, growth) and instruments (taxation, spending, money supply, interest rates, tariffs) and the trade-offs involved in achieving those goals.",
        "Concept 2: Mechanisms/tools of intervention (public provision, taxation, subsidies) and how they alter resource allocation and income distribution.",
        "Concept 3: Integration of science with governance \u2014 the role of stakeholders, openness, and institutional design in enabling adaptive management.",
        "Concept 1: Resource allocation aligned with the public interest to maximize societal benefits, and its impact on science outcomes.",
        "Concept 1: Cultural policy as a framework of government actions, laws, and programs designed to regulate and support arts and culture, aiming to improve accessibility and promote diverse cultural expressions.",
        "Concept 2: Mechanisms of cultural policy include funding, tax/economic instruments, and institutional structures (ministries, endowments, galleries, museums) that implement cultural objectives.",
        "Concept 3: The relationship and distinction between cultural policy and arts policy, with cultural policy being broader and addressing representation and diversity beyond purely aesthetic concerns.",
        "Concept 3: Governance and definitional variability across organizations and governments, shaping what counts as an \"open standard\" and how standards are adopted globally.",
        "Concept 3: Education policy as a tool for social transformation and political objectives (military obedience, literacy campaigns, universal compulsory education).",
        "Concept 1: Regulation-maps-to-behavior mechanism \u2014 Regulating land use is intended to change human behavior, which in turn is expected to produce social and environmental outcomes (noting that these outcomes may be context-dependent).",
        "Concept 1: Policy implementation as the mechanism by which politics becomes public programs (translation of politics into reality).",
        "Concept 3: Stabilization under policy constraints, including potential limitations like liquidity traps and political/institutional factors that influence the effectiveness and timing of policy actions.",
        "Concept 2: Policy frameworks and goals \u2014 how choosing inflation targeting, fixed exchange rate, or money-supply targeting shapes policy decisions, credibility, and outcomes.",
        "Concept 3: How government intervention, regulation, and antitrust policy shape industry structure, welfare, and the governance of economic activity.",
        "Mechanisms of regulation: supervision, enforcement, and disclosure to achieve market confidence, financial stability, and consumer protection (how regulation operates)",
        "Regulatory structure and the role of different actors (government, regulatory authorities, and self-regulatory organizations) and how they interact to govern securities markets and banking supervision (relationships within the regulatory ecosystem)",
        "Precautionary principle: why it is used when there is scientific uncertainty and how it shapes regulatory action to prevent harm.",
        "Concept 3: Mechanism by which social policy affects well-being through shaping the distribution of and access to goods and resources (and its engagement with wicked problems)",
        "Concept 1: Fossil-fuel dependence shapes political resistance and policy outcomes",
        "Concept 1: Learning by doing as a mechanism for infant-industry protection\u2014temporary protection or barriers enable firms to develop capabilities until they can compete internationally.",
        "Concept 3: The relationship and tensions between industrial policy and trade/liberalization, including debates about how intervention interacts with free trade and international cooperation."
      ],
      "parent_articles": [
        "Corporate governance",
        "Social determinants of health",
        "Corporate social responsibility",
        "Regulation",
        "Environmental policy",
        "Privacy",
        "Foreign policy",
        "Foreign policy",
        "Foreign policy",
        "Economic policy",
        "Economic policy",
        "Public finance",
        "Adaptive management",
        "Science policy",
        "Cultural policy",
        "Cultural policy",
        "Cultural policy",
        "Open standard",
        "History of education",
        "Land-use planning",
        "Public administration",
        "Fiscal policy",
        "Monetary policy",
        "Industrial organization",
        "Financial regulation",
        "Financial regulation",
        "Environmental law",
        "Social policy",
        "Politics of climate change",
        "Industrial policy",
        "Industrial policy"
      ]
    },
    {
      "question": "In the history of economic thought, why are private property rights and price formation described as organizing forces that allocate resources efficiently, as opposed to public ownership or price controls?",
      "options": {
        "A": "Private property creates incentives to invest and maintain resources, while price signals reflect scarcity and coordinate countless individual decisions toward higher-valued uses, enabling decentralized allocation without a central planner.",
        "B": "Private property ensures equal distribution of income, removing competition and stabilizing production.",
        "C": "Prices undermine information, and private property prevents learning about preferences, leading to misallocation.",
        "D": "Public ownership solves all coordination problems, so price signals are unnecessary."
      },
      "correct_answer": "A",
      "source_article": "History of economic thought",
      "x": 0.8175336718559265,
      "y": 0.8897200226783752,
      "concepts_tested": [
        "Concept 1: Property rights and price formation as organizing forces (private vs. public ownership; the idea of a just price) and their effects on economic activity.",
        "Concept 2: State intervention versus laissez-faire as policy mechanisms and their moral/economic justification.",
        "Concept 3: Division of labor and specialization as a mechanism for production and economic growth (early conceptual discussions of how labor division affects wealth)."
      ],
      "parent_concepts": [
        "Historical development of environmental economics and its foundational ideas (Condorcet, Smith, Malthus) shaping the analysis of environmental policy effects."
      ],
      "parent_articles": [
        "Environmental economics"
      ]
    },
    {
      "question": "In a complex system where many parts interact nonlinearly, why can a small, localized perturbation sometimes lead to a large, system-wide change (an emergent outcome) that was not predictable from the components alone?",
      "options": {
        "A": "Because nonlinear interactions make responses proportional to input, so small perturbations stay small.",
        "B": "Because nonlinear interactions can create amplification via feedback loops and threshold effects, causing the perturbation to propagate and reorganize global patterns.",
        "C": "Because emergent properties are simply the sum of independent component behaviors, so local changes always scale linearly.",
        "D": "Because the system's global state is solely determined by external constraints, so local perturbations cannot alter it."
      },
      "correct_answer": "B",
      "source_article": "Complex system",
      "x": 1.5652427673339844,
      "y": 1.104420781135559,
      "concepts_tested": [
        "Emergence and nonlinear interactions leading to system-wide properties",
        "Feedback loops, self-organization, and adaptation as mechanisms driving dynamics",
        "Network modeling and the holistic, interdisciplinary paradigm that challenges reductionism"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "How does interdisciplinary education foster cognitive flexibility and improve problem-solving in real-world contexts?",
      "options": {
        "A": "By emphasizing memorization of core definitions from each discipline to build a broad knowledge base.",
        "B": "By rigidly separating disciplinary approaches to avoid method confusion.",
        "C": "By exposing learners to multiple explanatory frameworks and methods, enabling them to reframe problems and transfer strategies across contexts.",
        "D": "By focusing exclusively on one discipline to deepen expertise before integrating others."
      },
      "correct_answer": "C",
      "source_article": "Interdisciplinarity",
      "x": 1.2667707204818726,
      "y": 0.9823008179664612,
      "concepts_tested": [
        "Concept 1: Integration of multiple disciplines to address complex, real-world problems",
        "Concept 2: Interdisciplinary education as a method to foster cognitive flexibility, active learning, and problem-solving through blending approaches from several fields",
        "Concept 3: Emergence of cross-boundary fields or organizational units to meet new needs and incorporate diverse perspectives (including addressing neglected or emerging areas)"
      ],
      "parent_concepts": [
        "Concept 1: Interdisciplinary relationships \u2014 physics intersects with fields like biophysics and quantum chemistry, and new physics ideas explain mechanisms in other sciences.",
        "Transdisciplinary foundations enabling cross-domain applicability of systems thinking",
        "Interdisciplinary relationships and the development of theoretical frameworks (e.g., cross-links with ethics, political philosophy, sociology, and frameworks like social ontology, care ethics)",
        "Concept 2: Ecocriticism employs interdisciplinary methodologies by borrowing theories and methods from ecology, environmental history, biopolitics, etc., to analyze texts in their environmental contexts."
      ],
      "parent_articles": [
        "Physics",
        "Systems science",
        "Social philosophy",
        "Ecocriticism"
      ]
    },
    {
      "question": "In the scientific method, why is it essential that a hypothesis yield specific, testable predictions that could, in principle, be falsified by evidence?",
      "options": {
        "A": "It provides objective criteria for evaluating the hypothesis, enabling empirical checks that can lead to revision or rejection when evidence contradicts predictions.",
        "B": "It guarantees that the hypothesis will be proven true given enough data.",
        "C": "It ensures researchers will rely on personal intuition rather than data.",
        "D": "It forces results to always agree with established theories, maintaining consistency."
      },
      "correct_answer": "A",
      "source_article": "Science",
      "x": 1.2426975965499878,
      "y": 1.0560698509216309,
      "concepts_tested": [
        "Concept 1: The scientific method as a systematic framework involving testable hypotheses, predictions, and empirical validation that builds knowledge about the universe.",
        "Concept 2: Relationships among disciplines and their methodologies (natural vs. social sciences; formal sciences; applied sciences) and how these relate to empirical versus deductive approaches and practical use of knowledge.",
        "Concept 3: The historical and social evolution of science (development from natural philosophy to modern science, the role of collaboration, institutions, and policy in shaping scientific practice)."
      ],
      "parent_concepts": [
        "Concept 1: Interdisciplinary relationships \u2014 physics intersects with fields like biophysics and quantum chemistry, and new physics ideas explain mechanisms in other sciences.",
        "Concept 2: The scientific method relies on empirical evidence and experiments, with hypotheses tested against observations rather than resting on a priori reasoning.",
        "Concept 3: The theory\u2013measurement\u2013law relationship (use of mathematics/logic to translate observations into measurable statements and predictive laws)",
        "Different theoretical approaches in physics (phenomenologists, model-builders, effective theories) and their goals (fitting data, unification, abstraction) in creating and evaluating models.",
        "Concept 3: The relationship of social science to broader science and its historical evolution (from moral philosophy to empirical science; division between stricter and broader senses of science).",
        "Concept 1: Chemical bonds form and rearrange during reactions, driving changes in matter."
      ],
      "parent_articles": [
        "Physics",
        "Empiricism",
        "Natural science",
        "Theoretical physics",
        "Social science",
        "Chemistry"
      ]
    },
    {
      "question": "In a principal-agent relationship with hidden actions, how do incentive alignment mechanisms (such as piece rates, profit sharing, or performance pay) conceptually affect the agent's decision rule to minimize agency costs?",
      "options": {
        "A": "They convert compensation into a fixed wage, reducing the agent's incentive to exert extra effort.",
        "B": "They tie pay to outcomes the agent can influence, aligning the agent's marginal incentives with the principal's marginal value of effort.",
        "C": "They replace all monitoring by the principal with automatic compliance.",
        "D": "They shift all risk to the agent, guaranteeing the same payoff regardless of effort."
      },
      "correct_answer": "B",
      "source_article": "Principal\u2013agent problem",
      "x": 1.316882610321045,
      "y": 0.9673541188240051,
      "concepts_tested": [
        "Concept 1: Information asymmetry and hidden actions/information (moral hazard and adverse selection) as drivers of the principal\u2013agent problem.",
        "Concept 2: Agency costs and incentive alignment mechanisms (e.g., piece rates, profit sharing, efficiency wages, performance measurement, bonds, termination) used to align agent behavior with principal interests.",
        "Concept 3: The multiple-principal problem and governance/collective-action dynamics when more than one principal must coordinate with an agent (including implications for the public sector)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does the existence of unforeseen contingencies lead to a firm\u2013market boundary where production is more likely to be internalized rather than outsourced to the market, according to contract theory?",
      "options": {
        "A": "Because markets can specify every possible contingency and price it precisely, eliminating the need for internal coordination.",
        "B": "Because unforeseen contingencies reduce the value of long-term relationships, making outsourcing to the market more attractive.",
        "C": "Because unforeseen contingencies create hold-up and misaligned incentives across contingencies, and internalizing governance within a firm reduces renegotiation costs and coordinate incentives more effectively.",
        "D": "Because all inefficiencies under uncertainty are eliminated when the firm contracts with external suppliers."
      },
      "correct_answer": "C",
      "source_article": "Contract theory",
      "x": 1.3178012371063232,
      "y": 0.9377552270889282,
      "concepts_tested": [
        "Concept 1: Incentive design under information asymmetry (principal\u2013agent problems, moral hazard, adverse selection, signaling)",
        "Concept 2: Complete vs incomplete contracts and the firm\u2013market relationship",
        "Concept 3: Risk, time structure, and uncertainty in contract design (how future unpredictability creates holes in contracts and shapes compensation/incentives)"
      ],
      "parent_concepts": [
        "Incentive alignment mechanisms (e.g., piece rates, profit sharing, performance measurement, bonds, termination) and governance approaches to reduce agency costs and align agent actions with principal interests.",
        "Concept 1: Information asymmetry and hidden actions/information drive agency costs and misalignment between principal and agent.",
        "Concept 2: Incentive alignment mechanisms (e.g., piece rates, profit sharing, efficiency wages, performance measurement, bonding, termination) as methods to reduce agency costs."
      ],
      "parent_articles": [
        "Principal\u2013agent problem",
        "Principal\u2013agent problem",
        "Principal\u2013agent problem"
      ]
    },
    {
      "question": "How does the explicit delineation of roles among management, the board, shareholders, and stakeholders create an effective governance framework?",
      "options": {
        "A": "It centralizes decision-making in management to speed up actions.",
        "B": "It establishes a checks-and-balances system where the board and shareholders set objectives and monitor performance, while management executes and reports, thereby aligning interests and providing accountability.",
        "C": "It eliminates information asymmetry completely so all parties always know all details of decisions.",
        "D": "It makes governance unnecessary once the objectives are set."
      },
      "correct_answer": "B",
      "source_article": "Corporate governance",
      "x": 1.314923882484436,
      "y": 0.8994338512420654,
      "concepts_tested": [
        "Concept 1: Corporate governance as a system of processes, structures, and mechanisms that influence the control and direction of a corporation.",
        "Concept 2: The relationships among key actors (management, board, shareholders, and stakeholders) and how these relationships provide the framework for directing, setting objectives, and monitoring performance.",
        "Concept 3: Governance frameworks based on general principles (e.g., Cadbury, OECD, Sarbanes\u2013Oxley) that guide proper governance and accountability."
      ],
      "parent_concepts": [
        "Incentive alignment mechanisms (e.g., piece rates, profit sharing, performance measurement, bonds, termination) and governance approaches to reduce agency costs and align agent actions with principal interests.",
        "Concept 3: Ethical/CSR orientation \u2014 why stakeholders' needs should be prioritized in action and how this reshapes traditional, shareholder-focused decision making.",
        "Concept 3: Governance and regulatory mechanisms (ESG reporting, standards, incentives) that move CSR from voluntary actions to mandatory or incentivized practices, shaping corporate behavior and outcomes.",
        "Concept 3: Governance and roles (enterprise architects overseeing solutions architects) and their impact on aligning decisions across the organization with the strategic vision.",
        "Concept 2: Incentive alignment mechanisms (e.g., piece rates, profit sharing, efficiency wages, performance measurement, bonding, termination) as methods to reduce agency costs."
      ],
      "parent_articles": [
        "Principal\u2013agent problem",
        "Stakeholder theory",
        "Corporate social responsibility",
        "Enterprise architecture",
        "Principal\u2013agent problem"
      ]
    },
    {
      "question": "In a strategic setting, a mixed-strategy Nash equilibrium can exist even when no pure strategy equilibrium exists. Why does the ability to randomize help sustain mutual best responses?",
      "options": {
        "A": "Because mixing shifts payoffs so that every strategy becomes strictly dominant.",
        "B": "Because a player's randomized mix can equalize the opponent's expected payoff across the opponent's pure responses, making them indifferent and preventing profitable unilateral deviations.",
        "C": "Because randomization guarantees that each player's strategy is the unique best response to the other's mix.",
        "D": "Because randomization minimizes risk for both players by always choosing the lowest payoff outcome."
      },
      "correct_answer": "B",
      "source_article": "Game theory",
      "x": 1.5081069469451904,
      "y": 1.1605703830718994,
      "concepts_tested": [
        "Concept 1: Equilibrium concepts in strategic interactions (e.g., mixed-strategy equilibria, Nash equilibrium) and their role in predicting rational behavior.",
        "Concept 2: Classification of games by payoff structure (zero-sum vs non-zero-sum; cooperative vs non-cooperative) and how that classification guides modeling and outcomes.",
        "Concept 3: Mathematical foundations and extensions (fixed-point theorems, axiomatic expected utility, evolutionary game theory) that provide the rigorous basis and broaden applicability of game-theoretic reasoning."
      ],
      "parent_concepts": [
        "Information asymmetry and contract design: how incomplete information between parties leads to market failures and how mechanism design can elicit information-sharing and welfare-enhancing outcomes.",
        "Concept 2: Information asymmetry and its effect on valuations and strategic bidding",
        "Concept 1",
        "Concept 3",
        "Concept 1: Distributive vs. integrative negotiation as fundamental types, and how the negotiators\u2019 mindset and the situation determine which type occurs."
      ],
      "parent_articles": [
        "Information economics",
        "Auction theory",
        "Cooperation",
        "Cooperation",
        "Negotiation"
      ]
    },
    {
      "question": "How does shifting from a traditional top-down master plan to an inclusive, resident-centered planning approach alter the way urban infrastructure, health, and environmental goals are balanced in practice?",
      "options": {
        "A": "It uses local resident knowledge to identify health risks, daily mobility needs, and environmental sensitivities, enabling decisions that better align infrastructure with actual community welfare and sustainability.",
        "B": "It makes decisions faster by bypassing community input and relying solely on technical expertise.",
        "C": "It reduces the need for cross-disciplinary collaboration by delegating all tasks to civil engineers.",
        "D": "It prioritizes aesthetic preferences of a few influential stakeholders over broad community needs."
      },
      "correct_answer": "A",
      "source_article": "Urban planning",
      "x": 1.3587636947631836,
      "y": 0.8639479279518127,
      "concepts_tested": [
        "Concept 1: Urban planning as a mechanism to balance public welfare with social, economic, environmental, and sustainability goals.",
        "Concept 2: Urban planning as an interdisciplinary, iterative process involving research, design, policy, and implementation across multiple fields.",
        "Concept 3: The evolving relationship between planning and communities/urban design, shifting from top-down master plans to inclusive, resident-centered approaches while considering infrastructure, health, and environmental preservation."
      ],
      "parent_concepts": [
        "Concept 1: Spatial planning mediates between competing demands on land from the state, market, and local community."
      ],
      "parent_articles": [
        "Spatial planning"
      ]
    },
    {
      "question": "Which mechanism best explains why a system exhibits emergent properties that are not present in any individual component?",
      "options": {
        "A": "The system's behavior is simply the arithmetic sum of each component's properties.",
        "B": "Interactions among components create nonlinear feedback and coupling that reconfigure the system's constraints, generating novel patterns.",
        "C": "Emergent properties only appear due to measurement scales; at finer scales they disappear.",
        "D": "The emergence is a result of external inputs being ignored by the analysis."
      },
      "correct_answer": "B",
      "source_article": "Systems theory",
      "x": 1.4902068376541138,
      "y": 1.0852227210998535,
      "concepts_tested": [
        "Emergence and synergy: systems are \"more than the sum of their parts\" due to interactions that produce new properties.",
        "Interdependence, boundaries, and context: systems have causal boundaries and are shaped by context, with structure, function, and relations determining behavior.",
        "Adaptation, learning, and equifinality: system growth and adaptation depend on engagement with the environment, allowing multiple paths to similar outcomes."
      ],
      "parent_concepts": [
        "Levels of analysis and cross-scale integration: studying the nervous system from molecular/cellular scales to imaging and cognitive tasks, and how each scale contributes to understanding brain function.",
        "Concept 1: Security is a relationship that depends on the referent\u2019s environment and the referent\u2019s own capabilities, i.e., security emerges from interactions between a target, its surroundings, and its response options.",
        "Ends-ways-means relationship: strategy describes how goals are achieved with available resources, with resources constraining actions and the possibility of both intended and emergent strategy.",
        "Concept 1: Connectivity and cross-sphere interactions among the Earth\u2019s subsystems",
        "The micro-level vs macro-level scales of analysis and how phenomena at different levels relate",
        "Concept 1: Transformation and efficiency \u2014 Operations converts inputs (materials, labor, energy) into outputs (goods/services) with the goal of efficient resource use to meet customer requirements.",
        "Concept 1: Innate vs Adaptive immunity \u2014 their differences in specificity, how they learn/remember (adaptive), and how they coordinate responses.",
        "Concept 1: The three-component feedback control system (receptor, control center, effector) and their interactions in maintaining a variable within a maintenance range.",
        "Concept 2: Stability and performance criteria\u2014how delays, overshoot, steady-state error, and stability criteria influence controller design and system behavior.",
        "Concept 3: Modeling and design tools\u2014how block diagrams and transfer functions model input-output relationships, and how controllability/observability relate to the ability to control and estimate system states.",
        "Concept 1: Feedback forms a loop that creates circular causality, requiring system-wide analysis rather than linear cause-and-effect reasoning.",
        "Concept 3: Feedback can modify system gain and behavior (e.g., boosting amplification through regeneration) but may also cause instability or undesirable effects (e.g., howl) if not managed.",
        "Self-organization and adaptation: order and patterns arise without central control through local rules and feedback, enabling systems to adapt to their environment.",
        "Transdisciplinary foundations enabling cross-domain applicability of systems thinking",
        "Interdependence of hard infrastructure, soft infrastructure, and governance",
        "The four components of quality management (planning, assurance, control, improvement) form an integrated system to consistently meet intended performance.",
        "Concept 1: Mathematical modeling as the core means of describing real-world systems to enable analysis and decision support.",
        "Concept 3: Drivers of change and their interaction with change management processes (technology evolution, process reviews, crises, regulation, etc.), illustrating cause-effect relationships that trigger and shape change efforts.",
        "Concept 1: Iterative learning loop \u2014 monitoring informs learning, which updates models and then shapes future decisions.",
        "Emergent properties of groups: the idea that group behavior cannot be fully understood by studying individuals in isolation.",
        "IT system composition: hardware, software, and peripherals work together to process/store/retrieve/transmit information.",
        "Concept 1: Interdependence of social and ecological systems with feedback mechanisms",
        "Concept 1: Sustainability through balancing human needs with natural systems and ecological limits (cause/effect: how different approaches aim to achieve a sustainable balance).",
        "Concept 2: Decomposition of risk into sources, events, consequences, and likelihood (a cause\u2013effect\u2013probability framework)",
        "Concept 2: The relationship between management style and ecological resilience\u2014how ecosystem management contrasts with command-and-control approaches to improve resilience and sustainability.",
        "Concept 2: BPM lifecycle and mechanisms \u2014 modeling, automation/execution, control, measurement, and optimization as an interconnected set of activities.",
        "Concept 3: People\u2013technology\u2013process relationships \u2014 BPM is enabled by technology and involves the participation of people, highlighting how workflows and automation relate to organizational goals and performance.",
        "Concept 2: Composability as a mechanism that enables modules to be combined to build larger systems (e.g., in functional programming).",
        "Concept 2: Existence of both linear (designed) and non-linear (emergent, complex) relationships in sociotechnical interactions.",
        "Concept 3: The risk of optimizing one aspect in isolation and the rationale for integrated design of social and technical elements to avoid unintended, detrimental effects.",
        "Concept 1: Closed-loop feedback control mechanism (measurement, comparison to setpoints, corrective action) to maintain process within target parameters.",
        "Concept 3: Objective-driven design and benefits (using control theory principles to achieve energy efficiency, reduced waste, improved quality, and enhanced safety).",
        "Encoding predetermined decision criteria into machines (control logic) to automate processes and reduce human intervention",
        "Systems integration of multiple technologies (mechanical, hydraulic, electrical, electronic, computer) to enable complex automation and affect performance metrics (labor savings, waste reduction, quality, costs)"
      ],
      "parent_articles": [
        "Neuroscience",
        "Security",
        "Strategy",
        "Earth system science",
        "Sociology",
        "Operations management",
        "Immune system",
        "Homeostasis",
        "Control theory",
        "Control theory",
        "Feedback",
        "Feedback",
        "Complex system",
        "Systems science",
        "Infrastructure",
        "Quality management",
        "Operations research",
        "Change management",
        "Adaptive management",
        "Group dynamics",
        "Information technology",
        "Socio-ecological system",
        "Environmentalism",
        "Risk",
        "Ecosystem management",
        "Business process management",
        "Business process management",
        "Modularity",
        "Sociotechnical system",
        "Sociotechnical system",
        "Industrial process control",
        "Industrial process control",
        "Automation",
        "Automation"
      ]
    },
    {
      "question": "In integrated systems thinking, why can't you assume that increasing the speed of a single subsystem (e.g., a machine) will automatically improve the entire system's performance?",
      "options": {
        "A": "Because the faster subsystem can alter the timing and workload at interfaces with people, materials, information, and energy, potentially creating new bottlenecks or inefficiencies elsewhere.",
        "B": "Because speed increases always reduce energy use and waste.",
        "C": "Because downstream processes will always adapt perfectly to upstream changes.",
        "D": "Because throughput is determined solely by the slowest component, so speeding one part can't help."
      },
      "correct_answer": "A",
      "source_article": "Industrial engineering",
      "x": 1.40120267868042,
      "y": 0.9979009032249451,
      "concepts_tested": [
        "Concept 1: Integrated systems thinking\u2014IE designs and optimizes systems that involve people, materials, information, equipment, and energy, focusing on interactions to specify, predict, and evaluate outcomes.",
        "Concept 2: Process-improvement mechanisms\u2014use of lean manufacturing, Six Sigma, and related methods to reduce waste and enhance quality and productivity, illustrating cause-effect links between practices and performance.",
        "Concept 3: Interdisciplinary synthesis\u2014IE combines engineering, mathematics, and social sciences (along with business principles) to model, analyze, and manage complex processes and organizations."
      ],
      "parent_concepts": [
        "Concept 1: Transformation and efficiency \u2014 Operations converts inputs (materials, labor, energy) into outputs (goods/services) with the goal of efficient resource use to meet customer requirements."
      ],
      "parent_articles": [
        "Operations management"
      ]
    },
    {
      "question": "Why does opsonization with antibodies or complement fragments improve the efficiency of phagocytosis by macrophages and neutrophils?",
      "options": {
        "A": "Opsonins create a favorable chemical gradient that draws phagocytes toward the pathogen.",
        "B": "Opsonins are recognized by Fc receptors or complement receptors on phagocytes, triggering signaling that reorganizes the cytoskeleton and engulfs the particle.",
        "C": "Opsonins chemically neutralize the pathogen, making ingestion unnecessary for clearance.",
        "D": "Opsonization causes pathogens to shrink, making them easier to internalize."
      },
      "correct_answer": "B",
      "source_article": "Immunology",
      "x": 2.085174560546875,
      "y": 1.153812050819397,
      "concepts_tested": [
        "Concept 1: Phagocytosis as a mechanism of immune defense (how immune cells ingest/clear foreign material).",
        "Concept 2: Immunity as a system whose components (organs, cells, tissues) interact to maintain health and can malfunction, leading to autoimmune diseases, hypersensitivities, immune deficiency, and transplant rejection.",
        "Concept 3: Organization and distribution of immune components (lymphoid organs and circulating cellular elements) and the idea that immune function arises from interactions across organs, tissues, and cells."
      ],
      "parent_concepts": [
        "Concept 1: Innate vs Adaptive immunity \u2014 their differences in specificity, how they learn/remember (adaptive), and how they coordinate responses."
      ],
      "parent_articles": [
        "Immune system"
      ]
    },
    {
      "question": "How do nonlinear interactions and network topology contribute to emergent system-level behaviors in biological systems, and why does integrating diverse quantitative data with dynamic models help reveal these properties rather than relying on single-component analysis?",
      "options": {
        "A": "Emergent system-level behaviors are simply the sum of independent component outputs, so data integration isn't necessary.",
        "B": "Emergent behaviors arise from feedback loops, nonlinear coupling, and constraints across components, so integrating multiple data types with a dynamic model captures context-dependent interactions that single-component analyses miss.",
        "C": "Emergent properties can be inferred directly from the most connected component, making holistic modeling redundant.",
        "D": "Emergent behavior is purely stochastic noise, so data integration just adds more noise."
      },
      "correct_answer": "B",
      "source_article": "Systems biology",
      "x": 1.5669333934783936,
      "y": 1.1008394956588745,
      "concepts_tested": [
        "Emergent properties and system-level behavior arising from dynamic interactions within biological networks, explored through modeling and data integration.",
        "Holistic integration of multiple components/data types with quantitative models, contrasted with reductionist approaches.",
        "Iterative modeling cycle (theory/modeling \u2192 experimental validation \u2192 refinement) for developing quantitative descriptions of cellular processes."
      ],
      "parent_concepts": [
        "Concept 1: Innate vs Adaptive immunity \u2014 their differences in specificity, how they learn/remember (adaptive), and how they coordinate responses.",
        "Concept 1: Genomics aims to characterize and quantify all genes and their interrelations within the genome, distinguishing it from studying individual genes (genetics).",
        "Endocrine regulation uses feedback loops to maintain homeostasis",
        "Concept 3: Morphogen gradients and diffusion-based signaling create positional information that guides development and cell fate decisions through GRN activity."
      ],
      "parent_articles": [
        "Immune system",
        "Genomics",
        "Endocrinology",
        "Gene regulatory network"
      ]
    },
    {
      "question": "In a system where outputs are fed back to influence the inputs, how does the sign of the feedback determine whether the overall behavior is stabilized or destabilized?",
      "options": {
        "A": "Positive feedback reinforces deviations, increasing the loop\u2019s tendency to amplify errors and potentially cause runaway growth or sustained oscillations; negative feedback opposes deviations, reducing errors and damping responses, promoting stability.",
        "B": "Positive feedback always dampens deviations and stabilizes the system; negative feedback always amplifies deviations and destabilizes it.",
        "C": "The sign of feedback has no impact on stability; stability depends only on external disturbances.",
        "D": "Both positive and negative feedback inevitably cause instability if there is any delay in the loop."
      },
      "correct_answer": "A",
      "source_article": "Feedback",
      "x": 1.582424283027649,
      "y": 1.0843225717544556,
      "concepts_tested": [
        "Concept 1: Feedback loop mechanism \u2014 outputs fed back to inputs to form a circuit; reasoning must analyze the system as a whole.",
        "Concept 2: Feedback can regulate or amplify system behavior, with potential for instability (e.g., regeneration in amplifiers, governors controlling speed).",
        "Concept 3: Cross-domain applicability \u2014 feedback as evaluative/corrective information that can influence the controlling source (e.g., business feedback)."
      ],
      "parent_concepts": [
        "Concept 2: Negative feedback as the mechanism that reverses changes and stabilizes the system once the variable returns to the set point."
      ],
      "parent_articles": [
        "Homeostasis"
      ]
    },
    {
      "question": "Why does determinism ensure a single future trajectory from a given present state, and how does introducing stochasticity alter this?",
      "options": {
        "A": "Determinism means the evolution rule yields a single next state for each current state; stochasticity introduces randomness so the next state is drawn from a distribution, giving multiple possible futures.",
        "B": "Determinism requires time to be continuous; stochasticity allows time to become discrete, changing the granularity of prediction.",
        "C": "Determinism implies the state space must be finite; stochasticity requires an infinite state space to accommodate randomness.",
        "D": "Determinism guarantees convergence to a fixed point; stochasticity guarantees perpetual oscillation, preventing convergence."
      },
      "correct_answer": "A",
      "source_article": "Dynamical system",
      "x": 1.6852811574935913,
      "y": 1.1590125560760498,
      "concepts_tested": [
        "Concept 1: Evolution rule and determinism vs stochasticity (how the current state leads to future states, and when randomness influences outcomes)",
        "Concept 2: State space and trajectories/orbits (the state space as the set of possible states and the path that results from evolving over time)",
        "Concept 3: Dynamical systems as a unifying framework (how they relate to ODEs, difference equations, ergodic theory, chaos, and other models)"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In a complex system composed of interacting subsystems with shared resources and feedback paths, why does optimizing only one subsystem's local performance often fail to improve the overall system performance?",
      "options": {
        "A": "Because subsystems operate in complete isolation and cannot affect each other.",
        "B": "Because the system's emergent behavior arises from interactions and feedback loops, so changes in one part can alter constraints, signals, and performance elsewhere.",
        "C": "Because the global objective is simply the sum of all local metrics, so improving one automatically improves the whole system.",
        "D": "Because optimization algorithms inherently prefer balanced resource distribution across all subsystems regardless of interactions."
      },
      "correct_answer": "B",
      "source_article": "Systems engineering",
      "x": 1.4441066980361938,
      "y": 1.029392123222351,
      "concepts_tested": [
        "Concept 1: Systems thinking / holistic integration \u2014 how components interact to produce emergent system behavior and why a whole-system view is necessary.",
        "Concept 2: Discovery-driven problem identification \u2014 why systems engineering begins with identifying real problems and high-impact failures rather than assuming manufacturing-like repetitive optimization.",
        "Concept 3: Life-cycle orientation and cross-disciplinary integration \u2014 how design, integration, risk management, testing, maintenance, and decommissioning across multiple disciplines are coordinated to ensure a cohesive system."
      ],
      "parent_concepts": [
        "Concept 3: Modeling and design tools\u2014how block diagrams and transfer functions model input-output relationships, and how controllability/observability relate to the ability to control and estimate system states.",
        "Concept 1",
        "Concept 3: Objective-driven design and benefits (using control theory principles to achieve energy efficiency, reduced waste, improved quality, and enhanced safety).",
        "Systems integration of multiple technologies (mechanical, hydraulic, electrical, electronic, computer) to enable complex automation and affect performance metrics (labor savings, waste reduction, quality, costs)"
      ],
      "parent_articles": [
        "Control theory",
        "Software engineering",
        "Industrial process control",
        "Automation"
      ]
    },
    {
      "question": "Why does co-creation with societal partners in transdisciplinary research improve problem-solving outcomes?",
      "options": {
        "A": "It ensures faster publication by satisfying disciplinary gatekeepers.",
        "B": "It brings together diverse lived experiences, practical knowledge, and values, enabling problem framing and solutions that are more context-appropriate and socially legitimate.",
        "C": "It eliminates the need for methodological rigor by focusing on practicality.",
        "D": "It keeps the process within academic silos to maintain intellectual rigor."
      },
      "correct_answer": "B",
      "source_article": "Transdisciplinarity",
      "x": 1.232293725013733,
      "y": 0.9879375100135803,
      "concepts_tested": [
        "Co-creation with societal partners and bridging academia with community perspectives to address real-world challenges",
        "Boundary-spanning integration of diverse knowledge systems and stakeholders to address complex problems",
        "The three knowledge types guiding transdisciplinary research: system knowledge, target knowledge, and transformation knowledge"
      ],
      "parent_concepts": [
        "Transdisciplinary foundations enabling cross-domain applicability of systems thinking"
      ],
      "parent_articles": [
        "Systems science"
      ]
    },
    {
      "question": "How does the interplay between social structure and individual agency explain both the persistence of social order and its potential for change?",
      "options": {
        "A": "Structural constraints completely determine action; individual choices never alter outcomes.",
        "B": "Individual actions are completely free; social structure is a passive backdrop with no influence.",
        "C": "Structures constrain and enable individual actions, and the routine repetition of these actions reproduces the structure, creating a stable order; but when agents alter patterns, the feedback loop can gradually transform the structure, producing change.",
        "D": "Social order arises randomly without any influence from structure or agency."
      },
      "correct_answer": "C",
      "source_article": "Sociology",
      "x": 1.2459790706634521,
      "y": 0.9889225959777832,
      "concepts_tested": [
        "Concept 1: Structure vs. agency \u2014 the interplay between social structure and individual agency in producing social order and social change.",
        "Concept 2: Micro-level and macro-level analysis \u2014 how individual interactions aggregate into large-scale social systems and patterns.",
        "Concept 3: Digital sociology and technology\u2019s impact \u2014 how digital technologies (e.g., the internet) reshape social relations, networks, and power dynamics."
      ],
      "parent_concepts": [
        "Concept 1: Culture is dynamic and socially constructed, consisting of interacting practices and processes rather than fixed, discrete entities.",
        "Concept 2: Meaning within culture is produced, disseminated, and contested within systems of power (ideology, class, gender, national formation, globalization), including concepts like hegemony and agency.",
        "Concept 2: The interaction between social structure and individual agency in shaping communication patterns and outcomes.",
        "Social norms as mechanisms that regulate behavior and sustain social order",
        "Concept 1: Cultural learning and transmission mechanisms (enculturation and socialization) that produce cultural diversity.",
        "Concept 1: A social role is a structured set of behaviors, rights, obligations, beliefs, and norms that guide expected conduct in a given social situation.",
        "Concept 3: Information-centered social conduct (the idea that theoretical knowledge and information shape how people live and behave).",
        "Concept 2: Stratification can be based on multiple factors (wealth, income, race, education, ethnicity, gender, occupation, social status, power) and can also arise from kinship, clan, tribe, or caste, showing diverse bases for forming strata.",
        "Stickiness and structural constraints: how limited resources or opportunities at the ends of the ladder affect individual mobility and long-term outcomes.",
        "Concept 3: Technology-induced social change \u2014 new technologies reconfigure social structures and daily life (e.g., smartphones altering family dynamics).",
        "Concept 3: Theoretical foundations (Marx, Durkheim, Weber, Simmel) and their explanations of urbanization outcomes such as social alienation, class formation, and changes in collective/individual identities."
      ],
      "parent_articles": [
        "Cultural studies",
        "Cultural studies",
        "Communication studies",
        "Society",
        "Culture",
        "Role",
        "Information society",
        "Social stratification",
        "Social mobility",
        "Media studies",
        "Urban sociology"
      ]
    },
    {
      "question": "How does social constructionism explain that the meaning of \"beauty\" can change across generations, even when there is no new biological evidence to justify a change?",
      "options": {
        "A": "The emphasis on empirical measurement ensures beauty standards converge to objective metrics over time.",
        "B": "The meaning is sustained and revised through ongoing social interactions and collective consensus, with individuals internalizing prevailing narratives while also contributing to and reshaping them through discourse and practice.",
        "C": "Individuals rely solely on parental instruction, which locks in standards across generations.",
        "D": "The beauty concept is fixed once set by ancient authorities and remains unchanged."
      },
      "correct_answer": "B",
      "source_article": "Social constructionism",
      "x": 1.219294786453247,
      "y": 1.0203258991241455,
      "concepts_tested": [
        "Social constructs are formed and sustained through ongoing social interactions and collective consensus rather than direct empirical observation of reality.",
        "The meanings of phenomena depend on mental and linguistic representations, making reality a shared construct rather than an independently given truth.",
        "Individuals actively shape and reinterpret social narratives in a two-way process, wherein internalization and social engagement both influence and modify constructs."
      ],
      "parent_concepts": [
        "Concept 1: Culture is dynamic and socially constructed, consisting of interacting practices and processes rather than fixed, discrete entities."
      ],
      "parent_articles": [
        "Cultural studies"
      ]
    },
    {
      "question": "How does praxis function in critical theory to bring about social transformation?",
      "options": {
        "A": "By separating theory from practice and evaluating power structures purely in abstract terms.",
        "B": "By integrating theory with collective action so that theoretical insights guide action and the outcomes of action feed back into theory, enabling transformative change.",
        "C": "By prioritizing theoretical elegance over practical engagement with social movements.",
        "D": "By assuming that knowledge alone, without organized effort or action, can automatically produce societal change."
      },
      "correct_answer": "B",
      "source_article": "Critical theory",
      "x": 1.1323741674423218,
      "y": 0.9604613184928894,
      "concepts_tested": [
        "Concept 1: Power-knowledge relationship and critique of objectivity",
        "Concept 2: Praxis\u2014the integration of theory and collective action for social transformation",
        "Concept 3: Intersections of oppression within historical/capitalist contexts"
      ],
      "parent_concepts": [
        "Concept 2: Meaning within culture is produced, disseminated, and contested within systems of power (ideology, class, gender, national formation, globalization), including concepts like hegemony and agency.",
        "Concept 3: Ongoing impact, identity, and interdisciplinary approaches",
        "Concept 2: False psychological needs created by mass culture, which capitalism purportedly manipulates and can only satisfy through commodified products."
      ],
      "parent_articles": [
        "Cultural studies",
        "Postcolonialism",
        "Culture industry"
      ]
    },
    {
      "question": "In the transactional model of communication, messages are sent and received simultaneously, and participants continuously encode and decode while adapting based on ongoing feedback. How does this simultaneity alter the roles of encoding/decoding and feedback relative to the linear model where the sender transmits a message with limited or no feedback?",
      "options": {
        "A": "It makes feedback a continuous, mutual adjustment, so encoding/decoding occur in a shared frame and meaning is co-created rather than simply moved along a unidirectional path.",
        "B": "It makes feedback unnecessary because both parties are sending at once.",
        "C": "It enforces a strict order where sending happens before any encoding or decoding, which aligns with the linear model.",
        "D": "It guarantees zero noise because simultaneous exchange automatically cancels errors."
      },
      "correct_answer": "A",
      "source_article": "Communication theory",
      "x": 1.2367424964904785,
      "y": 1.0152244567871094,
      "concepts_tested": [
        "Concept 1: Communication models (linear, interactional, transactional) and their mechanisms (encoding/decoding, feedback, noise) and how they differ in directionality and simultaneity.",
        "Concept 2: Transmission vs. ritual perspectives as two foundational relationships framing communication (information exchange vs. social connection) and their implications for interpreting messages.",
        "Concept 3: The role of social context and norms in shaping language use and communication practices (e.g., sociolinguistic findings on formality and context)."
      ],
      "parent_concepts": [
        "Concept 1: Transmission model of communication (encoding by a source, channel sending a message, decoding by a receiver) and how distortion or misalignment can affect understanding.",
        "Concept 2: Error control (channel coding) adds redundancy to detect/correct errors, improving reliability over noisy channels.",
        "Concept 3: The role of communication protocols and physical media in enabling data exchange across networks (how protocols plus media realize inter-host communication).",
        "Concept 2: Encoding/decoding model with negotiation and opposition, illustrating how producers encode messages and audiences decode them in ways shaped by context.",
        "Concept 3: Cultural agility as a framework of competencies enabling effective cross-cultural interaction (practical framework)"
      ],
      "parent_articles": [
        "Communication",
        "Coding theory",
        "Computer network",
        "Reception theory",
        "Intercultural communication"
      ]
    },
    {
      "question": "Why does Peirce\u2019s triadic sign model (sign, object, interpretant) better explain how meaning is produced and varies across interpreters than Saussure\u2019s dyadic model (sign, concept), and what does this imply for interpretation in different contexts?",
      "options": {
        "A": "Because the interpretant in Peirce\u2019s triad captures the mental effect the sign has on each interpreter, allowing meaning to emerge through ongoing semiosis and to differ by context; Saussure\u2019s dyad treats meaning as a fixed link between a sign vehicle and a social-conventional concept, neglecting active, context-sensitive interpretation.",
        "B": "Because Saussure\u2019s dyadic model already includes an interpretant by tying the sign to a flexible concept, so the triadic model is redundant and unnecessary for understanding variation in meaning.",
        "C": "Because the triadic model assigns a fixed relationship among sign, referent, and audience, ensuring universal interpretation across contexts.",
        "D": "Because the dyadic model, with its three elements, is better suited for non-linguistic signs, whereas the triadic model is tailored to linguistic signs and contexts."
      },
      "correct_answer": "A",
      "source_article": "Semiotics",
      "x": 1.25066339969635,
      "y": 1.0847828388214111,
      "concepts_tested": [
        "Concept 1: Sign relation frameworks (Saussure's dyadic model vs. Peirce's triadic model) and how they explain meaning",
        "Concept 2: Relationship between signs, meanings, users, and context (semantics, pragmatics, texts, codes)",
        "Concept 3: Classification of signs into iconic, indexical, and symbolic, and implications for interpretation"
      ],
      "parent_concepts": [
        "Concept 1: Transmission model of communication (encoding by a source, channel sending a message, decoding by a receiver) and how distortion or misalignment can affect understanding.",
        "Concept 3: The analysis of informational content and structural relations (e.g., sublanguage analysis, transformations to canonical form) as mechanisms to uncover how discourse organizes meaning.",
        "Concept 1: Mediation of perception and meaning through visual technology and images (how visuals structure experience and information).",
        "Concept 1: Meaning is co-created by the reader and the text; meaning is not intrinsic to the text itself.",
        "Concept 2: Encoding/decoding model with negotiation and opposition, illustrating how producers encode messages and audiences decode them in ways shaped by context.",
        "Relationships among linguistic subfields: how pragmatics relates to semantics, syntax, and semiotics, and what the boundaries are between them."
      ],
      "parent_articles": [
        "Communication",
        "Discourse analysis",
        "Visual culture",
        "Reception theory",
        "Reception theory",
        "Pragmatics"
      ]
    },
    {
      "question": "How does structuration theory account for the relationship between social structures and human agency in producing social outcomes, and why can't either be said to unilaterally determine those outcomes?",
      "options": {
        "A": "Structures strictly determine actions, and agents merely replicate those structures without change.",
        "B": "Agents operate independently of structures, creating social orders that structures fail to constrain.",
        "C": "Structures are both enabling resources and constraining rules instantiated through everyday practices; these practices reproduce or transform structures, creating a continuous feedback loop where agency and structure mutually shape outcomes.",
        "D": "The theory posits a fixed hierarchy where macro structures always determine micro actions, making micro-level variation irrelevant."
      },
      "correct_answer": "C",
      "source_article": "Structuration theory",
      "x": 1.225014328956604,
      "y": 0.997601330280304,
      "concepts_tested": [
        "Duality of structure and agency: structures shape actions and actions reproduce/transform structures; neither dominates, and neither micro nor macro analysis alone suffices.",
        "Social practices across space and time: social life is constituted by practices ordered through time and space, forming the basic domain of study and enabling the reproduction of social systems.",
        "Interdisciplinary/ontological approach: the theory integrates phenomenology, hermeneutics, and insights from geography, history, philosophy to address the abstract characteristics of social relations beyond purely empirical methods."
      ],
      "parent_concepts": [
        "Concept 2: The interaction between social structure and individual agency in shaping communication patterns and outcomes."
      ],
      "parent_articles": [
        "Communication studies"
      ]
    },
    {
      "question": "In sociological theories of social control, the \"paradox of deviance\" explains how deviations from norms can actually reinforce social order. How does deviance fulfill this role?",
      "options": {
        "A": "It weakens collective beliefs and dissolves shared norms.",
        "B": "It reveals that rules are arbitrary and always negotiable, reducing overall compliance.",
        "C": "It exposes the boundary between acceptable and unacceptable behavior, prompting reaffirmation of shared values among the majority.",
        "D": "It isolates deviants permanently, creating subcultures that replace mainstream norms."
      },
      "correct_answer": "C",
      "source_article": "Social control",
      "x": 1.2616952657699585,
      "y": 0.9911608695983887,
      "concepts_tested": [
        "Concept 1: Informal vs formal social control as mechanisms by which behavior is regulated to maintain social norms and order.",
        "Concept 2: The paradox of deviance in social control (deviance as both regulated by and defining social norms, reinforcing conformity).",
        "Concept 3: The role of institutions (government, religion, civil society) in formal social control to prevent chaos/anomie and sustain social order."
      ],
      "parent_concepts": [
        "Social norms as mechanisms that regulate behavior and sustain social order"
      ],
      "parent_articles": [
        "Society"
      ]
    },
    {
      "question": "How does the principle of reciprocal causation between social structure and individual action explain both stability and change in a society?",
      "options": {
        "A": "Social structure constrains choices and expectations; individuals repeat actions that reproduce the structure, producing stability, but if enough actors alter their actions or reinterpret norms, the pattern shifts and a new structure emerges.",
        "B": "Social structure is purely emergent from individual actions and cannot constrain later behavior; changes occur only when individuals collectively revise their preferences.",
        "C": "Individuals' actions generate structure, but once the structure exists, it exerts no further influence on behavior.",
        "D": "Change can only occur through deliberate top-down policy; everyday norms and actions do not affect structural change."
      },
      "correct_answer": "A",
      "source_article": "Social structure",
      "x": 1.2503582239151,
      "y": 0.9864968061447144,
      "concepts_tested": [
        "Concept 1: Structure as both emergent from and determinant of individual action (reciprocal causation)",
        "Concept 2: Multi-level nature of social structure (macro, meso, micro) and cross-level influences (structures, networks, norms, institutions)",
        "Concept 3: Norms and their internalization as a mechanism for sustaining or changing social structure"
      ],
      "parent_concepts": [
        "Social norms as mechanisms that regulate behavior and sustain social order",
        "Concept 1: A social role is a structured set of behaviors, rights, obligations, beliefs, and norms that guide expected conduct in a given social situation.",
        "Concept 2: Stratification can be based on multiple factors (wealth, income, race, education, ethnicity, gender, occupation, social status, power) and can also arise from kinship, clan, tribe, or caste, showing diverse bases for forming strata."
      ],
      "parent_articles": [
        "Society",
        "Role",
        "Social stratification"
      ]
    },
    {
      "question": "From a reciprocity-based understanding of social justice, why would a society design institutions like taxation, welfare, and public services to distribute opportunities and burdens across the whole community rather than relying on private markets to allocate them?",
      "options": {
        "A": "Because interdependence creates reciprocal duties; institutions translate these duties into collective protections and equal access to essential resources to sustain cooperative norms.",
        "B": "Because private markets always produce perfect fairness; institutions are unnecessary.",
        "C": "Because reciprocity requires that everyone have the same outcomes, regardless of personal effort or circumstance.",
        "D": "Because diverse cultures cannot agree on duties, so centralized power must enforce a single distribution regardless of interdependence."
      },
      "correct_answer": "A",
      "source_article": "Social justice",
      "x": 1.2208930253982544,
      "y": 0.9369004368782043,
      "concepts_tested": [
        "Concept 1: Social justice as the distribution of wealth, opportunities, and burdens mediated by institutional design (e.g., taxation, social insurance, public services, labor regulation) to achieve equal opportunity.",
        "Concept 2: The ethical foundation of social justice in reciprocity and interdependence within society, including varying cultural emphases on individual responsibility and power, and how these shape justice practices.",
        "Concept 3: The historical-theoretical evolution of social justice (from natural law and early philosophers to modern international law and movements) and how these theories inform contemporary policy and debate."
      ],
      "parent_concepts": [
        "Concept 3: Policy and economic policy shape health equity by distributing resources and opportunities, producing health disparities.",
        "Distributive norms as governing allocations (Equality, Equity, Power, Need, Responsibility)",
        "Environmental racism and unequal distribution of environmental harms affecting marginalized communities (cause-and-effect relationship and social mechanism)"
      ],
      "parent_articles": [
        "Social determinants of health",
        "Distributive justice",
        "Environmental justice"
      ]
    },
    {
      "question": "How do cytoplasmic determinants and inductive signals interact to establish region-specific transcription factor expression during early embryogenesis, and why does this dual input promote robust pattern formation?",
      "options": {
        "A": "Cytoplasmic determinants create initial, position-specific transcription factor programs by localized mRNA/protein; inductive signals from signaling centers later refine and sharpen domain boundaries by upregulating or repressing those factors in adjacent cells; together they generate a combinatorial code that specifies region identity and ensures robustness to fluctuations.",
        "B": "Cytoplasmic determinants act only as passive reservoirs, while inductive signals alone create all spatial patterns via diffusion; cytoplasmic determinants do not influence transcription factor expression.",
        "C": "Inductive signals establish global identity, and cytoplasmic determinants provide local noise that must be overcome by later programs; this leads to fragile, variable patterning.",
        "D": "Both inputs are unnecessary; patterns arise from random cell fate choices then fixed by later mechanical constraints."
      },
      "correct_answer": "A",
      "source_article": "Developmental biology",
      "x": 2.0355546474456787,
      "y": 1.1518750190734863,
      "concepts_tested": [
        "Regional specification and pattern formation: how cytoplasmic determinants and inductive signals create spatial patterns in early embryos and drive region-specific transcription factor expression.",
        "Differentiation vs. morphogenesis: how cells acquire specialized functions (differentiation) versus how tissues/organs attain three-dimensional structure through movements and remodeling (morphogenesis), including germ layer formation.",
        "Growth dynamics and allometry in development: how tissue growth and differential growth contribute to morphogenesis, including differences between animal and plant development (e.g., plant morphogenesis via differential growth due to immotile cells)."
      ],
      "parent_concepts": [
        "Morphogen gradients and positional information guiding cell fate (French flag model)",
        "Concept 3: Epigenetic regulation drives development, particularly cellular differentiation, by activating or repressing specific gene sets to create diverse cell types.",
        "Concept 3: Morphogen gradients and diffusion-based signaling create positional information that guides development and cell fate decisions through GRN activity."
      ],
      "parent_articles": [
        "Pattern formation",
        "Epigenetics",
        "Gene regulatory network"
      ]
    },
    {
      "question": "How do mechanical forces and cell movements get integrated with genetic regulation to drive morphogenesis, in terms of mechanism?",
      "options": {
        "A": "Mechanical forces directly mutate DNA to generate new gene programs that sculpt tissue.",
        "B": "Mechanical cues are sensed by cells via adhesion and the cytoskeleton, activating mechanotransduction pathways that alter transcription factor activity and gene expression, thereby coordinating migration, adhesion, and contractility to shape tissues.",
        "C": "Morphogenesis uses only chemical gradients; mechanical forces do not influence gene regulation.",
        "D": "Differentiation determines gene expression first, and mechanical forces only occur after tissue shape is already fixed, with no feedback."
      },
      "correct_answer": "B",
      "source_article": "Morphogenesis",
      "x": 2.019735813140869,
      "y": 1.148724913597107,
      "concepts_tested": [
        "Concept 1: Mechanical forces and cell movement are integral to morphogenesis and are coupled to genetic regulation.",
        "Concept 2: Morphogen gradients guide patterning and differentiation through signaling and receptor interactions.",
        "Concept 3: Gene regulatory networks and master regulatory genes orchestrate cascades of transcriptional events that control cellular behaviors such as migration, adhesion, and contractility."
      ],
      "parent_concepts": [
        "Morphogen gradients and positional information guiding cell fate (French flag model)"
      ],
      "parent_articles": [
        "Pattern formation"
      ]
    },
    {
      "question": "Which explanation best captures why mathematical modeling can reveal non-obvious dynamic regimes in biological systems, such as a growth parameter leading to stable oscillations rather than runaway growth?",
      "options": {
        "A": "Because a model encodes the essential nonlinear feedbacks and allows systematic variation of parameters to perform stability and bifurcation analysis, which can uncover regimes that experiments alone might not expose.",
        "B": "Because experiments can observe all outcomes directly, so a model is just a redundant description.",
        "C": "Because simplifying to a single variable removes nonlinear effects and always yields straightforward predictions.",
        "D": "Because enforcing conservation laws in the model ensures outcomes are parameter-independent."
      },
      "correct_answer": "A",
      "source_article": "Mathematical and theoretical biology",
      "x": 1.6960632801055908,
      "y": 1.1316745281219482,
      "concepts_tested": [
        "The role of mathematical modeling in representing biological processes to enable prediction and reveal properties not obvious from experiments.",
        "The relationship and overlap between theoretical biology and mathematical biology, including their differing emphases (theory vs. mathematics) and how the terms are used interchangeably.",
        "Interdisciplinary necessity: due to the complexity of living systems, multiple mathematical fields are employed and new techniques developed to study biology."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does natural selection lead to changes in the frequencies of heritable traits in a population over generations?",
      "options": {
        "A": "Traits acquired during an individual's life become more common in the population because offspring inherit them directly from their parents.",
        "B": "Alleles associated with heritable traits that increase survival or reproduction leave more copies in the next generation, so their frequencies rise over time.",
        "C": "Random fluctuations in allele frequencies (genetic drift) are the sole driver, regardless of differences in fitness.",
        "D": "The environment can rewrite DNA in individuals to produce fitter traits in the next generation."
      },
      "correct_answer": "B",
      "source_article": "Evolution",
      "x": 1.8430818319320679,
      "y": 1.1171718835830688,
      "concepts_tested": [
        "Concept 1: Natural selection as a mechanism where differential fitness acts on heritable variation, leading to changes in trait frequencies over generations.",
        "Concept 2: Additional evolutionary mechanisms (genetic drift, mutation, gene flow) that alter allele frequencies and interact with selection.",
        "Concept 3: Common descent and phylogenetic relationships (LUCA, speciation, extinction) linking similarities among organisms to shared ancestry, with modern genetic data informing phylogenies."
      ],
      "parent_concepts": [
        "Concept 1: Phylogenetic inference uses observable, heritable data to reconstruct evolutionary relationships and yields a phylogenetic tree as a diagram of inferred history.",
        "Concept 2: The interaction of inheritance, variation, and struggle for existence under environmental pressures governs microevolution, macroevolution, and potentially speciation.",
        "Concept 3",
        "Concept 1: Homologous structures across diverse species reflect shared ancestry and are used to infer evolutionary relationships (phylogeny).",
        "Concept 3: Genetic variation and trait complexity\u2014mutations create new alleles, loci, and the reality that many traits are polygenic or involve multiple gene interactions, influencing evolution.",
        "Concept 2: Environment-driven optimization of life history traits to maximize evolutionary fitness (timing of maturation, number of offspring, lifespan, parental investment).",
        "Concept 2: Evolutionary rates vary across genes, sites, and lineages, influenced by purifying and directional selection; frameworks like the neutral theory and the molecular clock help interpret divergence times and rate consistency.",
        "Concept 1: Mutation as the ultimate source of genetic variation, with recombination, genetic drift, and gene flow shaping overall variation."
      ],
      "parent_articles": [
        "Phylogenetics",
        "Natural selection",
        "Cooperation",
        "Comparative anatomy",
        "Heredity",
        "Life history theory",
        "Molecular evolution",
        "Genetic variation"
      ]
    },
    {
      "question": "In systematics, researchers use three complementary branches\u2014numerical systematics (biometry), biochemical systematics, and experimental systematics\u2014to classify organisms. Why does integrating these three independent data streams typically yield a more robust inference of evolutionary relationships than relying on any single data type alone?",
      "options": {
        "A": "It guarantees that all analyses will produce identical, convergent phylogenies because the data are independent.",
        "B": "It treats all data equally and averages their signals to minimize any single bias, ensuring a single consensus tree.",
        "C": "It brings together independent lines of evidence that are each subject to different biases, so concordant signals across data types increase confidence, while discordance identifies areas needing further investigation.",
        "D": "It allows selectively removing any data type that contradicts the preferred hypothesis, ensuring the final tree aligns with prior expectations."
      },
      "correct_answer": "C",
      "source_article": "Systematics",
      "x": 1.8304965496063232,
      "y": 1.0946602821350098,
      "concepts_tested": [
        "Concept 1: Phylogenetic trees encode both relationships (branching order) and amount of evolution (branch length); these trees are used to study evolution of traits and biogeography.",
        "Concept 2: Systematics uses multiple data-driven branches (numerical systematics/biometry, biochemical systematics, experimental systematics) that classify organisms based on statistics, molecular/biochemical characteristics, and evolutionary units\u2014complementing each other in revealing evolutionary relationships.",
        "Concept 3: The field has practical applications in documenting biodiversity (extinct and living), taxonomy practices (names, classifications), conservation, and management through biological control, illustrating how understanding phylogeny informs real-world decisions."
      ],
      "parent_concepts": [
        "Concept 1: Phylogenetic inference uses observable, heritable data to reconstruct evolutionary relationships and yields a phylogenetic tree as a diagram of inferred history.",
        "Concept 1: Homologous structures across diverse species reflect shared ancestry and are used to infer evolutionary relationships (phylogeny)."
      ],
      "parent_articles": [
        "Phylogenetics",
        "Comparative anatomy"
      ]
    },
    {
      "question": "How does the distinction between well-defined and ill-defined problems shape a solver's planning approach, and why does this difference arise in terms of goal clarity and representation?",
      "options": {
        "A": "Well-defined problems allow upfront, structured planning with explicit goals and constraints, enabling decomposition into subgoals; ill-defined problems require iterative reframing and flexible representations with ongoing goal clarification as the problem evolves.",
        "B": "Well-defined problems require frequent goal redefinition and varied representations; ill-defined problems enable a fixed, step-by-step plan from the start.",
        "C": "For well-defined problems, heuristics are unnecessary because the path is obvious; for ill-defined problems, heuristics must be avoided to prevent bias.",
        "D": "The planning approach is the same for both types; only the evaluation criteria at the end differ, so no reframing is needed."
      },
      "correct_answer": "A",
      "source_article": "Problem solving",
      "x": 1.3369420766830444,
      "y": 1.0390950441360474,
      "concepts_tested": [
        "Concept 1: Well-defined vs ill-defined problems and how they shape planning and solution strategies.",
        "Concept 2: Cognitive obstacles to problem solving (e.g., confirmation bias, mental set, functional fixedness) and approaches to overcome them.",
        "Concept 3: The role of resources, knowledge, and domain-specific techniques in enabling problem solving (professional skills, cross-domain methods, and the study of mental processes)."
      ],
      "parent_concepts": [
        "Concept 2: Designing is an iterative process comprising activities such as research, negotiation, reflection, modeling, and re-design, with variable duration and complexity.",
        "Concept 3: Design is a universal cognitive function (\u201ceveryone designs\u201d) and can be framed as a process of changing situations into preferred ones, not solely the work of professional designers."
      ],
      "parent_articles": [
        "Design",
        "Design"
      ]
    },
    {
      "question": "Why does recognizing innovation as a multi-stage process that yields measurable outcomes help organizations manage uncertainty and maximize value?",
      "options": {
        "A": "It implies value is generated exclusively at the point of first idea generation, making later stages unnecessary.",
        "B": "It emphasizes learning through iterative cycles, where value is progressively realized as ideas are tested, refined, and scaled across stages.",
        "C": "It eliminates the need to assess market viability until the final stage, saving time.",
        "D": "It fixes value creation to the initial concept\u2019s novelty, ignoring execution."
      },
      "correct_answer": "B",
      "source_article": "Innovation",
      "x": 1.342685341835022,
      "y": 0.9927322268486023,
      "concepts_tested": [
        "Concept 1: Innovation is the practical implementation of ideas that creates value, and it is not solely defined by new invention.",
        "Concept 2: Innovation is a multi-stage process that yields outcomes (new/improved products, services, processes, etc.) and can be seen as both a process and an outcome.",
        "Concept 3: The two-dimensional framework of innovation: degree of novelty (new to firm, market, industry, or world) and kind of innovation (process vs product-service system)."
      ],
      "parent_concepts": [
        "Concept 2: Designing is an iterative process comprising activities such as research, negotiation, reflection, modeling, and re-design, with variable duration and complexity.",
        "Concept 3: Design is a universal cognitive function (\u201ceveryone designs\u201d) and can be framed as a process of changing situations into preferred ones, not solely the work of professional designers.",
        "application relationship: life-science discoveries contribute to health, agriculture, medicine, and pharmaceutical/food industries, showing the link between basic disciplines and real-world outcomes."
      ],
      "parent_articles": [
        "Design",
        "Design",
        "List of life sciences"
      ]
    },
    {
      "question": "In aesthetics, disinterested pleasure is said to detach aesthetic judgment from practical concerns. How does this disinterested pleasure function mechanism-wise, and why is that detachment valuable for evaluating a work of art?",
      "options": {
        "A": "Disinterested pleasure ties judgment to the object's practical usefulness, ensuring evaluation tracks function.",
        "B": "Disinterested pleasure directs attention to the work's intrinsic formal qualities (like balance and harmony) for their own sake, independent of any desires for use or outcome, thereby reducing influence from personal goals.",
        "C": "Disinterested pleasure relies on the critic's personal goals to shape the evaluation, making judgments reflect individual aims.",
        "D": "Disinterested pleasure ensures judgments are driven by external moral or social outcomes rather than the artwork's form."
      },
      "correct_answer": "B",
      "source_article": "Aesthetics",
      "x": 1.1195964813232422,
      "y": 1.07779061794281,
      "concepts_tested": [
        "Concept 1: Objectivity vs subjectivity in aesthetic judgments \u2014 Can aesthetic judgments be objective, and what leads to disagreements about taste?",
        "Concept 2: Disinterested pleasure as a feature of aesthetic experience \u2014 Why is disinterested pleasure important, and how does it detach aesthetic judgment from practical concerns?",
        "Concept 3: The three approaches to aesthetics as a framework \u2014 How do concepts/judgments, experiences/responses, and the nature/features of objects relate to each other in studying aesthetics?"
      ],
      "parent_concepts": [
        "Concept 1: Architecture as part of philosophy of art, dealing with aesthetic value, semantics, and its relationship to culture.",
        "The relational positioning of popular culture with respect to folk culture and high culture, including different theoretical perspectives that interpret these relationships.",
        "Concept 1"
      ],
      "parent_articles": [
        "Philosophy of architecture",
        "Popular culture",
        "Graphic design"
      ]
    },
    {
      "question": "Why is disinterested pleasure posited as a hallmark of aesthetic experience, and how does adopting a disinterested stance affect the basis for aesthetic judgments?",
      "options": {
        "A": "It ties aesthetic judgments to practical usefulness, making them depend on utilitarian value.",
        "B": "It frees judgments from personal needs and external goals, directing evaluation toward the object's intrinsic form, relations, and sensory qualities.",
        "C": "It ensures judgments are universally agreed upon because they reflect objective moral facts.",
        "D": "It requires always aligning with the artist's stated intention to derive meaning."
      },
      "correct_answer": "B",
      "source_article": "Aesthetics",
      "x": 1.1312265396118164,
      "y": 1.0766427516937256,
      "concepts_tested": [
        "The objectivity vs. subjectivity of aesthetic properties and judgments",
        "Disinterested pleasure as a hallmark of aesthetic experience",
        "The three main approaches to aesthetics (concepts/judgments, experiences/responses, and nature/features of aesthetic objects) and their implications"
      ],
      "parent_concepts": [
        "Concept 1: Architecture as part of philosophy of art, dealing with aesthetic value, semantics, and its relationship to culture.",
        "The relational positioning of popular culture with respect to folk culture and high culture, including different theoretical perspectives that interpret these relationships.",
        "Concept 1"
      ],
      "parent_articles": [
        "Philosophy of architecture",
        "Popular culture",
        "Graphic design"
      ]
    },
    {
      "question": "In philosophy of culture, suppose there is a universal set of cognitive elements shared by all humans (a psychic unity), but cultures express these elements through distinct worldviews that can be incommensurable. How does this tension explain the outcome of cross-cultural analysis?",
      "options": {
        "A": "Because universal elements determine sameness, cross-cultural analysis should yield identical cultural products across all societies.",
        "B": "Because universal elements provide a common substrate, while worldview-specific modifications produce diverse, potentially incommensurable expressions; cross-cultural analysis can detect shared structures yet must respect interpretive gaps.",
        "C": "Because worldviews are entirely shaped by external factors, universal elements are irrelevant to analysis.",
        "D": "Because the tension eliminates any possibility of cross-cultural comparison, making analysis futile."
      },
      "correct_answer": "B",
      "source_article": "Philosophy of culture",
      "x": 1.1579793691635132,
      "y": 0.9951059818267822,
      "concepts_tested": [
        "The interplay between individual rationality (Enlightenment) and collective creativity (Bildung) as a mechanism shaping culture and cultural identity.",
        "Worldview (Weltanschauung) as a defining structure of culture, including the notion that different groups possess distinct and potentially incommensurable worldviews.",
        "Universal cognitive elements (psychic unity of mankind; elementary ideas) and their tension with cultural particularism in cross-cultural analysis."
      ],
      "parent_concepts": [
        "Concept 1: Architecture as part of philosophy of art, dealing with aesthetic value, semantics, and its relationship to culture."
      ],
      "parent_articles": [
        "Philosophy of architecture"
      ]
    },
    {
      "question": "How do ethical norms influence corporate decision-making when profit-maximization would conflict with non-economic concerns (like stakeholder welfare or social impact), and what mechanism explains this influence?",
      "options": {
        "A": "They replace all legal requirements with voluntary guidelines, allowing profits to be pursued without constraint.",
        "B": "They shift the expected payoff of actions by adding reputational and legitimacy costs, causing non-economic concerns to become part of the decision-maker\u2019s objective function.",
        "C": "They guarantee longer-term profits by enforcing a universal ethical outcome, regardless of market conditions.",
        "D": "They remove the need for any governance or oversight, since ethics alone will ensure optimal decisions."
      },
      "correct_answer": "B",
      "source_article": "Business ethics",
      "x": 1.3131933212280273,
      "y": 0.9498445391654968,
      "concepts_tested": [
        "Concept 1: The normative vs. descriptive dimensions of business ethics and how they guide or describe business behavior.",
        "Concept 2: The relationship between profit-maximizing behavior and non-economic (ethical, social) concerns, and how ethical norms mediate or influence corporate decision-making.",
        "Concept 3: Organizational mechanisms for ethical governance (ethics codes, social responsibility charters, ethics regimes) and their role alongside or beyond legal regulation."
      ],
      "parent_concepts": [
        "Concept 3: Ethical/CSR orientation \u2014 why stakeholders' needs should be prioritized in action and how this reshapes traditional, shareholder-focused decision making."
      ],
      "parent_articles": [
        "Stakeholder theory"
      ]
    },
    {
      "question": "Creating Shared Value (CSV) explains a link between social impact and profitability by which mechanism?",
      "options": {
        "A": "Donating profits to social causes to boost brand goodwill and long-term reputation.",
        "B": "Reconfiguring the firm's value chain to address a social need in a way that lowers costs, creates new revenue, or opens new markets.",
        "C": "Meeting regulatory ESG reporting requirements to avoid fines and penalties.",
        "D": "Isolating social programs from core business decisions to prevent distraction from profit goals."
      },
      "correct_answer": "B",
      "source_article": "Corporate social responsibility",
      "x": 1.3208461999893188,
      "y": 0.9089879989624023,
      "concepts_tested": [
        "Strategic CSR and stakeholder alignment as a driver of firm performance",
        "Creating Shared Value (CSV) as a model linking social impact to profitability",
        "CSR governance mechanisms: self-regulation, ESG reporting, standards, and government incentives"
      ],
      "parent_concepts": [
        "Concept 3: Ethical/CSR orientation \u2014 why stakeholders' needs should be prioritized in action and how this reshapes traditional, shareholder-focused decision making.",
        "The triple bottom line as an integrated, interrelated framework that broadens the traditional profit focus to include social and environmental performance."
      ],
      "parent_articles": [
        "Stakeholder theory",
        "Triple bottom line"
      ]
    },
    {
      "question": "The local continuity equation for a conserved density \u03c1 and its flux J is \u2202\u03c1/\u2202t + \u2207\u00b7J = 0. Which statement best explains why this expresses local conservation and how it constrains what can happen inside a fixed volume?",
      "options": {
        "A": "It says a region's density can change arbitrarily as long as the flux adjusts elsewhere, so global conservation is not enforced locally.",
        "B": "It says the time rate of change of \u03c1 at a point is determined by the divergence of J, linking a local change to transport, and the total amount in any fixed volume changes only by the net flux through its boundary.",
        "C": "It says J must be identically zero everywhere for \u03c1 to be conserved, forcing no transport.",
        "D": "It says local changes in \u03c1 are independent of transport, implying conservation is a global rather than local property."
      },
      "correct_answer": "B",
      "source_article": "Conservation law",
      "x": 1.726457118988037,
      "y": 1.1270138025283813,
      "concepts_tested": [
        "Concept 1: Noether's theorem\u2014the link between differentiable symmetries (e.g., time translation, space isotropy) and local conservation laws.",
        "Concept 2: Local conservation laws are described by continuity equations, expressing changes in a quantity as due to transport in/out of a region.",
        "Concept 3: Conservation laws can be exact or approximate, depending on the process/class of interactions and domains."
      ],
      "parent_concepts": [
        "Concept 1: The continuum hypothesis and use of differential equations to model conservation laws (mass, momentum, energy) for bulk materials."
      ],
      "parent_articles": [
        "Continuum mechanics"
      ]
    },
    {
      "question": "In a federal constitutional framework, how are powers allocated and conflicts between national and subnational governments resolved, and why is this mechanism necessary for a functioning state?",
      "options": {
        "A": "By giving the national government unlimited powers to override subnational laws in all matters, eliminating subnational sovereignty and local variation.",
        "B": "By placing the federal constitution above both levels and relying on centralized adjudication to force uniformity, potentially eroding local autonomy.",
        "C": "By dividing powers into exclusive, concurrent, and residual categories and providing independent courts or constitutional tribunals to adjudicate disputes, enabling both a unified framework and local autonomy.",
        "D": "By letting subnational units retain complete sovereignty and exempting them from any federal regulation, ensuring maximal local autonomy but leaving coordination gaps."
      },
      "correct_answer": "C",
      "source_article": "Constitutional law",
      "x": 1.1771583557128906,
      "y": 0.7925319671630859,
      "concepts_tested": [
        "Concept 1: Allocation and hierarchy of governmental powers (separation of powers and federal vs. unitary structures)",
        "Concept 2: Sources of constitutional rules (codified vs. uncodified constitutions; role of conventions, statutes, customary law, and international law)",
        "Concept 3: Rights and limits on government action (how constitutions grant powers like taxation/spending while also protecting individual rights)"
      ],
      "parent_concepts": [
        "Concept 3: Historical and institutional development of proportionality (origin in German administrative law and its adoption into constitutional law), illustrating how a principle becomes a testable framework.",
        "Concept 3: Defendants\u2019 procedural rights (knowing the charges, timely appearance, right to counsel) as mechanisms to ensure fair process and affect outcomes."
      ],
      "parent_articles": [
        "Proportionality (law)",
        "Criminal procedure"
      ]
    },
    {
      "question": "How does the rule of law function to prevent arbitrary governance, and what roles do constitutionalism and the Rechtsstaat play in making that mechanism effective?",
      "options": {
        "A": "By allowing rulers to adapt the legal rules for each case to achieve political aims, with little constraint from institutions.",
        "B": "By requiring that the same legal rules bind everyone, including those in power, and by instituting stable procedures and independent institutions (e.g., a judiciary) that can review and restrain power; constitutionalism and the Rechtsstaat formalize these constraints.",
        "C": "By prioritizing rapid policy change over predictability, while constitutionalism and the Rechtsstaat focus on preserving a static legal order.",
        "D": "By equating legal validity with political consent alone, bypassing any independent check or rights protection."
      },
      "correct_answer": "B",
      "source_article": "Rule of law",
      "x": 1.223412036895752,
      "y": 0.8386356830596924,
      "concepts_tested": [
        "Concept 1: Equality before the law and nonarbitrary governance as the core principle of the rule of law",
        "Concept 2: Formalist vs. substantivist conceptions, including how laws should be stable, accessible, clear, and how rights and international law broaden the concept",
        "Concept 3: Relationship to other political-legal ideas (rule of law vs rule of man; links to constitutionalism and Rechtsstaat)"
      ],
      "parent_concepts": [
        "Concept 3: Historical and institutional development of proportionality (origin in German administrative law and its adoption into constitutional law), illustrating how a principle becomes a testable framework.",
        "Concept 3: Defendants\u2019 procedural rights (knowing the charges, timely appearance, right to counsel) as mechanisms to ensure fair process and affect outcomes.",
        "Mechanisms and procedures that constrain power and safeguard citizens\u2019 rights, including minority protections",
        "Concept 1: Direct democracy vs. representative democracy, and the institutional mechanisms (constitution and supreme court) that constrain majority power to protect minority rights.",
        "Concept 3: Mutually related rights and obligations and collective enforcement as the basis of social order (e.g., how shared expectations and enforcement mechanisms sustain institutional functioning).",
        "Legal mechanisms for protection: how the force of law, due process, and administrative justice operationalize and safeguard these rights, including the right to redress.",
        "Concept 1: The role of commercial law in creating orderly, enforceable, and predictable exchanges to support fair competition and public trust."
      ],
      "parent_articles": [
        "Proportionality (law)",
        "Criminal procedure",
        "Constitutionalism",
        "Democracy",
        "Institution",
        "Civil and political rights",
        "Commercial law"
      ]
    },
    {
      "question": "Why does administrative law structure rulemaking, adjudication, and enforcement as distinct functional activities within government agencies rather than letting a single unit perform all three?",
      "options": {
        "A": "To maximize speed of policy changes by keeping all decisions centralized in one body.",
        "B": "To create checks and balances, ensure due process, and apply specialized expertise, so rules are made, applied, and reviewed in ways that limit bias and arbitrary decision-making.",
        "C": "To prevent any possibility of public participation in how laws are implemented.",
        "D": "To align administrative practice with private-law court procedures for consistency across sectors."
      },
      "correct_answer": "B",
      "source_article": "Administrative law",
      "x": 1.2349334955215454,
      "y": 0.7999059557914734,
      "concepts_tested": [
        "Concept 1: The core mechanisms of administrative law (rulemaking, adjudication, enforcement) as the functional activities of executive branch agencies.",
        "Concept 2: The civil law tradition\u2019s use of specialized administrative courts and procedures tailored to administrative cases, highlighting institutional design differences from private-law proceedings.",
        "Concept 3: The influence of supranational or international legal orders on domestic administrative law, driving changes in concepts like judicial control and the development of international/public administration."
      ],
      "parent_concepts": [
        "Concept 3: Historical and institutional development of proportionality (origin in German administrative law and its adoption into constitutional law), illustrating how a principle becomes a testable framework."
      ],
      "parent_articles": [
        "Proportionality (law)"
      ]
    },
    {
      "question": "In legal positivism, why is there no necessary connection between what the law is and what the law ought to be, and how does this shape the way analytic jurisprudence studies legal validity?",
      "options": {
        "A": "Because legal validity is determined by social sources and a recognized rule of recognition, not by moral evaluation; analytic jurisprudence thus analyzes the law's origins, adoption, and institutional status rather than assessing its morality.",
        "B": "Because morality fixes the content of law, analytic jurisprudence must evaluate laws on ethical grounds to determine whether they are valid.",
        "C": "Because there is a universal moral standard that law should meet, analytic jurisprudence cannot separate analysis from normative judgment.",
        "D": "Because law is an arbitrary decree of the sovereign, normative questions are irrelevant to legal analysis."
      },
      "correct_answer": "A",
      "source_article": "Jurisprudence",
      "x": 1.2243205308914185,
      "y": 0.8631913661956787,
      "concepts_tested": [
        "The analytic vs normative (and natural law vs legal positivism) debate about whether law and what it ought to be are necessarily connected, shaping how we study law.",
        "The normative function of law: what the law should do, which acts to sanction, and what punishments are permitted, reflecting the purpose and moral/political foundations of law.",
        "Law as a social institution: how jurisprudence analyzes law in light of social scientific knowledge, including cross-cultural variation and empirical study (sociological and experimental approaches)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does natural law theory claim that human-made laws derive their legitimacy from universal moral principles discoverable by reason, rather than from mere custom or authority?",
      "options": {
        "A": "Because reason can uncover universal moral norms grounded in human nature, which provide objective basis for legality; laws aligning with these norms gain binding force, while those violating them are illegitimate.",
        "B": "Because natural law holds that legality is entirely determined by the ruler's fiat, regardless of moral content.",
        "C": "Because natural law asserts that morality is merely a function of cultural custom and changes with time, making all laws legitimate if enforced.",
        "D": "Because natural law equates law with written statutes alone and claims enforcement guarantees legitimacy."
      },
      "correct_answer": "A",
      "source_article": "Natural law",
      "x": 1.2406854629516602,
      "y": 0.9755663275718689,
      "concepts_tested": [
        "Natural law consists of inherent, universal moral standards that can be discovered through reason, grounding intrinsic human rights.",
        "Natural law provides a relationship to positive law by undergirding and informing human-made laws, and it has been used to justify political theories (e.g., social contract) and rights, in opposition to legal positivism.",
        "The historical development and transmission of natural law across thinkers and eras (from ancient philosophers to Aquinas to the Enlightenment) shape its conceptual role in modern rights theory and jurisprudence."
      ],
      "parent_concepts": [
        "Concept 1: The distinction between natural rights and legal rights, including their bases (human nature vs. law) and implications for universality and context-dependence."
      ],
      "parent_articles": [
        "Rights"
      ]
    },
    {
      "question": "Why does the relational axiom claim that social phenomena should be understood through the properties of relations between actors rather than through the actors' attributes alone?",
      "options": {
        "A": "Because an actor\u2019s influence and exposure depend on their position and connections in the network, which shape interaction patterns and outcomes beyond what any single attribute would predict.",
        "B": "Because actor attributes alone determine outcomes; relations do not provide additional predictive value.",
        "C": "Because simply having ties assigns fixed roles that dominate personal choice, making the actor\u2019s attributes irrelevant.",
        "D": "Because diffusion is purely random and the network structure has no systematic effect."
      },
      "correct_answer": "A",
      "source_article": "Social network",
      "x": 1.2613211870193481,
      "y": 1.0176749229431152,
      "concepts_tested": [
        "The relational axiom: social phenomena should be understood through the properties of relations (ties) between actors, not solely by the attributes of the actors themselves.",
        "Structure-driven patterns and dynamics: local and global patterns, influence, and the spread of information arise from the network's architecture, linking cause (structure) to effect (patterns/outcomes).",
        "Foundational models and methods: triads, sociograms, and graph-theoretic formalization provide the theoretical and methodological framework for analyzing social networks."
      ],
      "parent_concepts": [
        "The role of communication channels and social capital in mediating diffusion within a social system."
      ],
      "parent_articles": [
        "Diffusion of innovations"
      ]
    },
    {
      "question": "How does social capital translate interpersonal trust and reciprocal expectations into sustained cooperation that yields public goods, particularly in diverse groups?",
      "options": {
        "A": "By creating formal penalties that deter defection more effectively than informal norms do.",
        "B": "By aligning individual incentives with shared norms so that actors anticipate reciprocity, lowering transaction costs and enabling cooperative action even when formal institutions are weak.",
        "C": "By concentrating decision-making in a single trusted leader who dictates all collective actions.",
        "D": "By encouraging members to pursue their own private interests unless coercive controls are present."
      },
      "correct_answer": "B",
      "source_article": "Social capital",
      "x": 1.2458597421646118,
      "y": 0.9833537340164185,
      "concepts_tested": [
        "Social capital as productive networks built on interpersonal relationships, shared identity, norms, and trust that enable cooperative action and generate public goods.",
        "Mechanisms by which social capital affects outcomes (e.g., performance in diverse groups, entrepreneurial firms, managerial performance, supply chain relations) through cooperation and reciprocity.",
        "The broader, historical/philosophical grounding of social capital (associational life, democracy, debates about modernization) as a conceptual framework linking social structure to collective outcomes."
      ],
      "parent_concepts": [
        "The role of communication channels and social capital in mediating diffusion within a social system.",
        "Concept 2: Inside-out, community-centered process (citizens as actors, importance of listening/asking, and broad-based involvement) (how local ownership and relationships drive development)."
      ],
      "parent_articles": [
        "Diffusion of innovations",
        "Asset-based community development"
      ]
    },
    {
      "question": "How do probabilistic network models (e.g., Erd\u0151s\u2013R\u00e9nyi random graphs or p*-type models) enable predictive understanding of real-world networks?",
      "options": {
        "A": "They guarantee exact replication of a specific real network if enough data about past edges is available.",
        "B": "They encode simple probabilistic rules for edge formation that translate into predictable global properties (like degree distribution and connectivity), allowing predictions from limited information.",
        "C": "They assume all edges are perfectly determined by node attributes and thus remove any randomness from edge formation.",
        "D": "They require complete, exact knowledge of every historical edge to forecast future links."
      },
      "correct_answer": "B",
      "source_article": "Network science",
      "x": 1.6056965589523315,
      "y": 1.1699597835540771,
      "concepts_tested": [
        "Concept 1: Networks as relational structures composed of nodes and edges, enabling representation and analysis of complex phenomena across disciplines.",
        "Concept 2: Graph-theoretic and probabilistic frameworks (e.g., Erd\u0151s\u2013R\u00e9nyi random graphs, network probability models, p*) as mechanisms to model edge formation and network properties to support predictive modeling.",
        "Concept 3: Multidisciplinary evolution of network science (from graph theory to sociograms to predictive network models) showing how theories from mathematics, physics, computer science, statistics, and sociology coalesce to study complex networks."
      ],
      "parent_concepts": [
        "The role of communication channels and social capital in mediating diffusion within a social system."
      ],
      "parent_articles": [
        "Diffusion of innovations"
      ]
    },
    {
      "question": "From a dynamic-systems perspective in developmental psychology, why can a small change in a child's social context lead to large, cascading changes across physical, cognitive, and social-emotional domains?",
      "options": {
        "A": "Because brain maturation imposes rigid domain boundaries, preventing cross-domain influence.",
        "B": "Because development arises from continuous, reciprocal interactions among multiple subsystems and contexts, so a perturbation in one part can reorganize the entire system.",
        "C": "Because each domain develops in isolation and only responds to domain-specific training.",
        "D": "Because contextual effects are only relevant in early life and fade with age."
      },
      "correct_answer": "B",
      "source_article": "Developmental psychology",
      "x": 1.2724337577819824,
      "y": 1.0051342248916626,
      "concepts_tested": [
        "Concept 1: Nature\u2013nurture interactions and context-dependent development across the lifespan",
        "Concept 2: Interrelation and co-development of physical, cognitive, and social-emotional domains",
        "Concept 3: Theoretical frameworks for development (stage-based vs dynamic-systems) and the role of context (lifespan/ecological factors) in explaining development"
      ],
      "parent_concepts": [
        "Concept 2: Developmental timing (extended dependence on adults in humans) creates a window that enables cultural learning and accumulation.",
        "Concept 1: Gene-environment interaction in development (maturation vs. environmental learning and their interdependence)",
        "Concept 2: Role of stable, supportive caregiver relationships and emotional climate in shaping emotional regulation and overall development",
        "Secure base and exploration: how a caregiver\u2019s sensitivity and responsiveness create a secure base that supports a child\u2019s exploration and returns for comfort.",
        "Attachment patterns and assessment framework: the categorization of attachment (secure, avoidant, anxious, disorganized) and the role of procedures like the Strange Situation in identifying these patterns."
      ],
      "parent_articles": [
        "Cultural learning",
        "Child development",
        "Child development",
        "Attachment theory",
        "Attachment theory"
      ]
    },
    {
      "question": "In life-history theory, why would higher adult mortality risk push energy allocation toward earlier reproduction at the expense of further growth, and what mechanism explains this shift?",
      "options": {
        "A": "Because the probability of surviving to future breeding opportunities decreases, the expected lifetime offspring gained from delaying reproduction declines; investing earlier maximizes the number of offspring produced over the lifetime under these survival constraints.",
        "B": "Because high adult mortality makes individuals invest more in growth to reach a larger size before reproducing, since larger individuals always have higher fecundity.",
        "C": "Because resource constraints fix a single allocation plan between growth, reproduction, and survival that is unaffected by mortality risk.",
        "D": "Because high mortality reduces selective pressure on reproduction, leading to a strategy of prolonged growth and delayed reproduction."
      },
      "correct_answer": "A",
      "source_article": "Life history theory",
      "x": 1.8210111856460571,
      "y": 1.1012256145477295,
      "concepts_tested": [
        "Concept 1: Allocation trade-offs across growth, reproduction, and survival shaped by the physical and ecological environment (why/how environment influences resource allocation to different life-history demands).",
        "Concept 2: Timing of key life events (e.g., maturation age, first reproduction, parental investment, senescence) is driven by optimizing evolutionary fitness under ecological constraints (why/how ecological conditions alter life-history schedules).",
        "Concept 3: The use of models and cross-generational fitness measures (genetic and phenotypic approaches) to generate testable predictions about life-history evolution (how models help explain and predict life-history outcomes)."
      ],
      "parent_concepts": [
        "Concept 2: Developmental timing (extended dependence on adults in humans) creates a window that enables cultural learning and accumulation."
      ],
      "parent_articles": [
        "Cultural learning"
      ]
    },
    {
      "question": "Why does the Brundtland definition include \"limitations imposed by the state of technology and social organization\" in the environment's capacity to meet present and future needs, and how does this shape policy design?",
      "options": {
        "A": "It implies that natural resources are infinite, so policies emphasize only rapid exploitation to maximize current generation welfare.",
        "B": "It acknowledges that present and future capacities depend on what technologies exist and how institutions organize society; policies must invest in scalable technologies, build adaptive institutions, and manage trade-offs to stay within environmental limits while expanding welfare for both current and future generations.",
        "C": "It suggests that only social equality matters, and environmental limits can be ignored if technology is advanced.",
        "D": "It asserts that future needs will always be met regardless of current actions, so policies should delay sustainability investments."
      },
      "correct_answer": "B",
      "source_article": "Sustainable development",
      "x": 1.3859723806381226,
      "y": 0.8594087958335876,
      "concepts_tested": [
        "Concept 1: Balance among economy, environment, and society (the triple nexus) and how trade-offs between these pillars are managed.",
        "Concept 2: Intergenerational equity embedded in the Brundtland definition\u2014the idea that present needs (especially for the world's poor) must be met without compromising the future, considering limits imposed by technology and social organization.",
        "Concept 3: Relationship between sustainable development and sustainability, and how processes, pathways, and global frameworks (e.g., Rio Process, SDGs) operationalize the broader goal."
      ],
      "parent_concepts": [
        "Integration of environmental, social, and economic dimensions in policy: environment, quality of life, health, resource management, and biodiversity as interconnected policy considerations.",
        "Interdependence of hard infrastructure, soft infrastructure, and governance",
        "Concept 1: Integration of farming with natural biological cycles and efficient use of on-farm and nonrenewable resources to sustain agricultural viability and environmental quality.",
        "Concept 2: Relationship between farming practices and ecosystem services, and the aim to prevent adverse effects on soil, water, biodiversity, and human communities.",
        "Concept 3: Land sparing versus land sharing as strategies to balance high-yield production with conservation of natural habitats within sustainable agriculture.",
        "The triple bottom line as an integrated, interrelated framework that broadens the traditional profit focus to include social and environmental performance."
      ],
      "parent_articles": [
        "Environmental policy",
        "Infrastructure",
        "Sustainable agriculture",
        "Sustainable agriculture",
        "Sustainable agriculture",
        "Triple bottom line"
      ]
    },
    {
      "question": "Why does informational social influence tend to produce private acceptance of beliefs, whereas normative social influence tends to produce public conformity without necessarily changing private beliefs?",
      "options": {
        "A": "Informational influence provides evidence about reality, prompting private belief change; normative influence evokes a desire to be liked, prompting outward conformity without guaranteed private belief change.",
        "B": "Informational influence relies on normative pressure, leading to private belief change; normative influence relies on evidence about reality, leading to private acceptance.",
        "C": "Informational influence leads to stable attitude shifts and long-term changes; normative influence leads only to temporary behavior changes.",
        "D": "Informational influence works only when there is consensus among others; normative influence works only when there is ambiguity in the situation."
      },
      "correct_answer": "A",
      "source_article": "Social influence",
      "x": 1.2519878149032593,
      "y": 1.0065126419067383,
      "concepts_tested": [
        "Concept 1: Kelman\u2019s three processes of attitude change (compliance, identification, internalization) and how they differ in public behavior vs. private belief.",
        "Concept 2: The distinction between informational vs. normative social influence, including when each operates and their typical outcomes (private acceptance vs. public conformity).",
        "Concept 3: The motivational bases for conformity (need to be right vs. need to be liked) and how they map onto the two types of influence and their effects."
      ],
      "parent_concepts": [
        "Concept 1: Leadership as a process of social influence and a power-relationship between leaders and followers that drives change or task accomplishment.",
        "Distinct forms of persuasion (propaganda, coercion, systematic persuasion, heuristic persuasion) as different mechanisms with unique approaches"
      ],
      "parent_articles": [
        "Leadership",
        "Persuasion"
      ]
    },
    {
      "question": "In the balance-of-power perspective, why does stability between two actors arise from relative strengths and mutual constraints rather than from any actor's absolute power?",
      "options": {
        "A": "Because legitimacy always mirrors absolute power, enabling the stronger actor to enforce compliance.",
        "B": "Because the total amount of power in a system is fixed, so one actor\u2019s gain necessarily reduces the other\u2019s power.",
        "C": "Because each actor\u2019s ability to compel or deter actions depends on the other\u2019s capacity to resist, making outcomes a product of interdependent constraints.",
        "D": "Because institutions can completely immunize power from change, ensuring outcomes remain static regardless of relative strengths."
      },
      "correct_answer": "C",
      "source_article": "Power (social and political)",
      "x": 1.2417422533035278,
      "y": 0.968173086643219,
      "concepts_tested": [
        "Power as relational and diffuse (including structural and discursive forms; legitimacy of authority)",
        "Classification of power tactics (soft vs hard, rational vs nonrational, unilateral vs bilateral) and how contexts/personality influence use",
        "Balance of power as a relational constraint framework (relative strengths, stability, and constraint rather than absolute power)"
      ],
      "parent_concepts": [
        "Concept 1: Leadership as a process of social influence and a power-relationship between leaders and followers that drives change or task accomplishment.",
        "Concept 1: Politics as mechanisms of decision-making and resource/status distribution within power relations (negotiation, lawmaking, force) and how these mechanisms produce specific political outcomes."
      ],
      "parent_articles": [
        "Leadership",
        "Politics"
      ]
    },
    {
      "question": "In a group task, the group solution often outperforms any individual member. Which mechanism best explains this emergent property (holism) of groups?",
      "options": {
        "A": "Information pooling across members combines diverse, independent information and reduces individual biases, producing a synthesis that exceeds any one member.",
        "B": "The group converges on the solution proposed by the most vocal member, regardless of other inputs.",
        "C": "The group's decision mirrors the average of individual preferences, with no new properties emerging.",
        "D": "Social loafing reduces individual effort, weakening overall performance."
      },
      "correct_answer": "A",
      "source_article": "Group dynamics",
      "x": 1.2570618391036987,
      "y": 0.9935538172721863,
      "concepts_tested": [
        "Emergent properties of groups (holism): group behavior and qualities that cannot be deduced from individuals alone.",
        "Group-level mechanisms/forces: positive and negative forces within groups that shape behavior (e.g., status, reciprocity, ostracism, leadership, group decision).",
        "Intergroup relations and social regulation mechanisms: how groups manage cooperation, accountability, and conflict (identifying cheaters, altruism, intergroup dynamics)."
      ],
      "parent_concepts": [
        "Concept 1: Leadership as a process of social influence and a power-relationship between leaders and followers that drives change or task accomplishment.",
        "Concept 2: Structured collaboration methods and social/egalitarian leadership influence success by improving behavior, communication, and collaborative problem-solving.",
        "Concept 2: Cohesion and communication as core mechanisms that drive effective teamwork and help overcome obstacles or resolve conflict, influencing performance.",
        "Concept 3: Role clarity and resource availability as enabling factors that support efficient collaboration within teams."
      ],
      "parent_articles": [
        "Leadership",
        "Collaboration",
        "Teamwork",
        "Teamwork"
      ]
    },
    {
      "question": "Why are property rights generally not treated as absolute, and how does a rule-of-law approach justify and constrain limitations to preserve legitimacy?",
      "options": {
        "A": "Because property ownership is a private preference with no social function, so the state may revoke property at any time.",
        "B": "Because the right to property is understood as including protection against arbitrary deprivation but not absolute; states may regulate, tax, or expropriate property to serve a legitimate public interest, provided actions are lawful, necessary, and proportionate.",
        "C": "Because the state must always expropriate property whenever there is a perceived public need, without any due process.",
        "D": "Because only corporations have property rights; individuals do not."
      },
      "correct_answer": "B",
      "source_article": "Right to property",
      "x": 1.2504724264144897,
      "y": 0.8289095759391785,
      "concepts_tested": [
        "Concept 1: The right to property comprises the entitlement to own property (individually or in association) and protection against arbitrary deprivation.",
        "Concept 2: Property rights are not absolute; they may be limited by public interest through mechanisms like regulations, taxation, and nationalisation.",
        "Concept 3: The scope and status of property rights are contested and vary by context, including which entities qualify as holders (individuals vs. corporations) and which kinds of property are protected, across different international instruments and regions."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In a knowledge economy, why do specialized and adaptable human capital become the core drivers of economic development?",
      "options": {
        "A": "They enable mass production of identical goods with less reliance on physical resources.",
        "B": "They allow firms to continually create, integrate, and apply new knowledge, solve novel problems, and reconfigure capabilities as markets change, which cannot be easily replicated by physical capital alone.",
        "C": "They primarily improve static efficiency by enforcing standardized routines across all firms.",
        "D": "They reduce the need for collaboration, since skilled individuals can work completely independently."
      },
      "correct_answer": "B",
      "source_article": "Knowledge economy",
      "x": 1.3107376098632812,
      "y": 0.9838825464248657,
      "concepts_tested": [
        "Concept 1: Knowledge and intangible assets become the principal sources of value, reducing reliance on physical resources.",
        "Concept 2: Human capital and specialized, adaptable skills are the core drivers of economic development in a knowledge economy.",
        "Concept 3: Intellectual property and information assets play a central role in growth, linking the knowledge economy to the information/digital economy and Information Age."
      ],
      "parent_concepts": [
        "Concept 1: Intellectual property as the core economic mechanism of the creative industries (exchange of finance for rights in IP) and its link to wealth and job creation."
      ],
      "parent_articles": [
        "Creative industries"
      ]
    },
    {
      "question": "How does the universality of human rights interact with cultural relativism in practice, and what mechanism in international law mediates this tension?",
      "options": {
        "A": "Universality imposes a fixed set of norms regardless of local culture, and cultural relativism fully rejects any universal standard.",
        "B": "Universality and cultural relativism are identical; there is no mechanism needed because culture doesn't matter for rights.",
        "C": "International law establishes a baseline of core, non-derogable rights that cannot be overridden by cultural practices, while other rights can be progressively realized and interpreted within local contexts; monitoring bodies help ensure adherence and address violations.",
        "D": "Cultural relativism overrides universality, leading to no enforcement; rights are not monitored."
      },
      "correct_answer": "C",
      "source_article": "Human rights",
      "x": 1.1500259637832642,
      "y": 0.8392872214317322,
      "concepts_tested": [
        "Concept 1: Universal and inalienable nature of human rights as a guiding principle and baseline for equality.",
        "Concept 2: Mechanisms of protection and promotion (national/international law, the UDHR as a framework, treaties, and monitoring institutions like the United Nations and NGOs).",
        "Concept 3: Relationships and tensions between universality and cultural/contextual variation (cultural relativism, implementation across cultures, and the historical shift after WWII)."
      ],
      "parent_concepts": [
        "Concept 2: Digital privacy as an extension of the privacy right and the role of law and policy in protecting it amid technological change",
        "Mechanisms and procedures that constrain power and safeguard citizens\u2019 rights, including minority protections",
        "Legal mechanisms for protection: how the force of law, due process, and administrative justice operationalize and safeguard these rights, including the right to redress."
      ],
      "parent_articles": [
        "Privacy",
        "Constitutionalism",
        "Civil and political rights"
      ]
    },
    {
      "question": "Why do privacy protections enshrined in law matter for both deterring invasions and enabling redress, beyond what social norms or voluntary policies can achieve?",
      "options": {
        "A": "They establish enforceable obligations and formal remedies that deter violators and provide a pathway for individuals to seek redress when violations occur.",
        "B": "They guarantee that no invasion can happen due to universal compliance.",
        "C": "They rely entirely on social norms, so laws are redundant.",
        "D": "They apply only to digital data, not bodily privacy."
      },
      "correct_answer": "A",
      "source_article": "Privacy",
      "x": 1.271323561668396,
      "y": 0.9405451416969299,
      "concepts_tested": [
        "Concept 1: Privacy as control of personal information and bodily integrity, enabling selective self-expression.",
        "Concept 2: The relationship between privacy, security, and legal rights (invasions, protections enshrined in laws/constitutions).",
        "Concept 3: Digital privacy as an extension of privacy concepts, including technological protections (encryption, anonymity) and methods of intrusion."
      ],
      "parent_concepts": [
        "The conceptual distinction between surveillance (typically overt and legal) and espionage (covert and often illegal), and the regulatory/ethical implications."
      ],
      "parent_articles": [
        "Surveillance"
      ]
    },
    {
      "question": "How does information lifecycle ethics explain why ethical obligations extend beyond the creator to include fair access and responsible handling during distribution and processing?",
      "options": {
        "A": "It claims that once information is created, ethical issues crystallize and distribution is only a technical step.",
        "B": "It asserts that only privacy and confidentiality matter, not access or rights to use.",
        "C": "It holds that information ethics sees rights and duties as emerging from the entire lifecycle; restricting distribution or processing can worsen digital inequality, so ethical practice requires balancing ownership with broad, responsible access and use.",
        "D": "It argues that librarians\u2019 duties suffice, so the rest of the lifecycle is ethically neutral."
      },
      "correct_answer": "C",
      "source_article": "Information ethics",
      "x": 1.2110886573791504,
      "y": 0.9982083439826965,
      "concepts_tested": [
        "Concept 1: Information lifecycle ethics and rights (creation, collection, recording, distribution, processing; ownership, copyright, digital divide, digital rights) and the ethical obligations they entail.",
        "Concept 2: Moral agency in the infosphere (whether artificial agents can be moral and how that possibility affects information ethics).",
        "Concept 3: Interdisciplinary relationships and frameworks (how information ethics relates to computer ethics, medical ethics, journalism, AI, big data ethics, and the role of information professionals in disseminating information responsibly)."
      ],
      "parent_concepts": [
        "The conceptual distinction between surveillance (typically overt and legal) and espionage (covert and often illegal), and the regulatory/ethical implications."
      ],
      "parent_articles": [
        "Surveillance"
      ]
    },
    {
      "question": "Which statement best explains the distinction between procedural due process and substantive due process, and why this distinction is controversial among scholars?",
      "options": {
        "A": "Substantive due process protects certain fundamental rights from government action even when the formal procedures are followed; a central critique is that it can amount to judicial activism by redefining rights and policy choices.",
        "B": "Procedural due process guarantees outcomes by ensuring strict timeliness of hearings, while substantive due process only concerns the procedural steps, not the rights involved.",
        "C": "Substantive due process mirrors the English concept of natural justice and is universally accepted as a clear, objective standard of fairness in all cases.",
        "D": "Procedural due process and substantive due process are identical, and the controversy lies only in terminology used by different legal traditions."
      },
      "correct_answer": "A",
      "source_article": "Due process",
      "x": 1.2572990655899048,
      "y": 0.789294421672821,
      "concepts_tested": [
        "Concept 1: Due process as a constraint that balances government power with the protection of individual rights to ensure fair treatment under the law.",
        "Concept 2: The distinction between procedural due process and substantive due process, and the controversy over whether due process includes fundamental fairness beyond formal procedure.",
        "Concept 3: The historical development and relationship of due process to the rule of law (origin in Magna Carta) and the divergence between English and American legal conceptions."
      ],
      "parent_concepts": [
        "Concept 3: Defendants\u2019 procedural rights (knowing the charges, timely appearance, right to counsel) as mechanisms to ensure fair process and affect outcomes."
      ],
      "parent_articles": [
        "Criminal procedure"
      ]
    },
    {
      "question": "Why does data science place a distinctive emphasis on prediction and action, and how does this emphasis shape its practice relative to traditional statistics or computer science?",
      "options": {
        "A": "Because data science prioritizes theoretical model guarantees over practical usefulness, unlike statistics which focuses on descriptive summaries.",
        "B": "Because data science aims to use models to anticipate future events and inform decisions, requiring attention to data preparation, modeling, validation, and deployment, whereas statistics may focus more on inference from historical data and CS on algorithms without deployment context.",
        "C": "Because data science treats all data as noise and aims to create generic algorithms that work everywhere, ignoring domain specifics.",
        "D": "Because data science is just about building flashy dashboards; prediction and action are secondary considerations."
      },
      "correct_answer": "B",
      "source_article": "Data science",
      "x": 1.3735928535461426,
      "y": 1.0479798316955566,
      "concepts_tested": [
        "Concept 1: Data science as an interdisciplinary integration of statistics, computing, scientific methods, and domain knowledge to extract knowledge from data.",
        "Concept 2: The data science workflow and skill set (preparing data, formulating problems, analyzing data, summarizing findings) spanning computer science, mathematics, visualization, design, communication, and business.",
        "Concept 3: The distinctive emphasis on prediction and action, and the broader, data-driven paradigm that differentiates data science from statistics or computer science."
      ],
      "parent_concepts": [
        "Concept 3: Descriptive statistics describes data, while inferential statistics uses probabilistic models to draw conclusions and test hypotheses, enabling secondary analyses and new studies."
      ],
      "parent_articles": [
        "Mathematical statistics"
      ]
    },
    {
      "question": "In international political economy, how do power relations among states, international organizations, and multinational corporations generate the distributive outcomes of the global economy?",
      "options": {
        "A": "By ensuring that formal rules fully reflect the preferences of less powerful actors.",
        "B": "By enabling stronger actors to shape the rules, enforcement, and investment flows, so benefits accrue to them and costs are borne by less powerful actors.",
        "C": "By allowing rules to emerge solely from economic efficiency calculations without political considerations.",
        "D": "By making all actors' influence identical through universal legal guarantees."
      },
      "correct_answer": "B",
      "source_article": "International political economy",
      "x": 1.2356510162353516,
      "y": 0.9138481020927429,
      "concepts_tested": [
        "Concept 1: Bidirectional influence between politics and the international economy (how political decisions affect economic outcomes and how economic conditions constrain or enable politics).",
        "Concept 2: Power relations and actors (states, international organizations, multinational corporations) as primary shapers of the international economic order and its distributive consequences.",
        "Concept 3: Role of institutions and regulation in mediating economic activity, reflecting the inseparability of economic phenomena from political actors and structures."
      ],
      "parent_concepts": [
        "How the objectives of defense/security, economic benefit, and humanitarian aid are interconnected and influence policy decisions.",
        "Concept 3: The relationship and tensions between industrial policy and trade/liberalization, including debates about how intervention interacts with free trade and international cooperation."
      ],
      "parent_articles": [
        "Foreign policy",
        "Industrial policy"
      ]
    },
    {
      "question": "From More's perspective, why must science, art, and personal virtue be cultivated together in statesmanship, and how does each dimension help turn theoretical knowledge into effective, legitimate governance?",
      "options": {
        "A": "Science provides accurate understanding; art enables skilled, context-sensitive implementation; personal virtue supplies moral legitimacy and public trust; together they ensure decisions are informed, feasible, and acceptable, reducing the risk of bad policy, botched execution, or cynical rule.",
        "B": "Science alone is enough; the other two dimensions are redundant.",
        "C": "Virtue alone suffices; knowledge and skill are unnecessary.",
        "D": "Art alone suffices; science and virtue naturally follow from charisma."
      },
      "correct_answer": "A",
      "source_article": "Statecraft",
      "x": 0.6529524326324463,
      "y": 0.4954695999622345,
      "concepts_tested": [
        "The triad of science, art, and personal virtue as elements of effective statesmanship (More\u2019s perspective)",
        "Narrow vs. broad conceptions of statecraft: managing interstate relations for national advantage vs. studying states and governance more broadly",
        "Statecraft as a contested, interdisciplinary concept linking theory (philosophical ideas) and practice (public diplomacy, governance, leadership)"
      ],
      "parent_concepts": [
        "How diplomacy and the diplomatic corps, along with think tanks, function as mechanisms in developing, informing, and implementing long-term foreign policy.",
        "Concept 1: Diplomacy as the main instrument and mechanism for influencing state behavior and foreign policy",
        "Concept 3: Organizational structure and processes (envoys/ambassadors, diplomatic missions, foreign ministries) enabling negotiation and treaty formation"
      ],
      "parent_articles": [
        "Foreign policy",
        "Diplomacy",
        "Diplomacy"
      ]
    },
    {
      "question": "Why do political systems, as frameworks that define acceptable methods, tend to channel changes in the distribution of resources and status through negotiation and lawmaking rather than through unilateral force?",
      "options": {
        "A": "Because the system's rules constrain actions and embed changes into stable, legitimate processes, making negotiated settlements and laws more durable and predictable than force, which risks illegitimacy, backlash, and destabilization.",
        "B": "Because force is always illegal and never contributes to any redistribution, so it is never used.",
        "C": "Because negotiations and laws are inherently more efficient at delivering optimal outcomes for all actors.",
        "D": "Because elections alone automatically reallocate resources, rendering other mechanisms unnecessary."
      },
      "correct_answer": "A",
      "source_article": "Politics",
      "x": 1.1840029954910278,
      "y": 0.9381901025772095,
      "concepts_tested": [
        "Politics as power relations and collective decision-making that determine the distribution of resources and status",
        "Political systems as frameworks that define acceptable methods and constrain or enable political action",
        "Mechanisms of political action (negotiation, lawmaking, party organization, elections, use of force) and how they interact to produce political change"
      ],
      "parent_concepts": [
        "Concept 1: Statecraft as an integrated art (combining science, art, and virtue) and its contested, hard-to-define nature.",
        "Concept 3: Classification and interaction of political systems (democracies, totalitarian regimes, authoritarian regimes, hybrids, monarchies) and the idea that forms can be mixed or non-mutually exclusive."
      ],
      "parent_articles": [
        "Statecraft",
        "Government"
      ]
    },
    {
      "question": "Why is it important to treat defense, economic interests, and humanitarian aid as interconnected objectives in a state's foreign policy, and how does this interconnectedness shape policy decisions?",
      "options": {
        "A": "Because pursuing all three in coordination can create synergies\u2014defense capacity can enable stable trade, economic engagement can fund defense and humanitarian programs, and humanitarian stability can reduce security threats\u2014so policymakers design integrated strategies rather than siloed plans.",
        "B": "Because defense and economic interests are incompatible with humanitarian aid, so interconnection forces policymakers to pick one domain to the exclusion of others.",
        "C": "Because each objective is entirely separate and their effects do not spill over, so policy decisions can optimize one area independently without affecting others.",
        "D": "Because humanitarian aid undermines national security by creating dependency, so it should be minimized to protect economic and defense priorities."
      },
      "correct_answer": "A",
      "source_article": "Foreign policy",
      "x": 0.6597936153411865,
      "y": 0.5098339915275574,
      "concepts_tested": [
        "Interconnectedness of objectives: defense, economic interests, and humanitarian aid are not isolated but contribute to a single, comprehensive foreign policy; test with how/why these goals influence one another.",
        "Factors shaping policy decisions: domestic considerations, behavior of other states, and geopolitical strategies affect how foreign policy is formulated; test with why these factors matter and how they interact.",
        "Institutional mechanisms in policy formation: diplomatic corps and think tanks serve as instruments to develop, advocate, and inform foreign policy decisions; test with how these institutions influence policy outcomes."
      ],
      "parent_concepts": [
        "Concept 1: Diplomacy as the main instrument and mechanism for influencing state behavior and foreign policy",
        "Imperialism as a policy of maintaining/extending power through expansion, using both hard power (military/economic) and soft power (diplomatic/cultural influence)."
      ],
      "parent_articles": [
        "Diplomacy",
        "Imperialism"
      ]
    },
    {
      "question": "Why do cultural relativists challenge the idea that universal political principles can justify political legitimacy across diverse cultures, and what strategy would a universalist typically use to defend legitimacy across cultures?",
      "options": {
        "A": "Cultural relativists argue that each culture's distinct history and practices ground its own legitimate norms, so a single universal standard would override local legitimacy; a universalist would respond by appealing to reasons grounded in universal human capabilities or rational autonomy to derive cross-cultural norms.",
        "B": "Cultural relativists claim all cultures share identical core values, so universality is unnecessary; universalists respond by appealing to empirical evidence from cross-cultural surveys.",
        "C": "Cultural relativists hold that legitimacy is purely procedural and local, while universalists insist on external enforcement by international authorities regardless of cultural context.",
        "D": "Cultural relativists maintain that only economic efficiency determines legitimacy, whereas universalists insist that legitimacy rests solely on government performance."
      },
      "correct_answer": "A",
      "source_article": "Political philosophy",
      "x": 1.186160922050476,
      "y": 0.9591484665870667,
      "concepts_tested": [
        "Concept 1: Normative foundations of political legitimacy (how justice, equality, liberty justify or critique political institutions and forms of government)",
        "Concept 2: Methodological frameworks in political philosophy (foundationalism vs particularism; bottom-up judgments vs top-down systems; role of theories about human nature)",
        "Concept 3: Universality vs cultural relativity of political principles (whether basic moral/political principles apply universally or vary by culture)"
      ],
      "parent_concepts": [
        "Education, power, and equality: how states or societal structures influence education (e.g., coercion to attend school) and issues of discrimination and wealth distribution affecting educational access and outcomes.",
        "Concept 1: The distinction between natural rights and legal rights, including their bases (human nature vs. law) and implications for universality and context-dependence.",
        "Concept 1: Politics as mechanisms of decision-making and resource/status distribution within power relations (negotiation, lawmaking, force) and how these mechanisms produce specific political outcomes.",
        "The dual nature of ideology, where practical elements are as prominent as theoretical ones, linking beliefs to policy, action, and governance.",
        "Distributive norms as governing allocations (Equality, Equity, Power, Need, Responsibility)",
        "Concept 1: Direct democracy vs. representative democracy, and the institutional mechanisms (constitution and supreme court) that constrain majority power to protect minority rights.",
        "Concept 2: Mechanisms to enable deliberation (random selection of lay citizens, resource/time allocation, deliberative polls, and the interplay of consensus vs. majority rule)"
      ],
      "parent_articles": [
        "Philosophy of education",
        "Rights",
        "Politics",
        "Ideology",
        "Distributive justice",
        "Democracy",
        "Deliberative democracy"
      ]
    },
    {
      "question": "Why does maintaining ends\u2013means alignment matter for strategy under conditions of uncertainty?",
      "options": {
        "A": "Because uncertainty makes resource availability and environmental conditions change, and keeping ends aligned with the actual means allows you to adapt actions or revise priorities to still pursue viable outcomes.",
        "B": "Because alignment guarantees that resources will always perfectly fit a fixed goal without any need to adapt.",
        "C": "Because misalignment only matters when resources are abundant; in scarcity, alignment is irrelevant.",
        "D": "Because the ends\u2013means relationship is incidental and can be ignored once a plan is made."
      },
      "correct_answer": "A",
      "source_article": "Strategy",
      "x": 1.3479024171829224,
      "y": 0.9857991337776184,
      "concepts_tested": [
        "Ends-means alignment: how goals, priorities, and available resources are connected and trade-offs made under conditions of uncertainty.",
        "Emergent vs deliberate strategy: strategy as a planned set of actions versus a pattern that emerges from ongoing decisions and environmental adaptation.",
        "Policy-to-action relationship in military strategy: how political objectives shape and constrain military means and actions, and the tension between ends (policy) and means (military capability)."
      ],
      "parent_concepts": [
        "Concept 1: Competitive positioning through trade-offs and fit (Porter\u2019s principles) \u2014 creating a unique position by choosing what not to do and aligning activities to support that position.",
        "Formulation vs implementation and the analytical vs synthesis distinction: why strategic planning coordinates analysis and execution, and how this relationship drives strategic outcomes.",
        "Strategic fit and activity alignment: ensuring that different activities reinforce and support the chosen strategy.",
        "Concept 1: Internal resources, assets, and capabilities create firm heterogeneity and enable different strategic choices.",
        "Concept 1: Analytical frameworks (Porter\u2019s Five Forces, value chain, SWOT) are used to diagnose the competitive environment and guide strategic marketing decisions.",
        "Concept 3: Brand audits function as a diagnostic process that connects brand positioning, internal capabilities, and external market factors to strategic improvements and resource allocation.",
        "Concept 2: The relationship and distinction between marketing strategy (planning) and marketing management (execution), and how they interact to turn ideas into action."
      ],
      "parent_articles": [
        "Strategic management",
        "Strategic planning",
        "Strategic management",
        "Resource-based view",
        "Marketing management",
        "Marketing management",
        "Marketing strategy"
      ]
    },
    {
      "question": "Why does sustaining competitive advantage rely on a value-creating strategy that is unique relative to rivals and supported by barriers to imitation, and how does strategic management reinforce this durability?",
      "options": {
        "A": "Because uniqueness makes competitors unable to observe the value proposition, so they cannot imitate.",
        "B": "Because uniqueness guarantees legal protection and permanent market exclusivity.",
        "C": "Because a unique combination of activities and resources creates a value proposition that rivals find costly or risky to copy, and strategic management builds aligned capabilities and barriers (such as brand, network effects, and tacit know-how) to deter imitation, making the advantage more durable.",
        "D": "Because sustainability arises solely from continuously lowering costs."
      },
      "correct_answer": "C",
      "source_article": "Competitive advantage",
      "x": 1.3589625358581543,
      "y": 0.9814627766609192,
      "concepts_tested": [
        "Concept 1: Cost advantage vs. differentiation advantage as mechanisms to create value and outperform competitors.",
        "Concept 2: The role of value proposition and customer-perceived value (including factors like brand loyalty) in generating and sustaining competitive advantage.",
        "Concept 3: Strategic positioning and sustainability: competitive advantage arises when a value-creating strategy is unique relative to current/potential rivals and is supported by strategic management and barriers to imitation."
      ],
      "parent_concepts": [
        "Concept 1: Competitive positioning through trade-offs and fit (Porter\u2019s principles) \u2014 creating a unique position by choosing what not to do and aligning activities to support that position.",
        "Concept 1: Internal resources, assets, and capabilities create firm heterogeneity and enable different strategic choices.",
        "Concept 1: Analytical frameworks (Porter\u2019s Five Forces, value chain, SWOT) are used to diagnose the competitive environment and guide strategic marketing decisions."
      ],
      "parent_articles": [
        "Strategic management",
        "Resource-based view",
        "Marketing management"
      ]
    },
    {
      "question": "How do strategic thinking and strategic planning interact to improve both the quality of strategy and its execution?",
      "options": {
        "A": "Strategic thinking provides a fixed set of actions; strategic planning adapts them during execution.",
        "B": "Strategic thinking creates hypotheses about why/what could be, while strategic planning operationalizes selected insights into concrete actions with timelines and resources.",
        "C": "Strategic planning generates new options and scenarios, while strategic thinking evaluates and implements the chosen plan.",
        "D": "Strategic thinking and strategic planning are the same, so one can replace the other without impact."
      },
      "correct_answer": "B",
      "source_article": "Strategic thinking",
      "x": 1.342566967010498,
      "y": 0.9852228760719299,
      "concepts_tested": [
        "Concept 1: Strategic thinking prioritizes asks \"Why\" and \"How\" over \"What,\" shaping decisions through reasoning, analysis, and synthesis rather than mere description.",
        "Concept 2: Strategic thinking and strategic planning are distinct but complementary processes; both are needed and interact to improve strategy and execution.",
        "Concept 3: Foresight and collaborative group thinking expand possibility space and generate diverse perspectives, contributing to proactive dialogue and competitive advantage."
      ],
      "parent_concepts": [
        "Concept 1: Competitive positioning through trade-offs and fit (Porter\u2019s principles) \u2014 creating a unique position by choosing what not to do and aligning activities to support that position."
      ],
      "parent_articles": [
        "Strategic management"
      ]
    },
    {
      "question": "Why does applying quantitative optimization to a management decision typically improve outcomes compared to relying on intuition alone?",
      "options": {
        "A": "It guarantees global optimality regardless of model accuracy.",
        "B": "It formalizes the problem into explicit objectives and constraints, reveals trade-offs, and enables assessing robustness through sensitivity analysis.",
        "C": "It eliminates all uncertainty about future events.",
        "D": "It replaces human judgment entirely with automated, unbiased decisions."
      },
      "correct_answer": "B",
      "source_article": "Management science",
      "x": 1.3632562160491943,
      "y": 1.0145680904388428,
      "concepts_tested": [
        "Concept 1: Quantitative modeling and optimization as tools to illuminate management issues and achieve optimal or near-optimal decisions.",
        "Concept 2: A three-level framework (fundamental mathematics; modeling; application) that structures management science research and practice.",
        "Concept 3: Interdisciplinary and cross-domain applicability, illustrating how rational, systematic techniques transfer from business to military, medical, public administration, and other contexts."
      ],
      "parent_concepts": [
        "Ends-to-means alignment over a defined time horizon: how goals are achieved using resources and why timing matters.",
        "Concept 1: Mathematical modeling as the core means of describing real-world systems to enable analysis and decision support."
      ],
      "parent_articles": [
        "Strategic planning",
        "Operations research"
      ]
    },
    {
      "question": "Why does a strategy that emphasizes making trade-offs and achieving 'fit' among activities tend to produce a sustainable competitive advantage?",
      "options": {
        "A": "Trade-offs force a firm to choose a narrow, valuable position instead of chasing everything; fit aligns and mutually reinforces activities to support that position, creating a coherent system that is hard to replicate.",
        "B": "Trade-offs encourage pursuing multiple competing frontiers simultaneously; fit ensures each activity is optimized in isolation, which increases flexibility.",
        "C": "Trade-offs eliminate the need for a clear value proposition; fit reduces interdependencies to minimize coordination costs.",
        "D": "Trade-offs and fit mainly affect internal costs and have little impact on external positioning."
      },
      "correct_answer": "A",
      "source_article": "Strategic management",
      "x": 1.3612613677978516,
      "y": 0.9774346351623535,
      "concepts_tested": [
        "Concept 1: Strategy involves creating a unique and valuable market position through trade-offs and aligning activities (fit).",
        "Concept 2: Strategy is dynamic and iterative, employing feedback loops to monitor execution and inform subsequent planning.",
        "Concept 3: Distinction between corporate strategy (portfolio-level decisions about what businesses to be in) and business strategy (how to compete in a given business), and how these levels relate to overall strategic management."
      ],
      "parent_concepts": [
        "Formulation vs implementation and the analytical vs synthesis distinction: why strategic planning coordinates analysis and execution, and how this relationship drives strategic outcomes.",
        "Concept 1: Internal resources, assets, and capabilities create firm heterogeneity and enable different strategic choices.",
        "Concept 2: Mechanisms of dynamic capabilities (adapting, integrating, and reconfiguring internal and external skills, resources, and routines to meet changing environment requirements).",
        "Concept 3: Successful international business requires navigating regulatory/cultural differences and conducting risk assessment with local adaptation, supported by market analysis and technology-enabled entry strategies.",
        "Concept 3: Governance and roles (enterprise architects overseeing solutions architects) and their impact on aligning decisions across the organization with the strategic vision.",
        "The role of market understanding (customer needs/wants, competitive environment, market nature) in driving NPD decisions",
        "Concept 1: Analytical frameworks (Porter\u2019s Five Forces, value chain, SWOT) are used to diagnose the competitive environment and guide strategic marketing decisions.",
        "Concept 3: Brand audits function as a diagnostic process that connects brand positioning, internal capabilities, and external market factors to strategic improvements and resource allocation.",
        "Concept 2: The relationship and distinction between marketing strategy (planning) and marketing management (execution), and how they interact to turn ideas into action.",
        "Concept 3: Evolution of HRM from transactional/administrative tasks to strategic initiatives (talent management, succession planning, diversity and inclusion) and its impact on turnover and retention",
        "Concept 2: The micro-environment focus on customers, partners, and competitors, and the emphasis on the customer market as central to marketing decisions."
      ],
      "parent_articles": [
        "Strategic planning",
        "Resource-based view",
        "Dynamic capabilities",
        "International business",
        "Enterprise architecture",
        "New product development",
        "Marketing management",
        "Marketing management",
        "Marketing strategy",
        "Human resource management",
        "Market environment"
      ]
    },
    {
      "question": "Why can the same dataset lead to different conclusions when different methodological approaches are used?",
      "options": {
        "A": "Because the data changes when you apply different methods, producing different numbers to analyze.",
        "B": "Because different methods encode different criteria for what counts as valid evidence and meaningful patterns, so they highlight different features of the data and can justify different interpretations.",
        "C": "Because conclusions are determined by personal interpretation, independent of the method used.",
        "D": "Because methods cannot be compared, and choosing a method automatically yields the \"correct\" conclusion."
      },
      "correct_answer": "B",
      "source_article": "Methodology",
      "x": 1.3383570909500122,
      "y": 1.0387264490127563,
      "concepts_tested": [
        "The relationship between method choice and conclusions: how the same data can lead to different conclusions depending on the method used.",
        "The role of philosophical background assumptions: how assumptions about phenomena and evidence shape methodological choices and interpretations.",
        "The purpose and value of evaluating methods and integrating approaches: why comparing methods matters and how mixed-methods combine quantitative and qualitative approaches to address research goals."
      ],
      "parent_concepts": [
        "Epistemology-driven variation in research approaches across disciplines (how different knowledge claims lead to different methods)",
        "Concept 2: The relationship and distinctions among branches of science (natural, social, formal, applied) and their underlying methodologies."
      ],
      "parent_articles": [
        "Research",
        "Science"
      ]
    },
    {
      "question": "Why does information governance require cross-disciplinary integration across security, privacy, data governance, analytics, IT management, etc., rather than being limited to records management?",
      "options": {
        "A": "Because the value and risk of information arise from how data is captured, stored, secured, shared, and used across systems, so integrating security, privacy, data governance, analytics, and IT management ensures policies cover the actual lifecycle and use cases.",
        "B": "Because information governance is essentially a records retention exercise; cross-disciplinary input is unnecessary and only increases complexity.",
        "C": "Because only the security team needs to enforce controls; other disciplines have little impact on governance outcomes.",
        "D": "Because analytics must be kept separate from governance to avoid bias in decision making; mixing them weakens governance."
      },
      "correct_answer": "A",
      "source_article": "Information governance",
      "x": 1.3918274641036987,
      "y": 0.9780970215797424,
      "concepts_tested": [
        "Concept 1: IG as a holistic framework that balances information risk with value, guiding legal compliance, transparency, and cost reduction.",
        "Concept 2: IG relies on cross-disciplinary integration (security, privacy, data governance, analytics, IT management, etc.) rather than being limited to records management.",
        "Concept 3: The Principles (e.g., Generally Accepted Recordkeeping Principles, IG Maturity Model) provide standardized hallmarks guiding consistent information governance practices across organizations."
      ],
      "parent_concepts": [
        "Concept 2: The impact of multiple data sources on internal data consistency and the need for governance/standardization to maintain quality across integrated datasets.",
        "Concept 3: The core aims of data governance are to maximize the value of data as a strategic asset while reducing risks from misuse or inaccuracy and ensuring regulatory, ethical, and business compliance."
      ],
      "parent_articles": [
        "Data quality",
        "Data governance"
      ]
    },
    {
      "question": "How does treating the information management lifecycle\u2014acquisition, custodianship/storage, distribution, and disposal\u2014as an integrated feedback-driven cycle improve an organization's ability to ensure information quality, accessibility, and utility for the right audience?",
      "options": {
        "A": "It isolates stages so each can optimize independently without considering downstream use.",
        "B": "It creates feedback loops where outcomes at disposal (e.g., what was used, what was archived, what was deleted) inform changes in earlier stages (acquisition, storage, distribution) to improve quality and relevance for decision-makers.",
        "C": "It emphasizes storage cost minimization as the sole driver of all decisions.",
        "D": "It delays disposal to extend data retention regardless of utility."
      },
      "correct_answer": "B",
      "source_article": "Information management",
      "x": 1.4011800289154053,
      "y": 1.031369924545288,
      "concepts_tested": [
        "The information management lifecycle: acquisition, custodianship/storage, distribution, and disposal as an integrated cycle.",
        "Governance and stakeholder roles: quality, accessibility, utility, rights to originate/change/distribute/delete information, and policy-driven control.",
        "Relational scope and value creation: IM overlaps with data, systems, technology, processes, and organizational strategy, and information gains value when it is effectively used by the right audience."
      ],
      "parent_concepts": [
        "Concept 2: The impact of multiple data sources on internal data consistency and the need for governance/standardization to maintain quality across integrated datasets.",
        "Data architecture and data flows as the engineered structure that enables efficient, scalable data movement aligned with business needs (how design decisions impact analytics and operations)",
        "Concept 2: Migration and media/format considerations are central mechanisms by which preservation is achieved, given varying lifespans and obsolescence of hardware and formats (e.g., SSDs, LTO tapes, archival discs, M-DISC), highlighting cause-and-effect between technology evolution and preservation actions."
      ],
      "parent_articles": [
        "Data quality",
        "Data management",
        "Digital preservation"
      ]
    },
    {
      "question": "Why is it advantageous to separate governance (setting strategy and policy at the top) from management (directing and implementing through subordinates), and how does this separation influence how strategic goals are translated into frontline actions?",
      "options": {
        "A": "Governance directly translates strategic goals into daily frontline tasks, speeding execution.",
        "B": "Management is responsible for setting strategy and policy and monitoring organization-wide outcomes.",
        "C": "Governance sets strategy and policy and ensures accountability; management translates those into actions and coordinates day-to-day operations, using feedback from operations to adjust strategy.",
        "D": "There is no real distinction; both levels perform the same tasks and responsibilities."
      },
      "correct_answer": "C",
      "source_article": "Management",
      "x": 1.3515793085098267,
      "y": 0.9964286684989929,
      "concepts_tested": [
        "Concept 1: Hierarchical structure of management and the flow of strategic goals from senior to line management (how goals/policies are translated into frontline actions).",
        "Concept 2: Distinction between governance and management (what senior management does in setting strategy/policy versus directing and implementing through subordinates).",
        "Concept 3: Management as an interdisciplinary, practice-informed field (the relationship between theory, education, and evidence-based management)."
      ],
      "parent_concepts": [
        "The four components of quality management (planning, assurance, control, improvement) form an integrated system to consistently meet intended performance.",
        "Concept 3: Drivers of change and their interaction with change management processes (technology evolution, process reviews, crises, regulation, etc.), illustrating cause-effect relationships that trigger and shape change efforts.",
        "Strategic fit and activity alignment: ensuring that different activities reinforce and support the chosen strategy.",
        "Concept 2: BPM lifecycle and mechanisms \u2014 modeling, automation/execution, control, measurement, and optimization as an interconnected set of activities.",
        "Concept 3: People\u2013technology\u2013process relationships \u2014 BPM is enabled by technology and involves the participation of people, highlighting how workflows and automation relate to organizational goals and performance.",
        "Concept 2: HRM as an integrated system of policies and processes (recruitment, training, development, performance appraisal, rewards, benefits) that influence employee performance and organizational outcomes",
        "Concept 3: Evolution of HRM from transactional/administrative tasks to strategic initiatives (talent management, succession planning, diversity and inclusion) and its impact on turnover and retention",
        "Concept 3: Role clarity and resource availability as enabling factors that support efficient collaboration within teams."
      ],
      "parent_articles": [
        "Quality management",
        "Change management",
        "Strategic management",
        "Business process management",
        "Business process management",
        "Human resource management",
        "Human resource management",
        "Teamwork"
      ]
    },
    {
      "question": "Why do cultural norms function as reliable templates for acceptable conduct within a group, and how is this stability maintained?",
      "options": {
        "A": "Because individuals observe others' rewarded behaviors, imitate them, and internalize the social consequences (approval, sanctions) into their own expectations, so deviation lowers social payoff and conformity is reinforced.",
        "B": "Because norms are written laws that force people to behave in a fixed way regardless of context.",
        "C": "Because norms reflect immutable genetic tendencies that predispose individuals to follow group guidelines.",
        "D": "Because norms are purely descriptive accounts of what people do, not prescriptions for action, so they have no causal effect on behavior."
      },
      "correct_answer": "A",
      "source_article": "Culture",
      "x": 1.246167778968811,
      "y": 0.9872503876686096,
      "concepts_tested": [
        "Cultural transmission through social learning (enculturation and socialization) as the mechanism by which individuals acquire culture",
        "Norms as templates for acceptable conduct and social expectations that shape behavior",
        "Cultural change dynamics: internal forces and external contact leading to repositioning or transformation of culture"
      ],
      "parent_concepts": [
        "Concept 1: Culture as a non-genetic adaptive system that varies with environment.",
        "The formation of cultural identity as a dynamic, multi-stage process: immersion in values/beliefs/practices, identification as a member based on one\u2019s standing in a community, and the development of social relationships.",
        "Concept 3: Outcomes and level-specific relationships (group-level changes in institutions and practices; individual-level effects on psychological/physical well-being; possible results such as integration, marginalization, coexistence, or cultural evolution).",
        "The relational positioning of popular culture with respect to folk culture and high culture, including different theoretical perspectives that interpret these relationships.",
        "Concept 3: Interdisciplinary and multimedia scope \u2014 visual culture overlaps with film studies, cognitive science, technology, and various media, shaping its theoretical frameworks and methods."
      ],
      "parent_articles": [
        "Cultural anthropology",
        "Cultural identity",
        "Acculturation",
        "Popular culture",
        "Visual culture"
      ]
    },
    {
      "question": "How does cultural transmission differ from genetic transmission, and what is the primary consequence of this difference for the rate at which cultural traits can spread within a population?",
      "options": {
        "A": "Cultural transmission is strictly vertical and slow, mirroring genetic inheritance.",
        "B": "Cultural transmission can spread horizontally and obliquely among individuals, enabling rapid, non-genetic spread and potentially cumulative cultural change, while genetic transmission remains mostly vertical and generation-bound.",
        "C": "Cultural transmission requires sexual reproduction to propagate, limiting its speed.",
        "D": "Cultural transmission and genetic transmission occur on the same timescale and are dictated by identical selection pressures."
      },
      "correct_answer": "B",
      "source_article": "Evolutionary anthropology",
      "x": 1.226550579071045,
      "y": 1.0023123025894165,
      "concepts_tested": [
        "Concept 1: Distinction and interaction between biological evolution and cultural evolution, including their different transmission mechanisms (genes vs. cultural information).",
        "Concept 2: Use of cultural-transmission models and cladistics as methodological approaches to study cultural evolution.",
        "Concept 3: Interdisciplinary integration, combining archaeology, primatology, genetics, psychology, and other fields to build a coherent picture of human evolution."
      ],
      "parent_concepts": [
        "Concept 1: Culture as a non-genetic adaptive system that varies with environment."
      ],
      "parent_articles": [
        "Cultural anthropology"
      ]
    },
    {
      "question": "Why does viewing human\u2013computer interaction as an open-ended dialogue between the user and the system influence which design choices are made and how user satisfaction is evaluated?",
      "options": {
        "A": "It pushes designers to minimize user input and rely on fixed, predefined task sequences.",
        "B": "It emphasizes that users and the system together shape the interaction, so designs must support exploration, adapt to evolving goals, and incorporate iterative feedback to enhance satisfaction.",
        "C": "It implies there is a single optimal interaction path for all users, simplifying evaluation to a universal metric.",
        "D": "It suggests satisfaction should be measured only by raw speed and task completion, ignoring understanding or learnability."
      },
      "correct_answer": "B",
      "source_article": "Human\u2013computer interaction",
      "x": 1.3566855192184448,
      "y": 1.0690908432006836,
      "concepts_tested": [
        "Concept 1: Interaction as an open-ended dialogue between human and computer, shaping how design decisions influence use and satisfaction.",
        "Concept 2: Multimodal interaction channels (visual, auditory, tactile) as mechanisms that enable and constrain how users communicate with systems.",
        "Concept 3: Interdisciplinary foundation and the design\u2013evaluation\u2013implementation lifecycle, showing how knowledge from multiple fields informs the creation and assessment of interactive systems."
      ],
      "parent_concepts": [
        "Design emphasizes interactivity, usability for non-programmers, and adaptability to changing environments",
        "Concept 1: Direct vs. indirect access and the role of assistive technology in achieving usable access."
      ],
      "parent_articles": [
        "Decision support system",
        "Accessibility"
      ]
    },
    {
      "question": "In design thinking, how does iterative prototyping with user testing promote learning and guide the development of a viable solution?",
      "options": {
        "A": "Each iteration confirms the initial hypothesis, enabling early commitment to the original plan.",
        "B": "Each iteration reveals underlying assumptions, gathers concrete user feedback, and allows reframing the problem to refine the solution toward viability.",
        "C": "Prototyping primarily accelerates final production by embedding all requirements into the first artifact.",
        "D": "Iteration enforces a strict linear sequence of steps that minimizes changes after initial framing."
      },
      "correct_answer": "B",
      "source_article": "Design thinking",
      "x": 1.3945176601409912,
      "y": 1.0395421981811523,
      "concepts_tested": [
        "Wicked problems and design thinking: why design thinking is suited to ill-defined/wicked problems and how it differs from solving well-defined problems.",
        "Iterative, non-linear process with prototyping and user testing: how iteration drives learning and solution development.",
        "Abductive and productive reasoning as core cognitive mechanisms: how these reasoning modes contribute to generating creative, viable design solutions."
      ],
      "parent_concepts": [
        "Design emphasizes interactivity, usability for non-programmers, and adaptability to changing environments"
      ],
      "parent_articles": [
        "Decision support system"
      ]
    },
    {
      "question": "How does empathy with users\u2019 mental models influence how a UX designer validates a design decision?",
      "options": {
        "A": "By informing testable hypotheses about users' goals and expected interactions that can be evaluated through user research and task-based testing.",
        "B": "By focusing only on visual aesthetics.",
        "C": "By eliminating the need for usability tests.",
        "D": "By relying solely on internal opinions."
      },
      "correct_answer": "A",
      "source_article": "User experience design",
      "x": 1.4019157886505127,
      "y": 1.0636316537857056,
      "concepts_tested": [
        "Concept 1: Research and data drive design decisions in UX design, rather than relying on aesthetic preferences.",
        "Concept 2: UX design is holistic, covering all aspects of the user\u2019s perceived experience (usability, usefulness, desirability, brand perception, performance) and not limited to the interface.",
        "Concept 3: UX design draws on multiple disciplines (HCI, UCD, IA, visual design, etc.) and relies on empathy and understanding of users\u2019 needs and mental models to shape and validate design decisions."
      ],
      "parent_concepts": [
        "Design emphasizes interactivity, usability for non-programmers, and adaptability to changing environments"
      ],
      "parent_articles": [
        "Decision support system"
      ]
    },
    {
      "question": "Why can epigenetic states be stably inherited through cell divisions without altering the DNA sequence?",
      "options": {
        "A": "Because the DNA sequence mutates in daughter cells to mirror the parent's gene expression pattern.",
        "B": "Because maintenance enzymes copy DNA methylation patterns to new strands during replication and parental histone modifications guide re-establishment of chromatin states in daughter cells.",
        "C": "Because transcription factors bind permanently to all necessary promoters so that gene expression is fixed in each cell lineage, regardless of replication.",
        "D": "Because epigenetic marks are erased every cell cycle and must be re-established from scratch each generation."
      },
      "correct_answer": "B",
      "source_article": "Epigenetics",
      "x": 2.0749025344848633,
      "y": 1.1519279479980469,
      "concepts_tested": [
        "Concept 1: Epigenetic regulation alters gene expression without changing the DNA sequence, using mechanisms such as DNA methylation, histone modification, and non-coding RNAs.",
        "Concept 2: Epigenetic states can be stably inherited through cell divisions and may persist across generations, linking environmental and developmental influences to long-term gene expression patterns.",
        "Concept 3: Epigenetics drives cellular differentiation during development by activating some genes and repressing others to form distinct cell types."
      ],
      "parent_concepts": [
        "Concept 1: Gene-environment interaction in development (maturation vs. environmental learning and their interdependence)"
      ],
      "parent_articles": [
        "Child development"
      ]
    },
    {
      "question": "How do emergent properties of the brain underpin cognitive functions, and why can't these functions be fully understood by studying neurons in isolation?",
      "options": {
        "A": "Emergent properties arise from the collective, nonlinear interactions across distributed neural networks, so cognitive functions depend on patterns of connectivity and network dynamics rather than any single neuron; studying isolated neurons misses context, integration, and system-level constraints.",
        "B": "Emergent properties are the summed average firing rates of individual neurons, so analyzing many single neurons is enough to explain cognition.",
        "C": "Emergent properties originate only from chemical processes at synapses and do not involve network structure; cognition is a synaptic reaction.",
        "D": "Emergent properties can be fully captured by studying genetics alone, without examining neural activity."
      },
      "correct_answer": "A",
      "source_article": "Psychology",
      "x": 1.227912425994873,
      "y": 0.9944067001342773,
      "concepts_tested": [
        "Mind\u2013brain relationship: how emergent properties of the brain underlie cognitive functions, perception, emotion, and behavior.",
        "Relationships among psychosocial variables: how psychology uses empirical methods to infer causal and correlational links between mental processes and behavior.",
        "Interdisciplinary and applied scope: how psychology integrates natural and social sciences and aims to apply knowledge to therapy, development, education, industry, and societal problems."
      ],
      "parent_concepts": [
        "Concept 2: Role of stable, supportive caregiver relationships and emotional climate in shaping emotional regulation and overall development",
        "Attachment patterns and assessment framework: the categorization of attachment (secure, avoidant, anxious, disorganized) and the role of procedures like the Strange Situation in identifying these patterns.",
        "Interdisciplinary integration of psychology/neuroscience with microeconomic theory to build behavioral models",
        "Concept 3: Radical behaviorism\u2019s inclusion of covert mental states under the same controlling variables and its relationships to applied behavior analysis and cognitive-behavioral therapies."
      ],
      "parent_articles": [
        "Child development",
        "Attachment theory",
        "Behavioral economics",
        "Behaviorism"
      ]
    },
    {
      "question": "Why do inclusion-oriented universal design approaches require trade-offs and prioritization, and how is such prioritization justified in practice?",
      "options": {
        "A": "They assume a solution can fully satisfy all users if resources were unlimited, so trade-offs would not be needed.",
        "B": "They confront diverse and sometimes conflicting needs with finite resources; prioritization is justified by concentrating on reducing the most widespread barriers and high-impact use to maximize overall participation.",
        "C": "They may sacrifice low-impact, niche accessibility features to improve overall ease of use, justified by the goal of maximizing participation across the largest number of users.",
        "D": "They defer decisions to designer opinion, believing personal authority ensures a coherent system, which is why trade-offs are justified."
      },
      "correct_answer": "B",
      "source_article": "Universal design",
      "x": 1.3573715686798096,
      "y": 1.0239697694778442,
      "concepts_tested": [
        "Concept 1: Universal design aims to maximize usability for the greatest number of people by removing barriers and enabling participation.",
        "Concept 2: Inclusion-oriented design involves trade-offs and prioritization, recognizing dilemmas when designing for diverse needs.",
        "Concept 3: Universal design emerges from barrier-free design and accessibility movements and requires interdisciplinary collaboration (engineering, architecture, medicine) with socio-material implications."
      ],
      "parent_concepts": [
        "Concept 2: Design for human diversity beyond disability (considering ability, language, culture, gender, age, etc., to maximize usability for many people).",
        "Concept 1: Direct vs. indirect access and the role of assistive technology in achieving usable access."
      ],
      "parent_articles": [
        "Inclusive design",
        "Accessibility"
      ]
    },
    {
      "question": "In a human-centered design process that follows immersion \u2192 brainstorming/conceptualization \u2192 prototyping \u2192 implementation, why does moving from immersion to prototyping matter for achieving user-centered innovations?",
      "options": {
        "A": "It prematurely locks in design ideas, reducing ongoing user input.",
        "B": "It converts contextual insights into testable concepts, enabling feedback-driven refinement through prototypes.",
        "C": "It postpones addressing feasibility until after deployment.",
        "D": "It eliminates the need for user involvement in later stages."
      },
      "correct_answer": "B",
      "source_article": "Human-centered design",
      "x": 1.368102788925171,
      "y": 1.037076711654663,
      "concepts_tested": [
        "Concept 1: User-centered focus as the driver of design outcomes (emphasizing users\u2019 needs, context, and human factors to improve usability, accessibility, and well-being)",
        "Concept 2: Iterative, stage-based design process (immersion/observation \u2192 brainstorming/conceptualization \u2192 prototyping \u2192 implementation) that enables ongoing refinement and innovation",
        "Concept 3: Transition from participatory involvement to solution generation (building on participatory action research; moving beyond documenting participants to producing practical solutions)"
      ],
      "parent_concepts": [
        "Concept 2: Design for human diversity beyond disability (considering ability, language, culture, gender, age, etc., to maximize usability for many people)."
      ],
      "parent_articles": [
        "Inclusive design"
      ]
    },
    {
      "question": "Why does designing for indirect access (compatibility with assistive technologies) impose architectural requirements that persist even when a product is already easy to use without assistive tools?",
      "options": {
        "A": "Indirect access is only about adding alternative content after development, so architecture doesn't matter.",
        "B": "Indirect access necessitates semantically rich, structured content and predictable interaction patterns so assistive technologies can reliably interpret and translate the experience.",
        "C": "Indirect access is achieved by maximal color contrast and font size; architecture remains unchanged.",
        "D": "Indirect access is primarily about legal compliance and has no impact on user experience."
      },
      "correct_answer": "B",
      "source_article": "Accessibility",
      "x": 1.375292181968689,
      "y": 1.048372507095337,
      "concepts_tested": [
        "Direct vs indirect access: the mechanisms by which accessibility enables unassisted use and compatibility with assistive technology.",
        "Relationships among accessibility, usability, and universal design: how these concepts interrelate, differ in emphasis, and collectively guide design goals.",
        "Rights-based, societal rationale for accessibility: the legislative framework and goal of enabling participation to close digital/knowledge divides."
      ],
      "parent_concepts": [
        "Concept 2: Design for human diversity beyond disability (considering ability, language, culture, gender, age, etc., to maximize usability for many people)."
      ],
      "parent_articles": [
        "Inclusive design"
      ]
    },
    {
      "question": "In mechanism design dealing with information sharing, why does offering a menu of contracts designed to satisfy incentive-compatibility constraints help align agents' incentives under private information?",
      "options": {
        "A": "Because it makes each agent's best response be to choose the contract intended for their private type, effectively revealing their type through self-selection and allowing the designer to tailor outcomes to each type, which reduces misallocation due to adverse selection.",
        "B": "Because it hides information by ensuring all agents pick the same contract, preventing type-based discrimination and equalizing outcomes.",
        "C": "Because it guarantees that agents will trade only if they are identical in all preferences, ensuring perfect screening without any constraints.",
        "D": "Because it forces the designer to reveal their own private information to the agents to maintain fairness."
      },
      "correct_answer": "A",
      "source_article": "Information economics",
      "x": 1.343581199645996,
      "y": 0.9931991100311279,
      "concepts_tested": [
        "Information asymmetry and contract theory: how incomplete information between parties affects incentives, pricing, and outcomes, and how contracts can mitigate adverse effects.",
        "Economics of information goods: the idea that information-intensive products have high fixed costs but negligible reproduction costs, influencing market dynamics, pricing, and public-sponsor considerations.",
        "Mechanism design and information sharing: using game-theoretic approaches to design rules that elicit truthful information and align incentives to improve welfare."
      ],
      "parent_concepts": [
        "Concept 2: Information asymmetry and its effect on valuations and strategic bidding",
        "Concept 2: Economic value and modeling of attention; treating attention as a scarce commodity and applying economic theory to information management and \"free\" goods.",
        "Concept 3: Distinction between negative and positive externalities and the practical challenges of policy design (such as informational limitations) in effectively internalizing them."
      ],
      "parent_articles": [
        "Auction theory",
        "Attention economy",
        "Externality"
      ]
    },
    {
      "question": "In the Second Welfare Theorem, what is the essential mechanism by which any Pareto efficient allocation can be implemented as the outcome of a competitive equilibrium, given the planner\u2019s choice and use of lump-sum transfers?",
      "options": {
        "A": "Lump-sum transfers shift relative prices to steer trades toward the planner's allocation.",
        "B": "Lump-sum transfers reallocate initial incomes without altering relative prices, so the market prices and trades at equilibrium can support the planner's chosen allocation as each agent maximizes utility given its income and prices.",
        "C": "Lump-sum transfers modify preferences, allowing the planner to change agents' marginal rates of substitution directly.",
        "D": "The planner imposes quantities via quotas, and transfers merely verify feasibility; prices are irrelevant."
      },
      "correct_answer": "B",
      "source_article": "Welfare economics",
      "x": 1.2542517185211182,
      "y": 0.926173985004425,
      "concepts_tested": [
        "The First Welfare Theorem: under certain assumptions, competitive markets lead to Pareto efficient allocations.",
        "The Second Welfare Theorem: any Pareto efficient outcome can be achieved with a competitive equilibrium plus lump-sum transfers, via a social planner selecting an outcome using a social welfare function.",
        "Social choice/ welfare aggregation: the use of a social welfare function to rank allocations and the connection to Arrow\u2019s impossibility theorem."
      ],
      "parent_concepts": [
        "Concept 1: The rules of exchange and allocation procedures are central to market design, and designing them is meant to fix or create markets with desirable properties.",
        "Concept 2: Mechanisms/tools of intervention (public provision, taxation, subsidies) and how they alter resource allocation and income distribution.",
        "Concept 3: The threefold objectives of public finance (efficient allocation, distribution of income, economic stability) and the cause\u2013effect relationships between interventions and these outcomes.",
        "Concept 1: Market power enables price setting above marginal cost due to a downward-sloping demand curve, and the gap between P and MC (captured by the residual demand) signals the degree of market power, with associated deadweight loss and welfare effects.",
        "Concept 1: Resource allocation aligned with the public interest to maximize societal benefits, and its impact on science outcomes.",
        "Concept 3: Distinction between negative and positive externalities and the practical challenges of policy design (such as informational limitations) in effectively internalizing them.",
        "Concept 1: Economic efficiency as a criterion for evaluating legal rules and predicting which rules will be promulgated",
        "Concept 1: Comparative advantage as the mechanism by which free trade can raise economic welfare through efficient resource allocation."
      ],
      "parent_articles": [
        "Market design",
        "Public finance",
        "Public finance",
        "Market power",
        "Science policy",
        "Externality",
        "Law and economics",
        "Free trade"
      ]
    },
    {
      "question": "Why does a macroscopic observable (such as pressure) emerge as a well-defined property when we describe a many-particle system by averaging over a large set of microscopic configurations (an ensemble) rather than relying on a single microstate?",
      "options": {
        "A": "The microscopic equations of motion guarantee that all microstates compatible with a macrostate yield identical macroscopic values, so averaging adds no information.",
        "B": "The law of large numbers ensures that the sum of many microscopic contributions fluctuates only as 1/\u221aN, so the ensemble average converges to a stable macroscopic value.",
        "C": "Entropy maximization fixes a unique microstate for each macrostate, so averaging over microstates is unnecessary.",
        "D": "Time-averaging over a single trajectory always equals the ensemble average, regardless of the system's dynamics."
      },
      "correct_answer": "B",
      "source_article": "Statistical mechanics",
      "x": 1.740687608718872,
      "y": 1.0972291231155396,
      "concepts_tested": [
        "Emergence of macroscopic properties from microscopic dynamics through probability distributions and ensemble averaging",
        "Equilibrium vs. non-equilibrium statistical mechanics and the fluctuation-dissipation theorem as a link between fluctuations and irreversible processes",
        "Foundational role of entropy and velocity distributions (Boltzmann entropy, Maxwell distribution) in connecting microstates to macroscopic behavior"
      ],
      "parent_concepts": [
        "Phase phenomena and mechanisms: diverse condensed phases (superconductivity, ferromagnetism/antiferromagnetism, Bose-Einstein condensation, liquid crystals) and the mechanisms that underlie them.",
        "Nucleation as a stochastic process: random fluctuations must produce a critically sized nucleus that then grows into the new phase.",
        "Classical nucleation theory and its limitations: CNT as a framework to estimate nucleation rates and their dependence on temperature/supersaturation, plus documented failures to match some experimental results.",
        "Microscopic/statistical interpretation: entropy counts microstates and connects to probability distributions (S \u221d log W, Boltzmann constant) bridging micro- and macro-behavior.",
        "Concept 3: Empirical nature and limitations of the Arrhenius model, and how theoretical frameworks like the Eyring equation provide deeper or alternative mechanistic explanations; why A can be temperature-dependent in more complete treatments."
      ],
      "parent_articles": [
        "Condensed matter physics",
        "Nucleation",
        "Nucleation",
        "Entropy",
        "Arrhenius equation"
      ]
    },
    {
      "question": "How does the structural aim of settler colonialism to supplant Indigenous populations shape the design and durability of governance compared to other forms of colonial rule, and why does that difference persist over time?",
      "options": {
        "A": "It preserves Indigenous sovereignty within the metropolitan legal framework, leading to balanced, long-term shared governance with settlers.",
        "B": "It replaces Indigenous sovereignty with settler sovereignty, embedding dispossession and a civilizing rationale into the core state institutions, creating durable domination that outlasts direct rule.",
        "C": "It concentrates power solely in economic extractive agencies, leaving political institutions of Indigenous communities largely intact.",
        "D": "It establishes transient administrative divisions that dissolve once formal decolonization begins, resulting in only short-term governance changes."
      },
      "correct_answer": "B",
      "source_article": "Colonialism",
      "x": 0.6549828052520752,
      "y": 0.5501371026039124,
      "concepts_tested": [
        "Concept 1: Coloniality and biopolitics as mechanisms of domination (how beliefs in superiority, civilizing missions, and the resulting racialized/gender/class hierarchies sustain colonization and subordinate colonized peoples)",
        "Concept 2: Forms of colonialism and their structural differences (settler colonialism aiming to supplant Indigenous peoples vs. other forms; the idea of organizing colonized peoples into separate colonies; neocolonialism as indirect continuation)",
        "Concept 3: Long-term impacts and processes (how colonial institutions influence modern economic development, regime types, and state capacity; the role of decolonization waves in shaping postcolonial trajectories)"
      ],
      "parent_concepts": [
        "Concept 3: Ongoing impact, identity, and interdisciplinary approaches"
      ],
      "parent_articles": [
        "Postcolonialism"
      ]
    },
    {
      "question": "In cultural studies, why does the dominant culture's meaning often feel natural to people across diverse backgrounds, and through which mechanism does this stabilization primarily arise?",
      "options": {
        "A": "Because individuals independently converge on similar interpretations due to universal human psychology.",
        "B": "Because coercive state power directly imposes uniform meanings through sanctions, leaving no room for subcultures.",
        "C": "Because a network of cultural institutions\u2014education, media, religion, and law\u2014produce and disseminate ideologies that bind meanings to power, shaping consent and common sense; contestation arises but remains within power-laden boundaries.",
        "D": "Because global technology erases local differences, enforcing a single global culture."
      },
      "correct_answer": "C",
      "source_article": "Cultural studies",
      "x": 1.1633901596069336,
      "y": 0.9712076783180237,
      "concepts_tested": [
        "Concept 1: Culture as a power-laden, meaning-generating process (how cultural practices relate to ideology, class, nation, and other social forces; how meaning is produced, disseminated, and contested).",
        "Concept 2: Culture as dynamic and processual (cultures are interacting, changing sets of practices rather than fixed entities).",
        "Concept 3: Interdisciplinary frameworks and mechanisms (use of multiple theoretical approaches including Marxism, semiotics, feminist theory, postcolonialism; ideas like cultural hegemony and agency; globalization as a context for cultural analysis)."
      ],
      "parent_concepts": [
        "Concept 3: Ongoing impact, identity, and interdisciplinary approaches",
        "The relational positioning of popular culture with respect to folk culture and high culture, including different theoretical perspectives that interpret these relationships.",
        "Concept 3: Interdisciplinary and multimedia scope \u2014 visual culture overlaps with film studies, cognitive science, technology, and various media, shaping its theoretical frameworks and methods.",
        "Concept 2: Encoding/decoding model with negotiation and opposition, illustrating how producers encode messages and audiences decode them in ways shaped by context.",
        "Concept 3: Cultural agility as a framework of competencies enabling effective cross-cultural interaction (practical framework)"
      ],
      "parent_articles": [
        "Postcolonialism",
        "Popular culture",
        "Visual culture",
        "Reception theory",
        "Intercultural communication"
      ]
    },
    {
      "question": "How do informal institutions contribute to global governance in the absence of a central political authority, and why might they be more effective than formal rules alone for coordinating complex interdependencies?",
      "options": {
        "A": "They rely on a centralized coercive power to enforce compliance, which is more effective than voluntary norms.",
        "B": "They cultivate shared norms, reputational incentives, and information channels that reduce uncertainty and align behavior among diverse actors, supplementing or substituting for formal enforcement.",
        "C": "They are limited to cultural exchanges and cannot influence concrete policy choices, making them ineffective for coordination.",
        "D": "They replace formal rules with voluntary guidelines that are non-binding and often fail to influence state behavior."
      },
      "correct_answer": "B",
      "source_article": "Global governance",
      "x": 1.2062574625015259,
      "y": 0.9154009819030762,
      "concepts_tested": [
        "Concept 1: Coordination, rule-making, monitoring, and enforcement as mechanisms to address collective-action problems in a global context.",
        "Concept 2: The role of diverse actors beyond states (NGOs, firms, epistemic communities) in shaping global governance and outcomes.",
        "Concept 3: Governance versus government in the international sphere, including how formal and informal institutions mediate interdependent relations without a central authority."
      ],
      "parent_concepts": [
        "Concept 2: International development as a distinct field linked to post-WWII institutions (e.g., Bretton Woods) and global governance frameworks guiding policy, practice, and research.",
        "Concept 3: WTO governance and decision-making structure (Ministerial Conference, General Council, Secretariat) and its impact on negotiation outcomes, legitimacy, and policy effectiveness (e.g., Doha Round dynamics, Appellate Body issues)."
      ],
      "parent_articles": [
        "International development",
        "World Trade Organization"
      ]
    },
    {
      "question": "How does the interdisciplinary integration of economics and politics enhance understanding of why development interventions succeed or fail, beyond what economics alone can explain?",
      "options": {
        "A": "It demonstrates that political incentives, institutional arrangements, and power relations influence both resource mobilization and policy implementation, thereby shaping outcomes.",
        "B": "It claims political considerations are noise and do not affect economic optimality.",
        "C": "It asserts that economics alone already captures all relevant constraints, so adding politics is redundant.",
        "D": "It suggests that development outcomes are determined by external aid only, ignoring internal policy dynamics."
      },
      "correct_answer": "A",
      "source_article": "Development studies",
      "x": 1.1807793378829956,
      "y": 0.8905182480812073,
      "concepts_tested": [
        "Interdisciplinary integration of economics and politics to address development issues (development studies as a synthesis of political and economic analysis)",
        "Political economy analysis as a framework for explaining factors that enhance or limit development and reform outcomes",
        "Historical emergence and contextual justification for the field (post-colonial/post-war era, Truman 1949) and the shift from economics-only to multi-disciplinary approaches"
      ],
      "parent_concepts": [
        "Concept 2: International development as a distinct field linked to post-WWII institutions (e.g., Bretton Woods) and global governance frameworks guiding policy, practice, and research."
      ],
      "parent_articles": [
        "International development"
      ]
    },
    {
      "question": "According to contingency theory, organizations maximize performance by matching their internal constraints and response mechanisms to environmental and internal variability; the needed variety of responses depends on context. Why does the theory predict that the variety of organizational responses should increase with contextual variability, and how does this mechanism operate to improve performance?",
      "options": {
        "A": "Because higher environmental and internal variability creates more distinct contingencies; having a broader repertoire of responses allows the organization to select a fit action for each situation, reducing mismatch between demand and capability.",
        "B": "Because increasing the number of rules and procedures always guarantees optimal performance, regardless of context.",
        "C": "Because context is irrelevant; a single standardized response works best in all situations.",
        "D": "Because performance only depends on external factors; internal response variety has no impact."
      },
      "correct_answer": "A",
      "source_article": "Organizational theory",
      "x": 1.2444666624069214,
      "y": 0.962929368019104,
      "concepts_tested": [
        "Contingency theory: Organizations maximize performance by matching their internal constraints and response mechanisms to environmental and internal variability; the needed variety of responses depends on context.",
        "Weberian bureaucracy: Characteristics such as impersonal positions, rule-governed decision-making, professionalism, chain of command, defined responsibility, and bounded authority as mechanisms for control and efficiency.",
        "Rational organization components: Specificity of goals, formalization, and division of labor as elements that structure work to increase output and efficiency."
      ],
      "parent_concepts": [
        "Concept 3: Drivers of change and their interaction with change management processes (technology evolution, process reviews, crises, regulation, etc.), illustrating cause-effect relationships that trigger and shape change efforts.",
        "Concept 3: The necessity of proper accounting practices and records management as preconditions for accountability (without accounting, accountability cannot exist).",
        "Concept 2: HRM as an integrated system of policies and processes (recruitment, training, development, performance appraisal, rewards, benefits) that influence employee performance and organizational outcomes"
      ],
      "parent_articles": [
        "Change management",
        "Accountability",
        "Human resource management"
      ]
    },
    {
      "question": "In the mind\u2013body problem, under non-reductive physicalism, how can a mental state like a belief causally influence a physical action without being reducible to brain states?",
      "options": {
        "A": "Because mental states are identical to brain states, so mental causation is just physical causation described differently.",
        "B": "Because mental states are defined by their functional roles and causal relations within the cognitive system, and yet they supervene on brain states, enabling their causal influence on brain and behavior without reducing them.",
        "C": "Because mental states have no causal influence; all behavior is determined by unconstrained physical processes.",
        "D": "Because the mind is a separate substance that directly interacts with the body to produce actions."
      },
      "correct_answer": "B",
      "source_article": "Mind\u2013body problem",
      "x": 1.1773436069488525,
      "y": 1.0711655616760254,
      "concepts_tested": [
        "The mind\u2013body relationship: distinctness vs. unity of mind and body and whether they can causally interact",
        "Competing theoretical frameworks: dualism, physicalism/monism, idealism, functionalism, property dualism, non-reductive theories",
        "Mental causation and agency: how mental states (beliefs, desires) causally influence physical actions and implications for free will and moral responsibility"
      ],
      "parent_concepts": [
        "Concept 3: Conceptual debates and relationships among related notions (consciousness vs. mind vs. brain; definitional boundaries across disciplines)"
      ],
      "parent_articles": [
        "Consciousness"
      ]
    },
    {
      "question": "How does identity act as a self-regulatory structure that provides meaning, direction, and behavioral guidance to influence a person's adaptation and well-being?",
      "options": {
        "A": "It rigidly fixes behavior to predefined social roles, eliminating the need to interpret new contexts.",
        "B": "It links core values, long-term goals, and social roles into a coherent framework that interprets events, guides choices, and mobilizes coping resources, thereby facilitating adaptive responses and well-being.",
        "C": "It is entirely determined by genetic traits and remains immune to context or perception from others.",
        "D": "It functions only as a descriptive label without affecting motivation or action."
      },
      "correct_answer": "B",
      "source_article": "Identity (social science)",
      "x": 1.2509652376174927,
      "y": 1.0079076290130615,
      "concepts_tested": [
        "Identity as a self-regulatory structure that provides meaning, direction, and behavioral guidance, affecting adaptation and well-being.",
        "The relationship between personal identity and collective identity, and how social/cultural factors and others\u2019 perceptions shape both individual behavior and group membership expectations.",
        "Developmental and contextual dynamics of identity: emergence in childhood, stability yet potential for change, and situational adaptability, as explained by theoretical frameworks."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In ethology, why are instinctive (innate) behaviors considered evolutionary adaptations, and how does this view contrast with learned behaviors in relation to natural selection?",
      "options": {
        "A": "Instinctive behaviors are completely fixed and universal across a species, changing only through slow genetic evolution; learned behaviors have no evolutionary significance.",
        "B": "Instinctive behaviors are largely encoded genetically, producing reliable, species-typical responses that can be favored by natural selection; learned behaviors arise from individual experience and can vary among individuals, with natural selection acting primarily on the capacity to learn and on general predispositions rather than on any single learned response.",
        "C": "Instinctive behaviors are acquired entirely through social learning and inheritance; learned behaviors are determined by genetics and do not vary with experience.",
        "D": "Instinctive and learned behaviors are both equally determined by the environment, with natural selection acting directly on each observed behavior regardless of heritability."
      },
      "correct_answer": "B",
      "source_article": "Ethology",
      "x": 1.3419272899627686,
      "y": 1.009497880935669,
      "concepts_tested": [
        "Ethology applies an evolutionary/natural selection framework to understanding behavior (including instinctive vs. other behavior).",
        "Ethograms as a foundational methodological tool for describing and quantifying behavior.",
        "Ethology as an interdisciplinary enterprise that combines laboratory and field study and connects with neuroanatomy, ecology, and evolutionary biology."
      ],
      "parent_concepts": [
        "Secure base and exploration: how a caregiver\u2019s sensitivity and responsiveness create a secure base that supports a child\u2019s exploration and returns for comfort."
      ],
      "parent_articles": [
        "Attachment theory"
      ]
    },
    {
      "question": "In the risk management process, why is evaluating and prioritizing risks before selecting minimization actions essential?",
      "options": {
        "A": "Because limited resources require directing mitigation toward the risks with the highest probability and greatest impact, maximizing overall risk reduction.",
        "B": "Because evaluating risks guarantees all risks will be mitigated to the same level, regardless of their severity.",
        "C": "Because prioritization helps you postpone addressing high-risk items until resources become abundant.",
        "D": "Because once risks are prioritized, monitoring becomes redundant and unnecessary."
      },
      "correct_answer": "A",
      "source_article": "Risk management",
      "x": 1.4502753019332886,
      "y": 1.026569128036499,
      "concepts_tested": [
        "The risk management process: identification, evaluation, prioritization, followed by minimization, monitoring, and control of risks.",
        "Risk treatment strategies and the risk\u2013opportunity relationship: avoidance, reduction, transfer, and retention for threats, with opposite considerations for opportunities.",
        "Standards and professional roles shaping practice: influence of organizations (PMI, NIST, ISO, actuarial societies) and roles like risk manager and risk analyst across contexts."
      ],
      "parent_concepts": [
        "Concept 1: The risk assessment process as a flow of steps (hazard analysis -> risk assessment -> risk evaluation) and how each step informs risk management decisions.",
        "Concept 2: How risk results are interpreted and communicated, including cognitive biases and the role of decision aids in shaping decisions.",
        "Precautionary principle: why it is used when there is scientific uncertainty and how it shapes regulatory action to prevent harm."
      ],
      "parent_articles": [
        "Risk assessment",
        "Risk assessment",
        "Environmental law"
      ]
    },
    {
      "question": "Why does defining risk as the effect of uncertainty on objectives imply that risk can be positive as well as negative, and what does this imply for how risk management should be approached?",
      "options": {
        "A": "Because uncertainty is always bad, so risk management should only minimize deterioration of objectives.",
        "B": "Because uncertainty can cause deviations in either direction from what was planned, so risk management should identify and exploit opportunities as well as mitigate threats across objectives.",
        "C": "Because risk is only about the probability of loss, so management should focus on reducing loss.",
        "D": "Because objectives never change with uncertainty, so risk is irrelevant to decision making."
      },
      "correct_answer": "B",
      "source_article": "Risk",
      "x": 1.5149210691452026,
      "y": 1.0716567039489746,
      "concepts_tested": [
        "Risk as the effect of uncertainty on objectives (deviation from expected; can be positive or negative)",
        "Components of risk (risk sources, potential events, their consequences, and their likelihood)",
        "Cross-domain application of risk management principles (ISO 31000 guidance) and the idea that risk management involves principles and processes, not just definitions"
      ],
      "parent_concepts": [
        "Concept 1: The risk assessment process as a flow of steps (hazard analysis -> risk assessment -> risk evaluation) and how each step informs risk management decisions."
      ],
      "parent_articles": [
        "Risk assessment"
      ]
    },
    {
      "question": "Why does tailoring risk communication messages to audiences' values typically improve the likelihood of behavior change to reduce threats?",
      "options": {
        "A": "It reduces the amount of information by focusing on a single value, making the message easier to accept.",
        "B": "It aligns the message with the audience's core values and social norms, increasing perceived relevance and trust, which promotes engagement and behavior change.",
        "C": "It guarantees that only scientifically accepted details are presented, avoiding conflicting data.",
        "D": "It ensures compliance by appealing exclusively to fear, which always leads to action."
      },
      "correct_answer": "B",
      "source_article": "Risk communication",
      "x": 1.3281779289245605,
      "y": 0.9888179302215576,
      "concepts_tested": [
        "Concept 1: Distinction between risk communication and crisis communication (goals, scope, outcomes)",
        "Concept 2: Mechanisms of risk communication (tailoring messages to audience values, raising awareness, persuading behavior change to reduce threats)",
        "Concept 3: Contexts and scales (community-level vs. individual-level risk communication; influence of information sources and decision-making processes)"
      ],
      "parent_concepts": [
        "Concept 2: How risk results are interpreted and communicated, including cognitive biases and the role of decision aids in shaping decisions."
      ],
      "parent_articles": [
        "Risk assessment"
      ]
    },
    {
      "question": "Why do study design features such as establishing temporality and controlling for confounding (via randomization or proper adjustment) matter for distinguishing causation from correlation in epidemiology?",
      "options": {
        "A": "Temporality ensures the exposure precedes the outcome, and randomization or rigorous adjustment minimizes confounding, making observed exposure-outcome differences more likely to reflect a causal effect rather than a coincidental association.",
        "B": "A large sample size alone converts a correlation into causation by eliminating random error.",
        "C": "Adjusting for a single confounder is sufficient to prove causality because it removes all bias in the estimate.",
        "D": "Biological plausibility is enough to infer causation without considering the study design or data analysis."
      },
      "correct_answer": "A",
      "source_article": "Epidemiology",
      "x": 1.0723103284835815,
      "y": 0.8857176303863525,
      "concepts_tested": [
        "Concept 1: The relationship between distribution/ppatterns/determinants in a population and the use of that knowledge to prevent disease.",
        "Concept 2: Causation vs correlation in epidemiology, including how study design, data collection, and statistical analysis identify risk factors and assess treatment effects.",
        "Concept 3: Interdisciplinary integration (biology, statistics, social sciences, engineering) and the broad application of epidemiology beyond infectious diseases to chronic conditions and population-level health outcomes."
      ],
      "parent_concepts": [
        "The environment-health relationship: environmental exposures (chemical, physical, biological) influence health outcomes and are studied to understand these effects.",
        "How study design choices influence bias and validity (e.g., why certain designs are more prone to recall bias or ecological fallacy and how that affects causal interpretation)",
        "Screening and immunization as mechanism-led prevention: how identifying risk factors and preventing disease onset/progression demonstrates cause-effect in preventive care."
      ],
      "parent_articles": [
        "Environmental health",
        "Clinical study design",
        "Preventive healthcare"
      ]
    },
    {
      "question": "In a One Health framework, why does ecological change (for example, habitat modification or climate shifts) alter disease risk and influence how we should approach treatment across humans and animals?",
      "options": {
        "A": "Because ecological changes reshape contact networks and pathogen ecology, altering spillover risk and the relevance of shared treatments across species, which requires integrated surveillance and cross-sector collaboration.",
        "B": "Because ecological changes only affect wildlife populations and have no impact on human disease risk, so treating humans alone is sufficient.",
        "C": "Because treatment choices are determined solely by human clinical guidelines and are independent of animal health or environmental context.",
        "D": "Because ecological changes always reduce pathogen load in the environment, thereby eliminating the need for coordinated, multi-sector health interventions."
      },
      "correct_answer": "A",
      "source_article": "One Health",
      "x": 1.2422738075256348,
      "y": 0.8568187355995178,
      "concepts_tested": [
        "Interdependence of human, animal, and environmental health and how ecological change affects disease risk and treatment",
        "One Health as a unifying, collaborative, multidisciplinary framework that mobilizes multiple sectors to balance and optimize health across humans, animals, plants, and ecosystems",
        "Drivers prompting the approach (zoonotic disease transmission, shared physiology, and antimicrobial resistance) and the need for integrated actions across sectors to manage these risks"
      ],
      "parent_concepts": [
        "The environment-health relationship: environmental exposures (chemical, physical, biological) influence health outcomes and are studied to understand these effects."
      ],
      "parent_articles": [
        "Environmental health"
      ]
    },
    {
      "question": "In health promotion, why does focusing on enabling people to influence health determinants offer a mechanism for improving health outcomes that goes beyond just changing individual behaviors?",
      "options": {
        "A": "It works by primarily increasing access to health services for individuals, which is the main driver of population health improvements.",
        "B": "It expands people's control over social, economic, and environmental determinants (e.g., housing, income, working conditions), so changes in policy and environment support healthier choices; this leads to broader, sustainable health improvements beyond mere individual behavior change.",
        "C": "It relies on short-term education campaigns to alter knowledge, which quickly translates to behavior without affecting determinants.",
        "D": "It assumes health outcomes are mostly genetic, so empowerment cannot influence them."
      },
      "correct_answer": "B",
      "source_article": "Health promotion",
      "x": 1.2643097639083862,
      "y": 0.9393352270126343,
      "concepts_tested": [
        "Concept 1: Health promotion as enabling/empowering people to influence health determinants (mechanism linking empowerment to health outcomes)",
        "Concept 2: The centrality of social determinants (income, housing, employment, etc.) and multi-sectoral policy approaches (Health in All Policies) in producing health outcomes",
        "Concept 3: Distinction between health promotion and health education, and the idea that preventive, environmental, and policy interventions are core to promotion (not just individual behavior change)"
      ],
      "parent_concepts": [
        "Prevention and control as core principles: assessing environmental factors to prevent disease and create health-supportive environments."
      ],
      "parent_articles": [
        "Environmental health"
      ]
    },
    {
      "question": "In causal inference, researchers rely on covariation (the cause and effect vary together), time-order (the cause precedes the effect), and elimination of plausible alternative explanations. How do these criteria work together to justify a causal claim, and what specific threat does each criterion address?",
      "options": {
        "A": "Covariation alone suffices to prove causality; time-order and eliminating alternatives are redundant and do not add new information about causality.",
        "B": "Time-order prevents reverse causation by ensuring the cause precedes the effect; elimination of plausible alternatives addresses confounding by other variables; together with covariation they constrain explanations and strengthen the causal inference.",
        "C": "Time-order only concerns the magnitude of the effect, not its direction, and removing alternatives only targets measurement precision; covariation is the sole determinant of causality.",
        "D": "These criteria are meaningful only in randomized experiments; in observational data, covariation, time-order, and eliminating alternatives cannot contribute to causal claims."
      },
      "correct_answer": "B",
      "source_article": "Causal inference",
      "x": 1.5830862522125244,
      "y": 1.1236891746520996,
      "concepts_tested": [
        "Concept 1: Causality requires observing the effect when the cause is changed (distinction from mere association)",
        "Concept 2: Criteria for inferring causality: covariation, time-order (cause precedes effect), and elimination of plausible alternative causes",
        "Concept 3: Role of methodological testing (falsifiable null hypotheses and statistical frameworks like frequentist vs Bayesian) in supporting causal claims"
      ],
      "parent_concepts": [
        "How study design choices influence bias and validity (e.g., why certain designs are more prone to recall bias or ecological fallacy and how that affects causal interpretation)"
      ],
      "parent_articles": [
        "Clinical study design"
      ]
    },
    {
      "question": "Why does randomization in experimental design help support causal inference, and how does it enable the use of p-values in statistical inference?",
      "options": {
        "A": "It increases measurement precision, making p-values smaller.",
        "B": "It guarantees that treatment effects exist, so p-values always indicate real effects.",
        "C": "It balances both known and unknown confounders across treatment groups in expectation, so observed differences can be attributed to treatment, which p-values quantify as evidence against the null.",
        "D": "It eliminates all sources of experimental error, so p-values become exact."
      },
      "correct_answer": "C",
      "source_article": "Biostatistics",
      "x": 1.5991631746292114,
      "y": 1.1276692152023315,
      "concepts_tested": [
        "The design of experiments and statistical inference as foundational principles for how biological data are collected, analyzed, and interpreted.",
        "The integration of statistics with genetics and evolution to form population genetics and the modern evolutionary synthesis (conceptual link between disciplines).",
        "The use of foundational statistical tools (e.g., ANOVA, p-values, Fisher\u2019s exact test) as mechanisms enabling testing and interpretation of biological hypotheses."
      ],
      "parent_concepts": [
        "How study design choices influence bias and validity (e.g., why certain designs are more prone to recall bias or ecological fallacy and how that affects causal interpretation)",
        "Distribution, patterns, and determinants: how identifying where/when diseases occur and what factors influence them leads to identification of risk factors and preventive targets."
      ],
      "parent_articles": [
        "Clinical study design",
        "Epidemiology"
      ]
    },
    {
      "question": "In a population health framework, why does prioritizing policies that modify social determinants and structural conditions tend to reduce health inequities more effectively than approaches that target only individual health behaviors?",
      "options": {
        "A": "Because changing individual behavior alone raises overall health but does not alter the underlying distribution of risk across the population.",
        "B": "Because social determinants have no impact on health outcomes; focusing on them is a distraction.",
        "C": "Because modifying social determinants expands healthcare capacity to treat illnesses after they occur.",
        "D": "Because behavior-focused interventions completely redirect resources away from communities in need."
      },
      "correct_answer": "A",
      "source_article": "Population health",
      "x": 1.2179906368255615,
      "y": 0.8876582980155945,
      "concepts_tested": [
        "Concept 1: Social determinants of health are major determinants of population health outcomes and health inequities.",
        "Concept 2: Population health shifts focus from individual-level factors to population-level determinants and policies/interventions to improve health.",
        "Concept 3: Health is a broader construct than absence of disease, including capacity to adapt to life\u2019s challenges and overall well-being."
      ],
      "parent_concepts": [
        "Distribution, patterns, and determinants: how identifying where/when diseases occur and what factors influence them leads to identification of risk factors and preventive targets."
      ],
      "parent_articles": [
        "Epidemiology"
      ]
    },
    {
      "question": "The mass media system is often described as one-to-many with a separation between where content is produced and where audiences receive it. How does this separation primarily account for both its wide reach across time and space and the limitations on audience feedback and customization?",
      "options": {
        "A": "It enables real-time, individualized feedback from every viewer, which rapidly reshapes the producer's output.",
        "B": "It decouples production from reception, allowing messages to reach very large, distant audiences, but reducing immediate, audience-specific feedback and local tailoring.",
        "C": "It requires content to be produced locally for each community, ensuring perfect alignment with local needs and ongoing two-way dialogue.",
        "D": "It guarantees instantaneous distribution with no lag, so audiences experience content as soon as it is produced, preserving a perfect feedback loop."
      },
      "correct_answer": "B",
      "source_article": "Mass media",
      "x": 1.241655945777893,
      "y": 0.9954867959022522,
      "concepts_tested": [
        "Concept 1: Production and distribution are both technical and institutional processes that shape how mass media outputs are created and circulated.",
        "Concept 2: Commodification of symbolic forms drives content production and dissemination by tying meaning and imagery to economic value.",
        "Concept 3: The mass media function as a one-to-many, time/space-spanning system with a separation between where content is produced and where/how audiences receive it."
      ],
      "parent_concepts": [
        "Legal/regulatory and institutional relationships: how freedom of speech laws, government control, and professional organizations influence journalistic practice.",
        "Concept 1: Technology-driven expansion of news dissemination and public access (e.g., printing press enabling broader, regular distribution).",
        "Concept 2: Evolution of news formats and the criteria that distinguish a \"newspaper\" (audience scope, regularity, accessibility) from earlier notices and pamphlets.",
        "Concept 2: The methods and reach of propaganda evolve with technology, from traditional media (paintings, posters, radio) to digital forms (social media, bots, computational propaganda).",
        "Concept 1: Printing as a mass-reproduction technology that enables widespread dissemination of text and images, influencing learning and literacy."
      ],
      "parent_articles": [
        "Journalism",
        "History of journalism",
        "History of journalism",
        "Propaganda",
        "Printing"
      ]
    },
    {
      "question": "Which statement best explains how the factors of extent, duration, motive, and avoidability function in evaluating the legitimacy of speech restrictions under a harm-based framework for freedom of expression?",
      "options": {
        "A": "They provide a sliding scale where any increase in extent or duration automatically justifies restricting speech, regardless of other considerations.",
        "B": "They are considered only for illegal content; if content is legal, these factors do not apply.",
        "C": "They are used to assess proportionality and necessity, ensuring restrictions target the least intrusive means to prevent harm, by weighing how far-reaching the speech is, how long the harm lasts, the speaker's intent, and whether the harm could have been avoided.",
        "D": "They prioritize the speaker's status or identity; if the speaker is a minority, any restriction is invalid."
      },
      "correct_answer": "C",
      "source_article": "Freedom of speech",
      "x": 1.1938668489456177,
      "y": 0.8327916860580444,
      "concepts_tested": [
        "Concept 1: Harm principle as justification for restricting freedom of speech",
        "Concept 2: Scope of freedom of expression vs. freedom of speech, including the seek/receive/impart information and the associated duties/responsibilities",
        "Concept 3: Mechanisms and criteria for limiting speech (legal boundaries like libel, obscenity, incitement, hate speech; and digital-age mechanisms like internet censorship and platform content moderation) and how factors (extent, duration, motive, avoidability) affect legitimacy"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In entertainment contract practice, including a profit-participation provision (e.g., back-end participation) is common. How does this mechanism affect incentives and risk, and why does it necessitate precise drafting of accounting terms and a waterfall structure?",
      "options": {
        "A": "It guarantees profits to participants, removing risk and accountability for financial reporting.",
        "B": "It aligns incentives by linking compensation to net performance, but introduces complexity in defining net profits, cost allocations, and payment order, requiring explicit accounting rules and audit rights to avoid disputes.",
        "C": "It shifts all risk to the financiers, so contract drafting focuses only on payment timelines, not accounting.",
        "D": "It has no impact on incentives; it is mainly a marketing term."
      },
      "correct_answer": "B",
      "source_article": "Entertainment law",
      "x": 1.2757223844528198,
      "y": 0.8894203305244446,
      "concepts_tested": [
        "Concept 1: Interdisciplinary nature of entertainment law and its overlap with multiple legal domains (IP, contract, labor, First Amendment, etc.), requiring cross-field understanding.",
        "Concept 2: Transaction-based practice and the negotiation/drafting mechanism (contracts, compensation, profit participation) that drive most work in the field, with potential for dispute resolution.",
        "Concept 3: IP framework as foundational to entertainment work (copyright ownership, exclusive rights) and the role of institutions like the US Copyright Office in establishing and recording rights."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "How does multiplexing enable multiple concurrent communication sessions on a single physical medium, and why does it rely on separating channels in time, frequency, or code to prevent interference?",
      "options": {
        "A": "By duplicating each session's signal and sending all copies in parallel on the same medium, with the receiver deducing the intended copy through timing.",
        "B": "By partitioning the medium into non-overlapping resources in time, frequency, or code, so each session uses a distinct resource and receivers separate channels based on those distinctions.",
        "C": "By packing all signals into one continuous waveform and letting a single shared filter separate content purely by message type at the receiver.",
        "D": "By increasing the physical size of the medium so that different sessions occupy physically distinct cables, avoiding any overlap."
      },
      "correct_answer": "B",
      "source_article": "Telecommunications",
      "x": 1.3567607402801514,
      "y": 1.0178149938583374,
      "concepts_tested": [
        "Concept 1: Multiplexing and communication channels\u2014how a single medium can carry multiple concurrent sessions.",
        "Concept 2: Media evolution and its consequences\u2014why physical limits of metallic media led to optical fiber and a shift from voice to data.",
        "Concept 3: Internet as a medium-independent network\u2014how a universal network enables global access and reduces location/time constraints, linking technology to services."
      ],
      "parent_concepts": [
        "Concept 2: Error control (channel coding) adds redundancy to detect/correct errors, improving reliability over noisy channels.",
        "Concept 3: The role of communication protocols and physical media in enabling data exchange across networks (how protocols plus media realize inter-host communication)."
      ],
      "parent_articles": [
        "Coding theory",
        "Computer network"
      ]
    },
    {
      "question": "Why is explanation design central to information design, and how does it influence decisions about what to show, how to organize it, and what to emphasize?",
      "options": {
        "A": "It prioritizes aesthetic appeal to engage users, since beauty guarantees comprehension and retention.",
        "B": "It directs content selection, organization, and emphasis to support causal reasoning and informed action, rather than merely listing data.",
        "C": "It ensures every possible data point is shown in the fastest way possible, regardless of audience needs.",
        "D": "It treats all information equally, avoiding any prioritization or guidance to prevent bias."
      },
      "correct_answer": "B",
      "source_article": "Information design",
      "x": 1.358228087425232,
      "y": 1.0713382959365845,
      "concepts_tested": [
        "The multi-scale structure of information design: large-scale content selection by audience and purpose; medium-scale organization with overviews, concepts, examples, references, definitions following an organizing principle; small-scale details focusing on logical development, emphasis, writing clarity, navigational clues, and layout (typography/white space).",
        "Explanation design as the core aim: information design is about explaining facts to foster knowledge and informed action, not just presenting information aesthetically.",
        "Relationships with related fields and the role of the information designer: overlap and distinctions with data visualization and information architecture, and the idea that information designers\u2019 skill sets align with information architects in digital contexts."
      ],
      "parent_concepts": [
        "Concept 3: Design as communication\u2014arranging map elements to effectively convey spatial information and the intended message."
      ],
      "parent_articles": [
        "Cartography"
      ]
    },
    {
      "question": "In visual communication, how does a viewer\u2019s prior experience shape the meaning they construct from a visual cue, and why can the same image be interpreted differently by different people?",
      "options": {
        "A": "The brain maps visuals to fixed universal symbols that are identical across all experiences.",
        "B": "Perception relies solely on low-level features like color and contrast, with no influence from context.",
        "C": "The brain uses prior knowledge and expectations to interpret ambiguous visuals, so different experiences yield different meanings.",
        "D": "Meanings are determined only by cultural background, not by individual experience or context."
      },
      "correct_answer": "C",
      "source_article": "Visual communication",
      "x": 1.3216086626052856,
      "y": 1.0316888093948364,
      "concepts_tested": [
        "Perception-based interpretation: how the brain constructs meaning from visual imagery and how interpretation varies with the viewer\u2019s experience.",
        "Design element framework: the seven components (color, shape, tones, texture, figure-ground, balance, hierarchy) as core levers shaping visual communication.",
        "Evaluation principle: effectiveness is judged by audience comprehension rather than aesthetic preferences."
      ],
      "parent_concepts": [
        "Concept 3: Design as communication\u2014arranging map elements to effectively convey spatial information and the intended message.",
        "Concept 1"
      ],
      "parent_articles": [
        "Cartography",
        "Graphic design"
      ]
    },
    {
      "question": "How does adopting a market-oriented mixed economy alter the way incentives interact with resource constraints, and why is this blending necessary for efficient production and distribution?",
      "options": {
        "A": "It centralizes decisions to achieve perfect pricing, thereby removing the need for incentives.",
        "B": "It relies solely on price signals and private contracts, ignoring any government role.",
        "C": "It blends private property and price-guided decisions with selective government actions to correct distortions (like externalities and public goods under-provision) and to ensure information-supported allocation, preserving market incentives while addressing failures.",
        "D": "It eliminates price signals and relies on equal distribution by policy."
      },
      "correct_answer": "C",
      "source_article": "Economic system",
      "x": 1.2490851879119873,
      "y": 0.9395354390144348,
      "concepts_tested": [
        "The four fundamental economic problems (what to produce, how to produce, for whom to produce/distribute, when to produce) and how pricing and resource constraints influence these decisions.",
        "The role of institutions, information flows, and property rights in coordinating production and allocation within an economic system.",
        "The evolution from market/plan dichotomies to market-oriented mixed economies and why the chosen system matters for incentives and resource allocation."
      ],
      "parent_concepts": [
        "Concept 2: The forms of socialism (non-market vs market socialism) and their distinct mechanisms for organizing the economy (planning and price signals vs continued use of monetary prices and markets) and the implications for efficiency and profit."
      ],
      "parent_articles": [
        "Socialism"
      ]
    },
    {
      "question": "In understanding ideology as a \"science of ideas\" that links sensory experience to ideas to form a structured system, what mechanism best explains how such a system remains coherent when new or conflicting experiences arise?",
      "options": {
        "A": "It re-senses the world to directly override existing ideas, letting raw data determine core principles.",
        "B": "It filters and reframes incoming experience through pre-existing categories, aligning new data with the system and treating anomalies as exceptions.",
        "C": "It treats all new sensations as equally valid, continuously reshaping its core structure in response to every new input.",
        "D": "It requires external empirical verification before updating any belief, ensuring complete alignment with observed data."
      },
      "correct_answer": "B",
      "source_article": "Ideology",
      "x": 1.1785646677017212,
      "y": 0.9714807271957397,
      "concepts_tested": [
        "Concept 1: Ideology as a \"science of ideas\" linking sensory experience to ideas to form a structured system of thought (mechanism/principle).",
        "Concept 2: The balance between practical elements and theoretical elements within an ideology (relationship between practice and theory).",
        "Concept 3: Normative core of ideology (defense of individual liberty, property, free markets, and constitutional limits on state power)."
      ],
      "parent_concepts": [
        "Concept 3: Religion\u2019s role in shaping extremist ideologies and movements (e.g., Islamism, Christian nationalism, religious terrorism) and how doctrinal beliefs translate into political violence or policy aims"
      ],
      "parent_articles": [
        "Religion in politics"
      ]
    },
    {
      "question": "Why is it conceptually appropriate to study macro policy effects using aggregate variables rather than simply summing up price changes from every individual market, and how do policy actions influence these aggregates despite heterogeneous micro responses?",
      "options": {
        "A": "Because micro markets are perfectly synchronized, so the aggregate outcome is identical to any single market\u2019s response.",
        "B": "Because macro policy operates through economy-wide channels (aggregate demand, expectations, and overall resource utilization) and the combined effect of many diverse micro responses can produce aggregate outcomes that are not predictable from any single market alone.",
        "C": "Because micro market data are too noisy and thus cannot inform policy, so economists only rely on aggregate statistics.",
        "D": "Because individuals can completely shield themselves from policy changes, making micro-level effects vanish and only aggregates move in policy experiments."
      },
      "correct_answer": "B",
      "source_article": "Macroeconomics",
      "x": 1.2758371829986572,
      "y": 0.9374863505363464,
      "concepts_tested": [
        "Concept 1: The macro/micro distinction and the focus on aggregate variables and policy effects at the economy-wide level.",
        "Concept 2: The time-frame decomposition in macroeconomics (short-term business cycles, medium-term structural levels, long-term growth) and how this shapes analysis and policy priorities.",
        "Concept 3: Policy mechanisms (fiscal policy\u2014taxation and government expenditure; monetary policy\u2014interest rates) and their causal impact on output, unemployment, inflation, and living standards, including the idea of stabilization vs. growth objectives."
      ],
      "parent_concepts": [
        "The fiscal policy mechanism: how government spending and taxation (fiscal stance) influence aggregate demand and macroeconomic stabilization, including deficits/surpluses as indicators.",
        "Concept 3: The threefold objectives of public finance (efficient allocation, distribution of income, economic stability) and the cause\u2013effect relationships between interventions and these outcomes.",
        "Concept 3: Measurement challenges and limitations in estimating the world economy (data quality, legality of markets, regulatory differences) and how they affect global comparisons.",
        "Concept 3: Stabilization under policy constraints, including potential limitations like liquidity traps and political/institutional factors that influence the effectiveness and timing of policy actions.",
        "Money\u2019s functions and their policy implications (medium of exchange, store of value, unit of account; why these roles matter for macro outcomes)",
        "Concept 2: Policy frameworks and goals \u2014 how choosing inflation targeting, fixed exchange rate, or money-supply targeting shapes policy decisions, credibility, and outcomes.",
        "Parity-based determinants of exchange rates (purchasing power parity, interest rate parity, and the international Fisher effect) and their implications for currency movements."
      ],
      "parent_articles": [
        "Economic policy",
        "Public finance",
        "World economy",
        "Fiscal policy",
        "Monetary economics",
        "Monetary policy",
        "International finance"
      ]
    },
    {
      "question": "In policy analysis, what is the fundamental difference between analysis for policy and analysis of policy, and why does that difference matter for policymaking?",
      "options": {
        "A": "Analysis for policy is prescriptive and aims to generate and compare policy options to achieve stated goals; analysis of policy is descriptive and explanatory, aiming to explain how policies were designed, implemented, and what effects they produced; the difference matters because prescriptive analysis directly informs decision-making with concrete proposals, while descriptive analysis provides understanding of causal mechanisms and outcomes to guide learning and reform.",
        "B": "Analysis for policy uses only quantitative methods; analysis of policy uses only qualitative methods.",
        "C": "Analysis for policy focuses on past performance; analysis of policy forecasts future outcomes.",
        "D": "Analysis for policy is done by political actors; analysis of policy is done by researchers; The difference is about who conducts the analysis, not the purpose or method."
      },
      "correct_answer": "A",
      "source_article": "Policy analysis",
      "x": 1.2865599393844604,
      "y": 0.9646441340446472,
      "concepts_tested": [
        "Concept 1: The decision-making process in policy analysis \u2014 identifying potential options and evaluating them on criteria such as effectiveness, efficiency, and feasibility to achieve stated goals.",
        "Concept 2: The dual roles of policy analysis \u2014 analysis for policy (prescriptive, policy development) vs. analysis of policy (descriptive, explanatory), and how each informs policymaking.",
        "Concept 3: The theoretical roots and traditions of policy analysis \u2014 origins in systems analysis and the existence of two research traditions (practice-driven policy development vs. academic/think-tank analysis)."
      ],
      "parent_concepts": [
        "Policy goals versus policy tools: the distinction between objectives (inflation, unemployment, growth) and instruments (taxation, spending, money supply, interest rates, tariffs) and the trade-offs involved in achieving those goals.",
        "EIA as a decision-support tool that requires accounting for environmental values and justification of decisions, rather than guaranteeing a predetermined environmental outcome."
      ],
      "parent_articles": [
        "Economic policy",
        "Environmental impact assessment"
      ]
    },
    {
      "question": "In the presence of a negative externality, how does a Pigouvian tax improve efficiency, and what mechanism explains why welfare rises?",
      "options": {
        "A": "It imposes a tax equal to the marginal external cost, raising private marginal cost to align with social marginal cost, so the market quantity moves toward the social optimum and total welfare increases.",
        "B": "It taxes the entire cost of production, leaving private marginal costs unchanged but redistributing surplus to the government, which does not necessarily improve welfare.",
        "C": "It exempts the polluting activity to encourage production, increasing efficiency by letting private costs dominate.",
        "D": "It shifts the external cost to consumers via price controls, eliminating the externality without changing production decisions."
      },
      "correct_answer": "A",
      "source_article": "Public economics",
      "x": 1.2465407848358154,
      "y": 0.9233269691467285,
      "concepts_tested": [
        "Concept 1: Market failures justify government intervention (e.g., public goods, externalities, imperfect competition) and the mechanisms by which policy addresses them.",
        "Concept 2: Balancing efficiency and equity in policy design using welfare economics and normative analysis to guide tax and expenditure decisions.",
        "Concept 3: Distinction between market failure and government failure, plus the framework for deciding the appropriate extent of government participation in the economy."
      ],
      "parent_concepts": [
        "Concept 2: Mechanisms/tools of intervention (public provision, taxation, subsidies) and how they alter resource allocation and income distribution.",
        "Concept 3: The threefold objectives of public finance (efficient allocation, distribution of income, economic stability) and the cause\u2013effect relationships between interventions and these outcomes.",
        "Concept 3: Stabilization under policy constraints, including potential limitations like liquidity traps and political/institutional factors that influence the effectiveness and timing of policy actions.",
        "Externalities in health (e.g., infectiousDisease spread, opioid abuse) lead to effects on others, justifying public intervention and collective action."
      ],
      "parent_articles": [
        "Public finance",
        "Public finance",
        "Fiscal policy",
        "Health economics"
      ]
    },
    {
      "question": "Why does the value of information (VoI) correspond to the maximum price a rational decision-maker would pay to reorder some uncertainties earlier in the decision sequence?",
      "options": {
        "A": "Because knowing an uncertainty earlier allows decisions to be conditioned on its realized value, expanding decision options and potentially raising the expected payoff; VoI captures the incremental improvement in the optimal expected payoff from having that earlier information.",
        "B": "Because VoI measures the average gain from any single additional decision, independent of information timing.",
        "C": "Because reordering uncertainties never affects optimal decisions under rationality, so VoI is a fixed property of the problem.",
        "D": "Because VoI is determined purely by the total number of uncertainties, not by their timing or impact."
      },
      "correct_answer": "A",
      "source_article": "Value of information",
      "x": 1.416479229927063,
      "y": 1.0360949039459229,
      "concepts_tested": [
        "The value of information depends on when information is available in the decision sequence; moving uncertainties earlier increases the potential payoff and is captured by the highest price a decision-maker would pay (VoI as the price for reordering information).",
        "VoI is connected to other information values and can be seen as the value of perfect information on some related uncertainty (VoC), tying together VOI with EVPI and EVSI.",
        "The standard decision framework assumes rationality with perfect recall and a linear ordering of decisions and uncertainties; this ordering defines what is known when decisions are made and how VOI is computed."
      ],
      "parent_concepts": [
        "Concept 2: Passive vs. active adaptive management \u2014 whether learning is valued only for decision quality or explicitly incorporated into the objective function to prioritize learning."
      ],
      "parent_articles": [
        "Adaptive management"
      ]
    },
    {
      "question": "In the context of optimal experimental design, the information matrix quantifies how much information the observed data provide about model parameters. Conceptually, why does making the information matrix larger (in the positive definite sense) tend to reduce the variances of the parameter estimates?",
      "options": {
        "A": "Because more information directly lowers the bias term, which in turn reduces variance.",
        "B": "Because a fundamental bound states that the covariance of any unbiased estimator is at least the inverse information matrix; thus increasing information lowers this bound on variance.",
        "C": "Because the information matrix is the same as the estimator\u2019s variance when errors are Gaussian, so increasing it reduces variance.",
        "D": "Because larger information reduces the number of parameters to estimate, which distributes variability and lowers each parameter\u2019s variance."
      },
      "correct_answer": "B",
      "source_article": "Optimal experimental design",
      "x": 1.606241226196289,
      "y": 1.1285841464996338,
      "concepts_tested": [
        "Concept 1: The connection between estimator variance and information",
        "Concept 2: Model- and criterion-dependent nature of optimal designs",
        "Concept 3: A-optimality as a concrete criterion"
      ],
      "parent_concepts": [
        "Concept 2: Passive vs. active adaptive management \u2014 whether learning is valued only for decision quality or explicitly incorporated into the objective function to prioritize learning."
      ],
      "parent_articles": [
        "Adaptive management"
      ]
    },
    {
      "question": "Why do metabolic pathways regulate enzyme activity to control flux rather than relying solely on changing enzyme abundance, and how does this enable rapid adaptation to changing cellular conditions?",
      "options": {
        "A": "Because post-translational regulation (allosteric and covalent modifications) can swiftly tune enzyme activity in response to signals, allowing fast changes in flux without new protein synthesis; changing enzyme abundance is slower and energetically costlier.",
        "B": "Because adjusting enzyme quantity is faster than changing activity, which would require slower transcription and translation.",
        "C": "Because pathway direction is fixed and unaffected by regulatory signals; only enzyme abundance determines flux, so regulation of activity is unnecessary.",
        "D": "Because regulation happens only at the gene level, so immediate flux changes cannot occur via enzyme activity."
      },
      "correct_answer": "A",
      "source_article": "Metabolism",
      "x": 1.9948660135269165,
      "y": 1.079206943511963,
      "concepts_tested": [
        "Concept 1: Catabolic vs. anabolic metabolism, and the role of energy release vs. consumption, with energy coupling via enzyme-catalyzed reactions.",
        "Concept 2: Metabolic pathways are enzyme-driven sequences that are regulated to control the rate and direction of metabolism in response to cellular conditions and signals.",
        "Concept 3: Core metabolic pathways are conserved across diverse organisms due to evolutionary history and their enduring efficacy."
      ],
      "parent_concepts": [
        "Concept 1: Energy transduction and ATP as the cellular energy currency, linking energy input (nutrient or light) to work output via metabolic pathways.",
        "Concept 2: Thermodynamics in biology, including energy conservation and the idea that breaking/forming bonds governs usable energy (first law application to metabolism)."
      ],
      "parent_articles": [
        "Bioenergetics",
        "Bioenergetics"
      ]
    },
    {
      "question": "Why is ATP hydrolysis essential for driving endergonic biosynthetic reactions in cellular metabolism?",
      "options": {
        "A": "Because ATP hydrolysis releases a large amount of free energy (negative \u0394G) that can be coupled to endergonic steps, and the energy is stored in high-energy phosphate bonds that are transferred to substrates via phosphorylation.",
        "B": "Because ATP is the only energy source in cells and its hydrolysis directly provides heat to accelerate all reactions.",
        "C": "Because ATP hydrolysis occurs exclusively in mitochondria, directing energy to synthesis elsewhere.",
        "D": "Because removing products from a reaction is always enough to make it spontaneous, so ATP is unnecessary."
      },
      "correct_answer": "A",
      "source_article": "Biochemistry",
      "x": 1.9675965309143066,
      "y": 1.0692552328109741,
      "concepts_tested": [
        "Concept 1: Metabolism as the set of chemical reactions by which cells harvest and use energy to drive biological processes.",
        "Concept 2: The major macromolecules (proteins, nucleic acids, carbohydrates, lipids) and their structures, functions, and interactions that enable cellular life.",
        "Concept 3: The relationships between biochemistry and related fields (molecular biology) and the broad applications of biochemical principles in medicine, nutrition, agriculture, and biotechnology."
      ],
      "parent_concepts": [
        "Concept 1: Energy transduction and ATP as the cellular energy currency, linking energy input (nutrient or light) to work output via metabolic pathways.",
        "Concept 2: Enzymes as catalysts that regulate metabolic reactions and enable coupling to spontaneous, energy-releasing steps to control reaction rates.",
        "The complementary roles of X-ray crystallography, NMR spectroscopy, and electron microscopy (including cryo-EM) in determining biological 3D structures and how advances in instrumentation/software drive progress."
      ],
      "parent_articles": [
        "Bioenergetics",
        "Metabolism",
        "Structural biology"
      ]
    },
    {
      "question": "Why is hydrolysis of ATP able to power an energetically unfavorable biosynthetic reaction, and which thermodynamic principle explains how the action enables the overall process to occur?",
      "options": {
        "A": "Because ATP hydrolysis releases a large negative Gibbs free energy change, and when that exergonic step is tightly coupled to the endergonic reaction, the total \u0394G is negative, allowing the overall process to proceed spontaneously.",
        "B": "Because ATP hydrolysis directly lowers the activation energy of bond formation in the endergonic reaction.",
        "C": "Because ATP acts as a persistent catalyst that stabilizes the transition state of the endergonic reaction without changing the energy balance.",
        "D": "Because hydrolysis of ATP generates heat that raises the temperature enough to drive the endergonic reaction."
      },
      "correct_answer": "A",
      "source_article": "Bioenergetics",
      "x": 1.8545693159103394,
      "y": 1.062508463859558,
      "concepts_tested": [
        "Concept 1: Energy transformation and storage in biology (ATP as the energy currency; how energy is captured, stored, and used to perform work)",
        "Concept 2: Integrative role of metabolic pathways (how glycolysis, the citric acid cycle, and respiration couple energy release with energy utilization across the network)",
        "Concept 3: Thermodynamics in biology (conservation of energy; energy changes when bonds form/break; how endergonic and exergonic steps are coupled, including energy flow from sunlight via photosynthesis to chemical energy)"
      ],
      "parent_concepts": [
        "Concept 2: Enzymes as catalysts that regulate metabolic reactions and enable coupling to spontaneous, energy-releasing steps to control reaction rates."
      ],
      "parent_articles": [
        "Metabolism"
      ]
    },
    {
      "question": "Why might a pre-implementation impact assessment (IA) and a post-implementation evaluation yield different conclusions about a policy's effects, and which mechanism best explains this divergence?",
      "options": {
        "A": "Divergence mainly results from measurement errors in post-implementation data, implying that better data collection would align results.",
        "B": "Changes in political regime or governance between the IA and implementation can shift policy goals, instruments, and context, causing observed outcomes to differ from the predicted ones.",
        "C": "Divergence primarily arises from overcomplexity in the IA model, which leads to overfitting and predictions that never reflect real-world conditions.",
        "D": "If the IA is conducted correctly, outcomes will always match predictions; any difference indicates a fundamental flaw in policy design, not in the assessment process."
      },
      "correct_answer": "B",
      "source_article": "Impact assessment",
      "x": 1.3285115957260132,
      "y": 0.880091667175293,
      "concepts_tested": [
        "Concept 1: Impact assessments function as a mechanism to improve policy legitimacy and transparency through stakeholder consultation and public disclosure.",
        "Concept 2: The relationship between pre-implementation impact assessment and post-implementation evaluation, including how divergence can arise from political changes or complex real-world conditions.",
        "Concept 3: Impact assessments as a learning tool that identifies causal relationships to inform ongoing policy development and ex-post review."
      ],
      "parent_concepts": [
        "EIA as a decision-support tool that requires accounting for environmental values and justification of decisions, rather than guaranteeing a predetermined environmental outcome."
      ],
      "parent_articles": [
        "Environmental impact assessment"
      ]
    },
    {
      "question": "How does metacognitive awareness interact with automatic and controlled processing to regulate performance when a task alternates between novel problem solving and well-practiced routines, and why?",
      "options": {
        "A": "It always improves performance by increasing attention to all processing streams, thereby removing the efficiency advantage of automaticity.",
        "B": "It mainly shifts control from automatic to conscious processing to speed up routine actions, which always yields faster responses.",
        "C": "It enhances performance for novel problems by engaging controlled processing guided by monitoring, but can impair performance for well-practiced tasks by introducing unnecessary conscious interference with automatic execution.",
        "D": "It only affects memory encoding, not perceptual or motor processes, so performance remains unchanged in most cognitive tasks."
      },
      "correct_answer": "C",
      "source_article": "Cognition",
      "x": 1.3322384357452393,
      "y": 1.0492011308670044,
      "concepts_tested": [
        "Concept 1: Functional organization of cognitive processes (perception, attention, memory, thinking, language) and how they interact to acquire, store, transform, and use information.",
        "Concept 2: Competing theories/models of cognition (classical computationalism, connectionism) and the role of representations (representationalism vs. anti-representationalism) in explaining processing mechanisms.",
        "Concept 3: Metacognition and the distinction between conscious and unconscious, as well as controlled and automatic processes, including how these regulate and monitor other mental processes."
      ],
      "parent_concepts": [
        "Ideology as a \"science of ideas\" grounded in sensory experience and the formation of ideas, describing the cognitive mechanism by which beliefs are developed.",
        "Concept 1: Hierarchical organization of executive functions (basic processes enabling higher-order skills like planning and problem-solving)",
        "Concept 2: Distributed neural basis of executive functions (involvement of multiple brain regions, not solely the prefrontal cortex)",
        "Concept 1: The information-processing framework (encoding, storage, retrieval, processing) as the mechanism by which social information is handled and subsequently influences perception and memory.",
        "Sensorimotor grounding of cognition: cognition is shaped by the body's motor and perceptual systems, not solely by abstract representations.",
        "Contextual embedding and situatedness: embodiment depends on biological, psychological, and cultural contexts, as well as interactions with the environment.",
        "Concept 1: Imagination as a cognitive process that generates new ideas by manipulating mental images and integrating semantic and episodic memory, supporting problem-solving and learning."
      ],
      "parent_articles": [
        "Ideology",
        "Executive functions",
        "Executive functions",
        "Social cognition",
        "Embodied cognition",
        "Embodied cognition",
        "Imagination"
      ]
    },
    {
      "question": "In Platonic justice, why does justice depend on assigning each person to the role best suited to their abilities and ensuring rewards are proportional to contribution, and what would follow if someone took a role outside their aptitude?",
      "options": {
        "A": "Because it guarantees equal outcomes for all, which preserves harmony regardless of role.",
        "B": "Because it preserves the city's working balance by aligning tasks with abilities and ensuring reciprocation matches contribution; if someone adopts a mismatched role, the interdependent parts fail to support each other, breaking justice.",
        "C": "Because justice requires punishment of those who do not perform their assigned role, ensuring equal penalties for deviation.",
        "D": "Because justice is dictated by divine command, so any deviation is inherently unjust and must be corrected by external authority."
      },
      "correct_answer": "B",
      "source_article": "Justice",
      "x": 1.2050434350967407,
      "y": 0.9714332818984985,
      "concepts_tested": [
        "Concept 1: Multiple justice frameworks (distributive, utilitarian, retributive, restorative) and how each justifies outcomes (distribution of goods, punishment, or repair of harms)",
        "Concept 2: Foundational grounds for justice (natural law, social contract, divine command) and how these explain why justice should govern conduct",
        "Concept 3: Platonic justice as balance and proper assignment of roles within a community, with fairness based on contribution and proportionate reciprocation"
      ],
      "parent_concepts": [
        "Distributive norms as governing allocations (Equality, Equity, Power, Need, Responsibility)"
      ],
      "parent_articles": [
        "Distributive justice"
      ]
    },
    {
      "question": "In a simple two-firm setting where each firm must invest in specialized assets to support the other's downstream production, and contracts cannot perfectly specify post-investment behavior (a hold-up problem), how does vertical integration help explain strategic outcomes in industrial organization models?",
      "options": {
        "A": "It guarantees the lowest possible average cost across all stages.",
        "B": "It internalizes quasi-rents and aligns incentives by removing the hold-up problem, reducing opportunistic bargaining after investments.",
        "C": "It completely eliminates information asymmetry between firms.",
        "D": "It ensures the market will always be perfectly competitive due to integration."
      },
      "correct_answer": "B",
      "source_article": "Industrial organization",
      "x": 1.306787371635437,
      "y": 0.9367971420288086,
      "concepts_tested": [
        "Concept 1: Boundaries between firms and markets are driven by real-world frictions (transaction costs, imperfect information, barriers to entry), which explain deviations from perfect competition.",
        "Concept 2: Strategic interaction and market power are analyzed through models (notably game theory) and empirical analysis to explain oligopoly behavior, pricing strategies, vertical integration, and contracting.",
        "Concept 3: Public policy and regulation shape market organization and incentives (antitrust policy, competition policy, governance of law, property rights, contracts)."
      ],
      "parent_concepts": [
        "Concept 2: Market power arises from structural features (firm size, market structure, barriers to entry) that shape the residual demand curve; higher market share and steeper residual demand imply greater pricing power and earnings.",
        "Concept 3: Relationships to other market structures and regulation \u2014 Distinctions from oligopolies, cartels, and monopsonies, and the role of competition laws and government intervention in shaping monopolies.",
        "Concept 1: Production costs and access to capital influence industry structure, driving consolidation around major studios while enabling independent production when barriers are lowered."
      ],
      "parent_articles": [
        "Market power",
        "Monopoly",
        "Film industry"
      ]
    },
    {
      "question": "Why might a competition authority opt for a divestiture remedy rather than a complete merger prohibition, and through what mechanism does the divestiture promote competitive outcomes?",
      "options": {
        "A": "Divestiture imposes criminal penalties on the merged firm's management to deter future strategy, ensuring competitive outcomes by punishing past behavior.",
        "B": "Divestiture distributes potential cost savings across all market players, thereby lowering barriers for new entrants.",
        "C": "Divestiture creates an independent competitor by selling off part of the merged business, restoring competitive constraints and disciplining the merged entity through real competition.",
        "D": "Divestiture imposes broad price controls on the merged entity to prevent price gouging and ensure affordability."
      },
      "correct_answer": "C",
      "source_article": "Competition law",
      "x": 1.292242407798767,
      "y": 0.8824014067649841,
      "concepts_tested": [
        "Concept 1: The three-element framework of competition law (prohibiting anti-competitive agreements/cartels, prohibiting abusive conduct by dominant firms, and supervising mergers/acquisitions with potential remedies).",
        "Concept 2: Enforcement and remedies as mechanisms to maintain competition (public/private enforcement, divestitures, licensing, access to facilities) and how they influence market outcomes.",
        "Concept 3: Cross-border scope and coordination (extraterritorial jurisdiction, effects doctrine, international agreements like WTO/GATT) and how they relate to protecting competition beyond national borders."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "How do receptive fields determine the brain's ability to localize stimulation on the skin?",
      "options": {
        "A": "Larger receptive fields recruit more neurons, increasing localization accuracy.",
        "B": "Larger receptive fields produce more precise localized signals due to integration across space.",
        "C": "Smaller receptive fields produce more distinct activation patterns across adjacent receptors, enabling finer spatial discrimination.",
        "D": "Receptive field size only affects sensitivity threshold, not spatial localization."
      },
      "correct_answer": "C",
      "source_article": "Sensory nervous system",
      "x": 1.8879237174987793,
      "y": 1.16024911403656,
      "concepts_tested": [
        "Receptive fields and their role in sensory perception",
        "Receptor transduction and the neural pathway (stimulus -> receptor -> action potential -> brain processing)",
        "Modality-specific receptors and their signal routes (chemoreceptors, photoreceptors, mechanoreceptors, thermoreceptors) and how they link stimuli to perception"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Which mechanism best explains how the middle ear ossicles overcome the impedance mismatch between air and cochlear fluids to efficiently transmit sound energy?",
      "options": {
        "A": "The ossicles vibrate at a higher frequency than the incoming sound, filtering energy to match the cochlea.",
        "B": "The lever action of the malleus\u2013incus pair, combined with the larger surface area of the tympanic membrane relative to the oval window, concentrates acoustic energy onto a smaller area, increasing pressure at the cochlear fluid.",
        "C": "The stapedius and tensor tympani muscles actively generate neural signals that amplify the transmitted sound.",
        "D": "The round window reflects most energy back into the middle ear, reducing energy transfer to the cochlea."
      },
      "correct_answer": "B",
      "source_article": "Hearing",
      "x": 1.6233023405075073,
      "y": 1.0813827514648438,
      "concepts_tested": [
        "Concept 1: The mechanical-to-neural transduction pathway in the ear (tympanic membrane \u2192 ossicles \u2192 oval window \u2192 cochlea \u2192 organ of Corti \u2192 neural signals).",
        "Concept 2: Impedance matching by the middle ear ossicles to convert airborne sound waves into fluid motions in the cochlea efficiently.",
        "Concept 3: Roles of ear structure and reflexes in sound localization and protection (outer ear localization cues due to asymmetry; stapedius/tensor tympani reflexes shielding the inner ear)."
      ],
      "parent_concepts": [
        "Concept 1: Outer hair cell motility and prestin-mediated somatic motor amplify cochlear traveling waves, increasing sensitivity and shaping frequency response."
      ],
      "parent_articles": [
        "Auditory system"
      ]
    },
    {
      "question": "How does the active, constructive view of perception explain why the same sensory input can yield different interpretations depending on context and prior knowledge?",
      "options": {
        "A": "It treats perception as a fixed readout of sensory data, with context playing no role.",
        "B": "It posits that separate, non-interacting sensory modules measure input and map it to one stable percept regardless of context.",
        "C": "It posits that perception arises from ongoing interaction between bottom-up input and top-down predictions formed by learning, memory, and attention; context and expectations bias interpretation, making perception a testable hypothesis about the world.",
        "D": "It claims perception only emerges when attention fully processes all sensory details, otherwise nothing is perceived."
      },
      "correct_answer": "C",
      "source_article": "Perception",
      "x": 1.6607639789581299,
      "y": 1.1078108549118042,
      "concepts_tested": [
        "Concept 1: Perception emerges from interaction between bottom-up sensory input and top-down cognitive influences (learning, memory, expectation, attention) shaping interpretation.",
        "Concept 2: The brain processes perception via modular, specialized neural systems (sensory maps) that transform and integrate information, producing stable percepts and enabling cross-modal influences (e.g., taste influenced by smell).",
        "Concept 3: Perception is an active, constructive process, potentially involving predictive/hypothesis-testing-like processing rather than purely passive data reception."
      ],
      "parent_concepts": [
        "Psychoacoustic principles inform practical signal-processing applications (e.g., masking in MP3/data compression, noise reduction) and relate objective measurements to perceptual attributes."
      ],
      "parent_articles": [
        "Psychoacoustics"
      ]
    },
    {
      "question": "Which explanation best captures why social change is typically understood as arising from the interaction between stable structural conditions and contingent, random events?",
      "options": {
        "A": "Structural factors alone determine the direction and magnitude of change, making contingency irrelevant.",
        "B": "Contingent events alone determine change, since structural conditions are stable and passive.",
        "C": "Structural conditions create a stable environment with certain vulnerabilities and opportunities, while contingent events act as triggers that push the system past thresholds, so change emerges from their interaction.",
        "D": "Social change is purely cyclical and independent of both structure and contingency."
      },
      "correct_answer": "C",
      "source_article": "Social change",
      "x": 1.203518033027649,
      "y": 0.969777524471283,
      "concepts_tested": [
        "Concept 1: Social change results from a combination of systematic (structural) factors and unique (contingent/random) factors, implying an interaction between stable conditions and variables.",
        "Concept 2: Theories of social change identify core components\u2014structural aspects, processes/mechanisms, and directions of change\u2014as a framework for explaining how change happens.",
        "Concept 3: Different theoretical frameworks propose distinct mechanisms for change (e.g., Hegelian dialectic with conflict and synthesis; Marxist class struggle and materialist history; Kuhnian paradigm shifts and critical junctures), highlighting how the underlying drivers differ across theories."
      ],
      "parent_concepts": [
        "Concept 3: Outcomes and level-specific relationships (group-level changes in institutions and practices; individual-level effects on psychological/physical well-being; possible results such as integration, marginalization, coexistence, or cultural evolution).",
        "Concept 3: Technology-induced social change \u2014 new technologies reconfigure social structures and daily life (e.g., smartphones altering family dynamics)."
      ],
      "parent_articles": [
        "Acculturation",
        "Media studies"
      ]
    },
    {
      "question": "In a consumerist society, why does consumption function as an identity-forming activity beyond merely satisfying basic needs?",
      "options": {
        "A": "It is driven purely by price minimization, leaving no room for symbolic meaning.",
        "B": "People use goods, brands, and consumption rituals to signal belonging, status, values, and group identity, and others interpret these signals to construct social identities.",
        "C": "Consumption primarily erodes social identity by promoting uniform tastes and reducing differences.",
        "D": "Identity is formed solely through work and production, independent of consumer choices."
      },
      "correct_answer": "B",
      "source_article": "Consumerism",
      "x": 1.3102562427520752,
      "y": 0.9379424452781677,
      "concepts_tested": [
        "Concept 1: Consumer sovereignty and its influence on production and economic organization (how consumer preferences shape what is produced and how).",
        "Concept 2: Consumption as a cultural and identity-forming activity (how buying and consuming contribute to social meaning and status, beyond basic needs).",
        "Concept 3: Environmental and social externalities of consumerism (overconsumption, resource depletion, waste, climate change, and inequality)."
      ],
      "parent_concepts": [
        "Concept 2: False psychological needs created by mass culture, which capitalism purportedly manipulates and can only satisfy through commodified products."
      ],
      "parent_articles": [
        "Culture industry"
      ]
    },
    {
      "question": "How does a thought experiment function as a methodological tool in philosophy, and why is it particularly effective for evaluating a general claim about morality without relying on empirical data?",
      "options": {
        "A": "It isolates and tests the logical implications of the claim by presenting a carefully constructed hypothetical scenario, revealing contradictions or latent premises.",
        "B": "It collects observational data about how people actually behave in morally relevant situations.",
        "C": "It provides a definitive empirical verification of the claim by measuring real-world outcomes.",
        "D": "It confirms that moral truths are universal by appealing to intuitive feelings."
      },
      "correct_answer": "A",
      "source_article": "Philosophy",
      "x": 1.1953215599060059,
      "y": 1.0620388984680176,
      "concepts_tested": [
        "Concept 1: Philosophy as a systematic, rational inquiry into general and fundamental questions, with attention to its methods and underlying assumptions.",
        "Concept 2: The methodological toolkit of philosophy (conceptual analysis, thought experiments, analysis of language, description of experience, critical questioning) and how these methods support studying and evaluating arguments.",
        "Concept 3: The major branches (epistemology, ethics, logic, metaphysics) and the idea that subfields and competing schools within branches define different domains of inquiry, plus philosophy\u2019s interdisciplinary connections to other fields."
      ],
      "parent_concepts": [
        "Interdisciplinary relationships and the development of theoretical frameworks (e.g., cross-links with ethics, political philosophy, sociology, and frameworks like social ontology, care ethics)"
      ],
      "parent_articles": [
        "Social philosophy"
      ]
    },
    {
      "question": "In dialectical materialism, how does the principle of quantity into quality explain the emergence of a new property or phase in a system?",
      "options": {
        "A": "Through the continuous accumulation of small quantitative changes that eventually crosses a threshold, reconfiguring the system into a new qualitative state that cannot be fully explained by the previous state.",
        "B": "Qualitative states arise independently of quantitative changes, existing as fixed properties regardless of magnitude.",
        "C": "Qualitative change always tracks quantitatively in a smooth, linear fashion with no abrupt transitions.",
        "D": "The qualitative state comes first and determines how much quantitative change will occur, implying reverse causality."
      },
      "correct_answer": "A",
      "source_article": "Dialectical materialism",
      "x": 0.9202624559402466,
      "y": 0.9469309449195862,
      "concepts_tested": [
        "Concept 1: Unity and conflict of opposites (contradictions within systems drive change)",
        "Concept 2: Quantity into quality (small quantitative changes accumulating to a qualitative transformation)",
        "Concept 3: Negation of the negation (development through iterative negation leading to higher forms or arrangements)"
      ],
      "parent_concepts": [
        "Concept 3: Class division and class struggle as the central dynamics through which changes in production and economy produce historical change."
      ],
      "parent_articles": [
        "Historical materialism"
      ]
    },
    {
      "question": "Why does the form of a medium shape the social effects of a message, even when the content is identical across formats? Suppose the same core information is delivered as a long print article, a brief video, and an interactive app. Which explanation best accounts for the different social outcomes across these formats?",
      "options": {
        "A": "The audience's interpretation is fixed by culture and the format does not change how people understand the content.",
        "B": "The medium's inherent affordances\u2014such as pacing, multimodality, interactivity, and social cues\u2014activate different ways of processing, sharing, and acting on the information, producing different social effects even with identical content.",
        "C": "The platform's popularity determine all effects; format only affects how widely the message spreads, not how it is interpreted.",
        "D": "Technical constraints alone decide attention, so content has no influence on social action."
      },
      "correct_answer": "B",
      "source_article": "Media studies",
      "x": 1.1892728805541992,
      "y": 0.9968863725662231,
      "concepts_tested": [
        "Concept 1: The medium is the message \u2014 the form of a medium shapes social effects and how people interact, not only the content.",
        "Concept 2: Media ecology and technology-driven environment \u2014 media and users form an ecosystem; technology changes the social environment and behavior.",
        "Concept 3: Broad definition of media as all technologies that mediate interaction \u2014 analysis extends to all forms of technology, not just traditional mass media, implying an interdisciplinary study of media phenomena."
      ],
      "parent_concepts": [
        "Concept 1: Mediation of perception and meaning through visual technology and images (how visuals structure experience and information).",
        "Concept 3: Interdisciplinary and multimedia scope \u2014 visual culture overlaps with film studies, cognitive science, technology, and various media, shaping its theoretical frameworks and methods.",
        "Concept 2: Evolution of news formats and the criteria that distinguish a \"newspaper\" (audience scope, regularity, accessibility) from earlier notices and pamphlets."
      ],
      "parent_articles": [
        "Visual culture",
        "Visual culture",
        "History of journalism"
      ]
    },
    {
      "question": "In the distinction between natural processes (physis) and artificial processes (techne), why can techne complete what nature cannot bring to a finish?",
      "options": {
        "A": "Because techne shares the same intrinsic ends as physis and cannot diverge from natural purposes.",
        "B": "Because techne is guided by external causes and external ends, allowing deliberate design that imposes ends beyond nature and completes what physis cannot finish.",
        "C": "Because techne merely imitates nature and thus remains bound by nature's limitations.",
        "D": "Because techne increases only the speed of natural processes without altering their ends or purposes."
      },
      "correct_answer": "B",
      "source_article": "Philosophy of technology",
      "x": 1.0016705989837646,
      "y": 1.0263882875442505,
      "concepts_tested": [
        "Techne as imitation of nature and its potential to surpass nature (techne can complete what physis cannot bring to a finish) along with the ontological distinction between natural and artificial processes.",
        "The role of telos (end/goal) in shaping techne, with techne being guided by external ends rather than intrinsic natural purposes.",
        "Knowledge of causes enabling greater human power over nature and the resulting social implications (e.g., expansion of human empire over nature)."
      ],
      "parent_concepts": [
        "Concept 1: Mediation of perception and meaning through visual technology and images (how visuals structure experience and information)."
      ],
      "parent_articles": [
        "Visual culture"
      ]
    },
    {
      "question": "How do intuitive reasoning and logical discursive reasoning relate in expert problem solving, and why might relying on only one mode be insufficient?",
      "options": {
        "A": "Intuition provides fast, bias-prone judgments; discursive reasoning provides slow, universal certainty; relying on either alone yields flawless outcomes.",
        "B": "Logical discursive reasoning provides systematic evaluation and validity but can be slow and insensitive to context; intuitive reasoning offers rapid, context-sensitive judgments that can be biased; when used together, intuition can generate candidate solutions and logic can test and refine them.",
        "C": "They are identical processes with different labels; mastering one makes the other redundant.",
        "D": "Intuition handles numerical calculation, while discursive reasoning handles storytelling and qualitative insight."
      },
      "correct_answer": "B",
      "source_article": "Reason",
      "x": 1.1824939250946045,
      "y": 1.077577829360962,
      "concepts_tested": [
        "Distinction and relationship between logical discursive reasoning and intuitive reasoning (how they differ, clash, and may complement each other)",
        "Forms of logical reasoning (deductive, inductive, abductive) as mechanisms for deriving conclusions",
        "Reasoning as a cognitive mechanism linked to decision making, knowledge formation, and cultural/disciplinary contexts, including its study in psychology, cognitive science, and automated reasoning"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Which statement best explains how technology and social structures influence each other over time according to the mutual shaping/coevolution idea?",
      "options": {
        "A": "Technology's capabilities are fixed and social structures must adapt without influencing the technology.",
        "B": "Social institutions determine technology's design completely, and the technology then remains stable regardless of use.",
        "C": "The adoption and use of technology reshape social practices and institutions, and these changing social contexts, in turn, guide subsequent technological innovations.",
        "D": "Technological progress proceeds independently of social values, which only respond after adoption."
      },
      "correct_answer": "C",
      "source_article": "Technology and society",
      "x": 1.2840808629989624,
      "y": 0.9426032304763794,
      "concepts_tested": [
        "Concept 1: Mutual shaping/coevolution of technology and society (technology and social structures influence each other over time).",
        "Concept 2: Technology as a driver of social/economic transformation and values (how tools enable changes in communication, production, economy, and ethics).",
        "Concept 3: Frameworks and governance as mediators of tech\u2013society outcomes (the role of theories like STS, tektology, and institutional context in shaping impact)."
      ],
      "parent_concepts": [
        "Concept 1: ICTs as drivers of cross-sector social transformation (how information and communication technologies influence education, economy, health, government, warfare, and democracy).",
        "Concept 3: Technology-induced social change \u2014 new technologies reconfigure social structures and daily life (e.g., smartphones altering family dynamics)."
      ],
      "parent_articles": [
        "Information society",
        "Media studies"
      ]
    },
    {
      "question": "In science and technology studies, why is a technological trajectory considered contingent rather than determined purely by the technology's own properties?",
      "options": {
        "A": "Once a technology works physically, it will be adopted identically in all cultures because technical feasibility overrides social variation.",
        "B": "Social actors, institutions, norms, and power relations guide how a technology is funded, manufactured, presented, regulated, and adopted, producing different histories in different contexts.",
        "C": "The trajectory is fixed by the initial design choices of engineers, independent of user practices or institutions.",
        "D": "Public policy uniformly accelerates adoption regardless of cultural meaning or economic structure."
      },
      "correct_answer": "B",
      "source_article": "Science and technology studies",
      "x": 1.2204484939575195,
      "y": 0.9802684783935547,
      "concepts_tested": [
        "Concept 1: Science and technology are socially embedded and studied within historical, cultural, and social contexts.",
        "Concept 2: Technological and scientific development is not determined by technology alone; it is shaped by social factors and contested through contextual critiques (e.g., anti-determinism).",
        "Concept 3: Interdisciplinary integration and institutional formation of STS (collaboration across disciplines and the development of programs/centers), including examination of power dynamics within science and society."
      ],
      "parent_concepts": [
        "Concept 3: The historical evolution of science (from natural philosophy to natural science) driven by methodological shifts and institutional development."
      ],
      "parent_articles": [
        "Science"
      ]
    },
    {
      "question": "How do governance mechanisms and ethical debates influence the development and deployment of technology in terms of balancing innovation with potential downsides?",
      "options": {
        "A": "They internalize externalities by setting standards, accountability, and funding for safety, guiding research and deployment toward socially desirable outcomes while preserving room for innovation.",
        "B": "They are irrelevant to technical progress; market demand alone determines both benefits and risks.",
        "C": "They only slow progress and cannot provide any meaningful way to address negative impacts.",
        "D": "They completely prevent new technologies from being adopted, eliminating both benefits and harms."
      },
      "correct_answer": "A",
      "source_article": "Technology",
      "x": 0.8576552867889404,
      "y": 0.17946286499500275,
      "concepts_tested": [
        "Concept 1: Technology as the systematic application of knowledge to practical ends (the link between conceptual knowledge and productive tools)",
        "Concept 2: Technology as a driver of social and economic change, with both positive outcomes (prosperity, communication) and negative impacts (pollution, unemployment)",
        "Concept 3: The ethical and political dimensions of technology, including debates about its role, governance, and ways to mitigate downsides"
      ],
      "parent_concepts": [
        "Concept 1: ICTs as drivers of cross-sector social transformation (how information and communication technologies influence education, economy, health, government, warfare, and democracy)."
      ],
      "parent_articles": [
        "Information society"
      ]
    },
    {
      "question": "How does the bidirectional relationship between individuals and society explain both the persistence of social norms and the potential for normative change?",
      "options": {
        "A": "Societal norms are inert constraints that individuals cannot meaningfully alter, so only external shocks cause change.",
        "B": "Individuals interiorize and reproduce norms, but can also innovate or reinterpret them; through social practices, institutions adapt in response to these intentional changes, producing a feedback loop that sustains stability while enabling gradual evolution.",
        "C": "Change occurs only through top-down legal mandates that override individual behavior, while persistence is the norm due to heavy enforcement.",
        "D": "Norms are entirely biologically driven and resistant to cultural modification."
      },
      "correct_answer": "B",
      "source_article": "Society",
      "x": 1.2644342184066772,
      "y": 0.9870331883430481,
      "concepts_tested": [
        "Societal norms as mechanisms that regulate behavior and enable coordination within a group.",
        "The bidirectional relationship between individuals and society: humans shape society, and society shapes humans (co-construction).",
        "Technology and economic activity shaping social structure and stratification (how surplus and economic organization influence class, governance, and institutions)."
      ],
      "parent_concepts": [
        "Concept 3: Information-centered social conduct (the idea that theoretical knowledge and information shape how people live and behave)."
      ],
      "parent_articles": [
        "Information society"
      ]
    },
    {
      "question": "Why does the Sabatier principle predict there is an optimal adsorption strength for catalytic turnover, and how do chemisorption and physisorption contribute to this optimum?",
      "options": {
        "A": "If adsorption is too strong (chemisorption), intermediates can saturate and block sites, hindering product desorption; if adsorption is too weak (physisorption), reactants do not bind or activate enough to proceed, so turnover is low; the best activity occurs at moderate chemisorption that activates bonds but allows easy desorption.",
        "B": "Adsorption strength is irrelevant; turnover is governed solely by gas-phase reactant concentrations and temperature.",
        "C": "Strong adsorption always increases rate by stabilizing all intermediates, so the optimum occurs at the highest possible binding energy.",
        "D": "Physisorption and chemisorption contribute equally to rate, so the adsorption mechanism type does not influence the optimum."
      },
      "correct_answer": "A",
      "source_article": "Surface science",
      "x": 1.8241475820541382,
      "y": 1.0656592845916748,
      "concepts_tested": [
        "Adsorption mechanisms and their effect on catalysis (chemisorption vs physisorption; Sabatier principle)",
        "Model vs. real catalysts: using single-crystal surfaces to study surface interactions and structure\u2013activity relationships",
        "Langmuir adsorption model: assumptions about monolayer coverage, equal affinity, and no adsorbate interactions, and its role as a framework and its limitations"
      ],
      "parent_concepts": [
        "Concept 3: Isotherms quantify adsorption by relating the amount adsorbed to pressure (gas) or concentration (solution) at constant temperature, with normalization by adsorbent mass and multiple models guiding interpretation.",
        "Concept 1: Coatings modify substrate surface properties to achieve functional performance (adhesion, wettability, wear resistance, conductivity/magnetic response).",
        "Concept 3: Coatings can introduce new properties and are integral to the final product\u2019s function (e.g., conductive or magnetic properties, automotive primer/basecoat/clearcoat systems, concrete sealing)."
      ],
      "parent_articles": [
        "Adsorption",
        "Coating",
        "Coating"
      ]
    },
    {
      "question": "How does the idea that government authority derives from and is limited by a higher law primarily function to prevent arbitrary power across different administrations?",
      "options": {
        "A": "It binds all official action to pre-existing rules and fundamental rights, so governance remains constrained even when political leadership changes.",
        "B": "It allows each new majority to reinvent the rules, thereby ensuring policy reflects current popular will.",
        "C": "It guarantees that the constitution can be easily amended to nullify minority protections whenever majority support shifts.",
        "D": "It authorizes the executive to suspend the higher law during crises if a majority supports it."
      },
      "correct_answer": "A",
      "source_article": "Constitutionalism",
      "x": 1.140319585800171,
      "y": 0.8334639668464661,
      "concepts_tested": [
        "Concept 1: Government authority must be derived from and limited by a higher law, i.e., the rule of law and the idea of limited government.",
        "Concept 2: Institutionalized mechanisms of power control and procedures in the constitution to protect citizens\u2019 liberties, including minority rights.",
        "Concept 3: The Descriptive vs. Prescriptive uses of constitutionalism (how it is historically descriptive and how it prescribes essential elements of government)."
      ],
      "parent_concepts": [
        "Concept 1: Direct democracy vs. representative democracy, and the institutional mechanisms (constitution and supreme court) that constrain majority power to protect minority rights."
      ],
      "parent_articles": [
        "Democracy"
      ]
    },
    {
      "question": "Why does the engineering design process rely on iterative testing and optimization under defined constraints rather than relying on a single, theory-only solution?",
      "options": {
        "A": "It accelerates production by eliminating safety monitoring and design validation steps.",
        "B": "It reveals unanticipated interactions, tolerances, and failure modes, guiding adjustments to meet performance, safety, cost, and reliability constraints.",
        "C": "It guarantees the optimal solution because repeated testing always converges to the best design.",
        "D": "It replaces scientific modeling with trial-and-error, which is more flexible across all contexts."
      },
      "correct_answer": "B",
      "source_article": "Engineering",
      "x": 1.4525490999221802,
      "y": 0.9987501502037048,
      "concepts_tested": [
        "Concept 1: The engineering design process as a method to solve problems using science, math, testing, and optimization under constraints.",
        "Concept 2: The ethical and public-safety responsibilities guiding professional engineering practice.",
        "Concept 3: The interdisciplinary nature of engineering and its integration with economics, business practices, and lifecycle management aided by software tools."
      ],
      "parent_concepts": [
        "Concept 1"
      ],
      "parent_articles": [
        "Software engineering"
      ]
    },
    {
      "question": "Under a competitive market mechanism with perfect competition, price signals, and no externalities, why does the resulting allocation achieve Pareto efficiency?",
      "options": {
        "A": "The price mechanism in a perfectly competitive market causes individuals to reveal their marginal valuations and firms to reveal marginal costs, aligning supply and demand so that any reallocation would lower someone\u2019s utility, leaving no further gains from trade.",
        "B": "A central planner assigns resources to maximize total welfare, guaranteeing that no one can be made better off without making someone else worse off.",
        "C": "Auctions always yield Pareto efficient allocations regardless of information or bidder behavior.",
        "D": "An allocation that uses all resources is by definition Pareto efficient, regardless of distribution or externalities."
      },
      "correct_answer": "A",
      "source_article": "Resource allocation",
      "x": 1.4200190305709839,
      "y": 1.0269542932510376,
      "concepts_tested": [
        "Pareto efficiency as a criterion for evaluating resource allocation outcomes and the conditions under which mechanisms achieve it",
        "Mechanisms of allocation (markets, planning, auctions, algorithmic allocation) and how they influence distribution of resources",
        "Contingency and prioritization rules (priority rankings, funding trade-offs) used to manage scarcity and guide allocation decisions"
      ],
      "parent_concepts": [
        "Concept 2: Economic value and modeling of attention; treating attention as a scarce commodity and applying economic theory to information management and \"free\" goods.",
        "Concept 2: The capital allocation mechanism \u2014 capital budgeting (which value-adding projects to fund) and financing choices (debt vs. equity) determine how resources are allocated and how value is created."
      ],
      "parent_articles": [
        "Attention economy",
        "Corporate finance"
      ]
    },
    {
      "question": "Why does attention function as a limited cognitive resource, and how does this limitation influence multitasking performance?",
      "options": {
        "A": "Attention can be increased without bound with enough motivation, so multitasking never falters.",
        "B": "Attention is a finite pool of processing capacity; allocating more resources to one task leaves fewer resources for others, reducing performance on the secondary task.",
        "C": "Attention is automatically distributed equally among all perceptual inputs, so multitasking yields equal performance across tasks.",
        "D": "Attention operates only on external stimuli with high saliency, so tasks with low saliency are never affected by resource limits."
      },
      "correct_answer": "B",
      "source_article": "Attention economy",
      "x": 1.3039920330047607,
      "y": 0.9720051884651184,
      "concepts_tested": [
        "Concept 1: Attention as a limited cognitive resource with finite processing capacity, affecting how we allocate mental effort across tasks.",
        "Concept 2: Economic framing of attention, where time and attention are valued and analyzed with economic theory (e.g., attention as a commodity, value of free goods).",
        "Concept 3: Design and information-management mechanisms (filtering/out filtering of information) driven by information overload, shaping how systems should allocate and prioritize attention."
      ],
      "parent_concepts": [
        "Concept 1: Data as a commodity and monetization through targeted advertising; how profit incentives drive collection and processing of personal data."
      ],
      "parent_articles": [
        "Surveillance capitalism"
      ]
    },
    {
      "question": "How do ICTs and Internet/Web technologies reconfigure production, distribution, and trade to alter business models and productivity in the digital economy?",
      "options": {
        "A": "They raise barriers to entry by increasing capital intensity, making traditional firms more dominant.",
        "B": "They enable rapid data collection and real-time coordination across value chain actors, enabling modular, platform-enabled and demand-driven production that improves productivity.",
        "C": "They promote isolated internal processes, reducing cross-organizational collaboration and thus slowing innovation.",
        "D": "They convert all transactions to offline, paper-based processes to improve reliability."
      },
      "correct_answer": "B",
      "source_article": "Digital economy",
      "x": 1.291351556777954,
      "y": 0.9635339379310608,
      "concepts_tested": [
        "Concept 1: Digital transformation mechanism \u2014 how ICTs and Internet/Web technologies reconfigure production, distribution, and trade, altering business models and productivity.",
        "Concept 2: The e-business/e-commerce framework \u2014 the interrelated components (infrastructure, e-business processes, and online commerce) that together enable digital economic activity.",
        "Concept 3: Governance and regulatory relationships \u2014 how the digital economy creates new challenges and needs for privacy, competition, and taxation regulation between states, firms, and individuals."
      ],
      "parent_concepts": [
        "Concept 1: Data as a commodity and monetization through targeted advertising; how profit incentives drive collection and processing of personal data."
      ],
      "parent_articles": [
        "Surveillance capitalism"
      ]
    },
    {
      "question": "Why might an individual's performance on intelligence measures differ across domains and occasions, even when underlying abilities are stable?",
      "options": {
        "A": "Because intelligence is a fixed, unitary ability that manifests identically across domains and occasions, so observed differences are only measurement error.",
        "B": "Because performance reflects context-specific demands, domain relevance, and the criteria used to judge success, meaning the same person can perform differently as task demands change.",
        "C": "Because intelligence is random and lacks any coherent structure, so scores are inherently unpredictable.",
        "D": "Because test scores are solely determined by the amount of practice the person has had on each domain, independent of cognitive processing."
      },
      "correct_answer": "B",
      "source_article": "Intelligence",
      "x": 1.2784171104431152,
      "y": 1.0216398239135742,
      "concepts_tested": [
        "Concept 1: Intelligence as a multi-domain construct comprising various cognitive and behavioral competencies.",
        "Concept 2: The mechanism by which intelligence operates\u2014perceiving/infering information, retaining knowledge, and applying it to adaptive behavior within an environment.",
        "Concept 3: Contextual and individual variability in intelligence\u2014performance varies by domain, occasion, and criteria, affecting measurement and interpretation."
      ],
      "parent_concepts": [
        "Concept 1: Hierarchical organization of executive functions (basic processes enabling higher-order skills like planning and problem-solving)"
      ],
      "parent_articles": [
        "Executive functions"
      ]
    },
    {
      "question": "How does environmental variation influence phenotype through transcriptional regulation in individuals with identical genomes?",
      "options": {
        "A": "Environmental cues alter the activity of transcription factors and the chromatin landscape, changing which genes are expressed and thereby producing different phenotypes.",
        "B": "The environment mutates the DNA sequence, creating new alleles that generate different phenotypes.",
        "C": "Environmental exposure affects protein function only after translation, so gene expression profiles remain the same but phenotypes differ.",
        "D": "The environment edits the mRNA sequence during transcription, creating different transcripts without changing the DNA."
      },
      "correct_answer": "A",
      "source_article": "Genetics",
      "x": 1.898614525794983,
      "y": 1.1189430952072144,
      "concepts_tested": [
        "Concept 1: Genes as discrete units of inheritance that transmit traits across generations (genotype-phenotype relationship and Mendelian inheritance)",
        "Concept 2: Gene expression and phenotype are influenced by the environment, illustrating gene-environment interaction and transcriptional regulation",
        "Concept 3: Genetic variation and analysis across multiple levels (molecular, cellular, organismal, population) and across subfields (molecular genetics, epigenetics, population genetics)"
      ],
      "parent_concepts": [
        "Concept 2: Polygenic architecture and environmental role \u2014 behaviours are influenced by many genes with small effects, and environmental factors also play a strong role, often increasing differences between individuals rather than similarities.",
        "Concept 3: Genetic variation and trait complexity\u2014mutations create new alleles, loci, and the reality that many traits are polygenic or involve multiple gene interactions, influencing evolution.",
        "Concept 1: Genomics aims to characterize and quantify all genes and their interrelations within the genome, distinguishing it from studying individual genes (genetics).",
        "Concept 1: Epigenetic mechanisms regulate gene expression without altering the DNA sequence (e.g., DNA methylation, histone modification, non-coding RNAs) and influence transcriptional activity.",
        "Concept 1: Mutation as the ultimate source of genetic variation, with recombination, genetic drift, and gene flow shaping overall variation.",
        "Concept 1: Mechanisms of genetic modification (insertion, knockout, use of recombinant DNA/synthetic DNA; random vs targeted genome integration)"
      ],
      "parent_articles": [
        "Behavioural genetics",
        "Heredity",
        "Genomics",
        "Epigenetics",
        "Genetic variation",
        "Genetic engineering"
      ]
    },
    {
      "question": "How does the dual-systems model explain why a person might both consciously plan a kind act and also act impulsively in a social situation?",
      "options": {
        "A": "It suggests that only the conscious plan drives behavior, and impulses are ignored.",
        "B": "It proposes a single mechanism that alternates between reflective and impulsive states but never operates simultaneously.",
        "C": "It posits two interacting systems\u2014one reflective and one impulsive\u2014so behavior can result from deliberate control, automatic impulses, or a cooperative or conflicting interaction between them, depending on context.",
        "D": "It asserts that social behavior is entirely determined by environmental cues with no internal processing."
      },
      "correct_answer": "C",
      "source_article": "Social behavior",
      "x": 1.3016488552093506,
      "y": 1.0052745342254639,
      "concepts_tested": [
        "Concept 1: Social behavior emerges from the interaction between an individual's characteristics and the environmental context (person-situation interplay).",
        "Concept 2: The dual-systems model of reflective and impulsive determinants explains how behavior can be conscious/intentional or automatic/impulsive, and how these processes can cooperate or oppose each other.",
        "Concept 3: Development of social behavior is shaped by biology, cognition, temperament, and settings, with culture and socialization shaping habitual interactions."
      ],
      "parent_concepts": [
        "Concept 1",
        "Concept 3"
      ],
      "parent_articles": [
        "Cooperation",
        "Cooperation"
      ]
    },
    {
      "question": "In a rooted phylogenetic tree, why does the root position matter for identifying the Most Recent Common Ancestor (MRCA) of a chosen subset of leaves, and how would re-rooting alter the MRCA for that fixed subset?",
      "options": {
        "A": "Because the root fixes the direction of ancestry, the MRCA is defined as the lowest (deepest) node that is ancestral to all leaves in the subset; changing the root can change which node satisfies that condition, thereby changing the MRCA.",
        "B": "The MRCA is determined solely by the pairwise distances among leaves and is independent of where the root is placed; re-rooting cannot change the MRCA.",
        "C": "The MRCA is always the node directly adjacent to the root for any subset; re-rooting only shuffles the tree above that node but leaves the MRCA unchanged.",
        "D": "The root only affects the apparent order of branching, not ancestry; the MRCA is defined by the most recent internal branching event and remains the same under re-rooting."
      },
      "correct_answer": "A",
      "source_article": "Phylogenetic tree",
      "x": 1.8005447387695312,
      "y": 1.1164963245391846,
      "concepts_tested": [
        "Concept 1: Phylogenetic trees encode evolutionary relationships and common ancestry; rooted trees establish direction and identify the most recent common ancestor (MRCA).",
        "Concept 2: Internal nodes represent hypothetical ancestors and edge lengths can reflect divergence times, enabling temporal interpretations of evolution.",
        "Concept 3: Computational phylogenetics uses algorithms to infer an optimal tree, highlighting principles of modeling, data usage (genetic/phenotypic), and methodological choices."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does specifying a root for a phylogenetic tree enable inference about the direction of evolutionary change, whereas an unrooted tree cannot?",
      "options": {
        "A": "Because the root defines the most ancestral node and establishes a time-ordering from the root toward the tips, allowing us to infer which character states are ancestral and which are derived along each path; unrooted trees lack this time axis and thus cannot indicate direction.",
        "B": "Because rooting changes the data used for inference, making some characters appear ancestral while others appear derived.",
        "C": "Because rooting automatically assigns numerical ages to all nodes, precisely determining the sequence of all evolutionary events.",
        "D": "Because rooting reveals the exact ancestral states at all internal nodes, which unrooted trees cannot do."
      },
      "correct_answer": "A",
      "source_article": "Phylogenetics",
      "x": 1.8343656063079834,
      "y": 1.1262065172195435,
      "concepts_tested": [
        "Concept 1: Phylogenetics infers evolutionary relationships from observable, heritable data (DNA, proteins, morphology) and represents them in a phylogenetic tree.",
        "Concept 2: Rooted vs unrooted trees convey different information about ancestry and the direction of character state changes.",
        "Concept 3: Phylogenetics has broad practical applications (e.g., cancer clonal evolution, drug discovery, forensic science), illustrating how phylogenetic reasoning yields biological insights."
      ],
      "parent_concepts": [
        "Concept 1: Rooted vs unrooted trees and the root as the most recent common ancestor; edge lengths can reflect time estimates."
      ],
      "parent_articles": [
        "Phylogenetic tree"
      ]
    },
    {
      "question": "Why does the Tree of Life often function as an axis mundi that links heavens, earth, and the underworld across cultures, and how do cross-cultural parallels in its symbolism arise?",
      "options": {
        "A": "Because it is a single universal physical tree species found worldwide that physically connects realms.",
        "B": "Because as an axis mundi, the tree's imagery organizes space by mapping realms to roots, trunk, and branches, enabling ritual communication and cosmological order, and because humans share a common cognitive tendency to encode the world in a central vertical symbol, leading to parallel uses of the tree motif.",
        "C": "Because it is used exclusively in temple iconography to decorate walls and has no relation to cosmology, so parallels are due to copying.",
        "D": "Because it is an ancient scientific diagram of plant physiology describing nutrient flow, which cultures interpreted mythically."
      },
      "correct_answer": "B",
      "source_article": "Tree of life",
      "x": 0.2858288586139679,
      "y": 0.43846365809440613,
      "concepts_tested": [
        "Concept 1: The tree of life as a world tree/axis mundi that connects heavens, earth, and the underworld, with cross-cultural parallels (e.g., Yggdrasil, Epic of Gilgamesh\u2019s immortality quest).",
        "Concept 2: The tree of life as an archetype representing immortality and fertility, recurring in myth and religious symbolism.",
        "Concept 3: The relationship between symbolic imagery and religious practice, including continuity and adaptation of symbols (Asherah, temple iconography, and the menorah) across cultures."
      ],
      "parent_concepts": [
        "Concept 1: Rooted vs unrooted trees and the root as the most recent common ancestor; edge lengths can reflect time estimates."
      ],
      "parent_articles": [
        "Phylogenetic tree"
      ]
    },
    {
      "question": "Why does embedding knowledge into organizational routines, processes, and artifacts help an organization sustain learning when individual staff members leave or are replaced?",
      "options": {
        "A": "It makes knowledge accessible across the organization through shared routines and systems, so learning endures beyond any single person.",
        "B": "It ensures that all tacit insights are fully codified, so turnover cannot affect performance.",
        "C": "It concentrates knowledge in a small set of experts, making the organization more efficient at knowledge retention.",
        "D": "It imposes rigid procedures that prevent adaptation to new experiences, hindering learning."
      },
      "correct_answer": "A",
      "source_article": "Organizational learning",
      "x": 1.314860224723816,
      "y": 1.0070343017578125,
      "concepts_tested": [
        "Concept 1: Knowledge creation, retention, and transfer as adaptive processes driven by organizational experience.",
        "Concept 2: The learning curve and organizational learning rates as a relationship between cumulative production and productivity, influenced by factors such as individual proficiency, technology, and coordination structures.",
        "Concept 3: The distribution of knowledge between individuals and the organization, and the importance of embedding and transferring knowledge for sustained organizational learning (including risks when individuals withhold knowledge or leave)."
      ],
      "parent_concepts": [
        "Concept 2: Mechanisms of dynamic capabilities (adapting, integrating, and reconfiguring internal and external skills, resources, and routines to meet changing environment requirements).",
        "Concept 2: Iterative refinement and learning: using monitoring/evaluation data to adjust the theory of change"
      ],
      "parent_articles": [
        "Dynamic capabilities",
        "Theory of change"
      ]
    },
    {
      "question": "In the planetary boundaries framework, why does crossing a boundary increase the risk of abrupt, large-scale environmental changes rather than causing a smooth, proportional response?",
      "options": {
        "A": "Because Earth system components are interlinked through non-linear feedbacks and thresholds; once a boundary is crossed, internal dynamics can amplify perturbations and trigger a regime shift.",
        "B": "Because boundaries are defined as fixed, linear limits, so any crossing should produce proportional, predictable changes in the system.",
        "C": "Because abrupt changes are primarily caused by external shocks (e.g., meteor impacts) and have little to do with how the boundaries are conceptually defined.",
        "D": "Because crossing a boundary guarantees that all other boundaries will cross immediately due to direct linear propagation across processes."
      },
      "correct_answer": "A",
      "source_article": "Planetary boundaries",
      "x": 1.3381632566452026,
      "y": 0.8900699019432068,
      "concepts_tested": [
        "Safe operating space and planetary boundaries framework: how boundaries define limits to human impact and guide governance decisions.",
        "Non-linear thresholds and tipping points: why crossing a boundary may trigger abrupt, large-scale environmental change.",
        "Normative baseline of the Holocene stability: why that stability is used as a reference and how deviations influence policy and societal assumptions."
      ],
      "parent_concepts": [
        "Concept 3: Human activities and geological reservoirs influence long-term storage and fluxes, introducing sequestration and release (e.g., fossil fuels, synthetic compounds) that modify natural cycles."
      ],
      "parent_articles": [
        "Biogeochemical cycle"
      ]
    },
    {
      "question": "Why does division of labor and specialization contribute to economies of scale and lower average costs as output expands?",
      "options": {
        "A": "Specialization increases the marginal product of individual workers, enabling more output per unit of labor and reducing average costs.",
        "B": "Division of labor reduces the total output produced, which lowers average cost per unit.",
        "C": "Specialization increases coordination overhead and friction, which lowers average cost.",
        "D": "Economies of scale cannot be driven by division of labor; only bulk purchasing matters."
      },
      "correct_answer": "A",
      "source_article": "Economies of scale",
      "x": 1.3114262819290161,
      "y": 0.9570436477661133,
      "concepts_tested": [
        "Concept 1",
        "Concept 2",
        "Concept 3"
      ],
      "parent_concepts": [
        "Concept 1: Production costs and access to capital influence industry structure, driving consolidation around major studios while enabling independent production when barriers are lowered."
      ],
      "parent_articles": [
        "Film industry"
      ]
    },
    {
      "question": "Why does an entrant-specific fixed cost act as a barrier to entry and how does it relate to incumbent market power?",
      "options": {
        "A": "It raises the entrant's average total cost relative to incumbents because the fixed cost is borne only by entrants, allowing incumbents to maintain prices above competitive levels without inviting entry.",
        "B": "It raises the marginal cost of production for all firms equally, causing higher prices and encouraging more entrants to compete.",
        "C": "It creates a signaling effect that improves perceived quality, increasing competition and driving prices down.",
        "D": "It is easily financed and thus does not affect entry decisions or market power."
      },
      "correct_answer": "A",
      "source_article": "Barriers to entry",
      "x": 1.3011499643325806,
      "y": 0.9337289929389954,
      "concepts_tested": [
        "Concept 1: An entrant-specific fixed cost (barrier to entry) creates an incumbent advantage and helps sustain monopoly or oligopoly power.",
        "Concept 2: Barriers to entry distort prices and competition, which has implications for antitrust policy and market regulation.",
        "Concept 3: Different sources of barriers (natural like brand loyalty vs. government-imposed or resource-based barriers) shape how markets function and how policy should respond."
      ],
      "parent_concepts": [
        "Concept 1: Production costs and access to capital influence industry structure, driving consolidation around major studios while enabling independent production when barriers are lowered."
      ],
      "parent_articles": [
        "Film industry"
      ]
    },
    {
      "question": "How does a practical problem in applied mathematics typically stimulate the development of new pure mathematical theory?",
      "options": {
        "A": "By showing that numerical methods can solve the problem without any need for theoretical insight.",
        "B": "By exposing a recurring mathematical structure or limit in the model that motivates the creation of new abstractions, definitions, and rigorous results.",
        "C": "By transferring all problem-specific assumptions into a general setting so that no new theory is needed.",
        "D": "By demonstrating that practical problems are inherently simple and do not require any conceptual innovation."
      },
      "correct_answer": "B",
      "source_article": "Applied mathematics",
      "x": 1.5813496112823486,
      "y": 1.1403042078018188,
      "concepts_tested": [
        "Concept 1: The bidirectional relationship between applied mathematics and pure mathematics \u2014 practical problems motivate theoretical developments, and advances in pure math can arise from applied needs (and vice versa).",
        "Concept 2: The evolving and debated scope of the field \u2014 there is no consensus on what counts as applied mathematics vs. applications of mathematics, and the field now includes areas originating in pure math (e.g., number theory in cryptography) that are used in applications.",
        "Concept 3: The historical and institutional relationship to other disciplines \u2014 the field\u2019s development has been tied to physics, engineering, and pedagogy (e.g., teaching mechanics in applied math departments; the legacy from Newtonian physics)."
      ],
      "parent_concepts": [
        "Concept 1: Approximate solutions with specified error bounds are central to numerical analysis, not exact symbolic results."
      ],
      "parent_articles": [
        "Numerical analysis"
      ]
    },
    {
      "question": "Why does adding randomness to an algorithm change the guarantees we can offer about its output compared to a fully deterministic procedure?",
      "options": {
        "A": "Randomness changes the input data and thus the problem being solved.",
        "B": "Randomness makes the state-transition path non-deterministic, so outputs can be correct with high probability or in expectation rather than guaranteed on every run.",
        "C": "Randomness guarantees termination because coin flips eventually finish.",
        "D": "Randomness ensures the result is always the same across runs."
      },
      "correct_answer": "B",
      "source_article": "Algorithm",
      "x": 1.5872163772583008,
      "y": 1.163649559020996,
      "concepts_tested": [
        "Concept 1: An algorithm is a finite, well-defined sequence of instructions that, starting from an initial state/input, proceeds through a finite number of states to produce output and terminate.",
        "Concept 2: Algorithms can be deterministic or involve randomness (randomized algorithms), leading to probabilistic outcomes.",
        "Concept 3: Distinction between algorithms and heuristics: algorithms have precise definitions and termination guarantees, whereas heuristics do not guarantee correctness or optimality."
      ],
      "parent_concepts": [
        "The hardware-independent nature of complexity through counting elementary operations as basic steps."
      ],
      "parent_articles": [
        "Computational complexity"
      ]
    },
    {
      "question": "Why do reductions in trade barriers, liberalization of capital movements, and advances in transportation and information and communication technologies together drive globalization?",
      "options": {
        "A": "They primarily shield domestic markets from foreign competition, thereby intensifying domestic production and reducing global interdependence.",
        "B": "They lower transaction costs and enable more frequent cross-border flows of goods, services, capital, data, and people, which increases economic and cultural linkages across countries.",
        "C": "They eliminate all cultural differences, making distinct economies behave identically with no need for cross-border exchange.",
        "D": "They slow down the movement of capital and information, leading to more homogeneous but less connected economies."
      },
      "correct_answer": "B",
      "source_article": "Globalization",
      "x": 1.1875979900360107,
      "y": 0.9486820697784424,
      "concepts_tested": [
        "Concept 1: Global interdependence and integration across economies, markets, societies, and cultures as a core outcome of globalization.",
        "Concept 2: Mechanisms that drive globalization (reduction of trade barriers, liberalization of capital movements, advances in transportation, and information and communication technologies).",
        "Concept 3: Flows that globalization encompasses (goods, services, data/technology, capital, people, and information) and how these flows create economic and cultural connections."
      ],
      "parent_concepts": [
        "Concept 1: Comparative advantage and international specialization lead to more efficient resource allocation and higher productivity in global production.",
        "Concept 3: Successful international business requires navigating regulatory/cultural differences and conducting risk assessment with local adaptation, supported by market analysis and technology-enabled entry strategies.",
        "Global/transnational dynamics and networks shaping environmental justice outcomes (mechanisms linking local conflicts to global processes and the shift of burdens)"
      ],
      "parent_articles": [
        "International business",
        "International business",
        "Environmental justice"
      ]
    },
    {
      "question": "Consider a small open economy that imports a single good. The world price for that good is Pw. The government imposes a tariff t per unit on imports, so the domestic price becomes Pd = Pw + t. As a result, imports fall and domestic production may rise. Which of the following best explains why tariffs affect trade flows and the distribution of welfare?",
      "options": {
        "A": "Tariffs lower domestic price, increasing consumers' surplus and reducing producers' surplus; trade flows rise.",
        "B": "Tariffs create a wedge between the domestic and world prices, causing the domestic price to rise, reducing imports; the government collects tariff revenue, domestic producers gain from higher prices, consumers lose, and there is overall deadweight loss.",
        "C": "Tariffs increase world demand for the imported good, causing more imports than before and improving terms of trade for the country.",
        "D": "Tariffs are identical to subsidies for foreign exporters, leading to no change in domestic welfare."
      },
      "correct_answer": "B",
      "source_article": "International economics",
      "x": 1.2715423107147217,
      "y": 0.9205408692359924,
      "concepts_tested": [
        "Concept 1: Comparative advantage as the explanation for international trade based on relative opportunity costs, shaping trade patterns.",
        "Concept 2: Policy variables (tariffs and quotas) influence trade flows and the outcomes of trade, motivating study of trade restrictions.",
        "Concept 3: The methodological distinction between classical (deductive) and modern (empirical) trade analysis and how empirical methods inform understanding of trade behavior."
      ],
      "parent_concepts": [
        "Concept 3: Successful international business requires navigating regulatory/cultural differences and conducting risk assessment with local adaptation, supported by market analysis and technology-enabled entry strategies.",
        "Parity-based determinants of exchange rates (purchasing power parity, interest rate parity, and the international Fisher effect) and their implications for currency movements."
      ],
      "parent_articles": [
        "International business",
        "International finance"
      ]
    },
    {
      "question": "How does the secularization of theological concepts into modern political concepts help stabilize political authority in plural societies, according to Schmitt's framework?",
      "options": {
        "A": "By insisting rulers claim direct divine authority to unify the state.",
        "B": "By transforming sacred vocabularies into impersonal, universally acceptable political concepts that still carry moral weight, thus enabling broad appeal without dependence on a single creed.",
        "C": "By removing any moral or normative content from politics to allow technocratic governance.",
        "D": "By ensuring that religious institutions govern the state through church-state symphonia."
      },
      "correct_answer": "B",
      "source_article": "Political theology",
      "x": 0.53287273645401,
      "y": 0.6134510636329651,
      "concepts_tested": [
        "Secularization of theological concepts into modern political concepts (as argued by Carl Schmitt)",
        "Church\u2013state relationships and the political theology of governance (e.g., symphonia, Augustine/Aquinas/Luther/Calvin)",
        "Divergent orientations within political theology (moral reform vs. social justice) and how these shape political analysis"
      ],
      "parent_concepts": [
        "Concept 1: Religion as a driver of political identity and mobilization (identity politics, revivalism, community revitalization)",
        "Concept 3: Religion\u2019s role in shaping extremist ideologies and movements (e.g., Islamism, Christian nationalism, religious terrorism) and how doctrinal beliefs translate into political violence or policy aims"
      ],
      "parent_articles": [
        "Religion in politics",
        "Religion in politics"
      ]
    },
    {
      "question": "Why does the sociology of religion adopt a stance of methodological atheism or indifference to supernatural claims and use multiple methods when studying religion?",
      "options": {
        "A": "It seeks to prove religious beliefs true by collecting data and relies only on quantitative surveys.",
        "B": "It begins with theological commitments and uses interpretive analysis to defend dogma.",
        "C": "It treats religion as a social variable independent of metaphysical truth claims, often adopting methodological atheism or indifference to the supernatural, and uses both quantitative and qualitative methods to triangulate understanding.",
        "D": "It aims to replace religion with secular philosophy and dismisses empirical data about religious groups."
      },
      "correct_answer": "C",
      "source_article": "Sociology of religion",
      "x": 1.2195091247558594,
      "y": 1.0047352313995361,
      "concepts_tested": [
        "Concept 1: Religion as a social variable that both shapes and is shaped by social structure and economic relations (as discussed through Durkheim, Marx, and Weber).",
        "Concept 2: The methodological stance of sociology of religion\u2014distinguishing it from philosophy/theology, including the use of multiple methods and the idea of methodological atheism or indifference to the supernatural.",
        "Concept 3: Contemporary theoretical debates about secularization, civil religion, globalization, and the sociology of irreligion, and how these forces affect religious beliefs, practices, and institutions."
      ],
      "parent_concepts": [
        "Concept 1: Religion as a driver of political identity and mobilization (identity politics, revivalism, community revitalization)"
      ],
      "parent_articles": [
        "Religion in politics"
      ]
    },
    {
      "question": "In ideologies that blend theoretical beliefs with concrete political aims and actions, why does the practical dimension make the system especially prone to dogmatic use when beliefs become partisan?",
      "options": {
        "A": "The practical stakes tie beliefs to tangible outcomes, creating a feedback loop where success is used to justify the beliefs and dissent is framed as jeopardizing the desired results, leading to certainty and suppression of alternative views.",
        "B": "The practical dimension ensures continuous experimentation and flexible adaptation, preventing dogmatism.",
        "C": "The practical dimension eliminates moral judgments, making beliefs neutral.",
        "D": "The practical dimension makes it easy to separate theory from action, reducing commitment to any single set of beliefs."
      },
      "correct_answer": "A",
      "source_article": "Ideology",
      "x": 1.1563912630081177,
      "y": 0.9568472504615784,
      "concepts_tested": [
        "Concept 1: Ideology as a \"science of ideas\" that ties perceptions and sensations to the formation of organized political/economic theories, with aims (e.g., defending liberty, property, free markets) and limits on state power.",
        "Concept 2: The relationship between theory and practice in ideology, including the prominence of practical elements, and the potential for pejorative, dogmatic, or fanatical use (ideologue) when beliefs become partisan.",
        "Concept 3: Historical origin and evolution of the term, including Tracy\u2019s original intentions and the shift to descriptive/polemical usage in political science, plus how historical contexts (Taine, revolutions) influenced its meaning and application."
      ],
      "parent_concepts": [
        "Concept 3: Religion\u2019s role in shaping extremist ideologies and movements (e.g., Islamism, Christian nationalism, religious terrorism) and how doctrinal beliefs translate into political violence or policy aims"
      ],
      "parent_articles": [
        "Religion in politics"
      ]
    },
    {
      "question": "Why does incorporating co-design with people from diverse backgrounds act as a mechanism to realize inclusive design rather than relying on a single stakeholder view?",
      "options": {
        "A": "It helps accelerate decision making by delegating all choices to the most dominant group.",
        "B": "It surfaces a broader set of needs and constraints, enabling iterative feedback that reduces design bias and better aligns the product with a wide range of user experiences.",
        "C": "It guarantees immediate consensus, allowing the team to finalize requirements without further testing.",
        "D": "It ensures the design remains faithful to initial assumptions by limiting input to early-stage prototypes."
      },
      "correct_answer": "B",
      "source_article": "Inclusive design",
      "x": 1.342003583908081,
      "y": 1.0162488222122192,
      "concepts_tested": [
        "Concept 1: Inclusive design as a methodology that accounts for human diversity and aims to fulfill a wide range of user needs, not just increasing the number of users.",
        "Concept 2: Co-design and open, transparent processes that involve people with diverse perspectives to realize inclusive design.",
        "Concept 3: Design operates within a complex adaptive system, where design changes influence larger systems and their interactions."
      ],
      "parent_concepts": [
        "Concept 1: Direct vs. indirect access and the role of assistive technology in achieving usable access."
      ],
      "parent_articles": [
        "Accessibility"
      ]
    },
    {
      "question": "Why does Alter advocate viewing an information system as a work system, and how does this viewpoint clarify the relationship between data systems and activity systems in producing outputs for customers?",
      "options": {
        "A": "It emphasizes that information activities involve people, tasks, technology, and structure working together to transform data into outputs, making data systems (capturing/storage) and activity systems (processes/workflows) interdependent and co-constructive through feedback to serve customers.",
        "B": "It implies that information systems can be optimized by focusing solely on automating data storage, ignoring human and organizational aspects.",
        "C": "It suggests that information systems are static artifacts whose only role is to store data for later retrieval, without affecting processes.",
        "D": "It claims that data systems and activity systems are independent, so changing one does not affect the other."
      },
      "correct_answer": "A",
      "source_article": "Information system",
      "x": 1.4316998720169067,
      "y": 1.0622215270996094,
      "concepts_tested": [
        "Concept 1: Sociotechnical four-component model (task, people, structure, technology) and their interdependencies in information system design and use.",
        "Concept 2: Information systems as work systems (per Alter) and their relationship to data systems and activity systems, illustrating how information activities produce outputs for customers.",
        "Concept 3: Information systems as a form of communication system and social memory, highlighting how data are represented, processed, stored, and used to support decision making."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does employing a cohesive, multi-level set of models that describe an enterprise's structure and functions improve an organization's ability to use architecture to guide decision-making and change?",
      "options": {
        "A": "Because it centralizes all decision authority in the enterprise architect, reducing the need for cross-functional input.",
        "B": "Because it makes explicit the interdependencies among business processes, information, and technology, allowing decisions to be evaluated for consistency with strategic objectives and potential ripple effects.",
        "C": "Because it ensures that only technological constraints drive all decisions, aligning IT with strategy independently of business needs.",
        "D": "Because it requires detailed documentation that prevents any changes once models are established."
      },
      "correct_answer": "B",
      "source_article": "Enterprise architecture",
      "x": 1.417971134185791,
      "y": 1.0708814859390259,
      "concepts_tested": [
        "Holistic, proactive leadership of organizational change to execute strategy",
        "Alignment of business, information, process, and technology decisions with strategic goals",
        "Use of cohesive, multi-level models to describe structure/functions and guide decision-making and change"
      ],
      "parent_concepts": [
        "Data architecture and data flows as the engineered structure that enables efficient, scalable data movement aligned with business needs (how design decisions impact analytics and operations)",
        "Concept 2: Architectural paradigms and trade-offs\u2014data warehouses with ETL (tight coupling, fast queries but less suitable for frequently updated data) vs mediated schema with loose coupling and real-time access (SOA), including their impact on synchronization and data freshness."
      ],
      "parent_articles": [
        "Data management",
        "Data integration"
      ]
    },
    {
      "question": "In critical thinking framed as self-directed, self-disciplined, self-monitored, and self-corrective habits, why does instituting scheduled, reflective checks on one's reasoning enhance problem-solving performance?",
      "options": {
        "A": "It increases the breadth of factual knowledge automatically.",
        "B": "It engages metacognitive monitoring that helps identify and adjust for biases, gaps, and faulty inferences.",
        "C": "It crowdsources judgment, allowing consensus to override individual errors.",
        "D": "It discourages questioning of assumptions, preserving cognitive ease."
      },
      "correct_answer": "B",
      "source_article": "Critical thinking",
      "x": 1.263258457183838,
      "y": 1.0409477949142456,
      "concepts_tested": [
        "Concept 1: Critical thinking as analysis and evaluation of facts, evidence, observations, and arguments, including recognizing assumptions and justifying ideas while assessing rationality and consequences.",
        "Concept 2: Critical thinking as a set of self-directed, self-disciplined, self-monitored, and self-corrective habits of the mind that require ownership and mindful communication/problem solving.",
        "Concept 3: The role of an individual's knowledge base in determining the excellence of critical thinking and the notion that critical thinking can be learned or trained."
      ],
      "parent_concepts": [
        "Criteria for evaluating arguments (validity, soundness, cogency) and the role of rebuttals/fallacies in challenging reasoning"
      ],
      "parent_articles": [
        "Argumentation theory"
      ]
    },
    {
      "question": "In a common law system, why does reliance on precedent often constrain a judge when deciding a new case, and by what routes can that constraint be modified?",
      "options": {
        "A": "Precedent is codified statutes that must be applied literally; the constraint can only be removed by statutory amendment.",
        "B": "Precedent represents established judicial reasoning from previous cases which binds current judges in similar fact patterns; it can be modified by distinguishing the current case, overruling by a higher court, or enacting legislation.",
        "C": "Precedent is merely persuasive and not binding; judges are free to set new rules based on policy; no formal mechanisms exist to overturn.",
        "D": "Precedent is a universal rule binding all jurisdictions; changes require a global consensus and constitutional overhaul."
      },
      "correct_answer": "B",
      "source_article": "Law",
      "x": 1.2695660591125488,
      "y": 0.9476741552352905,
      "concepts_tested": [
        "Concept 1: Mechanisms of law creation and sources (legislation, executive regulation, judicial decisions; role of precedent; constitutional influence)",
        "Concept 2: Structure of legal systems (civil vs. common law; codification vs. case law; public vs. private law)",
        "Concept 3: Law as a social mediator and normative project (how law influences politics, economics, society; aims of equality, fairness, justice)"
      ],
      "parent_concepts": [
        "Concept 2: The formal\u2013informal spectrum of institutions and the role of enforcement in maintaining coordination and compliance (e.g., how varying levels of formality and third-party enforcement affect stability).",
        "Concept 1: The role of commercial law in creating orderly, enforceable, and predictable exchanges to support fair competition and public trust."
      ],
      "parent_articles": [
        "Institution",
        "Commercial law"
      ]
    },
    {
      "question": "In a setting where breaking a social norm offers a potential short-term personal gain, which mechanism most directly explains why the norm can persist when other people observe and punish deviants?",
      "options": {
        "A": "Logic of consequences \u2014 people comply because they weigh costs and benefits; deviation only remains viable if enforcement keeps the payoff of violation low.",
        "B": "Logic of appropriateness \u2014 people comply because it aligns with social roles and identities, regardless of direct payoff.",
        "C": "Third-party punishment \u2014 observers enforce the norm by sanctioning deviants, creating a deterrent that can sustain the norm even when personal gains exist.",
        "D": "Evolutionarily stable strategy \u2014 the norm persists because the strategy is stable in a population and resistant to invasion by alternatives."
      },
      "correct_answer": "C",
      "source_article": "Social norm",
      "x": 1.2549736499786377,
      "y": 1.0003620386123657,
      "concepts_tested": [
        "Concept 1: Norm life cycle (emergence \u2192 cascade \u2192 internalization) and the processes that drive each stage (norm entrepreneurs, broad acceptance, taken-for-granted status).",
        "Concept 2: Mechanisms for normative influence (logic of appropriateness vs. logic of consequences; third-party punishment; evolutionarily stable strategies) and how they explain compliance and stability.",
        "Concept 3: Distinctions among norm types (regulative, constitutive, prescriptive) and how these categories relate to behavior, interests, and contextual variation."
      ],
      "parent_concepts": [
        "Concept 2: The formal\u2013informal spectrum of institutions and the role of enforcement in maintaining coordination and compliance (e.g., how varying levels of formality and third-party enforcement affect stability)."
      ],
      "parent_articles": [
        "Institution"
      ]
    },
    {
      "question": "Why do social contract theorists appeal to tacit consent as a mechanism for legitimating political authority, and how does tacit consent differ from explicit consent in grounding that legitimacy?",
      "options": {
        "A": "Tacit consent is inferred from individuals\u2019 continued residence in a political community and acceptance of its protections, providing a practical endorsement without a formal, signed agreement; explicit consent requires a clear, voluntary assent to authority.",
        "B": "Tacit consent and explicit consent are identical; both require individuals to sign a constitution to be legitimate.",
        "C": "Tacit consent means authority is legitimate regardless of any benefits or participation, since mere location suffices.",
        "D": "Tacit consent means birth within a territory automatically confers perpetual obedience without any ongoing endorsement."
      },
      "correct_answer": "A",
      "source_article": "Social contract",
      "x": 1.2056233882904053,
      "y": 0.964235246181488,
      "concepts_tested": [
        "State of nature as the hypothetical starting condition that motivates forming a political order",
        "Consent (explicit or tacit) as the mechanism by which individuals authorize authority",
        "The exchange of freedoms for protection of rights and social order, underpinning the legitimacy of the state"
      ],
      "parent_concepts": [
        "Concept 3: Mutually related rights and obligations and collective enforcement as the basis of social order (e.g., how shared expectations and enforcement mechanisms sustain institutional functioning)."
      ],
      "parent_articles": [
        "Institution"
      ]
    },
    {
      "question": "In cost\u2013benefit analysis, why is a discount rate applied to future costs and benefits when computing net present value?",
      "options": {
        "A": "To reflect that money today is worth more than money in the future, due to earning potential, so distant outcomes get lower weight.",
        "B": "To adjust only for inflation and maintain constant purchasing power over time.",
        "C": "To equally weight all future cash flows regardless of when they occur.",
        "D": "To convert all costs to negative values and all benefits to positive values, independent of timing."
      },
      "correct_answer": "A",
      "source_article": "Cost\u2013benefit analysis",
      "x": 1.3943573236465454,
      "y": 0.9748892188072205,
      "concepts_tested": [
        "Concept 1: Monetary valuation and time value of money (net present value) as the basis for comparing benefits and costs across time.",
        "Concept 2: Using a cost\u2013benefit ratio to rank options and determine which action increases welfare (and its relation to Pareto efficiency).",
        "Concept 3: Limitations and uncertainties in CBA (accuracy of estimates, potential manipulation by interest groups) and their impact on decisions."
      ],
      "parent_concepts": [
        "Concept 1: Economic efficiency as a criterion for evaluating legal rules and predicting which rules will be promulgated"
      ],
      "parent_articles": [
        "Law and economics"
      ]
    },
    {
      "question": "In leadership conceived as a process of social influence and a power-relationship between leaders and followers, why is enlisting the aid and support of followers essential for achieving a common goal rather than relying only on formal authority?",
      "options": {
        "A": "Because formal authority can compel actions in the short term but cannot generate sustained voluntary engagement or alignment with followers' intrinsic goals.",
        "B": "Because social influence aligns followers' motivations with the leader's vision, producing voluntary commitment and sustained effort beyond coercion.",
        "C": "Because charisma alone is universally sufficient to guarantee leadership effectiveness across all situations.",
        "D": "Because followers will only support a goal if they are physically coerced into doing so."
      },
      "correct_answer": "B",
      "source_article": "Leadership",
      "x": 1.262581706047058,
      "y": 0.989123523235321,
      "concepts_tested": [
        "Leadership as a process of social influence and a power-relationship between leaders and followers",
        "Theoretical frameworks of leadership (traits, situational interaction, function, behavior, power, vision, values, charisma, intelligence) that explain how leadership operates",
        "Ethico-cultural principles of leadership (intelligence, trustworthiness, humaneness, courage, discipline) as foundational virtues across traditions"
      ],
      "parent_concepts": [
        "Concept 2: Structured collaboration methods and social/egalitarian leadership influence success by improving behavior, communication, and collaborative problem-solving."
      ],
      "parent_articles": [
        "Collaboration"
      ]
    },
    {
      "question": "Why does data quality framed as \"fitness for use\" depend on the context of the intended operation or decision, rather than yielding a universal quality score?",
      "options": {
        "A": "Because data quality is judged by how well the data satisfy the specific requirements of the intended use, and different uses impose different accuracy, timeliness, and granularity needs.",
        "B": "Because there exists a universal accuracy standard that makes all data equally usable across contexts.",
        "C": "Because data quality is determined solely by data cleansing processes, independent of the use case.",
        "D": "Because governance can enforce a single standard that guarantees the same quality for all uses, eliminating context."
      },
      "correct_answer": "A",
      "source_article": "Data quality",
      "x": 1.4228514432907104,
      "y": 1.055965781211853,
      "concepts_tested": [
        "Fitness for use: data quality is determined by how well data meet the intended use in context (operations, decision making, planning).",
        "Conformance to standards and quality dimensions: data quality involves inherent characteristics and adherence to defined requirements or specifications.",
        "Governance and cleansing as mechanisms: data governance, standardization, and data cleansing are processes used to achieve and maintain data quality across multiple data sources."
      ],
      "parent_concepts": [
        "Concept 1: Official statistics are expected to be objective, accurate, and accessible, produced on a continuing basis to measure change."
      ],
      "parent_articles": [
        "Official statistics"
      ]
    },
    {
      "question": "In principlism, why are the four prima facie principles treated as overlapping guides rather than fixed, absolute rules, and how does this arrangement support ethical decision-making across different professional contexts?",
      "options": {
        "A": "It imposes a strict hierarchy where autonomy always overrides the others, making decisions uniform across contexts.",
        "B": "It acknowledges that principles can conflict and thus supports principled balancing to tailor decisions to specific real-world situations.",
        "C": "It elevates non-maleficence as the sole binding rule in all cases, eliminating the need to weigh other principles.",
        "D": "It assigns each principle to a separate, non-interacting domain, so boundaries prevent cross-domain ethical reasoning."
      },
      "correct_answer": "B",
      "source_article": "Applied ethics",
      "x": 1.1825162172317505,
      "y": 1.0123366117477417,
      "concepts_tested": [
        "Principlism: the four prima facie principles (autonomy, non-maleficence, beneficence, justice) as a framework for evaluating moral issues in real-world contexts.",
        "Relationship to normative/meta-ethics: how applied ethics draws on normative theories (e.g., consequentialism/utilitarianism, deontological ethics) to analyze and justify moral decisions.",
        "Interdisciplinary/multi-professional application: applied ethics requires domain-specific understanding across fields (medicine, business, IT) and shows how ethical frameworks are used within different professional contexts."
      ],
      "parent_concepts": [
        "Three conceptual orientations of industrial relations (science-building, problem solving, ethical) that guide research and practice."
      ],
      "parent_articles": [
        "Industrial relations"
      ]
    },
    {
      "question": "In a unionized workplace, why is the grievance process under the collective agreement typically used as the first step, and how does escalating to labor boards or arbitration embody a strategic principle of dispute resolution hierarchy?",
      "options": {
        "A": "The grievance process applies the contract's specific terms within its own procedures to preserve working relationships and provide a timely, specialized path; escalation to labor boards/arbitration occurs when the issue cannot be resolved within those terms, ensuring binding enforcement and independent judgment.",
        "B": "The grievance process is a courtesy step that delays decisions until civil courts can decide.",
        "C": "Labor boards are used first for all disputes to ensure consistent application of law, with the grievance process serving only as a record-keeping exercise.",
        "D": "Arbitration is used only for safety issues, while the grievance process handles all other disputes; escalation is unnecessary."
      },
      "correct_answer": "A",
      "source_article": "Labor relations",
      "x": 1.219774842262268,
      "y": 0.8690791726112366,
      "concepts_tested": [
        "Concept 1: Distinction and scope of labour relations vs. employee relations (unionized vs. non-union settings) and their place within industrial relations.",
        "Concept 2: Mechanisms and hierarchy of dispute resolution (grievance processes, arbitration, labour boards, tribunals, courts, OH&S) and how the forum chosen depends on issue type.",
        "Concept 3: Central role of collective bargaining and collective agreements in determining work terms (remuneration, hours, working rules) and structuring dispute resolution in unionized workplaces."
      ],
      "parent_concepts": [
        "Variability in the wage-labour relationship through employment/civil status and remuneration forms (full-time/part-time, indentured/serf, cash/in-kind/piece rates) that modify the meaning and mechanics of the relationship."
      ],
      "parent_articles": [
        "Wage labour"
      ]
    },
    {
      "question": "Why does empowerment through participatory democracy and rights-based practice tend to produce more durable community development outcomes than projects driven primarily by external experts?",
      "options": {
        "A": "It speeds up implementation by bypassing local input and decision-making.",
        "B": "It builds ownership, local capacity, and legitimacy by involving community members in defining problems, selecting solutions, and monitoring progress, which supports sustainable change even after external support ends.",
        "C": "It relies on external experts to set priorities and evaluate outcomes, ensuring objective standards.",
        "D": "It standardizes policies across diverse communities, reducing the need to tailor approaches to local contexts."
      },
      "correct_answer": "B",
      "source_article": "Community development",
      "x": 1.2659670114517212,
      "y": 0.8961822986602783,
      "concepts_tested": [
        "Empowerment through participatory democracy and rights-based practice",
        "Collective action and capacity-building via social groups to effect change",
        "Relational dynamics between communities and larger social institutions/governance (policy, international standards)"
      ],
      "parent_concepts": [
        "Concept 2: Inside-out, community-centered process (citizens as actors, importance of listening/asking, and broad-based involvement) (how local ownership and relationships drive development)."
      ],
      "parent_articles": [
        "Asset-based community development"
      ]
    },
    {
      "question": "In participatory development, empowerment is a core mechanism because it enables joint decision-making. How does this empowerment-based mechanism lead to more sustainable outcomes?",
      "options": {
        "A": "It concentrates decision power among external actors, reducing local accountability.",
        "B": "It builds ownership by primary stakeholders, aligning actions with local needs and commitment to follow through.",
        "C": "It removes all external support, forcing communities to self-sustain immediately.",
        "D": "It ensures that only technical experts design solutions, reducing cultural relevance."
      },
      "correct_answer": "B",
      "source_article": "Participatory development",
      "x": 1.254420280456543,
      "y": 0.9557003378868103,
      "concepts_tested": [
        "Empowerment and joint decision-making as core mechanisms and goals of participatory development (how empowerment leads to ownership and sustainable outcomes).",
        "Competing perspectives on participation (Social Movement Perspective vs Institutional Perspective) and how they shape power relations, roles of outsiders, and aims of PD.",
        "A staged project life cycle (Research, Design, Implementation, Evaluation) as a framework for incorporating stakeholder inputs and guiding participatory processes."
      ],
      "parent_concepts": [
        "Concept 2: Inside-out, community-centered process (citizens as actors, importance of listening/asking, and broad-based involvement) (how local ownership and relationships drive development)."
      ],
      "parent_articles": [
        "Asset-based community development"
      ]
    },
    {
      "question": "Why is present value essential for comparing investment projects with different cash-flow timing, and how does the discount rate influence the relative attractiveness of projects with earlier versus later returns?",
      "options": {
        "A": "Present value converts all future cash flows into a single current value by using the opportunity cost of capital; a higher discount rate devalues later cash flows more than earlier ones, making front-loaded projects comparatively more attractive.",
        "B": "Present value sums future cash flows without considering timing, so the discount rate does not affect relative attractiveness of timing.",
        "C": "Present value cancels risk completely, so only the total undiscounted cash matters; discount rate only matters for risk-adjusted returns.",
        "D": "Present value only reflects accounting for inflation, not timing or opportunity costs; discount rate captures inflation."
      },
      "correct_answer": "A",
      "source_article": "Financial economics",
      "x": 1.3288261890411377,
      "y": 0.9296298623085022,
      "concepts_tested": [
        "Present value and its use in evaluating and comparing future cash flows to make investment decisions",
        "Arbitrage-free pricing and the fundamental theorem of asset pricing (conditions under which prices must align to prevent arbitrage)",
        "Decision making under uncertainty in finance (how expectation, utility, and risk influence asset prices and allocation of resources)"
      ],
      "parent_concepts": [
        "Concept 2: The capital allocation mechanism \u2014 capital budgeting (which value-adding projects to fund) and financing choices (debt vs. equity) determine how resources are allocated and how value is created."
      ],
      "parent_articles": [
        "Corporate finance"
      ]
    },
    {
      "question": "Why does the renewability of a natural resource constrain its sustainable use rate, and how should policy respond to this constraint?",
      "options": {
        "A": "Sustainable use must stay at or below the natural replenishment rate; policy should set limits or incentives to ensure extraction does not outpace replenishment.",
        "B": "Renewable resources never become scarce regardless of use rate, so policy should not regulate extraction.",
        "C": "Replenishment rate is irrelevant because technological substitutes always eliminate scarcity, so policy should ignore resource limits.",
        "D": "Non-renewable resources replenish quickly, so policy should prioritize extraction of renewables after depletion."
      },
      "correct_answer": "A",
      "source_article": "Natural resource",
      "x": 1.5250228643417358,
      "y": 0.8842129111289978,
      "concepts_tested": [
        "Renewable vs non-renewable resources and sustainability: how renewability determines use rates, replenishment, and policy implications.",
        "Socio-political and environmental impacts of resource extraction and responses: how extraction drives conflicts and harms, and how sustainable development goals and circular economy aim to address these issues.",
        "Classification frameworks for resources (origin and stage of development): how biotic vs abiotic origins and potential resources classifications guide assessment, discovery, and policy decisions."
      ],
      "parent_concepts": [
        "Concept 1: Renewal depends on replenishment rate relative to extraction; if extraction outpaces replenishment on human time scales, a renewable resource becomes effectively non-renewable (with perpetual resources existing when replenishment outpaces human time scale).",
        "Concept 3: Context and management determine renewability; local conditions (aquifer recharge, subsidence from groundwater removal, pollution) and policy/treatment practices can make a resource renewable or non-renewable."
      ],
      "parent_articles": [
        "Renewable resource",
        "Renewable resource"
      ]
    },
    {
      "question": "Why does Hotelling's rule imply that the net price of a nonrenewable resource must rise at the rate of interest over time, and what mechanism ensures this intertemporal path?",
      "options": {
        "A": "Because an owner can either extract today and receive the current net price or postpone extraction and invest the proceeds to earn the market interest rate; to prevent arbitrage, the expected growth rate of the net price must equal the interest rate, making the choice between extracting now or later indifferent.",
        "B": "Because future demand must grow at the same rate as the interest rate, forcing the price path to match r.",
        "C": "Because extraction costs rise at rate r, requiring the net price to rise to offset those increasing costs.",
        "D": "Because government policies set a fixed price growth equal to the interest rate, regardless of scarcity or market conditions."
      },
      "correct_answer": "A",
      "source_article": "Natural resource economics",
      "x": 1.315705418586731,
      "y": 0.9235268235206604,
      "concepts_tested": [
        "Concept 1: Sustainability and ecological constraints as governing principles for economic activity (economy operating within Earth's natural resources; interdependence with natural ecosystems)",
        "Concept 2: Depletion and pricing dynamics governed by Hotelling-like models (nonrenewable resource extraction paths; price rising with time at a rate linked to interest rate)",
        "Concept 3: Non-market valuation and welfare considerations in resource economics (recreational vs commercial values; incorporation into welfare theory and environmental policy)"
      ],
      "parent_concepts": [
        "Concept 1: Renewal depends on replenishment rate relative to extraction; if extraction outpaces replenishment on human time scales, a renewable resource becomes effectively non-renewable (with perpetual resources existing when replenishment outpaces human time scale)."
      ],
      "parent_articles": [
        "Renewable resource"
      ]
    },
    {
      "question": "Why does resource leveling, as a mechanism to balance resource demand and supply over time, help keep service levels while minimizing cost?",
      "options": {
        "A": "It reschedules non-critical tasks to off-peak periods, spreading demand, preventing over-allocation, keeping critical work on track, and reducing the need for costly last-minute staffing or urgent purchases.",
        "B": "It maximizes resource utilization by keeping every resource busy every period, which always yields the lowest cost and highest service level.",
        "C": "It locks resources to specific tasks forever to guarantee no variability, which minimizes cost but destroys service levels.",
        "D": "It transfers all resources away from core capabilities to inventory, making service levels independent of demand."
      },
      "correct_answer": "A",
      "source_article": "Resource management",
      "x": 1.40867018699646,
      "y": 0.9922773241996765,
      "concepts_tested": [
        "Resource leveling as a mechanism to balance resource demand/supply over time while meeting service levels and minimizing cost.",
        "Resources as stored capabilities with a development dimension: investing in existing resources to build new capabilities and unleashing them as demanded.",
        "Corporate resource management and prioritization: focusing resources and abandoning less promising initiatives to prevent fragmentation and over-allocation across projects."
      ],
      "parent_concepts": [
        "Concept 3: Context and management determine renewability; local conditions (aquifer recharge, subsidence from groundwater removal, pollution) and policy/treatment practices can make a resource renewable or non-renewable."
      ],
      "parent_articles": [
        "Renewable resource"
      ]
    },
    {
      "question": "Why is specifying a statistical model essential for converting sample data into population-level conclusions, and how does model misspecification affect the interpretation of results?",
      "options": {
        "A": "The model defines a concrete data-generating process that links population quantities to the observed data, enabling estimates and uncertainty to be interpreted as statements about the population; if the model is wrong (misspecified), those conclusions reflect incorrect assumptions, leading biased estimates and invalid confidence or credible intervals.",
        "B": "The model is only a computational scaffold; once data are observed, population conclusions are determined by the data alone, so misspecification has no effect.",
        "C": "The model guarantees unbiased and valid inferences by accounting for all random variation; misspecification cannot affect the truth because the model can be corrected with larger samples.",
        "D": "The model is irrelevant to population conclusions because descriptive statistics suffice to summarize the sample and infer population properties directly."
      },
      "correct_answer": "A",
      "source_article": "Statistical inference",
      "x": 1.615736722946167,
      "y": 1.1357333660125732,
      "concepts_tested": [
        "The role of a statistical model in converting data into population-level conclusions (model-based inference)",
        "The importance of sampling and underlying assumptions for drawing inferences about a population",
        "The different forms of inferential propositions (point estimates, confidence intervals, credible intervals, hypothesis tests) and what they represent"
      ],
      "parent_concepts": [
        "Concept 3: The impact of statistical tools (e.g., ANOVA, p-values, Fisher\u2019s exact test) on hypothesis testing and interpreting biological data."
      ],
      "parent_articles": [
        "Biostatistics"
      ]
    },
    {
      "question": "From a sociocultural perspective on learning, why does pretend play promote the development of language, rule understanding, and symbol use in children?",
      "options": {
        "A": "Because it strengthens rote memorization of words through repetitive drills with minimal social interaction.",
        "B": "Because it creates opportunities for a more knowledgeable other to scaffold the child's use of language and symbols, gradually guiding internalization of rules and culturally meaningful practices.",
        "C": "Because it reduces cognitive load by allowing the child to rely on automatic motor routines rather than conceptual thinking.",
        "D": "Because it encourages solitary exploration that leads to independent mastery of language without social mediation."
      },
      "correct_answer": "B",
      "source_article": "Learning",
      "x": 1.3133190870285034,
      "y": 1.026892900466919,
      "concepts_tested": [
        "Concept 1: Mechanisms of learning (habituation, classical conditioning, operant conditioning) and how each leads to changes in behavior or knowledge.",
        "Concept 2: The role of play and social interaction (e.g., Vygotsky's view) in learning, including how play facilitates language, rule understanding, and symbol use.",
        "Concept 3: Memory systems and their relation to learning (declarative vs procedural; episodic vs semantic) and how different memory types influence what is learned and how it is retrieved."
      ],
      "parent_concepts": [
        "Concept 3: Transfer as a continuum integrated with learning \u2014 transfer is not always a separate, discrete event but is connected to learning itself, with debates about its boundaries and conceptualization."
      ],
      "parent_articles": [
        "Transfer of learning"
      ]
    },
    {
      "question": "In the framework of generalization, what mechanistic explanation accounts for why a learner responds more strongly to stimuli that are more similar to a previously learned cue and weaker as similarity declines?",
      "options": {
        "A": "Because learning builds overlapping feature representations across similar stimuli, creating graded activation that diminishes with decreasing similarity.",
        "B": "Because the learner stores each training instance as a discrete, exact memory and only responds to exact matches.",
        "C": "Because a single universal rule is learned for all contexts and is applied identically regardless of similarity.",
        "D": "Because response strength is completely determined by reinforcement frequency and is independent of similarity."
      },
      "correct_answer": "A",
      "source_article": "Generalization (learning)",
      "x": 1.3293994665145874,
      "y": 1.0361095666885376,
      "concepts_tested": [
        "Transfer of learned patterns/abstractions to new, similar situations (principle of generalization)",
        "Mechanisms: abstraction and connectionist processes that enable categorization and generalization",
        "Generalization gradient: relationship between stimulus similarity and the strength of the response, used to measure generalization"
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In the systems/holistic perspective of socio-environmental interactions, social institutions and environmental conditions influence each other through feedback loops. Which scenario best illustrates this coupling?",
      "options": {
        "A": "A city implements a policy to reduce emissions and sees an immediate drop in emissions with no changes in institutions, culture, or economic incentives.",
        "B": "After a pollution reduction improves air quality, public concern wanes, leading to cuts in funding for environmental programs, which then allow pollution to rise again.",
        "C": "A new technology fixes pollution permanently, making social factors irrelevant.",
        "D": "Social institutions independently regulate the environment without any feedback from environmental conditions."
      },
      "correct_answer": "B",
      "source_article": "Environmental sociology",
      "x": 1.2492692470550537,
      "y": 0.9538249373435974,
      "concepts_tested": [
        "Social construction of environmental problems: how societies define and frame environmental conditions as problems, shaping policy and action.",
        "Systems/holistic perspective on socio-environmental interactions: integration of social factors, institutions, and environmental contexts, including feedback between them.",
        "Existential dualism in the human-nature relationship: tension between humans as embedded in ecosystems and as unique agents with capacity to manipulate and transform the environment."
      ],
      "parent_concepts": [
        "Environmental racism and unequal distribution of environmental harms affecting marginalized communities (cause-and-effect relationship and social mechanism)",
        "Global/transnational dynamics and networks shaping environmental justice outcomes (mechanisms linking local conflicts to global processes and the shift of burdens)"
      ],
      "parent_articles": [
        "Environmental justice",
        "Environmental justice"
      ]
    },
    {
      "question": "In a river valley, a large-scale irrigation project controlled by a city-based corporation reallocates water rights. Downstream smallholder farmers experience reduced harvests and higher vulnerability to drought, while investors in the project reap increased profits and access to land subsidies. Which mechanism best explains why environmental costs and benefits are distributed unequally across social groups?",
      "options": {
        "A": "Environmental variability due to natural geography",
        "B": "Unequal political, social, and economic power shaping who bears costs and who benefits",
        "C": "Random variation in environmental impact across communities",
        "D": "Shared values leading to uniform acceptance of resource use"
      },
      "correct_answer": "B",
      "source_article": "Political ecology",
      "x": 1.2894445657730103,
      "y": 0.9206064939498901,
      "concepts_tested": [
        "Concept 1: Unequal distribution of environmental costs and benefits due to political, social, and economic differences.",
        "Concept 2: Any change in environmental conditions tends to affect the political and economic status quo, reshaping power relations.",
        "Concept 3: The politicization of environmental issues and the integration of ecological study with political economy, including how ownership rules and local institutions mediate broader pressures."
      ],
      "parent_concepts": [
        "Global/transnational dynamics and networks shaping environmental justice outcomes (mechanisms linking local conflicts to global processes and the shift of burdens)"
      ],
      "parent_articles": [
        "Environmental justice"
      ]
    },
    {
      "question": "Why does a scientific theory's explanatory role enable scientists to generate testable predictions beyond the observations it was built from?",
      "options": {
        "A": "Because a theory is a single universal law that replaces all observations with one equation.",
        "B": "Because a theory provides an explanatory framework that connects diverse observations through underlying mechanisms, allowing reasoning about unobserved cases and yielding testable predictions.",
        "C": "Because a theory is just a collection of verified facts that cannot be revised.",
        "D": "Because a theory is a guess that cannot be evaluated by experiments."
      },
      "correct_answer": "B",
      "source_article": "Scientific theory",
      "x": 1.5592981576919556,
      "y": 1.1036361455917358,
      "concepts_tested": [
        "The explanatory role of a theory: connects and explains multiple observations and yields testable predictions.",
        "The dynamic nature of scientific theories: they can be modified or rejected in light of new evidence; some become highly robust, while others remain approximations under certain conditions.",
        "The relationships among theory, fact, and law, and the role of reasoning (including abductive reasoning) in evaluating theories across contexts."
      ],
      "parent_concepts": [
        "The criteria for a physical theory: agreement with empirical observations and the ability to make new, testable predictions."
      ],
      "parent_articles": [
        "Theoretical physics"
      ]
    },
    {
      "question": "How does delegating monitoring and enforcement to an international organization alter a state's calculation about complying with an agreement, and why does this typically promote cooperation?",
      "options": {
        "A": "It increases the immediate material costs of compliance, making defection more attractive to avoid additional burdens.",
        "B": "It reduces information asymmetries and verification costs, while providing credible punishment and future cooperation incentives, making adherence more appealing.",
        "C": "It eliminates the need for ongoing communication among states, allowing silent compliance without any reciprocity considerations.",
        "D": "It guarantees universal compliance by giving the organization coercive power to force all states to obey regardless of consent."
      },
      "correct_answer": "B",
      "source_article": "International organization",
      "x": 1.190417766571045,
      "y": 0.8509390950202942,
      "concepts_tested": [
        "Mechanism by which IOs facilitate cooperation (reducing transaction costs, credible commitments, information provision, focal points, reciprocity).",
        "Compliance drivers for states (rational cost-benefit calculations and normative reasons such as social learning/socialization).",
        "Design/rationales of IOs (how membership, scope, rule rigidity/flexibility, obligations, and delegation affect effectiveness and behavior)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "How does the Lilliputian strategy enable small powers to influence a larger power within a multilateral setting, and why does this often lead to more favorable shared objectives for the coalition?",
      "options": {
        "A": "By forcing the large power to accept a binding veto on all its actions in the multilateral forum.",
        "B": "By coordinating a credible, jointly binding alternative to unilateral action that raises the large power\u2019s costs of breaking with the coalition and offers a shared path to objectives, thus changing bargaining dynamics.",
        "C": "By appealing primarily to the large power\u2019s legitimacy concerns and relying on public opinion to constrain its behavior, without any concrete policy threat.",
        "D": "By isolating the large power from all other states, reducing its options to negotiate and compelling it to concede unilaterally."
      },
      "correct_answer": "B",
      "source_article": "Multilateralism",
      "x": 1.2029783725738525,
      "y": 0.8837109208106995,
      "concepts_tested": [
        "Concept 1: Multilateralism as a governance mechanism that coordinates national policies among three or more states to discourage unilateral action and bind powerful actors.",
        "Concept 2: The Lilliputian strategy\u2014how small powers coalition-build in multilateral settings to influence larger powers and achieve shared objectives (including burden-sharing).",
        "Concept 3: Core theoretical principles (indivisibility and diffuse reciprocity) and the role of US or great-power context in shaping how multilateral arrangements function."
      ],
      "parent_concepts": [
        "Concept 3: WTO governance and decision-making structure (Ministerial Conference, General Council, Secretariat) and its impact on negotiation outcomes, legitimacy, and policy effectiveness (e.g., Doha Round dynamics, Appellate Body issues)."
      ],
      "parent_articles": [
        "World Trade Organization"
      ]
    },
    {
      "question": "Why does a shape with rotational symmetry imply that rotating the shape by a symmetry angle permutes its parts while leaving the whole unchanged, and how does this guarantee that any measurement that depends only on the unlabeled arrangement remains invariant under that rotation?",
      "options": {
        "A": "Because the rotation changes the shape in a way that makes all measurements depend on the new labeling of parts, so nothing stays the same.",
        "B": "Because the rotation maps the shape onto itself, permuting identical parts but preserving the overall arrangement, so any measurement defined without labeling a specific part remains unchanged.",
        "C": "Because rotating the shape inherently alters all pairwise distances, ensuring that only labeled features can remain constant under rotation.",
        "D": "Because symmetry requires a reflection rather than a rotation, so only reflective transformations can keep measurements invariant."
      },
      "correct_answer": "B",
      "source_article": "Symmetry",
      "x": 1.6611480712890625,
      "y": 1.193819522857666,
      "concepts_tested": [
        "Concept 1: Invariance under a transformation defines symmetry\u2014an object is symmetric if a transformation (e.g., reflection, rotation, translation) leaves its overall shape unchanged.",
        "Concept 2: Different symmetry types correspond to specific transformations (line/plane reflection, rotation, translation, glide reflection, rotoreflection, scale/helical symmetry), allowing classification by how parts relate under those transformations.",
        "Concept 3: Symmetry as a cross-domain principle\u2014present in mathematics, science/nature, and the arts, and even in abstract structures like logic\u2014indicating deep connections through invariance and balance."
      ],
      "parent_concepts": [
        "Concept 2: Relationship between symmetry and chirality: achirality occurs when the figure\u2019s symmetry group includes orientation-reversing isometries; presence of an axis of symmetry in 2D implies achirality.",
        "Concept 3: Real-world and mathematical manifestations of chirality (hands, helices, knots, tilings) as demonstrations of handedness and symmetry-based classification.",
        "Concept 1: A group action is a group homomorphism from G to the group of transformations of S, ensuring the action respects composition and captures the mechanism by which group elements act as symmetries."
      ],
      "parent_articles": [
        "Chirality",
        "Chirality",
        "Group action"
      ]
    },
    {
      "question": "Why does viewing rings, fields, and vector spaces as \"groups with additional operations and axioms\" provide a unifying framework for mathematics?",
      "options": {
        "A": "Because the group operation alone determines all properties of the structure, so extra operations add no new constraints.",
        "B": "Because the group operation captures the core combinatorial structure, and the extra operations encode how those elements interact with the group via compatibility conditions; this separation allows one to reuse group-theoretic methods (like homomorphisms and representation theory) to study more complex structures.",
        "C": "Because any property of rings and fields is independent of the underlying group structure, so the group viewpoint is irrelevant.",
        "D": "Because the underlying set must be finite for this viewpoint to be meaningful."
      },
      "correct_answer": "B",
      "source_article": "Group theory",
      "x": 1.671704888343811,
      "y": 1.2033798694610596,
      "concepts_tested": [
        "The idea that many mathematical structures can be viewed as groups with additional operations and axioms, providing a unifying framework.",
        "The role of symmetry groups and representation theory in connecting group theory to applications in physics, chemistry, and materials science.",
        "The Erlangen program as an organizing principle of geometry, linking geometric concepts to group actions."
      ],
      "parent_concepts": [
        "Concept 2: Relationship between symmetry and chirality: achirality occurs when the figure\u2019s symmetry group includes orientation-reversing isometries; presence of an axis of symmetry in 2D implies achirality.",
        "Concept 3: Real-world and mathematical manifestations of chirality (hands, helices, knots, tilings) as demonstrations of handedness and symmetry-based classification.",
        "Concept 1: A group action is a group homomorphism from G to the group of transformations of S, ensuring the action respects composition and captures the mechanism by which group elements act as symmetries."
      ],
      "parent_articles": [
        "Chirality",
        "Chirality",
        "Group action"
      ]
    },
    {
      "question": "Why does in vivo racemization of a chiral drug complicate safety assessment and regulatory testing?",
      "options": {
        "A": "Because the administered enantiomer can interconvert to the opposite enantiomer during metabolism, changing both efficacy and toxicity over time, so regulatory evaluation must characterize the interconversion kinetics and the activities of both enantiomers and the racemic mixture.",
        "B": "Because racemization alters the molecular weight of the drug, unpredictably changing its distribution and clearance.",
        "C": "Because racemization only occurs in test tubes, not in the body, so in vivo data are irrelevant to stereochemical safety considerations.",
        "D": "Because racemization creates diastereomers with entirely different receptor targets, requiring separate development for each diastereomer."
      },
      "correct_answer": "A",
      "source_article": "Stereochemistry",
      "x": 1.99049973487854,
      "y": 1.0425903797149658,
      "concepts_tested": [
        "Concept 1: Relationship between stereoisomers (enantiomers vs diastereomers, and epimers) and how their different spatial arrangements lead to distinct physical/chemical and biological properties.",
        "Concept 2: Dynamic stereochemistry and racemization, including how in vivo interconversion can affect drug safety and necessitate regulatory testing.",
        "Concept 3: Tools and conventions for describing stereochemistry (CIP priority rules and Fischer projections) that enable unambiguous communication of stereochemical configurations."
      ],
      "parent_concepts": [
        "Concept 2: The enantiodifferentiating step, i.e., the step at which the reaction could yield two enantiomeric products, determines selectivity through different transition-state energies and hence different rate constants."
      ],
      "parent_articles": [
        "Enantioselective synthesis"
      ]
    },
    {
      "question": "Why do ecologists argue that emergent ecosystem properties (such as resilience or nutrient cycling) cannot be predicted by examining individual species in isolation?",
      "options": {
        "A": "Because emergent properties arise from non-linear interactions, feedback loops, and the flow of energy and nutrients through the entire network; removing species or ignoring interactions disrupts these pathways and can change system-level behavior.",
        "B": "Because emergent properties are simply the arithmetic sum of each species' traits, which can be predicted by compiling all species data separately.",
        "C": "Because resilience depends only on the most productive species, and other species do not influence the overall system.",
        "D": "Because abiotic factors alone determine emergent properties, making biotic interactions irrelevant."
      },
      "correct_answer": "A",
      "source_article": "Ecology",
      "x": 1.6574903726577759,
      "y": 1.024176836013794,
      "concepts_tested": [
        "Emergent properties and the need to study ecosystems as integrated wholes rather than in isolation",
        "Energy and nutrient flux through ecosystems, including processes like primary production, nutrient cycling, and feedback mechanisms",
        "The role of biodiversity and species interactions (competition, predation, cooperation) in shaping ecosystem processes and ecosystem services"
      ],
      "parent_concepts": [
        "Concept 2: Environment-driven optimization of life history traits to maximize evolutionary fitness (timing of maturation, number of offspring, lifespan, parental investment).",
        "Concept 1: Sustainability through balancing human needs with natural systems and ecological limits (cause/effect: how different approaches aim to achieve a sustainable balance).",
        "Concept 1: Net growth rate and differential equation modeling (dN/dt = B \u2212 D = (b \u2212 d)N = rN) in a closed system; how births and deaths drive exponential growth or decline.",
        "Concept 2: Landscape heterogeneity as a driver of ecological outcomes \u2014 how variation and internal order within a landscape affect ecosystem functioning and biodiversity, and how heterogeneity is measured and interpreted.",
        "Concept 1: Integration of farming with natural biological cycles and efficient use of on-farm and nonrenewable resources to sustain agricultural viability and environmental quality.",
        "Concept 1: The economy as a subsystem of Earth's ecosystem and the primacy of natural capital (including strong vs. weak sustainability)."
      ],
      "parent_articles": [
        "Life history theory",
        "Environmentalism",
        "Population dynamics",
        "Landscape ecology",
        "Sustainable agriculture",
        "Ecological economics"
      ]
    },
    {
      "question": "Why does a persuasive argument that relies only on logos (appeal to reason) risk being less effective, even when its data and reasoning are solid?",
      "options": {
        "A": "Because logos claims are always misinterpreted, making the data unreliable regardless of its quality.",
        "B": "Because audiences often find storytelling and personal relevance more engaging than raw numbers, so logos alone may fail to capture attention.",
        "C": "Because audiences evaluate not only logic but also the speaker's credibility (ethos) and the message's emotional resonance or relevance to their values (pathos); logos alone can fail if ethos or pathos are weak.",
        "D": "Because data-driven arguments are universally compelling and will persuade any audience without considering delivery or context."
      },
      "correct_answer": "C",
      "source_article": "Rhetoric",
      "x": -0.12249501794576645,
      "y": 0.4737894833087921,
      "concepts_tested": [
        "The three persuasive appeals: logos, pathos, and ethos",
        "The five canons of rhetoric: invention, arrangement, style, memory, delivery",
        "The broader scope and interdisciplinary relationships of rhetoric (its application across domains and its connections to politics, ethics, logic, and culture)"
      ],
      "parent_concepts": [
        "Concept 2: The methods and reach of propaganda evolve with technology, from traditional media (paintings, posters, radio) to digital forms (social media, bots, computational propaganda).",
        "Distinct forms of persuasion (propaganda, coercion, systematic persuasion, heuristic persuasion) as different mechanisms with unique approaches"
      ],
      "parent_articles": [
        "Propaganda",
        "Persuasion"
      ]
    },
    {
      "question": "In a dataset, why does redundancy allow compression toward an optimal limit, and how does analyzing the compressed representation help turn data into usable knowledge?",
      "options": {
        "A": "Redundancy adds extra unique signals that must be kept; compression preserves all of this variability, and analysis then uses the preserved noise to infer broad knowledge.",
        "B": "Redundancy means parts of the data convey the same meaning, so compression removes these duplicates to reach a minimal representation that still preserves the essential patterns; analysis then detects the remaining structure to derive actionable knowledge.",
        "C": "The optimal compression limit is the maximum amount of data that can be stored without any loss, so compression always eliminates information; analysis is then needed to reconstruct the original dataset to form knowledge.",
        "D": "Redundancy makes data appear random; compression relies on increasing randomness, and analysis uses that randomness to identify surprising, novel facts."
      },
      "correct_answer": "B",
      "source_article": "Information",
      "x": 1.3529033660888672,
      "y": 1.0592825412750244,
      "concepts_tested": [
        "Concept 1: Information as meaning derived through interpretation; information is not the same as knowledge, and information processing is iterative (data \u2192 information \u2192 knowledge).",
        "Concept 2: The relationship between data, information, and knowledge, including how redundancy leads to compression toward an optimal limit and how analysis extracts usable knowledge.",
        "Concept 3: Encoding, transmission, and transformation of information across forms and channels (including encryption for safe storage/communication)."
      ],
      "parent_concepts": [
        "Concept 1: Data processing comprises a sequence of core functions (validation, sorting, summarization, aggregation, analysis, reporting, classification) that transform raw data into meaningful information.",
        "Concept 1: Printing as a mass-reproduction technology that enables widespread dissemination of text and images, influencing learning and literacy."
      ],
      "parent_articles": [
        "Data processing",
        "Printing"
      ]
    },
    {
      "question": "Why does the language L = { a^n b^n | n \u2265 0 } illustrate a crucial principle that separates regular from context-free languages in the Chomsky hierarchy, and how does its recognition differ from what a finite automaton can do?",
      "options": {
        "A": "A finite automaton has only bounded memory in its states and cannot enforce that the number of a\u2019s equals the number of b\u2019s across arbitrary n; a pushdown automaton uses a stack to push for each a and pop for each b, thus enforcing equality.",
        "B": "The language is regular, and a finite automaton can recognize it by maintaining a simple finite set of equivalence classes for all n.",
        "C": "Recognizing the language requires a Turing machine because it involves unbounded computation beyond context-free capabilities.",
        "D": "A nondeterministic finite automaton can backtrack across the input to ensure equal counts, which is why regular machines suffice for this language."
      },
      "correct_answer": "A",
      "source_article": "Automata theory",
      "x": 1.529194951057434,
      "y": 1.169921875,
      "concepts_tested": [
        "Concept 1: Transition mechanism \u2014 an automaton changes state based on the current state and input symbol via a transition function.",
        "Concept 2: Automata as representations of formal languages \u2014 finite automata recognize formal languages, linking machine models to language theory.",
        "Concept 3: Chomsky hierarchy as a framework \u2014 different classes of automata correspond to nested classes of languages, organizing their expressive power and capabilities."
      ],
      "parent_concepts": [
        "Concept 1: A formal language is defined by an alphabet and a formal grammar, shaping the set of allowable strings (syntactic structure)."
      ],
      "parent_articles": [
        "Formal language"
      ]
    },
    {
      "question": "Why does an iterative design process\u2014cycling through research, modeling, feedback, and redesign\u2014tend to produce designs that better balance diverse goals, constraints, and stakeholder needs compared with a single-pass approach?",
      "options": {
        "A": "Because each iteration reduces the total number of constraints, making decisions easier.",
        "B": "Because iteration provides opportunities to learn from real feedback, adjust trade-offs, and progressively align the design with user needs and context.",
        "C": "Because multiple iterations ensure every feature is implemented in full from the start, guaranteeing completeness.",
        "D": "Because iterative processes eliminate the need for stakeholder input, allowing designers to work faster."
      },
      "correct_answer": "B",
      "source_article": "Design",
      "x": 1.3920336961746216,
      "y": 1.058274269104004,
      "concepts_tested": [
        "Concept 1: Design is purposeful and contextual, balancing goals and constraints while considering aesthetic, functional, and experiential aspects.",
        "Concept 2: The design process is iterative, involving activities such as research, negotiation, reflection, modeling, and redesign.",
        "Concept 3: Design is a universal cognitive activity; everyone designs, indicating design ability is inherent and not exclusive to professional designers."
      ],
      "parent_concepts": [
        "Concept 1"
      ],
      "parent_articles": [
        "Graphic design"
      ]
    },
    {
      "question": "Why does the condition N*N = NN* (normality) enable the spectral theorem to represent N as a multiplication operator on some L^2 space?",
      "options": {
        "A": "Because normal operators are always diagonalizable by a unitary with a finite eigenbasis.",
        "B": "Because normality ensures the spectral projections associated with N commute with N, enabling a spectral measure and functional calculus that realize N as multiplication by a function on a direct integral of Hilbert spaces.",
        "C": "Because any operator can be approximated in operator norm by diagonal operators, and normality guarantees convergence to a diagonal model.",
        "D": "Because the spectrum of a normal operator consists only of eigenvalues, so N can be diagonalized by a unitary."
      },
      "correct_answer": "B",
      "source_article": "Operator theory",
      "x": 1.6672258377075195,
      "y": 1.1840465068817139,
      "concepts_tested": [
        "Spectral theorem: conditions under which an operator can be diagonalized or represented by multiplication operators; connection to commutative C*-algebras and spectral decomposition.",
        "Normal operators: definition via commutation with the adjoint (NN* = N*N) and their central role because the spectral theorem applies to them.",
        "Representation and dimensionality: how diagonalization and spectral decomposition differ between finite-dimensional spaces and infinite-dimensional Hilbert spaces, including the idea of modeling operators via multiplication."
      ],
      "parent_concepts": [
        "Concept 2: The spectral theorem and the role of analytic functions/functional calculus in understanding spectra, including generalized eigenfunctions and rigged Hilbert spaces."
      ],
      "parent_articles": [
        "Spectral theory"
      ]
    },
    {
      "question": "Why does liberal democracy rely on a constitutional framework and an independent judiciary to balance majority rule with minority rights?",
      "options": {
        "A": "Because it constrains majority decisions by requiring that laws respect fundamental rights and allows judges to review and invalidate legislation that violates those rights.",
        "B": "Because it ensures the majority can directly override minority protections whenever it wants.",
        "C": "Because it removes popular input by placing lawmaking solely in the hands of judges.",
        "D": "Because it eliminates the need for elections by giving permanent power to constitutional courts."
      },
      "correct_answer": "A",
      "source_article": "Democracy",
      "x": 1.151394009590149,
      "y": 0.86588054895401,
      "concepts_tested": [
        "Concept 1: Liberal democracy balances majority rule with minority rights through a constitutional framework and an independent judiciary.",
        "Concept 2: Direct democracy vs. representative democracy as distinct mechanisms for citizen participation and power delegation.",
        "Concept 3: The relationship between democracy and legitimacy/outcomes (e.g., health, education, economic outcomes) and the role of public opinion in sustaining democratic systems."
      ],
      "parent_concepts": [
        "Concept 2: Mechanisms to enable deliberation (random selection of lay citizens, resource/time allocation, deliberative polls, and the interplay of consensus vs. majority rule)",
        "How votes are translated into seats and how this translation affects proportionality and representation (mechanism and its outcomes)",
        "Accountability mechanism: how citizens judge representatives and sanction them if they do not act in the represented's interests."
      ],
      "parent_articles": [
        "Deliberative democracy",
        "Electoral system",
        "Political representation"
      ]
    },
    {
      "question": "How does emphasizing the development of general reasoning and critical-thinking abilities change the instructional role of a teacher compared with emphasizing the transmission of true beliefs?",
      "options": {
        "A": "It makes the teacher a facilitator who helps students assess evidence, identify bias, and revise beliefs, rather than a conveyor of pre-selected truths.",
        "B": "It makes the teacher a gatekeeper who must ensure students memorize an authoritative set of beliefs before considering evidence.",
        "C": "It leads teachers to avoid presenting controversial issues to prevent student confusion.",
        "D": "It requires teachers to prioritize memorization of canonical facts because reasoning cannot be taught."
      },
      "correct_answer": "A",
      "source_article": "Philosophy of education",
      "x": 1.1711238622665405,
      "y": 1.0344513654708862,
      "concepts_tested": [
        "Descriptive vs normative theories of education and how they influence educational practice",
        "Epistemic aims of education: transmission of true beliefs versus development of reasoning/critical thinking",
        "Education and power/equality: how schooling relates to state authority, discrimination, and wealth distribution"
      ],
      "parent_concepts": [
        "The relationship between pedagogy, learning, and learner development within social/political/cultural contexts (how pedagogy influences and is influenced by development).",
        "Curriculum theory as symbolic representation (Pinar) and how viewing curriculum as representation changes analysis and policy implications.",
        "The historical\u2013policy linkage in CT (e.g., Yale Report promoting rote memorization and faculty psychology committees shaping curriculum policy) and how historical interpretations influence current theory and practice."
      ],
      "parent_articles": [
        "Pedagogy",
        "Curriculum theory",
        "Curriculum theory"
      ]
    },
    {
      "question": "In the axiomatic method, theorems are produced by applying a fixed set of inference rules to axioms and previously proven theorems. Why does this design ensure that every proved statement is a logical consequence of the original axioms, provided the inference rules are sound?",
      "options": {
        "A": "Because each inference rule is truth-preserving, so a conclusion from premises that are themselves derived from axioms remains a consequence of those axioms.",
        "B": "Because the axioms themselves guarantee all possible truths, so any derived statement must be true.",
        "C": "Because inference rules randomly generate statements, but the axioms bias them toward the desired theorems.",
        "D": "Because adding any new axiom cannot affect the truth of previously proved theorems."
      },
      "correct_answer": "A",
      "source_article": "Foundations of mathematics",
      "x": 1.6159322261810303,
      "y": 1.1730355024337769,
      "concepts_tested": [
        "Concept 1: The axiomatic method and inference rules as the basis for deriving theorems and ensuring consistency, including the role of axioms/postulates and proofs.",
        "Concept 2: The foundational crisis and its resolution through mathematical logic (set theory, model theory, proof theory, computability) and the rise of formal frameworks (e.g., Zermelo\u2013Fraenkel set theory with AC; type theory).",
        "Concept 3: The relationship between mathematics and physical reality\u2014axioms are chosen based on intuition guided by reality but mathematical truth is internal to the axiomatic framework, with reality guiding intuition rather than defining mathematics."
      ],
      "parent_concepts": [
        "Concept 2: Foundational crisis and mechanisms to address it\u2014paradoxes and inconsistencies leading to alternative logical frameworks (constructive mathematics, intuitionistic logic, higher-order logics).",
        "Concept 1: Constructivism requires explicit construction to prove existence; this reframes the existential quantifier away from non-constructive proofs.",
        "Concept 2: The landscape of constructivist programs (intuitionism, finitism, recursive mathematics, Bishop) and their differing philosophical commitments (e.g., intuitionism\u2019s emphasis on human intuition vs objective viewpoints)."
      ],
      "parent_articles": [
        "Philosophy of mathematics",
        "Constructivism (philosophy of mathematics)",
        "Constructivism (philosophy of mathematics)"
      ]
    },
    {
      "question": "Why does a socio-technical systems lens in information science require analyzing interactions among people, processes, and technology rather than optimizing the technology in isolation when addressing a systemic problem?",
      "options": {
        "A": "Because the system's behavior emerges from ongoing interactions among social and technical components, and optimizing one part can shift pressures to others through feedback loops, creating new problems.",
        "B": "Because the technology is the sole driver of system performance, and human factors are only secondary considerations.",
        "C": "Because organizational policies are fixed and cannot adapt to new technologies, so focusing on policy is enough.",
        "D": "Because only technical performance metrics matter for system success, making other dimensions irrelevant."
      },
      "correct_answer": "A",
      "source_article": "Information science",
      "x": 1.2584470510482788,
      "y": 1.0063034296035767,
      "concepts_tested": [
        "Concept 1: Socio-technical systems perspective\u2014addressing systemic problems by considering the interactions between people, organizations, and information systems.",
        "Concept 2: Stakeholder-centric problem framing\u2014understanding problems from the perspective of involved stakeholders and applying information technologies accordingly.",
        "Concept 3: Transdisciplinary foundations\u2014integration across technical, organizational, and human dimensions to bridge different domains."
      ],
      "parent_concepts": [
        "Iterative query refinement: the feedback loop where user results influence subsequent querying to improve results.",
        "Concept 3: Relationships and context, including historical roots in diplomatics/archaeography and the field\u2019s evolution with digital technology, shaping how archival science relates to other institutions and practices."
      ],
      "parent_articles": [
        "Information retrieval",
        "Archival science"
      ]
    },
    {
      "question": "Why does consensus-based standardization tend to improve interoperability and reduce coordination problems across products from different firms and users?",
      "options": {
        "A": "It centralizes control in a single firm, making all decisions for the interface.",
        "B": "It aligns the interface specifications with the incentives and constraints of multiple stakeholders, increasing broad adoption and consistent interfaces.",
        "C": "It imposes random feature choices to maximize diversity, which accidentally improves compatibility.",
        "D": "It relies on voluntary ignore of previous standards, forcing each party to adapt independently."
      },
      "correct_answer": "B",
      "source_article": "Standardization",
      "x": 1.4860215187072754,
      "y": 0.9902338981628418,
      "concepts_tested": [
        "Concept 1: Consensus-based development of standards among firms, users, and governments as the mechanism by which standardization emerges.",
        "Concept 2: Standardization improves interoperability, compatibility, safety, repeatability, efficiency, and quality, illustrating cause-effect relationships.",
        "Concept 3: Standardization as a solution to coordination problems in economics/social sciences and its impact on reducing non-tariff trade barriers."
      ],
      "parent_concepts": [
        "Concept 3: Governance and definitional variability across organizations and governments, shaping what counts as an \"open standard\" and how standards are adopted globally."
      ],
      "parent_articles": [
        "Open standard"
      ]
    },
    {
      "question": "Why does interdisciplinary synthesis between sciences and humanities enable better understanding and addressing of environmental problems?",
      "options": {
        "A": "It eliminates empirical data and relies only on subjective interpretations.",
        "B": "It integrates quantitative evidence with normative and cultural analysis, revealing how data interacts with values, politics, and meaning to produce more comprehensive problem framing and actionable options.",
        "C": "It enforces a single disciplinary method to avoid contradictory results.",
        "D": "It slows progress by adding perspectives that do not contribute to practical outcomes."
      },
      "correct_answer": "B",
      "source_article": "Environmental humanities",
      "x": 1.2069216966629028,
      "y": 0.9491740465164185,
      "concepts_tested": [
        "Interdisciplinary synthesis: bridging sciences and humanities to generate new ways of thinking about environmental problems.",
        "Rejection of the nature\u2013culture divide: environmental issues are entangled with justice, labor, politics, and human meaning.",
        "Plural epistemologies and inclusivity: incorporating Western, Eastern, and Indigenous perspectives to reshape understanding of the environment."
      ],
      "parent_concepts": [
        "Concept 2: Ecocriticism employs interdisciplinary methodologies by borrowing theories and methods from ecology, environmental history, biopolitics, etc., to analyze texts in their environmental contexts."
      ],
      "parent_articles": [
        "Ecocriticism"
      ]
    },
    {
      "question": "In environmental ethics, how does attributing intrinsic value to the environment fundamentally differ from attributing only instrumental value, in terms of the type of obligation it generates?",
      "options": {
        "A": "It assigns moral status to the environment itself, generating duties that apply regardless of any human benefits (a deontological justification).",
        "B": "It frames obligations as policies to maximize aggregate human happiness, thus focusing on outcomes.",
        "C": "It ties obligations exclusively to the environment\u2019s usefulness for humans, making duties conditional on utility.",
        "D": "It grounds duties in economic valuations of ecosystem services to determine which actions are permissible."
      },
      "correct_answer": "A",
      "source_article": "Environmental philosophy",
      "x": 1.315144658088684,
      "y": 0.9235846400260925,
      "concepts_tested": [
        "Intrinsic vs. instrumental value of the environment and how this distinction grounds environmental ethics",
        "Rights of nature and moral status of non-human entities (e.g., rivers, ecosystems) and associated ethical considerations",
        "The relationship between humans, technology, and the natural world, and how ethical theories translate into responses to environmental challenges (climate change, conservation, restoration, policy)"
      ],
      "parent_concepts": [
        "Concept 2: Ecocriticism employs interdisciplinary methodologies by borrowing theories and methods from ecology, environmental history, biopolitics, etc., to analyze texts in their environmental contexts."
      ],
      "parent_articles": [
        "Ecocriticism"
      ]
    },
    {
      "question": "How does adopting a relationship orientation in marketing enable a firm to capture value from customers over time?",
      "options": {
        "A": "By maximizing short-term market share through aggressive price cuts and one-time promotions.",
        "B": "By increasing customer lifetime value through repeat purchases, cross-selling, and referrals, which create long-term revenue streams.",
        "C": "By prioritizing product features over customer needs and reducing ongoing engagement with customers.",
        "D": "By relying solely on mass advertising to attract new customers without focusing on retention."
      },
      "correct_answer": "B",
      "source_article": "Marketing",
      "x": 1.3638266324996948,
      "y": 0.9844871163368225,
      "concepts_tested": [
        "Concept 1: Marketing as a value-creating exchange process (creating, delivering, communicating, and exchanging offerings that have value for customers, clients, partners, and society)",
        "Concept 2: Relationship orientation in marketing (focus on building strong customer relationships and customer value to capture value from customers)",
        "Concept 3: Market orientation and the integrated marketing mix (how environment, research, and target market shape decisions about product, price, place, and promotion, including channels)"
      ],
      "parent_concepts": [
        "The role of market understanding (customer needs/wants, competitive environment, market nature) in driving NPD decisions",
        "Concept 3: Brand audits function as a diagnostic process that connects brand positioning, internal capabilities, and external market factors to strategic improvements and resource allocation.",
        "Concept 2: The micro-environment focus on customers, partners, and competitors, and the emphasis on the customer market as central to marketing decisions."
      ],
      "parent_articles": [
        "New product development",
        "Marketing management",
        "Market environment"
      ]
    },
    {
      "question": "Why does a market-research approach that combines qualitative primary research (like in-depth interviews) with quantitative secondary data (like industry statistics) tend to produce more reliable decision guidance than using only one data source?",
      "options": {
        "A": "It reduces the total number of data points needed, since secondary data covers everything.",
        "B": "It leverages the depth of qualitative insights to interpret broad quantitative patterns, while secondary data provides context and benchmarks, enabling cross-validation and less biased conclusions.",
        "C": "It guarantees that the sample represents the entire market.",
        "D": "It ensures that findings are purely objective and free of interpretation."
      },
      "correct_answer": "B",
      "source_article": "Market research",
      "x": 1.347917079925537,
      "y": 0.982230007648468,
      "concepts_tested": [
        "Concept 1: Market research is a systematic, organized process to gather and interpret information about target markets and customers to support decision making and maintain competitiveness.",
        "Concept 2: It employs a mix of qualitative and quantitative methods (primary research) and also uses secondary data, with distinctions between qualitative vs. quantitative and primary vs. secondary research.",
        "Concept 3: Market research and marketing research are related but distinct fields (markets and distribution vs. marketing processes), and confusion between them highlights conceptual boundaries relevant to business strategy."
      ],
      "parent_concepts": [
        "The role of market understanding (customer needs/wants, competitive environment, market nature) in driving NPD decisions"
      ],
      "parent_articles": [
        "New product development"
      ]
    },
    {
      "question": "Which explanation best captures how the implicit (hidden) curriculum influences learning outcomes beyond what is explicitly taught?",
      "options": {
        "A": "It adds extra factual content not covered in the explicit curriculum.",
        "B": "It conveys unspoken norms, attitudes, and expectations that shape students' motivation, engagement, and interpretation of feedback.",
        "C": "It replaces the formal curriculum when teachers decide to improvise.",
        "D": "It ensures standardized assessment results across classrooms."
      },
      "correct_answer": "B",
      "source_article": "Curriculum",
      "x": 1.2432337999343872,
      "y": 0.9785981178283691,
      "concepts_tested": [
        "Explicit vs implicit (hidden) curriculum: how non-taught aspects of the school environment and culture influence learning outcomes alongside the formal curriculum.",
        "Curriculum as the total student experience: how planned content, instructional materials, processes, and assessment collectively align with and realize educational objectives.",
        "Standardization vs autonomy in curriculum design: how centralized/national curricula vs. teacher/learner autonomy affect implementation, innovation, and student experiences."
      ],
      "parent_concepts": [
        "Curriculum theory as symbolic representation (Pinar) and how viewing curriculum as representation changes analysis and policy implications."
      ],
      "parent_articles": [
        "Curriculum theory"
      ]
    },
    {
      "question": "How does a governance structure that distributes authority across local, state, and federal levels shape the translation of education policy into classroom practice, and why does this often produce variation across districts?",
      "options": {
        "A": "Because federal standards uniformly dictate practice, removing local variation.",
        "B": "Because local actors interpret and implement policy within local constraints, leading to variation due to differences in resources, capacities, and priorities.",
        "C": "Because state mandates force identical practices in all districts regardless of local context.",
        "D": "Because market competition among schools eliminates the influence of governance levels on practice."
      },
      "correct_answer": "B",
      "source_article": "Education policy",
      "x": 1.1997034549713135,
      "y": 0.8728588223457336,
      "concepts_tested": [
        "Concept 1: Policy decisions and governance influence educational goals, practices, and outcomes; there are cause-and-effect relationships between policy choices and societal or personal objectives.",
        "Concept 2: Governance structure (local, state, federal) shapes how education policy is developed and implemented, leading to variation across contexts.",
        "Concept 3: Education policy analysis as an interdisciplinary framework (sociology, economics, political science, law, etc.) for asking about purpose, objectives, methods, and measurement of success; provides conceptual tools to assess policy impact."
      ],
      "parent_concepts": [
        "The historical\u2013policy linkage in CT (e.g., Yale Report promoting rote memorization and faculty psychology committees shaping curriculum policy) and how historical interpretations influence current theory and practice."
      ],
      "parent_articles": [
        "Curriculum theory"
      ]
    },
    {
      "question": "In a governance system where decision-making authority is distributed to local units to encourage localized governance, which mechanism best explains how this decentralization can, over time, become or reinforce centralization instead of sustaining local autonomy?",
      "options": {
        "A": "Local units' uniform preferences align with central goals, making central oversight redundant.",
        "B": "Local capacity and coordination constraints create information gaps, prompting central authorities to standardize, allocate resources, and supervise, which concentrates power upward and can produce a self-reinforcing centralization.",
        "C": "Decentralization automatically ensures that all local actors maintain veto power over nationwide policy, preventing any central action.",
        "D": "Local units independently optimize, resulting in complete independence from the center, which eliminates any centralization pressures."
      },
      "correct_answer": "B",
      "source_article": "Decentralization",
      "x": 1.3174974918365479,
      "y": 1.0066967010498047,
      "concepts_tested": [
        "Concept 1: Distribution of planning/decision-making authority to local units as a mechanism for localized governance and participation",
        "Concept 2: Decentralization\u2019s relationship to liberty and civic engagement (how it increases opportunities for citizens to participate in public affairs and acts as a counterweight to central power)",
        "Concept 3: The dynamic tension between decentralization and centralization (how decentralization can empower local actors yet, in practice, may evolve into or reinforce centralization)"
      ],
      "parent_concepts": [
        "Concept 1: Localized decision-making with centralized intervention only when local capability is insufficient; the principle that tasks should be handled at the most immediate level capable of resolving them."
      ],
      "parent_articles": [
        "Subsidiarity"
      ]
    },
    {
      "question": "In a federal system, how does the constitutional allocation of competences between central and regional governments enable both subnational autonomy and national unity?",
      "options": {
        "A": "By centralizing almost all policy powers at the center to create a uniform national policy.",
        "B": "By dividing policy domains so each level governs within its own sphere while the union still coordinates overarching matters, allowing local experimentation and national coherence.",
        "C": "By giving regional governments the authority to unilaterally override central laws whenever they prefer.",
        "D": "By abolishing regional authorities once a nationwide agreement is reached on any issue."
      },
      "correct_answer": "B",
      "source_article": "Federalism",
      "x": 1.1625384092330933,
      "y": 0.7542626857757568,
      "concepts_tested": [
        "Concept 1: Division of powers between central/federal and regional governments as the core mechanism and principle of federalism.",
        "Concept 2: Federalism as a middle-ground relationship on a spectrum between regional separation and regional integration, distinguishing it from confederalism and unitary states.",
        "Concept 3: The multi-level governance relationship: how constitutional allocation of competences enables autonomy at sub-national levels while maintaining a unified system."
      ],
      "parent_concepts": [
        "Concept 1: Localized decision-making with centralized intervention only when local capability is insufficient; the principle that tasks should be handled at the most immediate level capable of resolving them."
      ],
      "parent_articles": [
        "Subsidiarity"
      ]
    },
    {
      "question": "Why do intellectual property rights (IPR) function as an enabling governance mechanism in technology transfer, shaping incentives, dissemination, and commercialization?",
      "options": {
        "A": "IPR guarantees universal open access, which eliminates the need for collaboration or licensing.",
        "B": "IPR reduces uncertainty about ownership and potential returns, enabling creators and licensees or start-ups to invest in development and structured dissemination through licenses and collaborations.",
        "C": "IPR ensures that the owning institution can completely control all uses in perpetuity without considering societal impact.",
        "D": "IPR automatically leads to immediate dissemination to the public domain, removing all exclusivity."
      },
      "correct_answer": "B",
      "source_article": "Technology transfer",
      "x": 1.2925472259521484,
      "y": 0.9716598391532898,
      "concepts_tested": [
        "Concept 1: Intellectual property as an enabler and governance mechanism that shapes incentives, dissemination, and commercialization in technology transfer.",
        "Concept 2: The technology transfer process as a collaborative, non-linear sequence of activities (knowledge creation, disclosure, IP protection, fundraising, marketing, commercialization, product development) that transforms research into products.",
        "Concept 3: The network of stakeholders and cross-sector cross-border collaboration (universities, businesses, governments) aimed at connecting innovators with users to achieve societal impact."
      ],
      "parent_concepts": [
        "Concept 1: The video game industry as a driver of hardware and technological innovation (games influencing sound cards, graphics cards, CPUs, etc., and technology transfer to broader markets).",
        "application relationship: life-science discoveries contribute to health, agriculture, medicine, and pharmaceutical/food industries, showing the link between basic disciplines and real-world outcomes."
      ],
      "parent_articles": [
        "Video game industry",
        "List of life sciences"
      ]
    },
    {
      "question": "Why is integrating hardware, software, and peripheral components in an IT system crucial for effective information management and organizational processes?",
      "options": {
        "A": "Because integration focuses on maximizing the performance of the most expensive component.",
        "B": "Because integration enables end-to-end information flow, coordinated processing, and alignment of technology with business workflows.",
        "C": "Because integration guarantees that every user will have identical hardware.",
        "D": "Because integration allows avoiding changes to business processes."
      },
      "correct_answer": "B",
      "source_article": "Information technology",
      "x": 1.4089142084121704,
      "y": 1.0901952981948853,
      "concepts_tested": [
        "IT systems are integrated hardware, software, and peripheral components that support information management and organizational processes.",
        "The development of IT proceeds through distinct phases (pre-mechanical, mechanical, electromechanical, electronic) driven by advances in storage and processing technologies, illustrating cause-and-effect in technological progress.",
        "Successful IT projects require careful planning and ongoing maintenance to ensure alignment with organizational objectives."
      ],
      "parent_concepts": [
        "Concept 1: The video game industry as a driver of hardware and technological innovation (games influencing sound cards, graphics cards, CPUs, etc., and technology transfer to broader markets)."
      ],
      "parent_articles": [
        "Video game industry"
      ]
    },
    {
      "question": "Why does maintaining provenance and a documented chain of custody for archival records matter for both authenticity and usability, and how do archivists operationalize this?",
      "options": {
        "A": "It creates a traceable origin and context, enabling evaluators to assess reliability and detect alterations; by recording acquisition, custody events, and metadata, archivists provide verifiable evidence of authenticity and structured pathways for users to access relevant materials.",
        "B": "It is sufficient to store records in climate-controlled facilities; provenance and custody details are optional because physical storage guarantees authenticity.",
        "C": "Usability comes from decontextualizing records; provenance only hinders access because it adds extra metadata to sift through.",
        "D": "Authenticity can be assumed from the file format alone; chain-of-custody is unnecessary once digital copies exist."
      },
      "correct_answer": "A",
      "source_article": "Archival science",
      "x": 1.2721725702285767,
      "y": 0.9310458898544312,
      "concepts_tested": [
        "Authenticity and trustworthiness of archival records: why records must be what they claim to be and how archivists ensure reliability, integrity, and usability.",
        "The archival workflow as a mechanism: how appraisal, storage/preservation, and processing (arranging and describing) interact to preserve materials and enable access.",
        "The impact of digital technology on archival science: how the advent of digital documents and databases prompts re-evaluation of methods and the relationship between traditional practices and digital curation."
      ],
      "parent_concepts": [
        "Concept 2: Migration and media/format considerations are central mechanisms by which preservation is achieved, given varying lifespans and obsolescence of hardware and formats (e.g., SSDs, LTO tapes, archival discs, M-DISC), highlighting cause-and-effect between technology evolution and preservation actions."
      ],
      "parent_articles": [
        "Digital preservation"
      ]
    },
    {
      "question": "Why does records management distinguish records from ordinary documents based on their transactional/contextual nature?",
      "options": {
        "A": "Because records are consciously retained as evidence of actions and their context, whereas many documents are informational or transient and do not document a traceable activity for accountability or governance.",
        "B": "Because any document related to a transaction automatically becomes a record and must be kept forever.",
        "C": "Because records must always be digital to preserve evidential value, while ordinary documents can be in any format.",
        "D": "Because records are defined solely by legal requirements, regardless of context or purpose."
      },
      "correct_answer": "A",
      "source_article": "Records management",
      "x": 1.3803975582122803,
      "y": 0.9895872473716736,
      "concepts_tested": [
        "Records as evidence that supports accountability and governance",
        "The transactional/contextual nature of records: not all documents are records; records are persistent representations of activities requiring conscious retention",
        "Life-cycle management and control mechanisms: creation/receipt, classification, storage, retrieval, tracking, and disposition to manage risk and compliance"
      ],
      "parent_concepts": [
        "Concept 2: Migration and media/format considerations are central mechanisms by which preservation is achieved, given varying lifespans and obsolescence of hardware and formats (e.g., SSDs, LTO tapes, archival discs, M-DISC), highlighting cause-and-effect between technology evolution and preservation actions."
      ],
      "parent_articles": [
        "Digital preservation"
      ]
    },
    {
      "question": "Why does employing a faceted classification approach, supported by information technology, better serve diverse user groups and their search tasks than a single hierarchical taxonomy?",
      "options": {
        "A": "It restricts search paths to a predefined order, reducing cognitive load but limiting flexibility.",
        "B": "It provides multiple independent facets that users can combine to reflect their different tasks and contexts, and modern IT supports dynamic filtering, cross-domain search, and relevance ranking across facets.",
        "C": "It eliminates the need for metadata and allows keyword-only search to retrieve precise results.",
        "D": "It guarantees identical navigation experiences for all users because facets standardize the structure."
      },
      "correct_answer": "B",
      "source_article": "Library and information science",
      "x": 1.1367442607879639,
      "y": 0.9321359992027283,
      "concepts_tested": [
        "Concept 1: The relationship and overlap between library science and information science and how this relationship influences professional practice.",
        "Concept 2: The mechanism by which information resources are organized and classified to serve diverse user groups, including the interaction with classification systems and technology.",
        "Concept 3: The ethical, legal, and political economy considerations that govern library and information services and their impact on practice."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does the designation of something as \"heritage\" emerge as a selective social process, and how does that selectivity influence preservation decisions?",
      "options": {
        "A": "Because societies preserve all past legacies equally, with designation driven solely by technical preservation feasibility.",
        "B": "Because value judgments, power relations, and evolving group identities shape what is recognized as heritage, and these choices determine which sites, artifacts, or practices receive protection, funding, and visibility.",
        "C": "Because international law dictates a fixed list of heritage items, so preservation decisions follow that predetermined catalog.",
        "D": "Because preservation is a purely utilitarian choice based only on potential tourism revenue, independent of cultural significance."
      },
      "correct_answer": "B",
      "source_article": "Cultural heritage",
      "x": 0.9795193672180176,
      "y": 0.4106416404247284,
      "concepts_tested": [
        "Concept 1: Heritage as a selective social construct \u2014 not all past legacies are heritage; society selects what to preserve or recognize as heritage.",
        "Concept 2: Typology of heritage and its implications \u2014 tangible, intangible, and natural heritage require different preservation approaches and disciplines.",
        "Concept 3: Preservation/conservation as an active, governance-related process \u2014 involving laws, international agreements, institutions, and the link to economic value and tourism, illustrating cause-effect relationships between protection and societal outcomes."
      ],
      "parent_concepts": [
        "Concept 3: Relationships and context, including historical roots in diplomatics/archaeography and the field\u2019s evolution with digital technology, shaping how archival science relates to other institutions and practices."
      ],
      "parent_articles": [
        "Archival science"
      ]
    },
    {
      "question": "Why does constructing a mathematical or computational model of a biological system help reveal the governing principles of that system, and how does it enable prediction under new conditions?",
      "options": {
        "A": "It increases data complexity so that previously hidden patterns can be memorized and used as rules.",
        "B": "It replaces experiments by perfectly capturing all real-world variability, so no data collection is needed.",
        "C": "It requires making explicit, testable assumptions about components and interactions, so one can analyze how changes in the structure or parameters propagate to outcomes, thereby identifying which elements govern behavior and enabling predictions in untested scenarios.",
        "D": "It ensures exact replication of observed data, proving that the model is a perfect representation."
      },
      "correct_answer": "C",
      "source_article": "Mathematical and theoretical biology",
      "x": 1.6924428939819336,
      "y": 1.1256657838821411,
      "concepts_tested": [
        "Concept 1: Modeling as a tool to reveal governing principles of biological systems and to enable prediction through quantitative representations.",
        "Concept 2: The relationship and distinction between theoretical biology and mathematical biology (principles-focused vs. tools-focused) and their overlap.",
        "Concept 3: The role of mathematics in biology driven by system complexity, including the development of new techniques and cross-disciplinary insights."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "How does the notion that a differential equation encodes a rate of change of a quantity enable qualitative understanding of its long-term behavior even when an explicit solution is unavailable?",
      "options": {
        "A": "By guaranteeing that you can always obtain an explicit closed-form solution that reveals the long-term behavior.",
        "B": "By enabling analysis of the vector field in state space, focusing on trajectories, fixed points, and their stability to infer possible asymptotic behavior without needing an explicit formula.",
        "C": "By showing that the rate-of-change information is irrelevant to long-term behavior, which can be deduced from initial values alone.",
        "D": "By ensuring that numerical time stepping will always converge to the exact solution, so long-term behavior is directly computable."
      },
      "correct_answer": "B",
      "source_article": "Differential equation",
      "x": 1.7240636348724365,
      "y": 1.143460750579834,
      "concepts_tested": [
        "Concept 1: A differential equation encodes a relationship between an unknown function and its derivatives, representing how a quantity changes with respect to another variable.",
        "Concept 2: The study centers on the solutions and properties of those solutions, including the idea that not all equations have closed-form solutions.",
        "Concept 3: When explicit solutions are unavailable, numerical methods and dynamical-systems analysis provide alternative ways to understand and approximate the behavior of the system over time."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Which explanation best captures how the drivers of ADR\u2014lower costs, faster resolution, confidentiality, and control over the decision-maker\u2014shape the choice between ADR and traditional litigation?",
      "options": {
        "A": "They primarily increase the probability that courts will enforce a ruling, thus ADR is favored only when enforcement is unlikely.",
        "B": "They shift the expected payoff toward ADR by lowering costs and time, preserving confidentiality, and letting parties influence the decision-maker, so ADR is preferred when speed, privacy, and control matter.",
        "C": "They guarantee a faster outcome than litigation in all cases, making ADR always preferable.",
        "D": "Confidentiality is the only driver; the other factors do not affect dispute-resolution choices."
      },
      "correct_answer": "B",
      "source_article": "Alternative dispute resolution",
      "x": 1.2457666397094727,
      "y": 0.831534206867218,
      "concepts_tested": [
        "Concept 1: Why ADR is adopted and sustained (drivers such as reduced costs, faster resolution, confidentiality, and parties\u2019 control over decision-makers) and how these factors influence dispute-resolution choices.",
        "Concept 2: How ADR interacts with the court system (compulsory/ordered ADR, NCDR vs ADR, and judicial decisions like Halsey v Milton Keynes Trust and Churchill v Merthyr) and how legal frameworks shape ADR use.",
        "Concept 3: How the design of ADR has evolved (from traditional guild-arbitrated disputes to market-based arbitrators) and the trade-offs between accessibility and community involvement."
      ],
      "parent_concepts": [
        "Concept 3: Mediation vs. arbitration as forms of negotiation with third parties, and how these forms shape negotiation dynamics and outcomes."
      ],
      "parent_articles": [
        "Negotiation"
      ]
    },
    {
      "question": "Why does treating secularization as a single, universal decline in religious authority misrepresent how religion changes in modern societies, and how do multiple indicators (belief, belonging, practice) illustrate the complexity?",
      "options": {
        "A": "Modernization can differentiate secular and religious domains and privatize religion, reducing its public authority, while belief, belonging, and practice may diverge due to private piety, cultural affiliation, or ritual continuity; thus multiple indicators reveal non-universal trajectories.",
        "B": "Belief, belonging, and practice always decline together in all contexts, so measuring more indicators would be redundant.",
        "C": "Secularization concerns governance only; private life is unaffected and belief measures are irrelevant.",
        "D": "The universal trajectory is strictly linear and monotonic; any deviation is merely measurement error."
      },
      "correct_answer": "A",
      "source_article": "Secularization",
      "x": 1.1050429344177246,
      "y": 0.9351418614387512,
      "concepts_tested": [
        "Concept 1: Secularization thesis as a mechanism linking modernization/rationalization/science to diminished religious authority in social life and governance.",
        "Concept 2: Desecularization as a counter-trend involving resurgence of religion in certain contexts (e.g., Islamic revival, post-Soviet Russia).",
        "Concept 3: Non-universality and complexity of secularization, including debates about measurement (belief, belonging, practice), boundaries between religion and secular, and possible post-secular models."
      ],
      "parent_concepts": [
        "Concept 2: Transition from clerical/religious control to secular, mass, state-supported schooling as a mechanism of modernization."
      ],
      "parent_articles": [
        "History of education"
      ]
    },
    {
      "question": "According to modernization theory, why might economic development not automatically create democracy, and what role do \"self-expression values\" play in this process?",
      "options": {
        "A": "Economic growth directly creates democratic institutions regardless of cultural values, so democracy follows wealth without mediation.",
        "B": "Democracy is primarily caused by values that already exist; economic development only reinforces a preexisting democratic culture, not via a new value shift.",
        "C": "Only after or alongside substantial economic development do self-expression values emerge; these values\u2014tolerance, autonomy, and civil liberties\u2014mediate and sustain democratic institutions.",
        "D": "Democratic outcomes are random with respect to modernization, so neither wealth nor values reliably predict democracy."
      },
      "correct_answer": "C",
      "source_article": "Modernization theory",
      "x": 1.2112908363342285,
      "y": 0.9314556121826172,
      "concepts_tested": [
        "Concept 1: The core link proposed by modernization theory \u2014 economic modernization (wealth, education) leads to liberal democratic and rationalist political institutions.",
        "Concept 2: Causality debates \u2014 whether modernization causally produces democracy, whether the relationship can be reversed, or whether modernization merely supports democracy rather than creates it.",
        "Concept 3: Mediation by value change (self-expression values) in advanced stages \u2014 the idea that democratization may depend on cultural/value shifts that occur after or alongside economic development, rather than on economic growth alone."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In rule-consequentialism, why might adopting a general rule that tends to produce better overall outcomes be justified even if a single instance of following the rule yields a worse outcome than the best possible act in that instance?",
      "options": {
        "A": "Because evaluating every act individually requires extensive outcome prediction and can be unstable; a well-chosen rule aggregates many cases, reducing predictive error and more reliably producing greater net good over time.",
        "B": "Because the rule\u2019s content has intrinsic moral value independent of outcomes.",
        "C": "Because people prefer following rules for simplicity, regardless of consequences.",
        "D": "Because it ensures immediate gratification in all situations."
      },
      "correct_answer": "A",
      "source_article": "Consequentialism",
      "x": 1.194973349571228,
      "y": 1.027396321296692,
      "concepts_tested": [
        "Concept 1: The principle that the rightness of an act is determined by its consequences (outcome-based evaluation and balance of good over evil).",
        "Concept 2: The goods that count for evaluating consequences (pleasure, absence of pain, preference satisfaction, or a broader general good) and how different definitions shape judgments.",
        "Concept 3: The relationships and potential compatibilities between consequentialism and other ethical frameworks (deontology, virtue ethics, pragmatic ethics), including examples of how they might overlap or be reconciled (e.g., rule-consequentialism, rights justified by consequences)."
      ],
      "parent_concepts": [
        "Concept 1: Utility maximization as the moral aim (happiness/well-being as the metric and the end to maximize)",
        "Concept 2: Consequentialist framework and decision rules (outcomes determine right/wrong; distinction between act vs. rule utilitarianism)"
      ],
      "parent_articles": [
        "Utilitarianism",
        "Utilitarianism"
      ]
    },
    {
      "question": "Why does deontological ethics ground moral evaluation in the status of the action (duty/rights) rather than its consequences, and how would a virtue-deontological hybrid address cases where strict duties yield counterintuitive outcomes?",
      "options": {
        "A": "Because duties and rights provide universal constraints independent of outcomes; a hybrid would incorporate virtuous character to ensure duties are interpreted and applied in light of generally good dispositions, preventing moral formalism from endorsing bad results.",
        "B": "Because outcomes determine moral worth, and a hybrid would rely more on character than on duties.",
        "C": "Because character is the only reliable guide to action, and a hybrid would abolish duties in favor of virtuous traits.",
        "D": "Because contracts and social acceptance determine morality, and a hybrid would replace duty with social utility."
      },
      "correct_answer": "A",
      "source_article": "Normative ethics",
      "x": 1.193893551826477,
      "y": 1.0062617063522339,
      "concepts_tested": [
        "The three main normative theories (virtue ethics, deontological ethics, consequentialism): what each emphasizes (character, duties/rights, outcomes) and the idea that hybrids can combine elements.",
        "Normative ethics as prescriptive and its relationship to other branches (how it differs from metaethics, applied ethics, descriptive ethics) and why that matters for evaluating actions.",
        "Foundational frameworks within the theories (e.g., Kant\u2019s categorical imperative, Rawls\u2019 contract theory with a veil of ignorance, natural rights theories) and how these serve as mechanisms or principles to determine right action."
      ],
      "parent_concepts": [
        "Concept 1: Utility maximization as the moral aim (happiness/well-being as the metric and the end to maximize)",
        "Concept 2: Consequentialist framework and decision rules (outcomes determine right/wrong; distinction between act vs. rule utilitarianism)"
      ],
      "parent_articles": [
        "Utilitarianism",
        "Utilitarianism"
      ]
    },
    {
      "question": "How does viewing causality as a fundamental interpretive framework embedded in language and scientific practice illuminate why scientists rely on causal models to explain phenomena even when direct manipulation or complete data are unavailable?",
      "options": {
        "A": "It implies causal models are mere conveniences with no objective content, so they vanish if experiments can't be performed.",
        "B": "It shows that causal schemas encode regular, cross-context patterns in experience, providing stable predictions and guiding interventions when data are scarce or manipulations are impractical.",
        "C": "It claims that causal reasoning rests exclusively on deductive inference from first principles, so it fails without complete logical derivations.",
        "D": "It asserts that causality is merely a phenomenological illusion; thus, all explanations should be attempted without any causal assumptions."
      },
      "correct_answer": "B",
      "source_article": "Causality",
      "x": 1.2252726554870605,
      "y": 1.079972743988037,
      "concepts_tested": [
        "Concept 1: The cause\u2013effect relationship and its temporal direction, including multiple causes and causal factors and how effects can become causes for further effects.",
        "Concept 2: Major philosophical accounts of causality (Aristotle\u2019s four causes with emphasis on efficient cause; Hume\u2019s empirical justification; Kant\u2019s view on time/space and causality) illustrating different explanatory frameworks.",
        "Concept 3: Causality as a fundamental, interpretive concept embedded in language and scientific practice, including debates about justification (reason vs. habit/experience) and how causality underpins explanation."
      ],
      "parent_concepts": [
        "Concept 2: Decomposition of risk into sources, events, consequences, and likelihood (a cause\u2013effect\u2013probability framework)"
      ],
      "parent_articles": [
        "Risk"
      ]
    },
    {
      "question": "Why is biodiversity better understood as a multi-dimensional set of components rather than a single metric like species richness, and how do genetic diversity and functional diversity specifically contribute to predicting how ecosystems respond to environmental change?",
      "options": {
        "A": "Because species richness already captures all variation; genetic diversity and functional diversity do not add explanatory power.",
        "B": "Because genetic diversity within species provides adaptive potential, and functional diversity captures differences in ecological roles; together they influence resilience and functioning beyond what species counts reveal.",
        "C": "Because biodiversity is solely determined by climate, and adding more dimensions confuses the concept.",
        "D": "Because taxonomy-based measures are always superior to ecological or genetic measures for predicting ecosystem response."
      },
      "correct_answer": "B",
      "source_article": "Biodiversity",
      "x": 1.6395069360733032,
      "y": 0.958655834197998,
      "concepts_tested": [
        "Concept 1: Latitudinal gradient in biodiversity and its causal drivers (temperature, primary productivity, energy availability) that explain why tropical regions harbor more species.",
        "Concept 2: Biodiversity through deep time as a dynamic system influenced by mass extinctions and subsequent radiations (e.g., Cambrian explosion, Permian\u2013Triassic crisis) and recovery patterns.",
        "Concept 3: Multi-dimensional nature of biodiversity (genes/genetic diversity, species diversity, ecosystem diversity, phylogenetic diversity, functional diversity) and the idea that biodiversity is not a single, concrete definition but a set of related, interacting components."
      ],
      "parent_concepts": [
        "Concept 2: Landscape heterogeneity as a driver of ecological outcomes \u2014 how variation and internal order within a landscape affect ecosystem functioning and biodiversity, and how heterogeneity is measured and interpreted."
      ],
      "parent_articles": [
        "Landscape ecology"
      ]
    },
    {
      "question": "In adaptive management, why is it essential to treat management actions as iterative experiments with ongoing monitoring and feedback, and how does this approach improve outcomes under uncertainty in natural resource systems?",
      "options": {
        "A": "It concentrates decision-making power in a central authority to ensure uniform implementation across all contexts.",
        "B": "It creates a structured learning loop where outcomes inform updates to models and future actions, reducing uncertainty and improving decisions over time.",
        "C": "It minimizes data collection to reduce costs, relying on expert judgment to guide every decision.",
        "D": "It assumes ecological responses are fully predictable, so initial forecasts are never revised regardless of new information."
      },
      "correct_answer": "B",
      "source_article": "Natural resource management",
      "x": 1.4311354160308838,
      "y": 0.8927226066589355,
      "concepts_tested": [
        "Integrated, systems-based approach that links ecological health with human livelihoods and long-term sustainability.",
        "Adaptive management as a learning-based mechanism to adjust policies and practices in response to uncertainty and changing conditions.",
        "Governance and ownership regimes (e.g., state property, Indigenous land rights) shaping how resources are used, governed, and maintained."
      ],
      "parent_concepts": [
        "Concept 1: Ecosystem management as a holistic, adaptive approach that integrates ecological, socioeconomic, and institutional knowledge to sustain ecosystem function and services."
      ],
      "parent_articles": [
        "Ecosystem management"
      ]
    },
    {
      "question": "Why does multi-level, multi-actor governance enhance environmental policy effectiveness compared to a single-level, state-centric approach?",
      "options": {
        "A": "It concentrates decision-making power in a single authority to speed actions.",
        "B": "It mobilizes diverse legitimacy, resources, and knowledge across local, national, and global scales, enabling local experimentation and diffusion of successful practices while maintaining accountability through multiple actors.",
        "C": "It guarantees uniform implementation by imposing the same rules everywhere, removing local adaptation.",
        "D": "It reduces coordination costs by eliminating the need for cross-level communication and collaboration."
      },
      "correct_answer": "B",
      "source_article": "Environmental governance",
      "x": 1.3562544584274292,
      "y": 0.8807642459869385,
      "concepts_tested": [
        "Multi-level, multi-actor governance: interactions among state, market, and civil society across local, national, and global levels in formulating and implementing environmental policies.",
        "Embedding the environment in decision-making: ensuring environmental considerations permeate all levels of policy and action, and recognizing the connection between people and ecosystems.",
        "Transition to circular/sustainable systems: moving from cradle-to-grave waste models to cradle-to-cradle/closed-loop approaches within governance to promote sustainable development."
      ],
      "parent_concepts": [
        "Concept 2: The relationship between management style and ecological resilience\u2014how ecosystem management contrasts with command-and-control approaches to improve resilience and sustainability."
      ],
      "parent_articles": [
        "Ecosystem management"
      ]
    },
    {
      "question": "In an ecosystem-inspired, systems-based view of industrial ecology, why can optimizing a single technology in isolation fail to improve overall sustainability, and how does the ecosystem metaphor explain this phenomenon?",
      "options": {
        "A": "Because optimizing one component can alter the broader network of material and energy flows through feedbacks, causing compensating or new inefficiencies elsewhere and potentially offsetting gains.",
        "B": "Because the ecosystem metaphor suggests that each subsystem operates in complete independence; improving one has no effect on others.",
        "C": "Because natural ecosystems have no waste, so any waste produced by an industrial system is irrelevant to overall sustainability.",
        "D": "Because policy and markets always ensure that local optimizations scale to global benefits, making system-scale thinking unnecessary."
      },
      "correct_answer": "A",
      "source_article": "Industrial ecology",
      "x": 1.5577996969223022,
      "y": 0.9561868906021118,
      "concepts_tested": [
        "Concept 1: Closed-loop / industrial metabolism \u2014 shifting from open-loop waste generation to loops where wastes become inputs for new processes, highlighting material and energy flow as a systemic phenomenon.",
        "Concept 2: Ecosystem-inspired, systems-based view \u2014 understanding emergent behavior and interdependencies of industrial and natural systems, using ecosystem metaphors to guide sustainable design.",
        "Concept 3: Life-cycle thinking and eco-design (including product stewardship) \u2014 designing and evaluating products and processes across their entire life cycle to reduce environmental impact and decarbonize/dematerialize."
      ],
      "parent_concepts": [
        "Concept 1: The three base principles of a circular economy (designing out waste and pollution; keeping products/materials in use; regenerating natural systems) as a framework for transformation."
      ],
      "parent_articles": [
        "Circular economy"
      ]
    },
    {
      "question": "Why does the methodological foundation of historiography\u2014specifically the choice of sources, research techniques, and theoretical frameworks\u2014shape how we interpret the past?",
      "options": {
        "A": "It guarantees objectivity by including all sources and minimizing interpretation, so conclusions are fixed.",
        "B": "It has no effect on interpretation because facts are fixed and sources are perfect.",
        "C": "It works like selective lenses that filter and frame evidence, so different methodological choices can lead to different reconstructions of the past.",
        "D": "It only changes stylistic aspects of writing, not substantive conclusions about events."
      },
      "correct_answer": "C",
      "source_article": "Historiography",
      "x": -0.028069863095879555,
      "y": 0.4645410180091858,
      "concepts_tested": [
        "Concept 1: The methodological foundations of historiography (how sources, research techniques, and theoretical frameworks shape historical interpretation)",
        "Concept 2: The historical evolution of historiography (from ancient to modern periods, including professionalization and incorporation of social science perspectives)",
        "Concept 3: The influence of historians\u2019 identities and loyalties on historiography (debate about bias and perspective in historical writing)"
      ],
      "parent_concepts": [
        "Concept 1: Evidence-based reconstruction and source criticism as methods to explain past events"
      ],
      "parent_articles": [
        "History"
      ]
    },
    {
      "question": "How does the divergence between Humean causality and Kantian causality affect the type of historical explanation each approach tends to favor?",
      "options": {
        "A": "Humean causality treats causal links as empirical regularities derived from constant conjunctions, leading historians to explain events with patterns and probabilistic connections; Kantian causality treats causal relations as necessary conditions grounding experience, pushing historians to reveal underlying structures or conditions that render events intelligible, even if not directly observable.",
        "B": "Humean causality requires divine intervention to explain history; Kantian causality denies any causal explanation.",
        "C": "Both approaches endorse teleological explanations; the difference is only about the role of ethical judgments.",
        "D": "Both approaches rely on narrative coherence as the sole criterion; the difference is negligible."
      },
      "correct_answer": "A",
      "source_article": "Philosophy of history",
      "x": 1.084579586982727,
      "y": 1.0260422229766846,
      "concepts_tested": [
        "Analytic vs. speculative (critical) philosophy of history: their aims (pragmatic meaning/purpose vs. foundations/implications) and how this affects historical inquiry.",
        "Causality in historical explanation: the Hume-Kant divergence and its impact on how history explains events and processes.",
        "Normative purpose of history: the idea that history should teach good examples or shape moral/ethical understanding, contrasted with literary or poetic treatments of history."
      ],
      "parent_concepts": [
        "Concept 1: Evidence-based reconstruction and source criticism as methods to explain past events"
      ],
      "parent_articles": [
        "History"
      ]
    },
    {
      "question": "Why is separating strategic planning (analytical, finding the dots) from strategy formation (synthetic, connecting the dots) valuable for guiding organizational direction in a changing environment?",
      "options": {
        "A": "It enforces a rigid, long-term plan that dictates actions regardless of new information.",
        "B": "It creates a disciplined process where a comprehensive, data-driven set of options is generated (planning) while senior leaders synthesize these options into a coherent strategy that can adapt as patterns emerge over time.",
        "C": "It removes the need for ongoing monitoring of external changes.",
        "D": "It ensures that all strategic decisions are made solely by a single department."
      },
      "correct_answer": "B",
      "source_article": "Strategic planning",
      "x": 1.3673890829086304,
      "y": 0.9906255006790161,
      "concepts_tested": [
        "Concept 1: Ends-means alignment and the distinction between intended (planned) and emergent (patterns) strategy, including the role of time horizons.",
        "Concept 2: The separation and coordination between strategic planning (analytical, finding the dots) and strategy formation (synthetic, connecting the dots), and how they influence organizational direction.",
        "Concept 3: The McKinsey capability maturity model stages (Financial planning \u2192 Forecast-based planning \u2192 Externally oriented planning \u2192 Strategic management) and how progression reflects increasing strategic thinking and framework development."
      ],
      "parent_concepts": [
        "Concept 2: The relationship and distinction between marketing strategy (planning) and marketing management (execution), and how they interact to turn ideas into action."
      ],
      "parent_articles": [
        "Marketing strategy"
      ]
    },
    {
      "question": "How does the central executive enable flexible problem solving in information processing theory?",
      "options": {
        "A": "By acting as a passive storage buffer that lets information passively accumulate in working memory.",
        "B": "By coordinating retrieval from long-term memory and the manipulation of information in working memory to support goal-directed actions, especially when rules or tasks change.",
        "C": "By encoding all new input directly into long-term memory without engaging working memory or retrieval processes.",
        "D": "By determining cognitive development strictly through fixed stages, with no role in online processing."
      },
      "correct_answer": "B",
      "source_article": "Information processing theory",
      "x": 1.3492799997329712,
      "y": 1.0452624559402466,
      "concepts_tested": [
        "Concept 1: The information processing sequence and the roles of attention, working memory, encoding, and long-term memory in transforming input into output.",
        "Concept 2: The central executive as the control system that coordinates retrieval and manipulation of information across working and long-term memory.",
        "Concept 3: The continuous development view, where cognitive maturation changes processing components over time, contrasting with stage-based theories like Piaget\u2019s."
      ],
      "parent_concepts": [
        "Concept 1: The information-processing framework (encoding, storage, retrieval, processing) as the mechanism by which social information is handled and subsequently influences perception and memory."
      ],
      "parent_articles": [
        "Social cognition"
      ]
    },
    {
      "question": "In science and technology studies, why is it essential to analyze science and medicine within historical and cultural contexts rather than treating them as neutral, universal products?",
      "options": {
        "A": "Because the same technology can produce different effects, meanings, and outcomes depending on power relations, institutional structures, and everyday practices that shape its development and use.",
        "B": "Because once a technology is designed, its impact is determined solely by its technical specifications, making context irrelevant.",
        "C": "Because social context only determines who funds research, not how technologies are actually adopted or used in practice.",
        "D": "Because ethical considerations alone drive technology development, and social context plays no role in shaping technical choices."
      },
      "correct_answer": "A",
      "source_article": "Science and technology studies",
      "x": 1.236072063446045,
      "y": 0.9842521548271179,
      "concepts_tested": [
        "Concept 1: Science and technology are socially embedded enterprises whose development and consequences are shaped by historical, cultural, and social contexts.",
        "Concept 2: The critique of technological determinism and the use of contextual, historically informed analyses (including gender and power dynamics) to understand science and medicine.",
        "Concept 3: The interdisciplinary nature of STS, integrating anthropology, history, political science, sociology, etc., to study the creation, development, diffusion, and societal impacts of science and technology, including theoretical frameworks like paradigm shifts (Kuhn)."
      ],
      "parent_concepts": [
        "Concept 3: The historical evolution of science (from natural philosophy to natural science) driven by methodological shifts and institutional development."
      ],
      "parent_articles": [
        "Science"
      ]
    },
    {
      "question": "How does epigenetic DNA methylation at a gene promoter influence transcription, and why can this regulation be inherited through cell divisions?",
      "options": {
        "A": "It directly mutates the DNA sequence, creating permanent changes that are transmitted to daughter cells.",
        "B": "It recruits histone acetyltransferases that open chromatin and increase transcription, and this pattern is not inherited.",
        "C": "It recruits methyl-CpG-binding proteins that recruit repressive chromatin modifiers, leading to closed chromatin and reduced transcription; maintenance methyltransferases copy methylation to new DNA strands during replication, making the pattern heritable across cell divisions.",
        "D": "It changes the DNA sequence to prevent RNA polymerase binding, a change that is always permanent."
      },
      "correct_answer": "C",
      "source_article": "Regulation of gene expression",
      "x": 2.086825132369995,
      "y": 1.1520715951919556,
      "concepts_tested": [
        "Concept 1: Regulation can act at multiple stages of gene expression, with transcription initiation frequently being the primary control point, linking signals to transcriptional output.",
        "Concept 2: Epigenetic regulation (chromatin structure, histone modifications, DNA methylation, ncRNA) modulates gene accessibility and expression, with potential heritability.",
        "Concept 3: Gene regulatory networks and hierarchical regulation\u2014one regulator controls others, creating cascades that drive cellular differentiation and complex developmental programs."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "The functional boundary between public and private law is based on domain and purpose, not mere factual division. How does this functional approach explain why a government agency entering into a service contract for private services might be governed by private law?",
      "options": {
        "A": "Because if the core activities, participants, and principal concerns resemble a private transaction, the arrangement is better categorized under private law, even though a state actor is involved.",
        "B": "Because the mere involvement of a government agency automatically makes the arrangement public law, regardless of its nature.",
        "C": "Because private law cannot apply to relationships involving the state; only public law can.",
        "D": "Because government agencies are always immune from private contracts."
      },
      "correct_answer": "A",
      "source_article": "Public law",
      "x": 1.2381603717803955,
      "y": 0.8619212508201599,
      "concepts_tested": [
        "Rule of law and judicial oversight: government authorities must act within the law, with citizens able to seek judicial review to challenge decisions.",
        "Functional boundary between public and private law: classification is based on domain and purpose, not merely on factual division, with blurred lines in practice.",
        "Relationship-centric governance: public law governs asymmetric relationships between the state and individuals and among state institutions, shaping rights, duties, and remedies."
      ],
      "parent_concepts": [
        "Concept 1: The core mechanisms of administrative law (rulemaking, adjudication, enforcement) and how they structure accountability within executive agencies."
      ],
      "parent_articles": [
        "Administrative law"
      ]
    },
    {
      "question": "Why does bond formation release energy from a quantum-mechanical perspective, and how does electron distribution affect the system's energy?",
      "options": {
        "A": "The shared electrons occupy a more spread-out molecular orbital, which lowers their average kinetic energy and stabilizes the system through delocalization.",
        "B": "The energy release comes solely from increased attraction between electrons and nuclei, with no change in electrons' kinetic energy.",
        "C": "Bond formation reduces electron-electron repulsion by squeezing electrons closer to each nucleus, lowering potential energy without any kinetic energy change.",
        "D": "Electrons become more tightly confined between the nuclei, which increases kinetic energy but is completely offset by a large decrease in potential energy, yielding net stabilization."
      },
      "correct_answer": "A",
      "source_article": "Chemical bond",
      "x": 1.8691807985305786,
      "y": 1.0645512342453003,
      "concepts_tested": [
        "Concept 1: Quantum-mechanical stabilization and energy reasons for bond formation (why bond formation releases energy and how electron distribution lowers the system's energy, including the role of kinetic energy and orbital delocalization).",
        "Concept 2: Balance of attractive and repulsive forces sets bond length and strength (how bond distance is determined by competing interactions and why an optimal distance exists).",
        "Concept 3: Multiple theoretical frameworks explain bonding (how valence bond theory, molecular orbital theory, hybridization, resonance, and simplified models like the octet rule/VSEPR provide different but complementary explanations of bonds)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In computational biology, modeling and computational simulations are core mechanisms for understanding biological systems. How does using a simplified computational model enable insights that are difficult to obtain from direct measurement?",
      "options": {
        "A": "Because computational models always include every molecular detail, ensuring complete predictive accuracy.",
        "B": "Because modeling forces researchers to define and focus on key causal interactions, allowing controlled manipulation of variables and systematic exploration of emergent system-level behavior that might be invisible in real data.",
        "C": "Because simulations replace the need for empirical validation by producing results faster than experiments.",
        "D": "Because models primarily serve as data storage, reducing the amount of experimental data required."
      },
      "correct_answer": "B",
      "source_article": "Computational biology",
      "x": 1.5745915174484253,
      "y": 1.0746126174926758,
      "concepts_tested": [
        "Interdisciplinary integration of computer science, mathematics, and biology as a foundational principle driving the field",
        "Modeling and computational simulations as core mechanisms for understanding biological systems",
        "Data growth and the resulting need for new computational methods as a driving relationship in the field\u2019s development"
      ],
      "parent_concepts": [
        "The integration of computational methods (e.g., molecular dynamics, predictive modeling) with experimental structure determination to explore structure, dynamics, and function."
      ],
      "parent_articles": [
        "Structural biology"
      ]
    },
    {
      "question": "Why does a drug with very high receptor affinity not automatically yield a strong therapeutic effect in a living organism, and how do pharmacokinetics and pharmacodynamics together determine the outcome?",
      "options": {
        "A": "Because high affinity guarantees strong effect even if the drug never reaches the receptor in appreciable amounts.",
        "B": "Because the therapeutic outcome depends on both how much drug reaches the target (pharmacokinetics) and how the receptor responds to that concentration (pharmacodynamics); high affinity helps, but insufficient exposure or rapid clearance can prevent the effect.",
        "C": "Because pharmacokinetics and pharmacodynamics are completely independent and do not influence each other or the occupancy of receptors.",
        "D": "Because once a drug binds the receptor, the effect is fixed and pharmacokinetics cannot alter the duration or magnitude of the response."
      },
      "correct_answer": "B",
      "source_article": "Pharmacology",
      "x": 1.5062611103057861,
      "y": 1.0080946683883667,
      "concepts_tested": [
        "Concept 1: Pharmacodynamics vs pharmacokinetics as complementary frameworks that determine a drug's action (PD describes effects on biology; PK describes the body's effects on the drug) and how they together shape therapeutic outcomes.",
        "Concept 2: Drug-receptor interactions and signal transduction as the cellular/mechanistic basis for pharmacodynamic effects.",
        "Concept 3: ADME (absorption, distribution, metabolism, excretion) and organismal influences on drug exposure, concentration at targets, and hence efficacy and toxicity."
      ],
      "parent_concepts": [
        "Structure-Activity Relationships (SAR) and QSAR as guiding principles for predicting and optimizing therapeutic activity",
        "Interdisciplinary integration in drug design (how organic chemistry, biochemistry, computational chemistry, pharmacology, etc., connect to enable rational drug discovery)"
      ],
      "parent_articles": [
        "Medicinal chemistry",
        "Medicinal chemistry"
      ]
    },
    {
      "question": "Why is it essential to optimize multiple pharmacological properties together when evolving a hit into a viable drug candidate, rather than maximizing a single property like potency?",
      "options": {
        "A": "Increasing potency alone will automatically improve all other drug properties, leaving no trade-offs.",
        "B": "Because improvements in one property can degrade others (e.g., metabolism, bioavailability, or selectivity), requiring balanced optimization.",
        "C": "Improving selectivity guarantees regulatory approval without needing to consider pharmacokinetics.",
        "D": "Metabolic stability only affects pharmacokinetics and has no impact on safety."
      },
      "correct_answer": "B",
      "source_article": "Drug discovery",
      "x": 2.025172472000122,
      "y": 1.0971851348876953,
      "concepts_tested": [
        "Concept 1: Transition from traditional/serendipitous discovery to target-based reverse pharmacology and high-throughput screening.",
        "Concept 2: Multi-parameter optimization of hits (affinity, selectivity, efficacy/potency, metabolic stability, oral bioavailability) to create viable drug candidates.",
        "Concept 3: The drug development ecosystem\u2014funding, clinical trials, regulatory approval, and policy factors (e.g., orphan drug status) that shape translation from discovery to therapy."
      ],
      "parent_concepts": [
        "Structure-Activity Relationships (SAR) and QSAR as guiding principles for predicting and optimizing therapeutic activity",
        "Interdisciplinary integration in drug design (how organic chemistry, biochemistry, computational chemistry, pharmacology, etc., connect to enable rational drug discovery)"
      ],
      "parent_articles": [
        "Medicinal chemistry",
        "Medicinal chemistry"
      ]
    },
    {
      "question": "Why does representing chemical structures with a linear notation like SMILES enable efficient computational processing and data retrieval in cheminformatics?",
      "options": {
        "A": "Because SMILES provides explicit 3D coordinates that simplify docking calculations.",
        "B": "Because SMILES linearizes the molecular graph into a string that can be easily stored, indexed, and processed by standard algorithms.",
        "C": "Because SMILES encodes all quantum mechanical properties directly for immediate predictions.",
        "D": "Because SMILES guarantees a unique, unambiguous representation for every stereoisomer in all cases."
      },
      "correct_answer": "B",
      "source_article": "Cheminformatics",
      "x": 1.7859996557235718,
      "y": 1.0804526805877686,
      "concepts_tested": [
        "Interdisciplinary integration: Cheminformatics blends chemistry, computer science, and information science to turn data into actionable knowledge for drug lead identification and optimization.",
        "Data representation and storage: Use of specialized formats (e.g., SMILES, Chemical Markup Language) enables efficient storage, retrieval, and computation on chemical structures.",
        "In silico methods as drivers of design: Computational techniques (data mining, machine learning, docking, structure-based design) support decision making in drug discovery and link computational results to experimental workflows."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does computational science act as a third mode of science that complements experimentation and theory, and how do its core practices of building models and running simulations provide understanding beyond what experiments or theory alone can offer?",
      "options": {
        "A": "Because it provides exact depictions of reality that neither experiments nor theory can achieve.",
        "B": "Because it lets researchers systematically vary model assumptions and input conditions to reveal causal mechanisms and behaviors that may be inaccessible or impractical to study directly, thereby extending understanding beyond what physical experiments or mathematical derivations alone can offer.",
        "C": "Because it eliminates the need for empirical data by proving all phenomena through simulations.",
        "D": "Because it simply automates calculations that could be done by hand, without contributing new understanding."
      },
      "correct_answer": "B",
      "source_article": "Computational science",
      "x": 1.542296290397644,
      "y": 1.0624839067459106,
      "concepts_tested": [
        "Concept 1: Computational science as a third mode of science that complements experimentation/observation and theory, using modeling and computation to gain understanding.",
        "Concept 2: The modeling-experimentation relationship: a system (S) is studied via a model (M) and experiments (E) to answer questions about S.",
        "Concept 3: The core methods and tools (numerical algorithms, computational mathematics, high-performance computing) that enable large-scale simulations and problem solving."
      ],
      "parent_concepts": [
        "Concept 2: The conceptual relationship to theoretical chemistry \u2014 computational chemistry uses existing programs and mathematics, while theoretical chemistry develops new algorithms and models."
      ],
      "parent_articles": [
        "Computational chemistry"
      ]
    },
    {
      "question": "Why does an ecosystem typically deliver a mix of provisioning, regulating, cultural, and sometimes supporting services rather than all four categories appearing equally or exclusively, according to the four-category framework?",
      "options": {
        "A": "Because ecosystems are driven by a single dominant energy source that limits the number of possible services.",
        "B": "Because core ecological processes (like primary production, nutrient cycling, and habitat structure) generate multiple benefits, with supporting services underpinning the others and context-specific constraints leading to different subsets of services across ecosystems.",
        "C": "Because human observers only record certain benefits, causing an apparent mix that reflects valuation rather than actual ecological potential.",
        "D": "Because the framework imposes a fixed distribution of services that ecosystems are forced to fit, regardless of ecological reality."
      },
      "correct_answer": "B",
      "source_article": "Ecosystem service",
      "x": 1.586732029914856,
      "y": 0.9125792384147644,
      "concepts_tested": [
        "The four-category framework of ecosystem services (provisioning, regulating, supporting, cultural) and the idea that ecosystems typically provide a mix of these, not necessarily all four.",
        "The role of supporting services as the foundational basis for provisioning, regulating, and cultural services within the MA framework.",
        "The link between ecosystem processes and human benefits, including how evaluating services can involve economic valuation and how services vary across different ecosystems."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Which mechanism best explains why converting forest to agricultural land tends to increase atmospheric CO2, even before considering fossil fuel combustion?",
      "options": {
        "A": "Increased photosynthesis in crops sequesters more CO2, reducing atmospheric CO2.",
        "B": "Removal of carbon-rich vegetation and disturbance of soil reduces carbon storage and releases previously stored carbon to the atmosphere, elevating CO2.",
        "C": "The conversion increases soil carbon storage, lowering CO2 in the atmosphere.",
        "D": "Land-use change does not affect atmospheric CO2; CO2 levels are determined solely by fossil fuel emissions."
      },
      "correct_answer": "B",
      "source_article": "Land use",
      "x": 1.520616054534912,
      "y": 0.9103325009346008,
      "concepts_tested": [
        "Land use combines the products/benefits obtained from land with the human actions (management) used to produce those benefits, linking human activity to land outcomes.",
        "Land-use change is a major driver of environmental impacts and greenhouse gas emissions (especially CO2), illustrating a cause-and-effect relationship between human activity and environmental change.",
        "Studying land-use change relies on integrating diverse data sources and modeling approaches (monitoring, risk/vulnerability assessments, land-change modeling) to understand dynamics and impacts."
      ],
      "parent_concepts": [
        "Concept 3: Land sparing versus land sharing as strategies to balance high-yield production with conservation of natural habitats within sustainable agriculture."
      ],
      "parent_articles": [
        "Sustainable agriculture"
      ]
    },
    {
      "question": "Why is the accountability mechanism central to political representation, and how does it function to align a representative's actions with the interests of the represented?",
      "options": {
        "A": "Because accountability guarantees descriptive similarity suffices to justify representation.",
        "B": "Because accountability creates feedback loops that force representatives to reveal internal preferences to the public.",
        "C": "Because accountability provides a mechanism for citizens to judge performance and sanction representatives if they fail to act in the public interest, thereby incentivizing alignment with citizens' interests.",
        "D": "Because accountability ensures representatives always act in the majority's interest, suppressing minority concerns."
      },
      "correct_answer": "C",
      "source_article": "Political representation",
      "x": 1.1793370246887207,
      "y": 0.8866453170776367,
      "concepts_tested": [
        "Substantive representation: representation as \u201cacting for\u201d the interests of the represented, not just descriptive likeness or symbolic signaling.",
        "Accountability mechanism: citizens\u2019 ability to judge and sanction representatives based on whether they act in the represented's best interests.",
        "Theoretical frameworks for representation: Pitkin\u2019s substantive view versus descriptive/symbolic views, and Mansbridge\u2019s four democratic representations (promissory, anticipatory, surrogate, gyroscopic) as ways to explain how representatives act for people and how actions are normatively assessed."
      ],
      "parent_concepts": [
        "How votes are translated into seats and how this translation affects proportionality and representation (mechanism and its outcomes)"
      ],
      "parent_articles": [
        "Electoral system"
      ]
    },
    {
      "question": "In the evolution from bands to states, centralization and hierarchical organization concentrate authority. How does this architectural change primarily alter the system's capacity to make large-scale public decisions?",
      "options": {
        "A": "It disperses authority, increasing local experimentation but reducing overall coordination.",
        "B": "It concentrates authority, lowering coordination costs for large-scale decisions while increasing vulnerability to failures and legitimacy challenges.",
        "C": "It eliminates the need for rules and institutions, producing spontaneous order.",
        "D": "It guarantees equal distribution of resources across the society."
      },
      "correct_answer": "B",
      "source_article": "Political system",
      "x": 1.207747459411621,
      "y": 0.9195584058761597,
      "concepts_tested": [
        "Concept 1: Political systems are mechanisms for authoritatively allocating values and making public decisions (Easton\u2019s principle).",
        "Concept 2: Centralization and hierarchical organization (bands, tribes, chiefdoms, states) model how authority and governance structures evolve and influence political power.",
        "Concept 3: Regime types exist on a liberal-democratic to totalitarian spectrum (with hybrids), highlighting how legitimacy, rights, and state control interact within different political arrangements."
      ],
      "parent_concepts": [
        "Relationships among regime types: the idea that forms like democracies, authoritarian regimes, and hybrids are not strictly exclusive and can coexist or blur into mixed regimes, illustrating conceptual connections between theory and practice."
      ],
      "parent_articles": [
        "Government"
      ]
    },
    {
      "question": "In a framework for statistical inference that relies on a specified data-generating model, why does random assignment of the treatment help identify a causal effect, and how does this interact with confounding?",
      "options": {
        "A": "It reduces random sampling error and thereby automatically corrects for unobserved confounders.",
        "B": "It makes the treatment assignment statistically independent of both observed and unobserved confounders under the randomization process, so differences in outcomes can be attributed to the treatment within the assumed model.",
        "C": "It guarantees that the chosen model is correctly specified for the data-generating process.",
        "D": "It ensures that the outcome distribution becomes normal, which simplifies estimating the treatment effect."
      },
      "correct_answer": "B",
      "source_article": "Mathematical statistics",
      "x": 1.6152487993240356,
      "y": 1.1464191675186157,
      "concepts_tested": [
        "The foundational role of probability theory in mathematical statistics and its separation from data collection techniques",
        "The model-based nature of inference: selecting a model, checking conditions, quantifying uncertainty, and how study design (randomized vs observational) affects inference",
        "The role and types of probability distributions (univariate vs multivariate; discrete vs continuous; PMF vs PDF; measures) in modeling data"
      ],
      "parent_concepts": [
        "The parameter-to-distribution relationship: parameters influence the distribution of measured data, and estimation uses observed data to infer the parameters."
      ],
      "parent_articles": [
        "Estimation theory"
      ]
    },
    {
      "question": "In mysticism understood as a pathway of personal transformation enabled by practices and experiences, what mechanism links repeated practice to lasting change in the self?",
      "options": {
        "A": "Mystical transformation occurs only when experiences happen spontaneously, regardless of practice.",
        "B": "Repeated, structured practices recalibrate attention, emotion regulation, and self-referential processing, shaping how experiences are interpreted and integrating them over time.",
        "C": "Transformation is a direct result of memorizing doctrinal content, with no need for experiential practice.",
        "D": "Social validation from a community is sufficient to reframe identity, independent of individual practice or experience."
      },
      "correct_answer": "B",
      "source_article": "Mysticism",
      "x": 1.0818508863449097,
      "y": 1.0543891191482544,
      "concepts_tested": [
        "Concept 1: Mysticism as a pathway of personal transformation enabled by practices and religious experiences (the mechanism linking practice to transformation).",
        "Concept 2: The relationship between mysticism and different forms of experience (unitive mystical experience vs. insight into ultimate truths or altered states like samadhi) and how these interpretations coexist or diverge across traditions.",
        "Concept 3: Scholarly reframing of mysticism\u2019s definitions (how and why the understanding of mysticism shifts across historical periods and across Buddhist, Hindu, Sufi, Christian contexts)."
      ],
      "parent_concepts": [
        "Concept 2: Competing theoretical frameworks and typologies of mysticism (perennialism vs constructionism vs attribution; Zaehner\u2019s/theistic/monistic/panentheistic, Stace\u2019s extraverted vs introverted) and what they imply about universal vs context-dependent aspects of mysticism."
      ],
      "parent_articles": [
        "Mystical or religious experience"
      ]
    },
    {
      "question": "In a constructionist/attribution framework, how are cross-cultural reports of mystical experiences best understood, and how do Zaehner's typologies versus Stace's dichotomy relate to this understanding?",
      "options": {
        "A": "Cross-cultural similarities are explained by a universal metaphysical reality; Zaehner's typologies capture epistemic universals, and Stace's dichotomy is a redundant framing.",
        "B": "Cross-cultural similarities are explained as products of shared cognitive and cultural frames shaping interpretation, rather than identical phenomenology; Zaehner's typologies categorize what is attributed to the experience (theistic, monistic, panentheistic), while Stace's dichotomy distinguishes how the experience is framed (extraverted vs. introverted).",
        "C": "Cross-cultural similarities are due to identical neurophysiological activations across cultures; Zaehner and Stace map directly onto specific brain regions involved.",
        "D": "Cross-cultural similarities are illusory; there is no substantive phenomenology, and Zaehner and Stace offer incompatible, mutually exclusive classifications."
      },
      "correct_answer": "B",
      "source_article": "Mystical or religious experience",
      "x": 1.105865240097046,
      "y": 1.0491325855255127,
      "concepts_tested": [
        "Concept 1: James's four defining qualities of mystical experiences (ineffability, noetic quality, transiency, passivity) and how they influence interpretation and epistemic status.",
        "Concept 2: Competing theoretical frameworks (perennialism vs. constructionist/attribution approaches; Zaehner\u2019s typologies vs. Stace\u2019s dichotomy) and how they explain universality, mediation by frames of reference, and the classification of mysticism.",
        "Concept 3: Neurocognitive correlates of mystical experiences (temporal lobe, parietal lobe, default mode network, anterior insula) and what these relationships imply about the brain\u2013phenomenon link and the nature of consciousness during such experiences."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In a semantic theory that adopts compositionality, why does the meaning of a novel sentence get determined by the meanings of its parts and their syntactic arrangement?",
      "options": {
        "A": "Because the meaning of the sentence is simply the average of the meanings of its words.",
        "B": "Because there is a recursive composition rule that combines the semantic values of the constituents according to the syntactic structure to yield the whole meaning.",
        "C": "Because the full sentence meaning is fixed by the broader pragmatic context, making internal structure irrelevant.",
        "D": "Because only the most salient word determines the entire sentence meaning, regardless of order or composition."
      },
      "correct_answer": "B",
      "source_article": "Semantics",
      "x": 1.271680235862732,
      "y": 1.1051874160766602,
      "concepts_tested": [
        "Sense vs. reference: distinguishes the ideas/concepts associated with an expression from the object it points to, illustrating a fundamental relationship in semantic theory.",
        "Compositionality: the meaning of larger expressions is built from the meanings of their parts and their arrangement, explaining how new meanings are derived.",
        "Theoretical frameworks for meaning: multiple theories (referential, ideational, causal, truth-conditional, use, inferentialist) offer different mechanisms for how meaning is determined, signaling the variety of conceptual approaches in semantics."
      ],
      "parent_concepts": [
        "Context-dependent meaning and pragmatic competence: how context and social interaction shape interpretation and the ability to grasp intended meaning."
      ],
      "parent_articles": [
        "Pragmatics"
      ]
    },
    {
      "question": "Why does maintaining multiple accountability modes (administrative, political, market, judicial, professional, social) help accountability function across diverse organizational and societal contexts?",
      "options": {
        "A": "Because it ensures that there is a single universal standard that all actors must meet.",
        "B": "Because each mode enforces accountability with different audiences, criteria, and sanctions, enabling cross-checking, context-sensitivity, and redundancy to detect and correct misconduct.",
        "C": "Because multiple modes create conflicting expectations that undermine accountability.",
        "D": "Because it allows individuals to cherry-pick the mode that best justifies their actions, maximizing efficiency."
      },
      "correct_answer": "B",
      "source_article": "Accountability",
      "x": 1.2504488229751587,
      "y": 0.9507073163986206,
      "concepts_tested": [
        "Concept 1: Accountability as an account-giving relationship involving informing, justifying, and accepting consequences.",
        "Concept 2: The necessity of proper accounting practices and record-keeping for accountability to exist.",
        "Concept 3: Existence of multiple accountability modes (administrative, political, market, judicial, professional, social) as mechanisms to enforce accountability in different contexts."
      ],
      "parent_concepts": [
        "Accountability mechanism: how citizens judge representatives and sanction them if they do not act in the represented's interests."
      ],
      "parent_articles": [
        "Political representation"
      ]
    },
    {
      "question": "In the shift to formal deductive proofs, how does deriving a theorem from a fixed set of axioms and previously proven results enable universal truth claims, as opposed to showing the result by a collection of specific examples or intuitive constructions?",
      "options": {
        "A": "By establishing a strictly logical chain from axioms to the conclusion, ensuring that any object or situation meeting the axioms must satisfy the conclusion, regardless of particular instances.",
        "B": "By requiring that every possible instance be enumerated and checked, guaranteeing no counterexamples exist.",
        "C": "By grounding all claims in sensory observation and experiment, thereby generalizing from data.",
        "D": "By making axioms themselves indefinite and adjustable, so any derived statement can be accepted without justification."
      },
      "correct_answer": "A",
      "source_article": "History of mathematics",
      "x": 1.578647255897522,
      "y": 1.1730152368545532,
      "concepts_tested": [
        "Concept 1: The shift to deductive reasoning and rigorous proofs as a turning point in mathematics (Greek mathematics) from earlier demonstrative approaches.",
        "Concept 2: Cross-cultural transmission and accumulation of mathematical knowledge (e.g., Hindu\u2013Arabic numerals, Islamic mathematics, translations into Latin) and how this facilitated broader development and standardization.",
        "Concept 3: The relationship between practical needs (taxation, calendars, surveying) and mathematical advancement, including the pattern of discoveries followed by stagnation and the Renaissance-era acceleration due to interaction with science."
      ],
      "parent_concepts": [
        "The relationship between applied mathematics and pure mathematics: how practical problems motivate new theories and how abstract theories later become topics of study within pure mathematics."
      ],
      "parent_articles": [
        "Applied mathematics"
      ]
    },
    {
      "question": "Why would a homeostatic control center coordinate responses across multiple variables and use multiple effectors, rather than regulating each variable with an isolated, separate loop?",
      "options": {
        "A": "Because a single center can integrate inputs from receptors monitoring several variables, align its maintenance ranges, and deploy coordinated, multi-effector responses that reflect how physiological processes are interdependent, improving stability and avoiding conflicting actions.",
        "B": "Because the center always aims to keep every variable at the exact same numerical value, which is optimal for organismal function.",
        "C": "Because coordinating across variables eliminates the need for negative feedback altogether, allowing unrestricted changes.",
        "D": "Because effectors operate independently of control centers, so cross-variable coordination is unnecessary and rarely occurs."
      },
      "correct_answer": "A",
      "source_article": "Homeostasis",
      "x": 1.9232844114303589,
      "y": 1.1110903024673462,
      "concepts_tested": [
        "Concept 1: The three-component feedback control system (receptor, control center, effector) and negative feedback that maintains variables within a homeostatic range.",
        "Concept 2: The role of the control center in setting maintenance ranges and coordinating responses, including cross-variable regulation (e.g., systems that influence more than one variable).",
        "Concept 3: Multi-level regulatory mechanisms contributing to homeostasis, including cellular-level regulation (gene expression via receptors) and signaling pathways (e.g., retrograde signaling via endocannabinoids to modulate physiological processes)."
      ],
      "parent_concepts": [
        "Endocrine regulation uses feedback loops to maintain homeostasis",
        "Concept 3: Endocrine regulation and negative feedback maintaining homeostasis (e.g., insulin regulating blood glucose levels)."
      ],
      "parent_articles": [
        "Endocrinology",
        "Hormone"
      ]
    },
    {
      "question": "Why do structure-preserving maps (homomorphisms) enable a unified framework for analyzing different algebraic structures (such as groups, rings, and modules) within the same mathematical language?",
      "options": {
        "A": "Because homomorphisms preserve the defining operations, they ensure that the image and preimage behave consistently with the original structure, allowing a single notion of morphism and the study of constructions (kernels, quotients, products) that are meaningful across many structures.",
        "B": "Because homomorphisms are always bijections that reveal that all structures are the same up to renaming of elements.",
        "C": "Because homomorphisms ignore operations and only carry information about elements' membership, reducing algebra to set theory.",
        "D": "Because homomorphisms can be defined for all possible structures without any common features, making no general framework."
      },
      "correct_answer": "A",
      "source_article": "Abstract algebra",
      "x": 1.6763213872909546,
      "y": 1.2043263912200928,
      "concepts_tested": [
        "The use of homomorphisms and categories to create a unified framework for analyzing different algebraic structures.",
        "Category theory and universal algebra as high-level frameworks for studying algebraic structures as unified objects or types (e.g., varieties like the variety of groups).",
        "The historical shift to formal axiomatic definitions (groups, rings, fields) that unifies disparate results under common concepts and principles."
      ],
      "parent_concepts": [
        "Concept 1: A group action is a group homomorphism from G to the group of transformations of S, ensuring the action respects composition and captures the mechanism by which group elements act as symmetries.",
        "Varieties as equational classes: Collections of algebras defined by a shared set of identities, linking the specified axioms to the resulting family of structures."
      ],
      "parent_articles": [
        "Group action",
        "Universal algebra"
      ]
    },
    {
      "question": "In the context of architectural evaluation, why are fitness functions valuable for communicating and maintaining architectural quality?",
      "options": {
        "A": "They translate non-functional requirements into a quantitative scoring scheme that can be used to compare options and drive trade-offs over time.",
        "B": "They guarantee the architecture will remain optimal as requirements evolve.",
        "C": "They prioritize non-functional requirements at the expense of functionality.",
        "D": "They replace the need for modeling or simulation."
      },
      "correct_answer": "A",
      "source_article": "Software architecture",
      "x": 1.4310297966003418,
      "y": 1.072960615158081,
      "concepts_tested": [
        "Concept 1: Architectural decisions are fundamental structural choices that involve trade-offs and are costly to change, so early decisions matter.",
        "Concept 2: Software architecture serves as the high-level structure and blueprint, distinct from application design, providing the infrastructure within which functionality is realized.",
        "Concept 3: Modeling and evaluating architecture (e.g., via Architectural Kata, C4 Model) and assessing non-functional requirements through mechanisms like fitness functions are central to communicating, designing, and maintaining architectural quality."
      ],
      "parent_concepts": [
        "Concept 2: Composability as a mechanism that enables modules to be combined to build larger systems (e.g., in functional programming).",
        "Service composition and discovery through metadata/protocols to build applications from existing services"
      ],
      "parent_articles": [
        "Modularity",
        "Service-oriented architecture"
      ]
    },
    {
      "question": "Why does abstraction work as selective filtering of information, and how does this mechanism support general understanding across different situations?",
      "options": {
        "A": "It preserves all details of the original situation so you can reproduce it later.",
        "B": "It retains only the aspects relevant to a purpose, discarding irrelevant features, which lets the same abstract concept apply to different concrete instances.",
        "C": "It converts all experiences into fixed tokens to memorize them efficiently.",
        "D": "It creates a strict one-to-one mapping from concrete instances to a single label, preventing cross-context generalization."
      },
      "correct_answer": "B",
      "source_article": "Abstraction",
      "x": 1.2697399854660034,
      "y": 1.1056206226348877,
      "concepts_tested": [
        "Concept 1: Abstraction as selective filtering of information to retain only aspects relevant for a purpose.",
        "Concept 2: Type-token distinction as an example of levels of abstraction (e.g., 'ball' vs. 'leather soccer ball').",
        "Concept 3: Abstraction as a bridge to language and semantics, mapping particular experiences onto general concepts and connecting with metaphor and general semantics."
      ],
      "parent_concepts": [
        "Concept 2: Composability as a mechanism that enables modules to be combined to build larger systems (e.g., in functional programming)."
      ],
      "parent_articles": [
        "Modularity"
      ]
    },
    {
      "question": "Why does treating the capital stock as a heterogeneous pool of tangible and intangible assets matter for understanding how capital contributes to production?",
      "options": {
        "A": "It implies any asset can instantly substitute for any other in providing services, making the asset mix irrelevant.",
        "B": "It implies different assets deliver different flows of productive services, have different depreciation/marginal-product profiles, and thus the composition of the stock shapes the total capital services available over time.",
        "C": "It implies intangible assets do not provide any productive services and can be ignored in analysis.",
        "D": "It implies that capital and labor are perfect substitutes regardless of the asset mix."
      },
      "correct_answer": "B",
      "source_article": "Capital (economics)",
      "x": 1.3241292238235474,
      "y": 0.9401755332946777,
      "concepts_tested": [
        "Concept 1: Capital as a produced input that provides productive services over multiple production cycles, distinguishing it from one-time-use inputs.",
        "Concept 2: The capital stock as a heterogeneous pool of tangible and intangible assets that collectively supply capital services.",
        "Concept 3: Capital as a core factor of production alongside labor, represented in production functions (e.g., Q = f(L, K)) where capital (K) interacts with labor (L) to determine output."
      ],
      "parent_concepts": [
        "Concept 1: Human capital as a productive input in the production process; investments (education, training, health) increase outputs."
      ],
      "parent_articles": [
        "Human capital"
      ]
    },
    {
      "question": "In Hart's theory of the legal system, the rule of recognition serves as a shared criterion for legal validity. Why is this rule essential for making a diverse set of official pronouncements function as a single legal system, even when individual officials may disagree with particular rules?",
      "options": {
        "A": "Because it provides a common social criterion that officials publicly accept as the standard for validity, so compliance is based on social practice rather than personal belief about each rule.",
        "B": "Because it enforces obedience to a single sovereign who determines which pronouncements count as law.",
        "C": "Because it grounds legality in a universal moral order that all officials rationally endorse.",
        "D": "Because it ensures that all rules originate from an underlying basic norm."
      },
      "correct_answer": "A",
      "source_article": "Legal system",
      "x": 1.2197402715682983,
      "y": 0.8225279450416565,
      "concepts_tested": [
        "Rule of recognition and legal validity (Hart\u2019s concept of a shared rule that validates legal pronouncements)",
        "Foundational bases of legal systems (sovereignty-based vs. norm-based foundations, e.g., Austin\u2019s sovereign legislator vs. Kelsen\u2019s basic norm)",
        "Legal pluralism and cross-system relationships (overlapping authorities, indigenous/customary laws, federal and international law interactions)"
      ],
      "parent_concepts": [
        "Concept 1: The role of commercial law in creating orderly, enforceable, and predictable exchanges to support fair competition and public trust."
      ],
      "parent_articles": [
        "Commercial law"
      ]
    },
    {
      "question": "Under the empirical risk minimization objective, how does increasing model capacity influence generalization, and what mechanism determines when higher capacity helps or hurts?",
      "options": {
        "A": "It always reduces bias and thus guarantees better generalization as dataset size grows.",
        "B": "It reduces training error but never affects test error, so generalization remains the same.",
        "C": "It can reduce training error, but if the model becomes too flexible relative to data, it can increase test error due to high variance; generalization improves only when data is plentiful or regularization controls capacity.",
        "D": "It changes the optimization algorithm's convergence speed but not the model's predictive performance."
      },
      "correct_answer": "C",
      "source_article": "Machine learning",
      "x": 1.6032602787017822,
      "y": 1.13204026222229,
      "concepts_tested": [
        "Concept 1: Generalization from training data and empirical risk minimization as the core objective of ML.",
        "Concept 2: ML as a synthesis of statistics and optimization, with deep learning (neural networks) as a major subfield that leverages these foundations to improve performance.",
        "Concept 3: Theoretical framework of probably approximately correct (PAC) learning that provides formal, mathematical grounding for describing ML and its relation to empirical risk minimization."
      ],
      "parent_concepts": [
        "Concept 1: Supervised versus unsupervised learning in pattern recognition and the role of labeled training data.",
        "Concept 2: The probabilistic, \"most likely\" matching objective in pattern recognition, including handling statistical variation versus exact pattern matching.",
        "Concept 3: The types of patterns identified (e.g., clusters, anomalies, dependencies such as association rules) and the notion that these patterns serve as succinct summaries for further analysis or predictive tasks.",
        "Concept 2: Bagging, boosting, and stacking represent distinct mechanisms for creating and aggregating diverse base models to form the ensemble."
      ],
      "parent_articles": [
        "Pattern recognition",
        "Pattern recognition",
        "Data mining",
        "Ensemble learning"
      ]
    },
    {
      "question": "Why is data mining regarded as the analysis step in the knowledge discovery process and distinct from data collection/preparation and interpretation?",
      "options": {
        "A": "Because it is the only step that involves cleaning and normalizing data before any modeling.",
        "B": "Because it applies machine learning and statistical models to uncover previously unknown, interesting patterns in the data, whereas collection/preparation focuses on obtaining and cleaning data, and interpretation focuses on explaining and presenting findings.",
        "C": "Because it is responsible for designing database schemas and indexes.",
        "D": "Because it is identical to data analysis, which only tests hypotheses on a fixed dataset."
      },
      "correct_answer": "B",
      "source_article": "Data mining",
      "x": 1.4913935661315918,
      "y": 1.1000699996948242,
      "concepts_tested": [
        "Concept 1: Data mining is the analysis step within the knowledge discovery in databases (KDD) process and is distinct from data collection/preparation and interpretation.",
        "Concept 2: The objective of data mining is to uncover previously unknown, interesting patterns (such as clusters, anomalies, and associations) in large data sets using machine learning and statistics.",
        "Concept 3: Data mining relies on database techniques and is part of an end-to-end workflow that includes preprocessing, model/inference considerations, post-processing, visualization, and updating (i.e., not the entire data pipeline)."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does pattern recognition aim to assign the most probable label given the observed data, and how does accounting for statistical variation enable robust inference?",
      "options": {
        "A": "Because real-world observations are noisy and come from a distribution; probabilistic reasoning (likelihood plus priors) combines evidence and prior knowledge to select the label that is most plausible overall, yielding robustness to variation.",
        "B": "Because pattern recognition relies on exact matching to a fixed set of templates, which would not tolerate noise and variation.",
        "C": "Because the method only uses unlabeled data and unsupervised clustering to decide labels without any prior information.",
        "D": "Because it guarantees perfect accuracy by exhaustively checking all possible patterns for a perfect match."
      },
      "correct_answer": "A",
      "source_article": "Pattern recognition",
      "x": 1.5920357704162598,
      "y": 1.1343209743499756,
      "concepts_tested": [
        "Concept 1: Inference under uncertainty \u2014 pattern recognition aims to assign labels by the most likely match while accounting for statistical variation.",
        "Concept 2: Relationships and distinctions \u2014 how pattern recognition relates to, and differs from, related tasks (classification, regression, sequence labeling, parsing) and from pattern matching.",
        "Concept 3: Learning from data \u2014 the role of labeled training data, supervised vs unsupervised methods, and the connection to machine learning and data mining."
      ],
      "parent_concepts": [
        "Concept 3: The types of patterns identified (e.g., clusters, anomalies, dependencies such as association rules) and the notion that these patterns serve as succinct summaries for further analysis or predictive tasks."
      ],
      "parent_articles": [
        "Data mining"
      ]
    },
    {
      "question": "How does cross-functional integration across operations, supply chain, marketing, and finance, and collaboration with suppliers and technology, influence the effectiveness of capacity planning and meeting customer requirements during a new product launch?",
      "options": {
        "A": "It ensures each function optimizes its own goals, reducing cross-functional constraints.",
        "B": "It creates a shared understanding of demand, process capabilities, and constraints, enabling synchronized decisions on capacity, inventory, and quality to satisfy customers.",
        "C": "It allows marketing to dictate manufacturing schedules without considering production constraints.",
        "D": "It guarantees accurate demand forecasts and zero stockouts."
      },
      "correct_answer": "B",
      "source_article": "Operations management",
      "x": 1.3467828035354614,
      "y": 0.9789422750473022,
      "concepts_tested": [
        "Concept 1: Transformation of inputs into outputs with a focus on efficiency and meeting customer requirements (resources, processes, outputs).",
        "Concept 2: The role of design decisions (product design, process design, capacity, facilities, quality management) in shaping operational performance.",
        "Concept 3: Strategic and operational integration, including cross-functional alignment with other functions (supply chains, marketing, finance, HR) and collaboration with suppliers and technology."
      ],
      "parent_concepts": [
        "Resource leveling as a mechanism to smooth demand and supply, including data inputs (demands, resource configurations, supply forecasts) and trade-offs (service level vs. cost)."
      ],
      "parent_articles": [
        "Resource management"
      ]
    },
    {
      "question": "Interdepartmental coordination and trade-offs are used in supply chain management to minimize total costs. Which explanation best describes how this mechanism works in practice?",
      "options": {
        "A": "By forcing each department to optimize its own targets, the system inevitably achieves global cost reduction through market incentives.",
        "B": "By aligning incentives and sharing information so that decisions reflect the marginal costs of inventory (holding costs, obsolescence) and the marginal benefits (meeting demand, avoiding stockouts), enabling choices that minimize the overall cost across the chain.",
        "C": "By eliminating all buffers and safety stock, thereby always reducing total inventory costs regardless of demand variability.",
        "D": "By centralizing all decision-making into one manager who unilaterally dictates actions across planning, sourcing, production, and logistics."
      },
      "correct_answer": "B",
      "source_article": "Supply chain management",
      "x": 1.388537883758545,
      "y": 0.9845861196517944,
      "concepts_tested": [
        "End-to-end integration of material, information, and capital flows across planning, sourcing, production, and logistics to synchronize supply with demand and create net value.",
        "Interdepartmental coordination and trade-offs as a mechanism to minimize total supply-chain costs (e.g., balancing inventory levels between sales needs and warehouse cost constraints).",
        "Performance measurement and evolving SCM frameworks (including resilience, sustainability, risk management) as central to monitoring and guiding supply-chain activities."
      ],
      "parent_concepts": [
        "Resource leveling as a mechanism to smooth demand and supply, including data inputs (demands, resource configurations, supply forecasts) and trade-offs (service level vs. cost)."
      ],
      "parent_articles": [
        "Resource management"
      ]
    },
    {
      "question": "In stakeholder salience theory, managers judge which stakeholders matter by considering power (ability to influence outcomes), legitimacy (perceived validity of their claim), and urgency (time-sensitivity). Why would a stakeholder group with strong power and urgent needs but only weak legitimacy still be treated as salient by managers?",
      "options": {
        "A": "Because any two attributes guarantee that a stakeholder will be engaged with.",
        "B": "Because power provides leverage and urgency creates time pressure, making ignoring them risky even if legitimacy is weak.",
        "C": "Because legitimacy is the sole determinant of salience; without strong legitimacy, they cannot be salient.",
        "D": "Because urgency alone is sufficient to demand attention, regardless of power or legitimacy."
      },
      "correct_answer": "B",
      "source_article": "Stakeholder theory",
      "x": 1.329371690750122,
      "y": 0.9726212024688721,
      "concepts_tested": [
        "Concept 1: Stakeholder identification and salience (normative identification vs descriptive salience) and how managers determine which parties matter.",
        "Concept 2: Integrated strategic framework (combining resource-based view, market-based view, and a socio-political layer) to form stakeholder-centric strategy.",
        "Concept 3: Ethical/teleological rationale (prioritizing stakeholders\u2019 needs and CSR, challenging shareholder-centric models for long-term value)."
      ],
      "parent_concepts": [
        "Concept 2: The micro-environment focus on customers, partners, and competitors, and the emphasis on the customer market as central to marketing decisions."
      ],
      "parent_articles": [
        "Market environment"
      ]
    },
    {
      "question": "How do the three architectural stages (conceptual, logical, physical) function as a mechanism for modeling data from business concepts to implementable structures, and why does this arrangement support data integration across systems?",
      "options": {
        "A": "They lock the data design into a single representation early, ensuring uniform implementation across systems.",
        "B": "They provide a progressive abstraction that preserves business meaning in the conceptual model, defines relationships and constraints in the logical model, and then map these into concrete storage and processing structures in the physical model, enabling consistent interpretation and reliable data integration across diverse systems.",
        "C": "They separate data governance from data storage, so standards are defined only at the governance layer.",
        "D": "They prioritize hardware optimization and storage efficiency before defining data semantics, to maximize performance."
      },
      "correct_answer": "B",
      "source_article": "Data architecture",
      "x": 1.4246790409088135,
      "y": 1.0697664022445679,
      "concepts_tested": [
        "The role of data architecture in establishing standards to govern data and enable data integration across systems.",
        "The three architectural stages (conceptual, logical, physical) as a mechanism for modeling data from business concepts to implementable structures.",
        "The relationship between data architecture and broader enterprise planning/architecture, including how data artifacts map to qualities, applications, and locations and the emphasis on planning the target state."
      ],
      "parent_concepts": [
        "Concept 2: Architectural paradigms and trade-offs\u2014data warehouses with ETL (tight coupling, fast queries but less suitable for frequently updated data) vs mediated schema with loose coupling and real-time access (SOA), including their impact on synchronization and data freshness."
      ],
      "parent_articles": [
        "Data integration"
      ]
    },
    {
      "question": "In applied research, why is there a need to adapt methodological choices to real-world constraints (for example, forgoing random sampling) while still clearly reporting what was done and what this means for interpreting results?",
      "options": {
        "A": "to preserve internal validity under all circumstances",
        "B": "to acknowledge that pragmatic constraints can bias results and to allow users to correctly interpret limitations and appropriate scope of conclusions",
        "C": "to ensure results are generalizable to every setting",
        "D": "to avoid any bias by using flexible methods"
      },
      "correct_answer": "B",
      "source_article": "Applied science",
      "x": 1.3885056972503662,
      "y": 1.044348955154419,
      "concepts_tested": [
        "Concept 1: The primary aim of applied research is to translate existing theories and methods into practical, client- or market-oriented outcomes, distinguishing it from basic/pure research which seeks new theories.",
        "Concept 2: Real-world research requires flexibility in methodology (e.g., may forego random sampling) while maintaining transparency about methods and acknowledging the implications of relaxing strict standards.",
        "Concept 3: There are distinct applied-research types (action research, evaluation research, industrial research, gauging research), each with a specific practical or evaluative purpose (solving issues, informing decisions, creating new goods/services, assessing processes)."
      ],
      "parent_concepts": [
        "Concept 1: The research continuum from basic/bench science to preclinical to clinical/translational research, and how each stage connects to practical applications.",
        "application relationship: life-science discoveries contribute to health, agriculture, medicine, and pharmaceutical/food industries, showing the link between basic disciplines and real-world outcomes."
      ],
      "parent_articles": [
        "Medical research",
        "List of life sciences"
      ]
    },
    {
      "question": "Why is a diversified R&D portfolio essential for a firm pursuing future-oriented, high-risk development aimed at long-term competitive advantage?",
      "options": {
        "A": "It guarantees immediate profitability across all projects, reducing the need for long-term planning.",
        "B": "It spreads risk across multiple uncertain initiatives and aligns with a long-term horizon where breakthroughs may occur.",
        "C": "It ensures all projects will yield quick returns, accelerating the payback period.",
        "D": "It concentrates resources on a single breakthrough to maximize certainty of success."
      },
      "correct_answer": "B",
      "source_article": "Research and development",
      "x": 1.3481931686401367,
      "y": 0.9346787929534912,
      "concepts_tested": [
        "Concept 1: R&D as a future-oriented, high-risk activity aimed at developing new products/services, with an uncertain and non-immediate return on investment, enabling long-term competitive advantage.",
        "Concept 2: The link between R&D strategy and market/consumer needs (marketing-driven vs technology-driven development) and how market research and customer needs shape R&D direction.",
        "Concept 3: R&D governance and metrics (R&D intensity, patents, publications), including outsourcing and risk implications for organizations."
      ],
      "parent_concepts": [
        "Concept 1: The research continuum from basic/bench science to preclinical to clinical/translational research, and how each stage connects to practical applications.",
        "Concept 3: The relationship and progression among basic, preclinical, and clinical research within the drug development pipeline, including why pharmaceutical research is only a part of the broader medical research landscape."
      ],
      "parent_articles": [
        "Medical research",
        "Medical research"
      ]
    },
    {
      "question": "How does translational (bench-to-bedside) research function to connect basic science to clinical benefit, and why is pharmaceutical research only a subset of medical research?",
      "options": {
        "A": "It assumes basic discoveries automatically translate to patient care, thus bypassing safety testing.",
        "B": "It assesses whether mechanistic findings from basic science hold in human biology, guides trial design, and recognizes that medical research also includes diagnostics, devices, and non-pharmaceutical therapies beyond drugs.",
        "C": "It eliminates the need for preclinical studies by focusing solely on human trials.",
        "D": "It ensures all medical research is funded exclusively by industry."
      },
      "correct_answer": "B",
      "source_article": "Medical research",
      "x": 1.3226497173309326,
      "y": 0.9541388154029846,
      "concepts_tested": [
        "The research spectrum and translational bridge: how basic science leads to preclinical and clinical research, and the note that pharmaceutical research is only a subset of medical research.",
        "Ethics and governance as a guiding principle: the role of the Declaration of Helsinki and institutional review boards in shaping what research is permissible.",
        "Impact of medical research on health outcomes and ongoing challenges: how advances contribute to vaccines, treatments, and longevity, alongside challenges like antibiotic resistance and obesity."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why is the non-linear view of the scientific method more accurate than a fixed, linear sequence?",
      "options": {
        "A": "It enforces a single, universal order of steps that must be followed in all inquiries.",
        "B": "It acknowledges that researchers may need to revisit or revise hypotheses, methods, and interpretations as new data and biases emerge.",
        "C": "It ensures that once results are obtained, no further questions arise.",
        "D": "It eliminates the role of hypothetical reasoning in favor of empiricism alone."
      },
      "correct_answer": "B",
      "source_article": "Scientific method",
      "x": 1.33817720413208,
      "y": 1.0629783868789673,
      "concepts_tested": [
        "Falsifiability as a criterion for a meaningful, testable hypothesis",
        "Iterative, non-linear nature of the method: general principles with variable steps rather than a fixed sequence",
        "Empirical testing cycle: inductive hypothesizing from observations, predicting consequences, testing with experiments/statistics, and revising/discarding hypotheses based on results (with skepticism to mitigate cognitive bias)"
      ],
      "parent_concepts": [
        "Concept 1: Method choice shapes evidence and conclusions (the relationship between methods and what can be claimed as knowledge).",
        "Concept 2: Distinctions between quantitative and qualitative research (their goals, methods, and appropriate contexts) and the value of integrating them through mixed-methods.",
        "Theory construction criteria: conditions like consistency, generality, parsimony, and conditionality that govern robust, testable social theories.",
        "Concept 1: Epistemological divide shaping research method (positivist vs interpretivist)",
        "Concept 2: A core workflow in mathematical statistics involves selecting a model, checking its conditions/assumptions, and quantifying uncertainty (e.g., through confidence intervals).",
        "Systematic, bias-controlled inquiry as a core principle guiding how research is conducted",
        "Concept 3: Scientific knowledge in anatomy advances via empirical observation and cross-species comparison, challenging authorities when discrepancies arise.",
        "Concept 2: Falsifiability and the provisional nature of scientific claims (impossibility assertions are highly probable but not proven; counterexamples can refute theories)",
        "Concept 3: The theory\u2013measurement\u2013law relationship (use of mathematics/logic to translate observations into measurable statements and predictive laws)",
        "The criteria for a physical theory: agreement with empirical observations and the ability to make new, testable predictions.",
        "Different theoretical approaches in physics (phenomenologists, model-builders, effective theories) and their goals (fitting data, unification, abstraction) in creating and evaluating models.",
        "Concept 1: The research continuum from basic/bench science to preclinical to clinical/translational research, and how each stage connects to practical applications."
      ],
      "parent_articles": [
        "Methodology",
        "Methodology",
        "Social theory",
        "Social science",
        "Mathematical statistics",
        "Research",
        "Comparative anatomy",
        "Natural science",
        "Natural science",
        "Theoretical physics",
        "Theoretical physics",
        "Medical research"
      ]
    },
    {
      "question": "In astronomy, why is the iterative loop between observational data and theoretical modeling essential for advancing understanding?",
      "options": {
        "A": "Because observations can confirm any theory; models are only expansions of data.",
        "B": "Because theoretical models generate predictions that can be falsified by targeted observations; when observations match predictions, the model gains credibility; when not, the model is revised or replaced, and new predictions are generated, continuing the cycle.",
        "C": "Because only observational data are trustworthy, and theories should be adjusted to fit every data point without prediction.",
        "D": "Because once a model is built, future observations are unnecessary."
      },
      "correct_answer": "B",
      "source_article": "Astronomy",
      "x": 2.007233142852783,
      "y": 1.3890222311019897,
      "concepts_tested": [
        "The relationship between observational astronomy and theoretical astronomy: how data collection leads to models and how models predict/explain observations, with a reciprocal validation loop.",
        "The role of interdisciplinary physical principles (physics, mathematics, chemistry) in explaining the origins and evolution of celestial objects and phenomena.",
        "The scope and integration of cosmology within astronomy: studying the universe as a whole and how cosmology connects to broader astronomical inquiry."
      ],
      "parent_concepts": [
        "Formation and evolution (mechanisms driving the formation, dynamics, and history of planets and planetary systems)"
      ],
      "parent_articles": [
        "Planetary science"
      ]
    },
    {
      "question": "How does the theory\u2013observation loop in astrophysics explain progress in understanding celestial objects, and what role do multi-wavelength observations play in resolving model ambiguities?",
      "options": {
        "A": "Observations directly validate models without invoking physical reasoning; multi-wavelength data are redundant in testing predictions.",
        "B": "Theories propose testable predictions about observable properties; observations test those predictions; when discrepancies arise, models are revised; multi-wavelength observations provide independent constraints that help break degeneracies between parameters like temperature, composition, and density.",
        "C": "Observations merely record numbers that must fit a pre-existing model; multi-wavelength data merely add more numbers without changing the model.",
        "D": "The loop proceeds linearly from data collection to theory finalization; once a model is chosen, observations are no longer needed to validate it, and different wavelengths cannot change the outcome."
      },
      "correct_answer": "B",
      "source_article": "Astrophysics",
      "x": 2.0456128120422363,
      "y": 1.409057855606079,
      "concepts_tested": [
        "The aim of astrophysics: uncovering the intrinsic nature of celestial objects using physics (what they are, not just where they are).",
        "Interdisciplinary methodology: applying multiple physics disciplines across the electromagnetic spectrum to determine properties like luminosity, temperature, density, and composition.",
        "Theory\u2013observation loop: development of theoretical models (e.g., cosmology, magnetohydrodynamics, relativity) guided by and tested against observational data."
      ],
      "parent_concepts": [
        "Formation and evolution (mechanisms driving the formation, dynamics, and history of planets and planetary systems)"
      ],
      "parent_articles": [
        "Planetary science"
      ]
    },
    {
      "question": "Why does mantle convection in the asthenosphere cause lithospheric plates to move and organize into plate tectonics, and how does this convection pattern explain both divergent and convergent boundary behavior?",
      "options": {
        "A": "The lithosphere moves because the mantle radiates heat, causing plates to drift upward independently of mantle flow, with no connection to boundary formation.",
        "B": "Mantle convection causes radial expansion of mantle beneath the plates, pushing all plates outward uniformly and creating divergent boundaries as a byproduct of this global expansion.",
        "C": "The mantle\u2019s convection drives horizontal flow in the asthenosphere that shears and drags the rigid lithospheric plates; upwelling zones promote divergence and crust creation, while cooling, sinking slabs at subduction zones pull plates downward, enabling convergence and subduction.",
        "D": "Plate motion arises solely from gravitational settling of the entire planet; mantle convection has no role in moving plates or forming boundaries."
      },
      "correct_answer": "C",
      "source_article": "Earth science",
      "x": 1.6335545778274536,
      "y": 0.9840663075447083,
      "concepts_tested": [
        "Mantle convection drives lithospheric plate movement and the overall framework of plate tectonics.",
        "Plate boundary types (divergent, convergent, transform) govern crust creation/destruction and are associated with earthquakes.",
        "Subduction at convergent boundaries links plate interactions to seismic activity (and associated geological processes)."
      ],
      "parent_concepts": [
        "The sedimentary cycle: how weathering/erosion, transport, deposition, and diagenesis interact to form sedimentary rocks.",
        "Uniformitarianism and analog reasoning: using modern processes and structures to reconstruct past environments from the rock record."
      ],
      "parent_articles": [
        "Sedimentology",
        "Sedimentology"
      ]
    },
    {
      "question": "Uniformitarianism is often described as a foundational, untestable postulate that underpins scientific inquiry. Why is it treated as a methodological assumption rather than an empirically verifiable fact?",
      "options": {
        "A": "Because it claims past processes were exactly the same as present processes and that can be directly tested in the lab using ancient samples.",
        "B": "Because it cannot be directly proven by experiments about the distant past, yet it provides a stable, general basis to interpret observations and infer historical processes from present-day evidence.",
        "C": "Because it asserts that only gradual changes occur and excludes any use of catastrophic events.",
        "D": "Because it asserts that natural laws change over time and must be recalibrated with every new discovery."
      },
      "correct_answer": "B",
      "source_article": "Uniformitarianism",
      "x": 1.7873730659484863,
      "y": 0.9236931204795837,
      "concepts_tested": [
        "Invariance of natural laws and cause-and-effect across time and space (uniformitarianism as a guiding principle).",
        "The geological corollary and its evolution: \"the present is the key to the past\" and the shift from strict gradualism to a more nuanced view including catastrophes.",
        "Uniformitarianism as a foundational, untestable postulate that underpins scientific inquiry (a methodological assumption rather than an empirically verifiable fact)."
      ],
      "parent_concepts": [
        "Uniformitarianism and analog reasoning: using modern processes and structures to reconstruct past environments from the rock record."
      ],
      "parent_articles": [
        "Sedimentology"
      ]
    },
    {
      "question": "Why does classical physics emerge as an effective description from quantum mechanics in everyday regimes (low speeds, large distances), and what mechanism primarily ensures that quantum interference does not spoil this classical picture?",
      "options": {
        "A": "Wavefunction collapse during observation creates definite outcomes which align with Newtonian trajectories in all macroscopic systems.",
        "B": "Ehrenfest's theorem guarantees Newton's laws hold exactly for all quantum systems, so classical physics is simply a restatement of averaged quantum dynamics.",
        "C": "When the action S of a system is much larger than Planck's constant \u0127, contributions from non-classical paths cancel out due to the stationary-phase (destructive interference) and interactions with the environment (decoherence) suppress quantum superpositions, yielding effectively classical trajectories.",
        "D": "Quantum entanglement becomes strong in macroscopic systems, forcing a single classical path to be chosen by the universe."
      },
      "correct_answer": "C",
      "source_article": "Modern physics",
      "x": 1.729216456413269,
      "y": 1.1050240993499756,
      "concepts_tested": [
        "The classical limit: how and why classical physics emerges from quantum and relativistic descriptions at low speeds and large distances.",
        "Relationships and unification among theories: how quantum mechanics relates to special relativity, why combining quantum mechanics with general relativity is challenging, and what the Standard Model covers and does not.",
        "Regime-dependent descriptions and statistics: how quantum effects lead to different distributions (Fermi\u2013Dirac/Bose\u2013Einstein) versus Maxwell\u2013Boltzmann, and when these transitions signal the need for modern physics."
      ],
      "parent_concepts": [
        "Concept 2: Field theories describe how field values evolve in space and time and admit both classical-field and quantum-field (field-quanta) descriptions, linking to particles."
      ],
      "parent_articles": [
        "Field (physics)"
      ]
    },
    {
      "question": "Consider a charged particle of charge q moving with velocity v in a region with a magnetic field B and no electric field. Which statement best explains how the magnetic field affects the particle's trajectory, and why this happens according to the Lorentz force law?",
      "options": {
        "A": "The magnetic field exerts a force in the same direction as the velocity, increasing the particle's speed and causing straight-line motion.",
        "B": "The magnetic field exerts a force perpendicular to the particle's velocity and to B, with magnitude |F| = |q| |v| |B| sin(phi), where phi is the angle between v and B; this force changes the direction but not the speed, leading to circular or helical motion.",
        "C": "The magnetic field extracts energy from the particle, causing circular motion with decreasing speed.",
        "D": "The magnetic field only acts if the particle is at rest; moving charges are unaffected by B."
      },
      "correct_answer": "B",
      "source_article": "Electromagnetism",
      "x": 1.793031930923462,
      "y": 1.0765131711959839,
      "concepts_tested": [
        "The unification of electric and magnetic phenomena into a single electromagnetic field and how charges/ currents relate to electric and magnetic fields.",
        "Maxwell's equations as the framework that describe relations between E, B, charges, and currents and predict electromagnetic waves.",
        "The Lorentz force as the microscopic mechanism by which moving charges experience force in electric and magnetic fields, linking field concepts to particle motion."
      ],
      "parent_concepts": [
        "Concept 1: The coupled dynamics of electric and magnetic fields (curl relations) and how changes in one field induce the other, constituting the mechanism by which E and B interact."
      ],
      "parent_articles": [
        "Maxwell's equations"
      ]
    },
    {
      "question": "In a framework where the innovation process is viewed as an iterative cycle of search, select, implement, and capture, how does this iterative structure fundamentally enable alignment among organizational capabilities, technological possibilities, and market opportunities?",
      "options": {
        "A": "It enforces a linear progression that prevents revisiting earlier assumptions, ensuring speed.",
        "B": "It establishes a learning loop where each iteration re-assesses goals in light of new information, thereby adjusting resource commitments, technical feasibility, and market value to maintain integrated alignment.",
        "C": "It separates the domains of organization, technology, and market so that changes in one domain do not influence the others.",
        "D": "It shifts emphasis entirely to external idea sourcing, making internal capabilities less relevant."
      },
      "correct_answer": "B",
      "source_article": "Innovation management",
      "x": 1.3552931547164917,
      "y": 0.9851201176643372,
      "concepts_tested": [
        "Concept 1: Innovation management uses a set of tools to coordinate collaboration across managers, workers, and users, creating a common understanding of processes and goals.",
        "Concept 2: The innovation process is iterative and integrative, framed as a cycle of search, select, implement, and capture that links organization, technology, and market.",
        "Concept 3: Innovation development can be driven by push (supply-side) or pull (demand-side) forces, shaping how ideas are generated and brought to market."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In ecological economics, strong sustainability holds that certain natural capital stocks cannot be substituted by human-made capital. How does this principle influence how we evaluate and design long-term policy compared to weak sustainability?",
      "options": {
        "A": "It implies manufactured capital can fully offset losses in natural capital, so policy should focus on maximizing total wealth, regardless of its stock composition.",
        "B": "It implies some ecosystem services are non-substitutable or only imperfectly substitutable by manufactured capital, so policy should aim to maintain or enhance natural capital stocks to avoid irreversible welfare losses.",
        "C": "It implies discounting future benefits is the only ethical concern, so natural capital can be ignored if present costs are low in present value terms.",
        "D": "It implies natural capital is only relevant for aesthetics, not production, so policy can ignore ecosystem services in growth planning."
      },
      "correct_answer": "B",
      "source_article": "Ecological economics",
      "x": 1.2351123094558716,
      "y": 0.9409351348876953,
      "concepts_tested": [
        "Concept 1: Economy as a subsystem of Earth's ecosystem with emphasis on natural capital and strong vs. weak sustainability",
        "Concept 2: Intergenerational equity, time, irreversibility, uncertainty, and normative valuation in economic analysis",
        "Concept 3: Transdisciplinary methodology and relationships with related schools (environmental/feminist economics, ecosocialism) and alternative analytical approaches (e.g., positional analysis)"
      ],
      "parent_concepts": [
        "Concept 2: Human action and dynamic value of natural capital. Natural capital can be improved or degraded by human activities, challenging the view of it as fixed like traditional land.",
        "Concept 3: Valuation and assessment frameworks. Methods like natural capital asset checks and the issue of unpriced natural capital influence policy and economic well-being by making the ecological contributions visible or invisible in decision-making."
      ],
      "parent_articles": [
        "Natural capital",
        "Natural capital"
      ]
    },
    {
      "question": "In the view that information is \u201ca distinction that makes a difference,\u201d which scenario best demonstrates how information functions within a system, and why is that distinction essential?",
      "options": {
        "A": "A random sequence of bits that never influences any process is treated as information because it contains data that could be interpreted.",
        "B": "A weather sensor reading that changes the thermostat\u2019s behavior, causing the environment to respond differently, illustrates information because the distinction (the reading) makes a difference to the system\u2019s outcome.",
        "C": "A static state that exists but never interacts with any agent or process, which therefore cannot influence results, is information because it reflects an underlying state of the world.",
        "D": "A perfectly correlated pair of events that never interacts with any mechanism, which counts as information since the correlation distinguishes possible histories."
      },
      "correct_answer": "B",
      "source_article": "Philosophy of information",
      "x": 1.2729566097259521,
      "y": 1.0557234287261963,
      "concepts_tested": [
        "Concept 1: Floridi\u2019s four kinds of information (information about, information as something, information for something, information in something) and their interrelations and applications.",
        "Concept 2: Peirce\u2019s semiotic view of information as it relates to signs, denotation/extension, and connotation/comprehension (how information is tied to meaning and symbolic communication).",
        "Concept 3: The principle that information is \u201ca distinction that makes a difference\u201d (and relatedly, how informational content can influence systems and outcomes)."
      ],
      "parent_concepts": [
        "Concept 3: Foundational limits and interdisciplinary connections (e.g., G\u00f6del\u2019s incompleteness, information theory, learning models) that influence theoretical CS."
      ],
      "parent_articles": [
        "Theoretical computer science"
      ]
    },
    {
      "question": "According to the view of power as \"the production, in and through social relations, of effects that shape the capacities of actors to determine their circumstances and fate,\" which best explains how power can grow even when material resources remain constant?",
      "options": {
        "A": "By coercively forcing others to comply with demands, increasing control over events.",
        "B": "By reconstituting actors' identities and social relations so their preferences, interests, and practices align with the power holder, creating new capacities.",
        "C": "By disseminating persuasive arguments that freely convince others to change their minds, thereby altering outcomes.",
        "D": "By accumulating more physical resources, which automatically translates into greater influence."
      },
      "correct_answer": "B",
      "source_article": "Power (international relations)",
      "x": 1.2041833400726318,
      "y": 0.9048880338668823,
      "concepts_tested": [
        "Concept 1: Power as a social process and social relation that not only yields material advantages but also structures actors\u2019 identities and capacities.",
        "Concept 2: Polarity (unipolar, bipolar, multipolar) as a distribution of power in the international system and its effects on state behavior and inter-state dynamics.",
        "Concept 3: Multiple conceptualizations of power (goal of states/leaders, influence/control outcomes, victory/security, resource/control, status) and the methodological implication that power is production of effects through social relations (as argued by Barnett & Duvall), not mere causality or persuasion."
      ],
      "parent_concepts": [
        "Imperialism as a policy of maintaining/extending power through expansion, using both hard power (military/economic) and soft power (diplomatic/cultural influence)."
      ],
      "parent_articles": [
        "Imperialism"
      ]
    },
    {
      "question": "In a closed-loop automation control system, why does comparing the measured process variable to the desired setpoint and using the resulting error to adjust the input help keep the process near the setpoint, even when disturbances occur?",
      "options": {
        "A": "It increases the input in the direction that makes the process diverge from the setpoint, ensuring rapid change.",
        "B": "It uses the measured error to adjust the control input so as to reduce the error, pulling the process back toward the setpoint despite disturbances.",
        "C": "It keeps the input constant and relies on disturbances to cancel themselves.",
        "D": "It replaces the setpoint with the actual measurement, so the system automatically matches the current value."
      },
      "correct_answer": "B",
      "source_article": "Automation",
      "x": 1.5821770429611206,
      "y": 1.0446301698684692,
      "concepts_tested": [
        "Concept 1: Closed-loop control and negative feedback maintain a process at its setpoint by comparing sensed values to desired values and correcting input.",
        "Concept 2: Integration of diverse technologies (mechanical, hydraulic, pneumatic, electrical, electronic devices, and computers) to predetermine decisions and embody them in automated systems.",
        "Concept 3: Disturbance rejection and stability as central aims of control theory, enabling automation to function despite disturbances."
      ],
      "parent_concepts": [
        "Concept 2: System architecture and data flow (sensors -> controllers like PLC/DCS -> actuators) and the role of the HMI."
      ],
      "parent_articles": [
        "Industrial process control"
      ]
    },
    {
      "question": "Which statement best captures how a nuanced theory of reductionism accounts for emergent higher-level features that arise from the interactions of parts?",
      "options": {
        "A": "Emergent properties show that higher-level explanations are fundamentally non-reducible, hence any reductionist program must be abandoned.",
        "B": "Reductionism and emergentism are incompatible; once emergence occurs, lower-level explanations cease to be sufficient.",
        "C": "A nuanced reductionism holds that higher-level features are grounded in the parts and their interactions; such features may not be captured by naive lists of components, but they can be explained or derived from lower-level mechanisms via translation, derivation, and explanation.",
        "D": "Emergent properties prove that only the whole-system description matters, and there is no meaningful way to refer to the system\u2019s parts."
      },
      "correct_answer": "C",
      "source_article": "Reductionism",
      "x": 1.2085456848144531,
      "y": 1.0944805145263672,
      "concepts_tested": [
        "Concept 1: The three-part division of reductionism (ontological, methodological, theory reductionism) and the subcomponents of theory reduction (translation, derivation, explanation).",
        "Concept 2: The relationship between reductionism and emergentism, including how higher-level features can arise from parts despite reductionist aims.",
        "Concept 3: Epistemological/conceptual reductionism (replacement of facts or entities across discourses) and the distinction between ontological and epistemological reductionism."
      ],
      "parent_concepts": [
        "Scale-based focus: differentiation between micro-scale branches (molecular biology, biochemistry) and larger-scale branches (cytology, immunology, ecology), illustrating how scope shapes study questions."
      ],
      "parent_articles": [
        "List of life sciences"
      ]
    },
    {
      "question": "In genetic engineering, why is it necessary to place a gene under the control of a promoter that matches the host organism's transcription machinery?",
      "options": {
        "A": "Because promoters from other species are always ineffective, and only host promoters can drive expression.",
        "B": "Because the promoter provides binding sites for the host's RNA polymerase and transcription factors, enabling transcription of the inserted gene in that host.",
        "C": "Because the promoter changes the gene's codon usage to match the host's translation system.",
        "D": "Because expression depends solely on the coding sequence; regulatory elements do not influence whether the gene is read."
      },
      "correct_answer": "B",
      "source_article": "Biotechnology",
      "x": 1.8555514812469482,
      "y": 1.0345253944396973,
      "concepts_tested": [
        "Concept 1: The core principle of biotechnology\u2014harnessing biological systems and organisms to perform tasks or produce valuable substances.",
        "Concept 2: Mechanisms/techniques\u2014genetic engineering, tissue culture, and fermentation as methods that enable manipulation and production in biotechnology.",
        "Concept 3: Relationships to applications and society\u2014how biotechnology translates to medicine, agriculture, and environmental solutions, and how ethical considerations and regulation shape its use."
      ],
      "parent_concepts": [
        "Concept 1: Mechanisms of genetic modification (insertion, knockout, use of recombinant DNA/synthetic DNA; random vs targeted genome integration)"
      ],
      "parent_articles": [
        "Genetic engineering"
      ]
    },
    {
      "question": "Why is the requirement F(g \u2218 f) = F(g) \u2218 F(f) essential for a functor between categories?",
      "options": {
        "A": "It ensures that the image of a composed chain equals the composition of the images in the same order, so the functor preserves how morphisms compose in the source category.",
        "B": "It guarantees that identity morphisms map to identity morphisms.",
        "C": "It ensures objects are mapped to objects with the same underlying structure, which is necessary for maintaining labels.",
        "D": "It ensures contravariant functors flip the direction of arrows."
      },
      "correct_answer": "A",
      "source_article": "Category theory",
      "x": 1.6683765649795532,
      "y": 1.214179515838623,
      "concepts_tested": [
        "Concept 1: Category structure (objects, morphisms, composition, identity) and how morphisms compose, generalizing function composition (e.g., a monoid as a single-object category).",
        "Concept 2: Functors as structure-preserving mappings between categories (mapping objects to objects and morphisms to morphisms while preserving sources/targets; including contravariant functors).",
        "Concept 3: Natural transformations as morphisms between functors, i.e., higher-level relationships between functors."
      ],
      "parent_concepts": [
        "Varieties as equational classes: Collections of algebras defined by a shared set of identities, linking the specified axioms to the resulting family of structures."
      ],
      "parent_articles": [
        "Universal algebra"
      ]
    },
    {
      "question": "In a welfare state where programs are delivered through public institutions and private partners across different territorial levels, how does coordinated governance influence the realization of equal opportunity and equitable wealth distribution?",
      "options": {
        "A": "It ensures that private providers compete on price alone, driving down costs.",
        "B": "It aligns eligibility criteria and service standards across levels and actors, reducing fragmentation that could otherwise undermine universal access.",
        "C": "It eliminates the need for public responsibility by shifting all duties to private partners.",
        "D": "It guarantees that all services are delivered exclusively through central government agencies."
      },
      "correct_answer": "B",
      "source_article": "Welfare state",
      "x": 1.2394816875457764,
      "y": 0.9074622988700867,
      "concepts_tested": [
        "The welfare state aims to protect and promote citizens' economic and social well-being through equal opportunity, equitable wealth distribution, and public responsibility.",
        "Governance mechanisms: delivery of welfare programs via public institutions and private partners across different territorial levels (public-private partnerships and multi-level administration).",
        "Evolution and drivers: expansion tied to historical events (WWI, the Great Depression, WWII) and the shift toward fuller forms after World War II within a mixed-economy framing."
      ],
      "parent_concepts": [
        "Concept 3: Mechanism by which social policy affects well-being through shaping the distribution of and access to goods and resources (and its engagement with wicked problems)"
      ],
      "parent_articles": [
        "Social policy"
      ]
    },
    {
      "question": "How does increasing atmospheric CO2 from human activities lead to ocean acidification and alter the balance of carbon fluxes among the major reservoirs?",
      "options": {
        "A": "More atmospheric CO2 raises the air\u2013sea partial pressure gradient, driving CO2 into surface waters where it forms carbonic acid, lowers pH, reduces carbonate ion availability, and changes how oceans take up and store carbon.",
        "B": "Excess atmospheric CO2 is rapidly transformed into solid carbonates by oceanic organisms, removing it from both air and water and stabilizing the cycle.",
        "C": "Atmospheric CO2 is split into carbon and oxygen in the upper atmosphere, with carbon sinking to the deep ocean while oxygen escapes back to space, leaving the cycle unchanged.",
        "D": "The carbon cycle is entirely buffered by weathering, so additional CO2 in the atmosphere has no effect on ocean chemistry or inter-reservoir fluxes."
      },
      "correct_answer": "A",
      "source_article": "Carbon cycle",
      "x": 1.6834536790847778,
      "y": 0.9108536839485168,
      "concepts_tested": [
        "Concept 1: Fast carbon cycle vs. slow (deep/geological) carbon cycle: distinct timescales, reservoirs, and pathways that move carbon between atmosphere, biosphere, oceans, sediments, and Earth's interior.",
        "Concept 2: Human perturbations alter natural carbon flows: land-use change and burning fossil fuels increase atmospheric CO2, driving climate change and ocean acidification.",
        "Concept 3: Interlinked exchange processes and balance: carbon transfers are governed by chemical, physical, geological, and biological processes, with natural flows tending toward a balanced state absent human influence."
      ],
      "parent_concepts": [
        "Concept 2: Land-use changes and the carbon cycle (fast vs slow cycles) significantly influence atmospheric CO2 levels and warming, with agriculture, deforestation, and methane as key components."
      ],
      "parent_articles": [
        "Climate change mitigation"
      ]
    },
    {
      "question": "How do policy instruments such as carbon pricing and renewable portfolio standards cause a shift in the energy mix toward lower-emission options?",
      "options": {
        "A": "They primarily reduce total energy demand uniformly across all sources.",
        "B": "They alter the relative economics of different energy sources, changing investment decisions toward low-emission technologies.",
        "C": "They guarantee equal subsidies to all energy sources, preserving the status quo.",
        "D": "They impose direct limits on consumer energy use, independent of fuel type."
      },
      "correct_answer": "B",
      "source_article": "Energy policy",
      "x": 1.4027520418167114,
      "y": 0.8304596543312073,
      "concepts_tested": [
        "Concept 1: Energy policy decisions influence greenhouse gas emissions through infrastructure choices (e.g., coal vs. renewables) and through regulation and standards.",
        "Concept 2: Policy instruments (carbon pricing, renewable portfolio standards, energy efficiency mandates, subsidies/incentives) act as mechanisms that drive shifts in the energy mix and decarbonization.",
        "Concept 3: International agreements and global climate frameworks (e.g., Paris Agreement, IRA, European Green Deal) shape national energy strategies and decarbonization trajectories by aligning domestic actions with global targets."
      ],
      "parent_concepts": [
        "Concept 1: Fossil-fuel dependence shapes political resistance and policy outcomes"
      ],
      "parent_articles": [
        "Politics of climate change"
      ]
    },
    {
      "question": "Why can crossing a climate tipping point lead to abrupt, large-scale changes in the climate system even if external forcing is later reduced, and how do inertia and adaptation limits influence the outcome?",
      "options": {
        "A": "Because all climate processes respond linearly with no memory, so reversing forcing immediately undoes any change.",
        "B": "Because many climate components interact nonlinearly with long response times; crossing a threshold can shift feedbacks to a stronger regime, creating a new, persistent state due to inertia, and adaptation limits can prevent complete protection against residual impacts.",
        "C": "Because tipping points cause all CO2 to be removed from the atmosphere as soon as forcing stops, so warming ends instantly.",
        "D": "Because adaptation measures fully compensate for any abrupt changes, eliminating any risk once a tipping point is reached."
      },
      "correct_answer": "B",
      "source_article": "Climate change",
      "x": 1.3633995056152344,
      "y": 0.8461888432502747,
      "concepts_tested": [
        "Concept 1: Greenhouse effect mechanism (how greenhouse gases like CO2 trap heat and drive global warming)",
        "Concept 2: Anthropogenic causal chain (fossil fuel use and deforestation increase CO2, leading to warming and cascading environmental and societal impacts)",
        "Concept 3: Tipping points and inertia (potential abrupt changes and long-lived effects, and the role of adaptation limits)"
      ],
      "parent_concepts": [
        "Concept 3: Human disturbance and climate feedbacks \u2014 how land-use changes and fossil fuel combustion increase atmospheric CO2, driving global warming and ocean acidification, and the role of carbon sinks/sequestration in modulating this balance."
      ],
      "parent_articles": [
        "Carbon cycle"
      ]
    },
    {
      "question": "Why does the absence of a global clock complicate coordinating a distributed system, and what mechanism is commonly used to reason about the ordering of events across nodes?",
      "options": {
        "A": "It prevents any ordering, requiring a single global lock across all nodes.",
        "B": "It prevents a single global total order; it relies on logical clocks (e.g., Lamport clocks or vector clocks) to capture causal relationships and reason about event ordering.",
        "C": "It makes coordination impossible, so the system cannot maintain consistency.",
        "D": "It allows perfect synchronization with GPS-based time, enabling immediate global consensus without extra coordination."
      },
      "correct_answer": "B",
      "source_article": "Distributed computing",
      "x": 1.4650269746780396,
      "y": 1.0990073680877686,
      "concepts_tested": [
        "The fundamental challenges in distributed systems: maintaining concurrency, the lack of a global clock, and handling independent component failures.",
        "Message-passing as the primary coordination mechanism, with examples of implementations (HTTP, RPC-like connectors, message queues).",
        "The relationships and trade-offs between distributed systems and monolithic architectures, including scalability, durability, changeability, and cost considerations."
      ],
      "parent_concepts": [
        "Service composition and discovery through metadata/protocols to build applications from existing services"
      ],
      "parent_articles": [
        "Service-oriented architecture"
      ]
    },
    {
      "question": "How do open standards enable true interoperability across diverse systems, and what mechanism makes the difference from mere compatibility?",
      "options": {
        "A": "Open standards are publicly available, collaboratively developed specifications that define not only data formats but shared semantics and reference models, so varied systems can interpret and act on exchanged information consistently, enabling end-to-end interoperability.",
        "B": "Open standards force a single vendor's protocol on all products, ensuring uniformity and thus interoperable behavior.",
        "C": "Open standards only specify syntax, not semantics, so multiple systems can exchange data but cannot interpret it meaningfully; this still counts as interoperability.",
        "D": "Open standards are expensive and exclusive, creating barriers that prevent widespread adoption and thereby ensuring only a few interoperable systems."
      },
      "correct_answer": "A",
      "source_article": "Interoperability",
      "x": 1.441236138343811,
      "y": 1.0597271919250488,
      "concepts_tested": [
        "Concept 1: Syntactic vs semantic interoperability and the requirement of a common information exchange reference model for semantic interoperability.",
        "Concept 2: The role of open standards in facilitating interoperability and the distinction between interoperability and mere compatibility.",
        "Concept 3: Cross-domain interoperability as an extension that involves multiple social, organizational, political, and legal entities impacting information exchange."
      ],
      "parent_concepts": [
        "Service composition and discovery through metadata/protocols to build applications from existing services"
      ],
      "parent_articles": [
        "Service-oriented architecture"
      ]
    },
    {
      "question": "How does robustness and potential self-repair arise in a self-organizing system where global order is produced by local interactions without external control?",
      "options": {
        "A": "It arises because a hidden central authority continuously adjusts local states to align with a global plan.",
        "B": "It arises because the global order comes from many local interactions, removing a single weak point; perturbations are absorbed locally and the system re-stabilizes via distributed feedback among components.",
        "C": "It arises only when energy input is strictly regulated by external agents that enforce redundancy and repair.",
        "D": "It arises because random fluctuations are always harmful and must be suppressed to maintain order."
      },
      "correct_answer": "B",
      "source_article": "Self-organization",
      "x": 1.6646040678024292,
      "y": 1.1113362312316895,
      "concepts_tested": [
        "Emergence and decentralization: global order arises from local interactions without external control, leading to robustness and potential self-repair.",
        "Four key ingredients/mechanisms: strong dynamical non-linearity with feedback, balance of exploitation and exploration, multiple interactions among components, and availability of energy to overcome entropy.",
        "Attractors and the role of noise: principles by Ashby and Foerster describe how systems move toward attractors and how random perturbations can facilitate reaching stable, robust states."
      ],
      "parent_concepts": [
        "Emergence from interacting components and non-linearity: how local rules and interactions give rise to global properties that are not reducible to the parts."
      ],
      "parent_articles": [
        "Complexity"
      ]
    },
    {
      "question": "Within the Integrative SIMCA framework, perceived collective efficacy is described as a necessary predictor that interacts with perceived injustice and group identity to determine collective action. How does this component conceptually shape whether people mobilize, and why?",
      "options": {
        "A": "Efficacy operates independently of injustice and identity and is the sole driver of mobilization.",
        "B": "Efficacy moderates the relationship such that mobilization occurs only when both injustice is high and identity is strong, but not otherwise.",
        "C": "Efficacy provides a necessary condition; beliefs that unified action can succeed are required for injustice- and identity-driven motivations to translate into actual mobilization, so without perceived efficacy action is unlikely even with injustice and identity present.",
        "D": "Efficacy is simply a downstream consequence of identity and does not influence the likelihood of mobilization directly."
      },
      "correct_answer": "C",
      "source_article": "Collective action",
      "x": 1.268159031867981,
      "y": 0.986206591129303,
      "concepts_tested": [
        "The Integrative SIMCA framework: injustice, efficacy, and identity are interrelated predictors of collective action, with subjective disadvantage potentially arising from perceptions regardless of objective reality.",
        "Injustice and group-based emotions as drivers: perceived injustice (relative deprivation) fosters emotions like anger that motivate collective action.",
        "Perceived collective efficacy as a necessary predictor: belief that unified action can achieve goals influences the likelihood of mobilization alongside injustice and identity."
      ],
      "parent_concepts": [
        "Concept 1: Interdependence and shared goals as the structural basis for teamwork and coordinated action toward a common objective."
      ],
      "parent_articles": [
        "Teamwork"
      ]
    },
    {
      "question": "Structured collaboration mechanisms and communication practices that improve collaborative problem-solving (e.g., introspection, coordinated processes, governance) primarily work by which mechanism, and why does that mechanism enhance collaboration?",
      "options": {
        "A": "Forcing strict compliance through centralized authority to ensure everyone follows a single plan, which reduces deviation and speeds decisions.",
        "B": "Creating a shared mental model and transparent feedback loops that surface misalignments, coordinate actions, and sustain commitment to the joint goal.",
        "C": "Increasing the number of meetings to collect more opinions, which automatically leads to better consensus and faster decisions.",
        "D": "Assigning blame for failures to individuals, which motivates others to adjust behavior and maximize personal gain rather than the collective outcome."
      },
      "correct_answer": "B",
      "source_article": "Collaboration",
      "x": 1.3164176940917969,
      "y": 0.999979555606842,
      "concepts_tested": [
        "Concept 1: Collaboration as a purposeful, value-creating process where multiple actors choose to work together to achieve a shared outcome, involving shared space and pooling resources.",
        "Concept 2: Structured collaboration mechanisms and communication practices that improve collaborative problem-solving (e.g., introspection, coordinated processes, governance).",
        "Concept 3: Variants and contexts of collaboration (e.g., decentralized/egalitarian leadership, adversarial collaboration, cross-domain collaboration like international trade) and the role of governance and social bonds in enabling collaboration."
      ],
      "parent_concepts": [
        "Concept 1: Interdependence and shared goals as the structural basis for teamwork and coordinated action toward a common objective."
      ],
      "parent_articles": [
        "Teamwork"
      ]
    },
    {
      "question": "In industrial and organizational psychology, why does performance often follow an inverted-U pattern with respect to stress or arousal, and which cognitive mechanism explains this pattern?",
      "options": {
        "A": "Increased stress continuously raises motivation, so performance always improves with more stress regardless of task demands.",
        "B": "Moderate arousal sharpens selective attention and processing speed, boosting performance, while high arousal degrades working memory and decision accuracy, causing performance to decline.",
        "C": "Arousal only affects overall well-being and has no systematic effect on performance, which is determined solely by skill level.",
        "D": "Positive mood alone drives performance and arousal level does not influence cognitive processing or task outcomes."
      },
      "correct_answer": "B",
      "source_article": "Industrial and organizational psychology",
      "x": 1.2563350200653076,
      "y": 0.9908587336540222,
      "concepts_tested": [
        "Concept 1: The relationship between employee attitudes/emotions/motivation/stress and job performance and well-being (and how these factors influence one another).",
        "Concept 2: Organizational interventions (recruitment, training and development, 360-degree feedback, change management) as mechanisms to modify attitudes, motivation, and stress to improve performance, satisfaction, health, and safety.",
        "Concept 3: The scientist\u2013practitioner model as a guiding principle that integrates research and practice in I-O psychology to optimize organizational outcomes."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "Why does setting a Pigouvian tax equal to the marginal external cost typically move the market outcome toward Pareto efficiency when a negative externality is present?",
      "options": {
        "A": "It raises the private marginal cost by the tax, so the private supply curve shifts up to align with the social marginal cost, causing the equilibrium quantity to fall to the socially optimal level, assuming the external cost is accurately measured and enforcement is adequate.",
        "B": "It raises consumer willingness to pay by transferring the external damage cost back to consumers, thereby increasing quantity toward efficiency.",
        "C": "It guarantees perfect information and enforcement so the tax always achieves the social optimum.",
        "D": "It guarantees the externality is eliminated completely regardless of initial market conditions."
      },
      "correct_answer": "A",
      "source_article": "Externality",
      "x": 1.2821956872940063,
      "y": 0.9297236800193787,
      "concepts_tested": [
        "Externalities create a divergence between private prices and social costs/benefits, leading to market failure and Pareto inefficiency.",
        "Pigouvian taxation as a mechanism to internalize negative externalities by aligning private costs with social costs (marginal external cost) to move toward Pareto efficiency, with caveats about information and enforcement.",
        "Externalities can be negative or positive, and governments may use taxation or regulation to internalize them, though the best approach and its feasibility are debated."
      ],
      "parent_concepts": [],
      "parent_articles": []
    },
    {
      "question": "In a morphogen gradient model, how do cells along a tissue convert a continuous gradient of signaling molecules into discrete cell fates?",
      "options": {
        "A": "Each cell reads an exact, unique concentration value and activates a fixed gene program corresponding to that value, creating a gradual spectrum of fates.",
        "B": "Each cell compares the local morphogen concentration to intracellular thresholds in gene regulatory networks, triggering distinct fate programs when thresholds are crossed, often reinforced by cross-regulatory interactions to sharpen boundaries.",
        "C": "The gradient directly mechanically rearranges cells into distinct stripes, so fate is determined by position rather than gene expression.",
        "D": "Diffusion causes the morphogen signal to fade, so cells randomly choose fates in the absence of any concentration cues."
      },
      "correct_answer": "B",
      "source_article": "Pattern formation",
      "x": 1.6624341011047363,
      "y": 1.1208544969558716,
      "concepts_tested": [
        "Morphogen gradient\u2013based positional information (e.g., French flag model) guiding cell fates along a field",
        "Reaction\u2013diffusion (Turing) mechanisms generating patterns through chemical interactions and diffusion",
        "Alternative/mechanical and computational patterning frameworks (elastic instability, cellular automata, neural networks) as models to explain or simulate patterns"
      ],
      "parent_concepts": [
        "Concept 3: Morphogen gradients and diffusion-based signaling create positional information that guides development and cell fate decisions through GRN activity."
      ],
      "parent_articles": [
        "Gene regulatory network"
      ]
    },
    {
      "question": "Why does evaluating a program by aligning with its original objectives and by comparing predicted outcomes to actual outcomes support effective learning and decision-making?",
      "options": {
        "A": "It allows cherry-picking favorable outcomes that align with the aims, simplifying reporting.",
        "B": "It reveals whether the program achieved intended aims, whether outcomes matched predictions, and explains deviations to guide future design or policy changes.",
        "C": "It reduces the need for rigorous data collection by prioritizing anecdotal impressions over systematic comparison.",
        "D": "It legitimizes post hoc changes to aims after results are known, ensuring alignment with outcomes rather than original plan."
      },
      "correct_answer": "B",
      "source_article": "Evaluation",
      "x": 1.3583452701568604,
      "y": 0.999104380607605,
      "concepts_tested": [
        "Concept 1: Formative vs. summative evaluation as distinct mechanisms with different aims (improving a concept/project vs assessing its final value and impact).",
        "Concept 2: Alignment of evaluation with original objectives and interpretation of predicted versus actual outcomes (assessing whether aims were achieved and how).",
        "Concept 3: Evaluation as a theoretically informed, rigorous process that uses scientific methods and standards, with implications for decision-making and future change (including resource considerations)."
      ],
      "parent_concepts": [
        "Concept 2: Iterative refinement and learning: using monitoring/evaluation data to adjust the theory of change",
        "Concept 1: Evaluation aims to determine effectiveness (doing what is intended) and efficiency (value for money) to inform decision-making."
      ],
      "parent_articles": [
        "Theory of change",
        "Program evaluation"
      ]
    },
    {
      "question": "Why is identifying social mechanisms essential in sociological explanation, particularly in relation to general laws and descriptive accounts?",
      "options": {
        "A": "Because social mechanisms are universal laws that apply identically across all contexts, ensuring exact cross-context predictions.",
        "B": "Because social mechanisms articulate the causal pathways that connect micro-level actions to macro-level outcomes, thereby offering a testable, context-sensitive explanation that sits between laws and description.",
        "C": "Because social mechanisms impose normative judgments that prioritize some outcomes over others, guiding what counts as an explanation.",
        "D": "Because social mechanisms disregard contextual variation, focusing on static descriptions of social roles."
      },
      "correct_answer": "B",
      "source_article": "Sociological theory",
      "x": 1.2272107601165771,
      "y": 0.9851464033126831,
      "concepts_tested": [
        "Social mechanisms as causal processes and the \u201cmiddle ground\u201d between laws and description",
        "Dynamic social theory: treating institutions and patterns of behavior as social models that replicate/adapt to yield predictable outcomes",
        "Distinction between sociological theory and social theory: emphasis on abstract, testable propositions (objectivity, scientific method) versus normative critique and commentary"
      ],
      "parent_concepts": [
        "Concept 3: Theoretical foundations (Marx, Durkheim, Weber, Simmel) and their explanations of urbanization outcomes such as social alienation, class formation, and changes in collective/individual identities."
      ],
      "parent_articles": [
        "Urban sociology"
      ]
    }
  ]
}