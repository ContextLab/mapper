I'll now introduce you to the concept of a random variable. And for me, this is something that I always had a lot of trouble getting my head around. And that's really because it's a byproduct of what it's called. It's called a variable. And we're used to variables as kind of an unknown in an equation if I write x plus 3 is equal to 7. The variable was x. Maybe you could solve for it. Or maybe you could have an equation y is equal to 3x minus 2. And then here y and x are both variables. If you input 1x, you could solve for the other variable y. And you can change them. And variables were kind of things that could change and that you could solve for. And they could take on particular values. A random variable is kind of the same thing in that it can take on multiple values. But it's not something that you really ever solve for. So just so you get used to the notation, a random variable is usually a capital letter. Usually a capital x, y, or is usually a capital x. And what really differs from a traditional variable is that it can take on a bunch of different values like a traditional variable, but you never solve for it. And really, it's a little misleading to call it a variable at all. It's really a function. And it's a function that maps you from the world of random processes to an actual number. So let's say, I don't know, I wanted to somehow quantify a random process. Is it going to rain or not tomorrow? So let's see, rain tomorrow. So you could observe that. You could wait until tomorrow and see if it rains or not. But then how do you quantify it? Well, we can define a random variable that'll quantify it. We can say this random variable is going to be equal to 1 if it rains tomorrow and it equals 0 if it doesn't rain tomorrow. We didn't have to assign 1 and 0. Those tend to be a little bit more useful. They make sense. But we could have assigned this as, I don't know, we could have said that this is 21 and that this is 100. It's however you define it. So it's important to keep this distinction in mind that a random variable, it isn't a variable in the traditional sense of the world. It's more of a function that maps us from the world of a random process to a number. And then this number is going to be random, right? Because we don't know if it's going to rain or not tomorrow. Maybe we have some sense of the probabilities. So this variable can take on either value. And let me draw a couple of more random variable definitions, just so you get the intuition that these really are functions. So we could define a random variable x is equal to, well actually, it could just be a very obvious numeric mapping. It could just be the number facing up when I roll a fair dice. That's a random variable. I could have also said it's the number most facing east when I roll a fair dice. Although that's a little less useful. You could also define a random variable x is equal to 1 if I get if heads. And I could say 0 if tails. Or I could have done it the other way around. Once again, these heads and tails are outcomes of an experiment. When I flip a coin, that's a random process. Each flip is an experiment. And then the random variable is just quantifying that experiment. So I know it sounds a little technical with the terminology, but what we're really doing is fairly something simple. We're just assigning a 1 if we get a heads, a 0 if we get a tails, and the random variable is just that function mapping. Now, I'm going into all of this random variable business, which I didn't do before when we did probability, because it does start to become a little bit useful notationally, because we'll start to talk about things like probability distributions and expected values. And it really is useful to quantify things as a random variable. And with that said, let's talk about probability distributions and expected values. So the first thing, probability distribution. Actually, let me define something else. There's two types of random variables. You can have discrete random variables, discrete, or continuous. Discrete would be like really all of the definitions that we had up until now. The role of the flip of a coin, you're either going to get a 1 or a 0. There's two discrete cases. When I roll a die, there's one of six different outcomes I can have. Whether it rains tomorrow, there's one of two outcomes, yes or no. So in all of these situations, you could almost say you could have a countable number of outcomes. A continuous random variable could take on an infinite number of outcomes. So a continuous random variable would be the exact, it could be x is equal to the exact amount of rain in inches tomorrow. Now why is this continuous? Well, if you think about it, that could take on any of an infinite set of values. You might have 1 inch of rain tomorrow, or you might have 1.1 inches of rain. You might have 1.111 inches of rain. You might have 2.1111 inches of rain. As you can see, you can come up with an infinite number of combinations of the amount of rain you have. And to get exact, well, I'll go into more of this when I talk about probability density functions. But in general, even though you might say, oh, well, I can't imagine having an infinite amount of rain, because we're not going to have 100 gallons of rain tomorrow, but if you think about it, you could take on any value between 1 and 2 inches of rain. There's actually an infinite number of values between 0 and 1, right? For any value, you could find a number that's a little, just to think about it, between 0 and 1. 1 half is in between those. And you can always find a number that's halfway between those, and then a number that's halfway between those. There's an infinite number of numbers between any two numbers, while with the discrete random variables, it just took on a finite number of values. Those ones up here, it could only take on 1 or 0. It didn't take on 1.1, and it couldn't take on infinity. And I make that difference, because actually how we look at it in terms of their probability distributions are a little different, but they're very related. So a discrete random variable, like the ones that we had defined at the beginning of these videos, they have a probability distribution. So let's do it for, let's say, x is equal to the number facing up on a fair dice. So we already know that to get each outcome, so there's six outcomes, you're going to get a 1, 2, 3, 4, 5, or 6 facing up. So let's draw the probability distribution. So here are all the outcomes. I'll draw that on the horizontal axis. So the at 1 outcome is 1, 2, 3, 4, 5, 6. And then in the y-axis, or in the vertical, you plot what is the probability of each of those outcomes occurring. What's the probability? Switch colors? So what's the probability of getting a 1? Well, it's 1 sixth. So if I draw 1 sixth here, 1 sixth. So the probability of each of these occurring, no, I didn't want to do it like that, are 1 sixth. It's essentially like a histogram or a bar chart. And it's just going to be, each of these, my intention is to draw them all the exact same height. So this is telling us that each of these, there's a 1 sixth chance of it occurring. If I were to draw a probability distribution for, if I were to define the random variable x is equal to 1 if heads, 0 if tails, this has a very simple probability distribution. There's only two outcomes. You're either going to get a 1 or a 0. And then in the y-axis, you'll have the probabilities. And each of these, if it's a faradice, it's going to be a 1 half probability. And you're going to draw a little box like that that tells you each of them are 1 half. Now let's say you had another, I don't know, probability distribution function that looks something like this. Those are kind of very run of the mill examples. But what if I had something like this? Let's see. Let's say it had some weird weightings on it, where it had an outcome of 1, I had a 1 sixth chance. Let's say for some reason a 2 could never happen. Maybe there is no 2. Let's say 3 has a 1 sixth chance. A 4 has a 1 sixth chance. A 5 has a 1 sixth chance. And let's say there's two 6's. We erase the 2 when we put a 6 where the 2 is. So there's two 6's. So the 6 has a 2 sixth chance. So the 6 would be a 2 sixth chance. So now I think you can see where the probability distribution function starts to become a little bit more interesting. In the other ones, it was kind of what we would call a uniform distribution. All of the outcomes are equally likely. That's a uniform distribution. Once again, this is a uniform distribution. This one all of a sudden is not a uniform distribution. One is just as likely as 3, 4, 5. Two is impossible to happen. But 6 is twice as likely to happen as everything else. It's two 6. So if someone gives you a probability density function, or if they give you a little chart like this, you can immediately say what's the probability of different events occurring. So if you said that x is equal to the number on unfair dice that's described by this probability distribution function, then if I were to ask you the probability that x is equal to 6, you'd say, oh, the probability x equals 6 is equal to 2 sixth, or 1 third. If I were to say, what's the probability that x, the random variable x, as given by this definition, is greater than 5, you would take, well, let's say greater than or equal to 5, right? Because you want to include 5, and at least I did. So it would include this situation and this situation. So it would be 1 sixth plus 2 sixth. It'll be 1 sixth plus 2 sixth. And so you could say that's 3 sixth, or 1 half. So it gets pretty interesting once you don't have a completely uniform distribution. And I'm doing all of this because in the next couple of videos, well, one, we'll move away from discrete and actually study continuous probability distributions, which are called probability density functions. And then we'll go to study a lot of distributions that show up in nature. The uniform distribution is one of them. There's also the binomial distribution and the normal distribution, which is what some people call the Gaussian, or the bell curve, which is a very common thing. But anyway, I'm all out of time, and I'll see you in the next video.