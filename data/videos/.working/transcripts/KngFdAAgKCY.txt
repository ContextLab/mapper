Hi everyone, Sal here from Khan Academy, and as some of y'all know, I have released my second book, Brave New Words, about the future of AI in education and work. It's available wherever you might buy your books. But as part of the research for that book, I did some interviews with some fascinating people, which you are about to watch. I'm excited to introduce Professor Ethan Mollick, who's a professor at the University at Wharton School at the University of Pennsylvania, who has also done a lot of work on simulations in business school. But I think even more relevant to what we're doing, you've kind of made a name for yourself over the last several months as someone who has been using AI for good in education. So welcome, Ethan. Thank you for having me. I'm thrilled to be here. So let's just start at the beginning. What was your first indoctrination or exposure to especially things like large language models? What were some of your initial reactions? And then what were some of the ways that you started to actually realize that it could be valuable? So as you said, I've been building like thinking about how we democratize education for a really long time. Like I've covered a business school perspective and there's all this research at like small amounts of business education, transform lives and controlled studies around the world. So like I've been thinking about this for a while and I've also been playing with tools that do this. So building simulations, but also kind of was aware of GPT-3, which was the pre-chat GPT version of the software, which is sort of did a good high-level fifth grade kind of essay at that point. And I thought I should get my students aware of this stuff. So I started assigning them assignments to cheat with it. So write as best an essay as you could using this and using Dolly to generate an image and then talk about where the state of the world was. And what was very funny is halfway through the cheating assignment, when half my students turned in, but the other half didn't, chat GPT came out. So there was a sudden change in the quality level that was quite dramatic during that period. And what did you notice? Actually, I'm curious. I mean, you said, all right, in theory, you could cheat with this stuff. So students go cheat with this stuff and by definition, it's not cheating if you're pulled to cheat. But what did you see a difference in? I mean, you obviously have difference between chat GPT, which is using GPT 3.5 and regular GPT-3. You already saw a difference there. But did you see a difference relative to what you saw in previous years from student work? Yeah, I mean, well, it's interesting, right? It's like we judge writing and intelligence as being very close to each other, right? And in ways that are hard to sort of separate, we consider essay writing to be how we learn how to think as we write essays. Maybe that's true. Maybe it's not. We really haven't tested those things. It's like a lot of education stuff. We don't actually know the answers. And so I've had students in my class who are brilliant people, but not good writers. English is their third language or they came from a background where they never learned to write really well. So even just having that little bit of a hint, it's sort of like grammarly, right? Like made a difference of making their writing better. And after I introduced some of my students to chat GPT, they're like, you know, I'm now getting job callbacks. I didn't before and I'm getting the job when I have an interview, but because I can write well now, right? So it's part of why I made AI uses mandatory in all my classes. So I no longer accept anything that isn't perfectly written at this stage. Why bother? And what's your sense? You know, think about it from employers point of view where I guess they were using a signal, someone who writes a really eloquent cover letter versus someone who doesn't and they were using this little signal. Now, it's all eloquent. But maybe that person comes to the comes to work and they're like, oh, maybe their language skills aren't as strong as I thought they were based on what's your point of view? Is it are they cheating or is that okay? Because I can use chat GPT or whatever to continue to write well. It's actually two really interesting questions. The first is, you know, this question of cheating overall is sort of a big question, right? What does it mean to cheat nowadays? Right? If I ask the AI for advice, but don't use it. If I ask you to punch up a paragraph, if I ask you for is that cheating? It's a much different question than plagiarizing, right? And then the second question is like, you know, a lot of stuff that is good is going to be hurt by AI. But a lot of stuff that's bad, right? Turns out like judging people based on cover letters has never been a particularly great method or college essay has never been a pretty great method of deciding admissions. The best method we have for large-scale, you know, meta-analyses is actually doing a detailed interview that's based around what people actually accomplish in their life, right? If writing skills are important, you're gonna have to give people writing tests that's separate. But for a lot of jobs, that isn't the main skill or it's going to be done by AI now. So in some ways it's cheating, but it's also kind of forcing us to reconsider what's actually valuable. In terms of signaling. A lot of stuff that we do, right, especially as instructors in the room, is about sort of setting your time on fire to show that you care, right? Like if someone asks me to write a letter of recommendation for them, it takes an hour to write a really good letter of recommendation. I could paste the resume of the person and the job they're applying for and what says the GPD-4 and get a better letter, then it would take me an hour to write. And I'm always struggling like, do I use the generated letter? Because it indicates my thoughts, but I'm not spending the time anymore that I was going to spend to make this work. And I think that's the really interesting challenge. I love your phrase of setting my time on fire to show that I care. As someone, my mom always wants me to pick her up from the airport. My parents do. I do. I set that part of my day on fire so that I can show her that I care. But I think you're right. We are full of traditions, including maybe the cover letter and all of this, that are almost just rituals just to light your time on fire to show that you care. But do they actually add value? And even for folks who, some people have other people coaching them, helping them for things like college essays or resumes. And that's kind of a resource intensive version of chat GPT or GPD-4. Exactly. And it was, I mean, the exciting thing, and this is why I love what you guys are doing, is like we suddenly have billions of people who have access to the single best AI ever released in public. Like if you're rich, you don't get access to a better AI and get free access to through Bing or through the kinds of things that you guys are doing. Right. It's available everywhere. And that's like the most profoundly interesting thing in education because we used to have all of these barriers. All the previous attempts to do this were hard and difficult. Right. So I think part of that question is, you know, it democratizes stuff. We didn't get to democratize before. It used to be like you can hire a tutor. You'll do better. Now, what happens when we have a tutor that everybody could use that's actually better than human tutors? That's that's a really exciting and a little bit scary prospect. Yeah, no, I mean, you're right. It's both exciting and scary. And all of us, as you know, we're working on Conmigo inside of Khan Academy and rolling it out pretty increasingly widely now. And you and I are bumping into each other a lot because we seem to be on the speaking docket together a lot. Like this is what Khan Academy is doing. And look at this professor who's using AI for not afraid to use AI. So let's continue on your journey because you talk about those early days. You encourage the kids to quote cheat using artificial intelligence. But it was kind of leading to better outcomes. But what have you changed what the assignments are? Have you changed your threshold of what makes a good assignment? Yeah, so I mean, there's basically three things I've had to do right as a result of AI. So level one, I think everyone's gonna have to face these problems, right? Level one is just expecting and more from students, right? So the first thing we're all have to do is like so, you know, I teach an entrepreneurship class and you know, again, I know there's people listening who teach, you know, basic writing skills. You're gonna have to adjust in different ways. This is gonna be different for every person. Some people it's gonna be all about having writing assignments in class. So people learn how to write because they'll be cheating outside of class. I get that. So this is not a universal thing, but it's certainly my case. I expect more. So people used to have to turn in like a business plan. Now they have to turn into business plan working code, even if they could never code before. I now code. I can't code, but I've written 12 Python programs the last couple weeks, right? You have to turn in, you know, fully working web page. You have to interview both real and fake people with the AI and this data that you could survey the AI and it's actually accurate. So my expectations for work is now much higher than it was before. So that's the sort of first adjustment, right? The seconds of adjustments is in now have AI integrate into assignments. So AI is a teammate for my students. So they now end up actually having to bring AI, you know, there's assignments. For example, every assignment they turn in has to be critiqued by at least three famous other entrepreneurs, which they have to generate. So they get feedback along the way and then the fourth thing which is the third thing which is the really big thing is changing how we do classrooms. Lectures don't make as much sense when I've got tools like Conmigo that could do truly amazing training, you know, remotely. So we think about how we can flip the classroom in that way. Yeah, no, well, I mean, there's so much in there. I mean, I found fascinating your some students were at like an executive summary for like a business plan or something and then ask like Steve Jobs or some famous entrepreneur to, you know, Ford or somebody or Tesla or somebody to weigh or I guess Elon Musk to weigh in on on their business plan and that's part of the assignment now. They're required to have so for just turning their outline alone, which is something I would just comment on. They have to have three famous entrepreneurs comment on their plan, right? And that also teaches a little about writing prompts, but the limits of these things are not actually invoking the spirit of, you know, of Steve Jobs, right? Instead, they have to realize, you know, it helps them think about this new world we're in. And then they also have to do pre-mortem. So projects succeed better when you actually do imagine how they could fail. So they have to generate a whole bunch of failure opportunities as a result of this to work backwards and how to solve them. So it lets me do different things that we know for the research make teams work better, make people work better, but we could do before because it was just too much work. And this is so powerful. And you know, what you're also doing, it sounds like either explicitly or implicitly is you're just making them intimately familiar with these tools and the power that they have. So because the worst thing you could do is these students are in a bubble and then they come out into the workforce in a year or two. They're like, wait, what just happened? Everyone's using GPT-5 now or whatever. But they're going to be able to lead in that. And your point about a flipped classroom, as you know, I've been talking about even pre-AI in a world of on-demand video, honestly, even pre-on-demand video, humanities classes, even business school classes. Read the case, come to school, and we're going to discuss it. That's always, I think, been a best practice even more so in an AI world. Where is this going? You know, are you continuing to evolve your courses? What are, I'm sure all sorts of faculty members are coming to you and saying, what do I do? What are you telling them? I mean, so one thing we're doing is, you know, we're sharing prompts, right? Like to me, this is the most important thing to do. So I've got a couple of papers and I'm sure we can put, you know, links somewhere for people. But we're trying to kind of take pedagogical approaches, right? Prompting is not magical, but it helps me with expertise. So we've written some prompts that do various things like generate explanations and analogies, some of the stuff you do in commingo, but that can kind of be applicable to many classrooms. There's tools to help, you know, teachers. So I'm trying to figure out how we, the democratization mission that you guys have is the same one I'm thinking about, right? How do we give teachers tools? How do we give students tools? You know, the promise of AI is that suddenly, you know, the thing we thought that the internet would do, which is if we give everyone access to information, they'll do everyone to learn everything. Turns out a very small set of people are really kind of constructivist learners who don't need support and could just learn on their own. But now we have a tool that actually can provide the support, the tutoring, some of the other material that we know works and do it at scale, right? And I've heard you talk about, you know, Bloom's, you know, two, I mean, we don't even know how well this works at this point, but we couldn't do it before. And just like you, I've done massive, you know, not anywhere you do your scale, but I've had like, you know, a few hundred thousand people take my online video courses. You know, there's a big difference between that and actually having an exercise and getting feedback. So we're trying to think about all of those kind of pieces. And what are you telling faculty? Because I have no doubt. I mean, you already are not only navigating this successfully, you're thriving in a generative AI world. You're making it work for education. I feel similar optimism to what you do, but I would guess, you know, 90 something percent of teachers right now are not in the same frame of mind. They're kind of freaking out. You know, let's say you were writing freshman composition. That's all you had to do. Like your whole job is to make sure that the students are learning to write and that you're evaluating them. What would you tell teachers like that who are a little bit more afraid that things like chat GPT just set off like a bomb in their pedagogical style? I mean, I think we started with the bad news. It absolutely did. Right. I mean, a lot of stuff just got blown up and some of that was good stuff, right? I mean, there's ways we teach over 2000 years that made a lot of sense. Maybe they weren't really researched back, but we got very good at them. Right. We've got a good at lectures. We've gotten good at doing essay assignments at home and evaluating them. We were good at that stuff. That's blown up. Right. I mean, even for your best students, your students who wouldn't cheat, by the way, students have been cheating forever, right? The cheating just got much easier and cheaper. But even now your best students are disadvantaged because they're not cheating, right? Because, you know, they're not writing the same way. So it does blow up a lot of it. If you are teaching a freshman composition class, you are, you have to change how you teach. This is AI is undetectable. Anyone who's telling you otherwise is not actually telling you the truth. It's essentially undetectable. One of the things I learned from my students cheat is after a couple rounds of doing, you know, back and forth of the AI, which is the best way to interact with it. You just put a prompt in you sort of engage with it. The essays are undetectable by both humans and any AI tutor. It blew up what you did. So you have to take this opportunity, but it's also it's scary and we can admit that as educators. What we should realize is that education is going to be okay. We will adapt to this change, right? It's bigger than calculators, but not that different that the narrow damage. Calculators did in math classes, right? They'll be as a instructor. You're probably going to want to have more instruction. I'll be outside of class with videos, other stuff, more active writing assignments in class with critiquing each other and writing short essays and you know, and you could make this work, but it absolutely is a big change, but it's an opportunity to do things new and to figure out what works for you. And also the thing I like to stress to instructors is this also makes your life easier in a lot of ways. Like there's a lot of stuff we wish we could do that we didn't have time to do. And we got a prompt for all this. It writes great quizzes for you. I know you guys have guides also to do this stuff. It helps you as an instructor. So it's not just increasing your workload to make your life difficult. It's also lowering your workload and giving you a little more time to think more about education and how to transform students lives, which is why we're all in this in the first place. Now I can imagine you threw out, I think some very good tips in your answer, which is if I'm, if I'm teaching freshman English comp at a university or if I'm teaching a English comp class in a high school, the world we're going into could very reasonably be, okay. I have you for an hour, hour and a half at a time, right? And maybe you're writing with the AI. It's not writing for you, but it's, it's acting so it can help answer some questions, et cetera, but then it can evaluate. It can give me a, it can do a first pass of grading for me. And so your students are actually going to get more writing time and more feedback in this world. And yeah, maybe they have less to do at home. That's good. Everyone has less to do at home. You have less to do at home. You're not grading, you know, like your 80th essay on, you know, something that's, you know, you probably don't mind numbing at that point. And the students don't either. Everything can happen in that night. It's just sufficient for everyone. So yeah, that makes a ton of sense. Yeah. And I think that, you know, that embracing this is going to be important and it's scary. It is okay for it to be scared as you listen to this and be like, oh no, I don't want to change what I've been doing. But we also recognize a lot of the ways we are having people write essays didn't make sense. Like the people who weren't very good in class, right? They wrote bad essays outside of class. How much time do we have to tutor them and make them better? Well, in a sort of flipped classroom, active learning environment, right? And the active learning is more important than the flipped classroom. The idea that we're doing things in class, maybe there's more time for this to do. Maybe the AI can help them catch up or give them an explanation where they were as opposed to being an instructor who's grading 80 essays. Like you said, maybe of the AI help you flag the couple that need the most help or a couple that are great examples, you know, and give feedback that way. We don't have all the answers yet, right? So we are in an exploratory environment, but we can't pretend the world didn't change. This isn't like one of those things. Like one day video classes, what are you going to do about a massive online course? It's too late for that. Like this is here now and whether we like it or not, we have to adjust as instructors. And where do you think this is? Because as you know, we've been talking about large language models. You mentioned Dali, which is about generative images. There's technologies around video, degenerative video, speech to text, text to speech. I've seen some demos, you know, things like speech to text and text to speech have been around for a while, but I've seen some demos lately of some text to speech that really is not discernible from the original, you know, the human being, so to speak, which is going to create issues with deep fakes and all of that in the broader world. But where do you think this is going? Like what? I mean, it seems I think even for folks like us every week, there's new every week, there's new things going on. What do you think this is all going to look like in two or three years and how are you keeping tabs on everything? So a couple things there, right? One is everyone has to recognize that a I generative AI is what's called a general purpose technology. And so I'm a you know, I teach entrepreneurship and innovation and innovation studies. General purpose technologies come along very rarely. They come around once in, you know, every generation or two think steam power, maybe the Internet, maybe computers, but they affect every aspect of life. And this is the fastest one we've ever seen. Fast adoption. It's the most personal. People can do things. It's going to affect every industry differently, every person differently, every job differently. But it's going to affect everything. Right. The job that's least affected by AI, according to the early studies we have is roofing. And I've talked to a couple roofers who are like, oh, no, actually roofing is going to change, too, because we can now do all of our proposals and stuff with AI help. So it's going to change roofing also. So we should recognize this is the world's changing in ways we don't always know. So what you think what you should think about as a instructor, right, is preparing people to live in a world with fast adaptation. So the more we start to use AI and get familiar with using it, the easier it will be for people to adapt to whatever is coming next. Because I think just like, you know, you know, you and I both this moment of GPT forward, it's like, oh, my gosh, it really does a lot of what people does it like things like people like this isn't really software. It's worth thinking about like a person. It's not a person, but you can think of it like a person that could be helpful. And then the question is, what's next? We don't know. Does this keep getting better? Does it stay roughly where it is? We I don't have answers to that, but we have to be ready. And the best way to do that is start using it. Well, you know, as a business school professor and I mean, you just touched on it. The world is moving faster and faster and faster. What advice I'm sure our students are asking you or parents are like, what should my kids be working? Like what skills should they be developing and which ones are not maybe as important as they were before? So I think thinking still matters, right? So a lot of my people said writing was important. Writing essays was thinking. I think that's still very true. We need to teach people how to think. I think that for right now and hopefully for the foreseeable future, AI is great. If you were in the bottom 50% of a lot of different categories, you're now at the 50th or 60th or 70th percentile. That's exciting. Expands opportunities for people who did before, right? You couldn't write before you could do that now. You weren't good at programming. You're now an okay programmer. Like that's exciting. I think the question is, what are you good at? What do you love that you might be in the top 10% of people in? And I think that's something where you can add a lot of value to an AI world. So I think part of this is about thinking about what you want to do that, you know, you're talented and how do you develop that talent to that expertise? And that requires you to still learn the basic knowledge of school. You build expertise by building basic knowledge, right? By, you know, seeing lots of examples working with the AI to get there. And I think that can get you to a really exciting place. But let's just, I'll just make it some tangible examples. Like if someone says my dream is to be a roofer, you'd be like great. That's going to be a great job in the future because you're going to be able to do more roofing and AI is going to write your proposals for you. But if someone came to you said, I want to be a copyright editor or I want to, would you say the same answer? Just, you know, get really good at it, even though GPT-4 is already pretty good at it. So that's the, that's the bet, right? We don't know how much better these systems are going to get, right? And I do think there's disruption. We're seeing in early controlled studies, 30 to 80% performance improvement on many high-powered white-collar analytical tasks, right? Writing-based tasks, analysis tasks, consulting tasks, programming tasks. So if you want to be in these fields, AI is going to be a part of your life. So you need to figure out if you can use AI to be 10 times more productive, there'll be huge value in you. There's still a need for a human in the loop. If you can't figure out how to use AI to get more productive, I'd be more nervous in those spaces. You know, I think what industries to go into, I mean, to be fair, people have been predicting that radiologists would be absolutely by AI for the last 15 years, been saying don't become a radiologist. There's still lots of jobs for radiologists. So it's hard to make a bet. I wouldn't be making huge career bets, but I would say the more writing-based your job is and the more routine it is. If you're being a fiction writer, AI still can't, you're a comedy writer, AI still can't write a good joke. Those are tough jobs anyway, but you know, those are places. But if you're trying to do copywriting, I think unless you figure out a way to use the AI, I would be nervous, right? So the more exposed to AI the field is, the better AI is at it, the more you need to be a centaur in the model. Gary Kasparov said it, half man, half horse, half person, half horse. You need to be able to work with the AI as your horse and be the human integrated with it, and then you could write better. I don't know. I found my writing has improved tremendously with using the AI to throw back a paragraph I'm not interested in working on anymore because I'm stuck. Give me 20 versions of this and it does, right? So I think there's hope in these fields, but we don't know how good this is going to get, and that's also a little bit scary. And you mentioned scary, I mean, because you seem like someone very not scared right now. But when you say scary, what are the scary thoughts in your head? I mean, so there's a couple levels of scary, right? I mean, there's there's stuff that's definitely going to happen. We have disruption that's definitely going to occur, right? As you said, it is now trivial to create fake videos, fake videos of myself talking with a minute of my speech. I've done that before. It's fake photos are easy, right? Content and mass is easy. So there's a bunch of social issues we're going to have to deal with as a result of that. Then there's also the fact that this is going to disrupt jobs. We don't know which jobs yet and in what way. We don't know how much disruptions going to involve. You know, usually in economic terms when jobs get disrupted people, it's not about jobs, but tasks. So you're not it's not your job that changes the tasks you do and hopefully usually that ends up with getting a better bundled task. You put off your boring stuff and you but that can be a disruptive period. People get fired. People who are going to get hired don't get hired. We don't know how this is going to turn out. So there is some scariness that's going to happen with job disruption, even if it does grow the economy. And then the question is, does it keep getting better right now? If you're the top 10 20% of a field, I think you know, AI is a tool for you. Now, the question is, how do we train up interns when AI works as a better intern than a lot of our interns that we would have how we train people in the future? And if AI keeps getting better, what if it's better than everyone but the top 1%? What do we all do with our jobs then? And then of course, there's a sort of really scary thought that a lot of people spend too much time worrying about relative to these other concerns, which I think are much bigger, which is, you know, what happens if this thing actually become a super intelligent this AGI idea and like what happens then? But I think you don't need to worry about that piece is what is, you know, people are worried about it. You should worry about it. But I think that this other stuff about what happens to jobs and how do we survive in this world of disruption? I think is more important. And I mean, not you know, both of our our bread is buttered by this, but I do think education is part of the key here to being able to think and adapt is going to be important, right? Not being trained for one thing, but being trained for many things. Yeah, when you mentioned that you're already making your business school students write code and the business plan and you know, and once again, they're able to do they're able to almost be a small scale manager of an AI team, so to speak. That's exactly right. I mean, I think you have to think about everyone on Earth just got a free intern. What are you going to do with it is sort of like asking everyone. Or 10 writer and they do different things that you and it's not magical. People bounce off and get scared of the AI and I get all the reasons to be nervous. We've been talking about them here, but the fact is it's here and by filling with teaching students how to use this is you kind of need five to 10 hours of using this in your job to see what it does for you. If you don't spend five or 10 hours, you're not going to get there. So that's that's sort of my advice is like you have to use this if you're a teacher, your student use it for stuff and see what happens. And that's the only way to kind of go forward. It's not a magic of copying a prompt off the Internet. It really is just experimenting and being in dialogue with this thing like you're with a person. I 100% agree with that and someone who's probably personally spent at this point about 300 hours. I can I can and I would say it's also you know, if I were to add one skills to creativity because I've seen so many people go to like chat GPT or use GPT for and they're just like, what do I do? They're like like it can like the sky's the limit like try interesting things and you're going to realize that it it's able to do things that are you know, would have been science fiction. I am curious, you know, what advice do you have for us? We're obviously working on conmigo. It's you know, we're trying to make it a tutor for every student to teaching assistant, you know, maybe more than that. We are trying to add things like memory and different types of activities expand our horizons. Like what are the types of things that you would like to see it do to make students or teachers or parents lives easier or anyone's lives easier? So I think part of the interesting thing is what's the interface with the human becomes an interesting question, right? How do I how do we build these tools so that they fit into the human system that we have? Like what's the advice for how students use them? How do they give feedback to teachers in the right kind of way? You know, you guys are you know, thinking of a lot about that, but I think how we fit those are the human systems matter. And then I think the other thing is like trying to be even more creative, right? What you what you're doing is replicating this human at a very high level. What if I had a one-on-one tutor, but you know, that was the best we could think of, right? So the question is what what can we do beyond that? Like what does education look like in it? Like can we give different kinds of puzzles and tasks? Can we do more game-based instruction and teaching than we did before, right? Those are very powerful set of tools. How do we start to you know, another big question for me is how do we start doing multiplayer version of this? How do we include many people in a classroom interacting with the AI? How do we create persistent personalities for the AI that you interact with and you select a person to keep working with it? I mean these I think that there's I think we just need to we get very constrained by this idea of like now we can finally build Bloom's tutor, right and like that's wonderful. But that was also human constrained. We have a new system now. It's going to change how we work, how we organize work. I would be thinking internally like do we still want to do spritz? Do we still want to agile? Those were built around human systems. What's the new model look like? So I think that that's that's the view and like how do you take a companion to you know, how does it force you to go beyond the classroom also and actually solve problems? Maybe it could push you to actually create something, right? So rather than just doing a project that's like a single class project, how we integrate them together. And then the other thing I would just say is I think STEM just became much less interesting relative to humanities than it has been in the past. And humanities really help and social science really helps here because it kind of works like a person and the more human history you can dive into the more you can force the ad to think in interesting ways. So I also think trying to weave some of that, you know, like AI, you know, a lot of stuff that wasn't practical before just became practical. A lot of stuff that was very practically oriented just became a lot more theoretical. So taking that lead to rethinking agendas and syllabi is also really interesting. You're absolutely right. As you know, someone who's kind of traveled both worlds, you know, with a more technical background, computer science, you know, I saw back when in school that a lot of the students who struggled with things like engineering and coding, they had trouble reducing problems to something that an algorithm that you could kind of linearize in an algorithm and think about all the edge cases and how do you create variables and how do you really reduce it down to that. But now with AI, even though it's a list software, you're seeing the other way where I've actively told even members of the team, you've written this prompt like it's an algorithm. Do not do that. Give like, you know, people say first, ask the user this, then do this. I was like, no, don't do that. Tell the AI what your goal is because you want the AI to be more robust and flexible. You don't want to always do that first and always do that second. You want it to give it your goal here. Don't micromanage how it gets to the goal and it's going to do it a more in a more dynamic way or or give it a sense of tone or these things are not. Yeah, tell it who it is. Again, it's bad software. It's good people, right? Like it doesn't work well as software because it doesn't do the same thing every time it gets stuck in loops. Like you have to learn to work with it. It lies to you. You have to learn to work with it. No matter what we do, it does these things, right? Like you do your absolute best. That's dropping. Hallucinations are dropping, but like they're real. It's a real problem. So if you think of this like a person, right? It's it does better like I've given it tests, you know, it does better on neuro education myths than the teachers do. It doesn't believe anymore in, you know, in learning styles, for example, which is great, but it still makes mistakes. And I think you're right. You have to give it a person, but you also have to teach people who are using it. It's a person. If it starts going off on a tangent, you have to redirect it. It's not a super intelligent entity that knows what the future is. You have to and people use it that way. Is it Oracle all the time? What is the future of AI look like? It doesn't know it's not even if it was intelligent as a person, it doesn't have answers for you. Treat it like a person and program it like a person and it's a very different kind of beast to play with them. No, and you do a lot of work, you know, just on the other dimension, you do a lot of work on simulations, business simulations, things like that. I could imagine you're going to town with and I, we should think about collaborating. I would love to get some of even your pre AI simulations out to kids in K-12 or another context, but I'm curious how you're thinking about it in the AI world. We'd love that. I mean, we've I've been spending, you know, I wrote a book on games in education like 12 years ago. I've been building games ever since Wharton, matching with Wharton to invest in this thing. I've had 14 people, we've had people who won the Hugo Award for best science fiction novels. I see some science fiction behind you. So, you know, as one of our writers who helped us out with some of the storyline and they're amazing, right? I spent years building these games where you run a fake startup company in real time or you're on a Doom space mission to Saturn and it teaches you about leadership skills. And then, of course, the disturbing thing was I typed in a one well-directed prompt into AI and it started role playing all the characters in my game very well, right? 70% of a year's worth of effort can be accomplished with a paragraph. So I think this idea of playing with simulations is another thing. We're used to very didactic learning and even the tutor model sort of interactive didactic learning. We can start doing other things, right? I mean, a lot of educators will be familiar with like the Diamond Age model, right? Of like this universal tutor that turns work at, you know, teaching into a game. What I've learned is you can't make games that teach as compelling as enough to take the place of real games. Like at their very best, they're 80% as much fun as a real life game, but they can be a really interesting way to teach. And combining simulations and games and actual didactic learning and quizzing and write a book to do this and project-based work. Suddenly all of this is cheap to do. It's easy to do at scale. It is so exciting because I can tell you the simulation-based stuff makes such a difference in people's lives. And it's just something that normally we would have to spend millions of dollars building a sim. And now it's something we could do much more easily. And I think that's really, really exciting too. No, I'm sorry. I mean, I'm serious about this. After this, we should, we'll connect because I want to, you know, obviously there's two schools that I help start. Con lab school, including it has a high school as well. And we have this other online high school. I think all your business school simulations, I would love to have it, you know, middle high school, maybe even elementary school students doing all of them. I think you transformational. Actually, it's pretty funny. We built this for college students. Our best players are often actually high school students who are playing these games because they don't get a chance to actually do business stuff and they take it very seriously. And as a result, they get a lot out of it, right? While somebody who's in a business school class is like, I run, you know, they get into it, but it's a different kind of experience. The high school students were trying to, you know, the goal before this was actually to create a class in a box in the same sort of way. I've done massive online courses like you, you know, you have. And just like you have recognized the limits of these things, right? In the same way, we've recognized the limits of these. So how do we get people to experience the game and learn on demand became our big goal here? And I think we've accomplished it. So I'd love to talk about those things and get you to try them out there. You know, all the education we've got talked to various billionaire founders and they, you know, we fictionalize their experience in the game. And you know, there's hundreds of branching paths and we've filled the world with, we've actually filled Google and Wikipedia with fake information about the world of the game. So you can actually just Google stuff and get useful information out of it. So had a lot of fun building that too. You've made the reality part of your simulation. You got, you know, all that alternate reality games. Yeah, exactly. So very awesome. Well, Ethan, I could talk to you for hours about this. I think, you know, you're one of the few people who are really leaning into this and especially in education. So I expect this will not be our first, our last conversation. It's actually not our first either. I mean, I can't, yeah, I love it. And your mission, I love what you're doing, your mission. And it's just exciting to see, you know, I was perfectly involved with everything from like one laptop per child down through all these educational efforts. And it's, we're now actually close to that dream of like, how do we make technology actually make education better? What you guys are doing is so important and it's so exciting, but it's also really scary to a lot of people. But you know, I think, I think it's, I think it's, I think we, embracing it, you start to see the real value of what's happening here. So thank you for having me. Thank you. Thank you.