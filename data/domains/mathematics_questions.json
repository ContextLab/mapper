[
  {
    "id": "523df7e78a49a05c",
    "question_text": "A function $f$ is continuous on the closed interval $[a, b]$, with $f(a) < 0$ and $f(b) > 0$. What can you conclude?",
    "options": {
      "A": "There exists at least one point $c \\in (a, b)$ where $f(c) = 0$ — this follows from the Intermediate Value Theorem",
      "B": "The function must be monotonically increasing on $[a, b]$ because it transitions from a negative value at $a$ to a positive value at $b$, which requires a strictly positive derivative throughout the interval",
      "C": "$f$ must have a derivative at every point in $(a, b)$, because continuity implies differentiability",
      "D": "There is exactly one zero of $f$ on $[a, b]$, since a continuous function crosses zero at most once"
    },
    "correct_answer": "A",
    "difficulty": 1,
    "x": 0.99,
    "y": 0.557321,
    "z": 0.573495,
    "source_article": "Intermediate Value Theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Intermediate Value Theorem",
      "continuity",
      "real analysis"
    ]
  },
  {
    "id": "27414a490ead2109",
    "question_text": "If $A$ is a $3 \\times 3$ matrix with $\\det(A) = 0$, what does this tell you about the system $A\\mathbf{x} = \\mathbf{0}$?",
    "options": {
      "A": "The system has exactly one solution, namely $\\mathbf{x} = \\mathbf{0}$, because the homogeneous system always has the trivial solution and a zero determinant merely indicates that the coefficient matrix is poorly conditioned",
      "B": "The system has infinitely many solutions — the null space of $A$ is nontrivial (contains nonzero vectors)",
      "C": "The system has no solutions at all",
      "D": "The matrix $A$ must be the zero matrix, because the only $3 \\times 3$ matrix with determinant zero is the matrix with all entries equal to zero, since any nonzero entry would contribute a nonzero term to the Leibniz expansion of the determinant"
    },
    "correct_answer": "B",
    "difficulty": 1,
    "x": 0.818512,
    "y": 0.655723,
    "z": 0.065548,
    "source_article": "determinant",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "determinant",
      "null space",
      "singular matrix",
      "linear systems"
    ]
  },
  {
    "id": "ac8eaa55458be45e",
    "question_text": "Two fair six-sided dice are rolled. What is the probability that their sum equals 7?",
    "options": {
      "A": "$\\frac{7}{36}$, because 7 is one of the possible sums from 2 to 12",
      "B": "$\\frac{1}{12}$, because there are 12 possible sums",
      "C": "$\\frac{1}{6}$, because exactly 6 of the 36 equally likely outcomes sum to 7: $(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)$",
      "D": "$\\frac{1}{7}$, because each sum from 1 to 7 is equally likely"
    },
    "correct_answer": "C",
    "difficulty": 1,
    "x": 0.826831,
    "y": 0.99,
    "z": 0.623473,
    "source_article": "probability",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "probability",
      "sample space",
      "combinatorics",
      "equally likely outcomes"
    ]
  },
  {
    "id": "2c3f26f96fb23ca2",
    "question_text": "An integer $n > 1$ is prime if and only if it has no divisors other than 1 and itself. Which statement about prime numbers is true?",
    "options": {
      "A": "Every even number greater than 2 is composite (not prime), which follows from the fact that an even number $n = 2k$ with $k > 1$ is divisible by 2 — however, the statement that every even number greater than 2 is non-prime does not address the infinitude of primes",
      "B": "Every prime number is odd, which can be verified by checking that 2, the smallest prime, is the only exception — but since 2 is in fact prime and even, this statement is actually false, as it overlooks the unique even prime",
      "C": "There are finitely many prime numbers, and the largest known prime is the upper bound on all possible primes — Euclid's theorem is sometimes invoked but only proves that at least three primes exist, not infinitely many",
      "D": "There are infinitely many prime numbers, as proven by Euclid's argument that no finite list of primes can include all of them"
    },
    "correct_answer": "D",
    "difficulty": 1,
    "x": 0.718774,
    "y": 0.708371,
    "z": 0.711467,
    "source_article": "prime numbers",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "prime numbers",
      "Euclid's theorem",
      "infinitude of primes"
    ]
  },
  {
    "id": "0a5c9c652e4e5d0b",
    "question_text": "The derivative of a function $f$ at a point $x = a$ is defined as a limit. What does $f'(a)$ geometrically represent?",
    "options": {
      "A": "The slope of the tangent line to the graph of $f$ at the point $(a, f(a))$ — it gives the instantaneous rate of change of $f$ at $x = a$",
      "B": "The area under the curve $f(x)$ from $0$ to $a$, computed as the definite integral $\\int_0^a f(x)\\,dx$, which represents the total accumulation of $f$ over the interval $[0, a]$",
      "C": "The average value of $f(x)$ over an interval containing $a$, computed by dividing the integral by the interval length",
      "D": "The distance between $f(a)$ and the $x$-axis, equal to $|f(a)|$"
    },
    "correct_answer": "A",
    "difficulty": 2,
    "x": 0.952025,
    "y": 0.70034,
    "z": 0.620549,
    "source_article": "derivative",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "derivative",
      "tangent line",
      "instantaneous rate of change",
      "limit definition"
    ]
  },
  {
    "id": "8d5a4e1e5588d7b0",
    "question_text": "A $3 \\times 3$ matrix $A$ has eigenvalues $\\lambda_1 = 2$, $\\lambda_2 = 3$, and $\\lambda_3 = 5$. What is $\\det(A)$?",
    "options": {
      "A": "$10$, because the determinant equals the sum of the eigenvalues: $2 + 3 + 5 = 10$ — the sum of eigenvalues gives the trace, not the determinant, but this is a common confusion",
      "B": "$30$, because the determinant of a matrix equals the product of its eigenvalues: $2 \\times 3 \\times 5 = 30$",
      "C": "$0$, because only matrices whose eigenvalues are all zero can have a nonzero determinant",
      "D": "$15$, which equals the average of the eigenvalues $(2 + 3 + 5)/3 = 10/3$ multiplied by the matrix dimension $3$ and then rounded — this formula conflates the trace with the determinant through an incorrect averaging procedure"
    },
    "correct_answer": "B",
    "difficulty": 2,
    "x": 0.795749,
    "y": 0.774348,
    "z": 0.027773,
    "source_article": "eigenvalues",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "eigenvalues",
      "determinant",
      "characteristic polynomial"
    ]
  },
  {
    "id": "d509a3135184f094",
    "question_text": "The series $\\sum_{n=1}^{\\infty} \\frac{1}{n}$ (the harmonic series) diverges, while $\\sum_{n=1}^{\\infty} \\frac{1}{n^2}$ converges. Both have terms approaching zero. What determines whether a series of positive decreasing terms converges or diverges?",
    "options": {
      "A": "A series converges whenever its terms approach zero — since both $1/n$ and $1/n^2$ approach zero, both should converge",
      "B": "Convergence depends on whether the terms are rational or irrational numbers",
      "C": "Terms approaching zero is necessary but not sufficient — the terms must decrease fast enough that the partial sums remain bounded. For $p$-series $\\sum 1/n^p$, the critical threshold is $p > 1$: the terms $1/n^2$ shrink fast enough to produce a bounded sum, while $1/n$ does not",
      "D": "The harmonic series diverges because it has infinitely many terms, while convergent series have only finitely many nonzero terms"
    },
    "correct_answer": "C",
    "difficulty": 2,
    "x": 0.861552,
    "y": 0.649686,
    "z": 0.868045,
    "source_article": "series convergence",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "series convergence",
      "harmonic series",
      "p-series test",
      "necessary vs sufficient conditions"
    ]
  },
  {
    "id": "81487020bfd31ff2",
    "question_text": "What does it mean for two sets to have the same cardinality?",
    "options": {
      "A": "They contain exactly the same elements — two sets have the same cardinality if and only if they are identical sets, meaning every element of one set belongs to the other and vice versa, which makes cardinality equivalent to set equality by the axiom of extensionality",
      "B": "One set is a subset of the other, meaning that equal cardinality requires a containment relationship between the two sets — if $A \\subseteq B$ then $|A| = |B|$, and conversely if neither set contains the other, their cardinalities must differ because elements exclusive to one set contribute additional cardinality",
      "C": "They have the same number of elements when both sets are finite, and for infinite sets, cardinality is determined by which set has 'more' elements in the intuitive sense — for instance, $\\mathbb{R}$ has more elements than $\\mathbb{N}$ because the real numbers form a continuum, but $\\mathbb{N}$ and $\\mathbb{Z}$ have different cardinalities because $\\mathbb{Z}$ includes negative integers",
      "D": "There exists a bijection (one-to-one and onto function) between them — this definition extends naturally to infinite sets, where for example $\\mathbb{N}$ and $\\mathbb{Z}$ have the same cardinality despite $\\mathbb{N} \\subset \\mathbb{Z}$"
    },
    "correct_answer": "D",
    "difficulty": 2,
    "x": 0.811049,
    "y": 0.661257,
    "z": 0.690783,
    "source_article": "cardinality",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "cardinality",
      "bijection",
      "set theory",
      "countability"
    ]
  },
  {
    "id": "1c4e44c4f9714116",
    "question_text": "A continuous function $f: [0,1] \\to [0,1]$ maps the closed unit interval to itself. What can you guarantee about the existence of fixed points?",
    "options": {
      "A": "There must exist at least one point $c \\in [0,1]$ where $f(c) = c$ — this follows from the Intermediate Value Theorem applied to the function $g(x) = f(x) - x$",
      "B": "Fixed points exist only if $f$ is differentiable on the open interval $(0, 1)$, because the Mean Value Theorem — which requires differentiability — is needed to establish the existence of a point where $f'(c) = 1$, and without this derivative condition, fixed points cannot be guaranteed",
      "C": "No fixed point is guaranteed unless $f$ is also injective (one-to-one) on $[0, 1]$",
      "D": "A fixed point exists only if $f(0) = 0$ or $f(1) = 1$, so that the boundary conditions pin down a fixed point"
    },
    "correct_answer": "A",
    "difficulty": 3,
    "x": 0.955179,
    "y": 0.528709,
    "z": 0.677234,
    "source_article": "fixed point theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "fixed point theorem",
      "Intermediate Value Theorem",
      "Brouwer fixed point theorem"
    ]
  },
  {
    "id": "673ab1df4985158b",
    "question_text": "In modular arithmetic, Fermat's Little Theorem states that if $p$ is prime and $\\gcd(a, p) = 1$, then $a^{p-1} \\equiv 1 \\pmod{p}$. What is the conceptual significance of this result?",
    "options": {
      "A": "It shows that prime numbers can always be factored into products of smaller primes using repeated modular exponentiation — the theorem provides a constructive algorithm for prime factorization by iterating the map $a \\mapsto a^{p-1} \\pmod{p}$ and observing which values yield nontrivial factors",
      "B": "It establishes that the multiplicative group of integers modulo a prime has order $p - 1$, and every element's order divides the group order — so $a^{p-1}$ must equal the identity element 1",
      "C": "It proves that $a^p = a$ for all integers $a$, including those divisible by $p$, with no exceptions",
      "D": "It means that exponentiation modulo a prime is always reversible, which provides the mathematical guarantee that RSA public-key encryption is secure — the difficulty of computing discrete logarithms modulo a prime follows directly from Fermat's Little Theorem, making factorization-based cryptography provably hard"
    },
    "correct_answer": "B",
    "difficulty": 3,
    "x": 0.61,
    "y": 0.683255,
    "z": 0.803801,
    "source_article": "Fermat's Little Theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Fermat's Little Theorem",
      "multiplicative group",
      "group order",
      "Lagrange's theorem"
    ]
  },
  {
    "id": "c42964147478dce9",
    "question_text": "The Fundamental Theorem of Calculus connects differentiation and integration. Specifically, if $f$ is continuous on $[a, b]$ and $F(x) = \\int_a^x f(t)\\,dt$, what is $F'(x)$?",
    "options": {
      "A": "$F'(x) = \\int_a^x f'(t)\\,dt$",
      "B": "$F'(x) = f(x) \\cdot (x - a)$",
      "C": "$F'(x) = f(x)$ — differentiation undoes integration, so the derivative of the integral is the original function",
      "D": "$F'(x) = f(b) - f(a)$"
    },
    "correct_answer": "C",
    "difficulty": 3,
    "x": 0.945964,
    "y": 0.638872,
    "z": 0.769268,
    "source_article": "Fundamental Theorem of Calculus",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Fundamental Theorem of Calculus",
      "antiderivative",
      "integration",
      "differentiation"
    ]
  },
  {
    "id": "c1c4f5946874b071",
    "question_text": "The group $(\\mathbb{Z}/6\\mathbb{Z}, +)$ consists of residues $\\{0, 1, 2, 3, 4, 5\\}$ under addition mod 6. Is this group cyclic, and what characterizes its subgroup structure?",
    "options": {
      "A": "It is not cyclic because $6$ is not a prime number — a group $\\mathbb{Z}/n\\mathbb{Z}$ is cyclic if and only if $n$ is prime, since composite moduli produce groups where no single element can generate all residues through repeated addition, and the existence of proper subgroups at orders $2$ and $3$ proves that no generator exists",
      "B": "It is cyclic with generators $1$ and $5$, and every nonzero element generates the full group because repeated addition of any nonzero element eventually cycles through all six residues — the subgroups $\\{0, 2, 4\\}$ and $\\{0, 3\\}$ are artifacts of a particular presentation rather than genuine subgroups, since they are not closed under the group operation of addition modulo $6$",
      "C": "It is cyclic and has nontrivial proper subgroups $\\{0, 3\\}$ and $\\{0, 2, 4\\}$ corresponding to divisors of $6$, but it lacks a full one-to-one correspondence between subgroups and divisors because this bijective relationship holds only for prime-order cyclic groups, not composite-order ones like $\\mathbb{Z}/6\\mathbb{Z}$",
      "D": "It is cyclic, generated by 1 and 5 (elements coprime to 6), and its subgroups $\\{0, 2, 4\\}$ (order 3) and $\\{0, 3\\}$ (order 2) correspond exactly to the divisors of 6 — by the Fundamental Theorem of Cyclic Groups, there is exactly one subgroup for each divisor of the group order"
    },
    "correct_answer": "D",
    "difficulty": 3,
    "x": 0.654132,
    "y": 0.670673,
    "z": 0.505709,
    "source_article": "cyclic group",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "cyclic group",
      "subgroup",
      "Lagrange's theorem",
      "Fundamental Theorem of Cyclic Groups"
    ]
  },
  {
    "id": "79833f027687badd",
    "question_text": "A metric space $(X, d)$ is called complete if every Cauchy sequence in $X$ converges to a limit in $X$. The rational numbers $\\mathbb{Q}$ with the standard metric are NOT complete. What does this incompleteness mean concretely?",
    "options": {
      "A": "There exist Cauchy sequences of rational numbers that converge to irrational numbers — the 'holes' in $\\mathbb{Q}$ correspond to missing limits, and filling these holes by completing $\\mathbb{Q}$ yields the real numbers $\\mathbb{R}$",
      "B": "No sequence of rational numbers can converge at all in $\\mathbb{Q}$, because the rational numbers form a discrete set with no limit points — between any two rationals there is a gap (an irrational number), and these gaps prevent any sequence from getting arbitrarily close to a single rational limit, which is the fundamental reason $\\mathbb{Q}$ fails to be complete",
      "C": "The distance function on $\\mathbb{Q}$ does not satisfy the triangle inequality, so it is not a valid metric",
      "D": "$\\mathbb{Q}$ is incomplete because it is countable, and all complete metric spaces are necessarily uncountable"
    },
    "correct_answer": "A",
    "difficulty": 4,
    "x": 0.868322,
    "y": 0.553076,
    "z": 0.668408,
    "source_article": "completeness",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "completeness",
      "Cauchy sequence",
      "metric space",
      "Dedekind completion",
      "real numbers"
    ]
  },
  {
    "id": "f8344d14d8a08723",
    "question_text": "In probability, the Central Limit Theorem is one of the most important results. What does it state?",
    "options": {
      "A": "The sample mean of any distribution always equals the population mean for every sample of any size — this is because each observation is drawn from the same population, so averaging any collection of observations must reproduce the true expected value exactly, not just approximately, and any observed deviation from the population mean indicates a sampling procedure error",
      "B": "The sum of $n$ independent identically distributed random variables with finite variance, when properly standardized, converges in distribution to a standard normal distribution as $n \\to \\infty$ — regardless of the shape of the original distribution",
      "C": "All probability distributions are approximately normal if the sample size is large enough — this overstates the CLT, which applies to sums and means, not to the original distribution",
      "D": "The law of large numbers guarantees that sample proportions converge to the true population proportion as the sample size increases — while this is a valid asymptotic result, it is the law of large numbers rather than the Central Limit Theorem, which makes a much stronger statement about the distributional shape of the sample mean rather than just its convergence"
    },
    "correct_answer": "B",
    "difficulty": 4,
    "x": 0.827767,
    "y": 0.875057,
    "z": 0.936296,
    "source_article": "Central Limit Theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Central Limit Theorem",
      "convergence in distribution",
      "normal distribution",
      "standardization"
    ]
  },
  {
    "id": "c85cf40afe2c5257",
    "question_text": "A topological space $X$ is connected if it cannot be written as the union of two disjoint nonempty open sets. Which of the following spaces is NOT connected?",
    "options": {
      "A": "The real line $\\mathbb{R}$ with the standard topology, which is in fact connected — it cannot be written as the union of two disjoint nonempty open sets because any partition of $\\mathbb{R}$ into two nonempty open sets would require a boundary point that belongs to neither, contradicting the fact that $\\mathbb{R}$ has no gaps",
      "B": "The unit circle $S^1$ in $\\mathbb{R}^2$, which is a compact, connected topological space — any attempt to separate it into two disjoint open sets fails because the circle has no endpoints where a disconnection could occur, and every continuous path between two points can be completed around the circle",
      "C": "The set $\\{0\\} \\cup \\{1\\}$ with the subspace topology inherited from $\\mathbb{R}$ — it is the union of two disjoint open singletons, hence disconnected",
      "D": "The closed interval $[0, 1]$ with the standard topology, which is connected by the same argument as the real line — the completeness of $[0, 1]$ ensures that any partition into two nonempty sets must include a point in both closures"
    },
    "correct_answer": "C",
    "difficulty": 4,
    "x": 0.911548,
    "y": 0.538632,
    "z": 0.375275,
    "source_article": "connectedness",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "connectedness",
      "topological space",
      "subspace topology",
      "disconnected space"
    ]
  },
  {
    "id": "71c237c56c90909b",
    "question_text": "The Galois group of a polynomial captures the symmetries among its roots. What is the deep connection between Galois theory and the unsolvability of the general quintic equation by radicals?",
    "options": {
      "A": "Fifth-degree polynomials are too computationally complex to solve, and Galois theory quantifies this complexity",
      "B": "The general quintic has no real roots, so no formula can express them",
      "C": "Quintic polynomials always have repeated roots, making the radical formula degenerate",
      "D": "The Galois group of a general quintic is the symmetric group $S_5$, which contains the simple, non-abelian alternating group $A_5$ as a composition factor — since $A_5$ has no proper normal subgroups, $S_5$ is not solvable, and a polynomial is solvable by radicals if and only if its Galois group is a solvable group"
    },
    "correct_answer": "D",
    "difficulty": 4,
    "x": 0.628234,
    "y": 0.58315,
    "z": 0.55484,
    "source_article": "Galois theory",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Galois theory",
      "solvable group",
      "symmetric group",
      "Abel-Ruffini theorem",
      "simple group"
    ]
  },
  {
    "id": "b566058f51a75409",
    "question_text": "The Lebesgue integral extends the Riemann integral to a much larger class of functions. What is the key conceptual difference in how the two integrals partition the domain versus the range?",
    "options": {
      "A": "The Riemann integral partitions the domain ($x$-axis) into subintervals and approximates the function on each, while the Lebesgue integral partitions the range ($y$-axis) into subintervals and measures the size of the preimage sets — this 'horizontal slicing' approach handles highly discontinuous functions that defeat the Riemann integral",
      "B": "The Lebesgue integral uses a finer partition of the $x$-axis with infinitesimally small subintervals, making it a strict refinement of the Riemann approach",
      "C": "The Lebesgue integral replaces summation with a limit of products, fundamentally changing the algebraic structure of integration",
      "D": "The Lebesgue integral is defined only for bounded functions on finite intervals, while the Riemann integral handles unbounded functions"
    },
    "correct_answer": "A",
    "difficulty": 5,
    "x": 0.908208,
    "y": 0.663629,
    "z": 0.983728,
    "source_article": "Lebesgue integral",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Lebesgue integral",
      "Riemann integral",
      "measure theory",
      "preimage",
      "horizontal vs vertical slicing"
    ]
  },
  {
    "id": "0d09eb2cc31c8e65",
    "question_text": "Bayesian and frequentist interpretations of probability lead to fundamentally different approaches to statistical inference. What is the core philosophical distinction?",
    "options": {
      "A": "Bayesian methods are always computationally more expensive than frequentist methods because they require numerical integration over high-dimensional posterior distributions using Markov chain Monte Carlo (MCMC) sampling, whereas frequentist methods rely on closed-form maximum likelihood estimators that can be computed analytically — this computational cost, rather than any philosophical distinction, is the primary practical difference between the two frameworks and determines which approach is used in any given application",
      "B": "In the frequentist framework, probability represents long-run relative frequency of events and parameters are fixed unknown constants, while in the Bayesian framework, probability quantifies degrees of belief and parameters are treated as random variables with prior distributions that are updated via Bayes' theorem as data are observed",
      "C": "Frequentist methods can only handle discrete data with finite sample spaces, while Bayesian methods extend naturally to continuous probability distributions and uncountable parameter spaces",
      "D": "The two frameworks always produce identical numerical results for any dataset and any statistical model — they differ only in their philosophical interpretation and the terminology they use to describe the same underlying mathematical operations, and any apparent numerical disagreement indicates an implementation error rather than a genuine methodological distinction"
    },
    "correct_answer": "B",
    "difficulty": 5,
    "x": 0.85934,
    "y": 0.947892,
    "z": 1.0,
    "source_article": "Bayesian inference",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Bayesian inference",
      "frequentist inference",
      "prior distribution",
      "Bayes' theorem",
      "philosophy of probability"
    ]
  },
  {
    "id": "ad96090da273010c",
    "question_text": "The Euler characteristic $\\chi$ is a topological invariant. For a convex polyhedron with $V$ vertices, $E$ edges, and $F$ faces, Euler's formula gives $V - E + F = 2$. What deeper topological fact does this reflect?",
    "options": {
      "A": "The formula $V - E + F = 2$ holds because convex polyhedra always have more vertices than edges — specifically, the excess of vertices over edges plus faces always equals 2 for geometric reasons related to the convexity constraint, and this relationship breaks down for non-convex polyhedra where vertices can outnumber edges by different amounts",
      "B": "The Euler characteristic depends only on the edge lengths and face angles of the polyhedron, not on its topology — changing the shape while preserving metric quantities preserves $\\chi$",
      "C": "The Euler characteristic $\\chi = V - E + F = 2$ reflects that a convex polyhedron is homeomorphic to the 2-sphere $S^2$, which has $\\chi(S^2) = 2$ — deforming the surface continuously preserves $\\chi$, making it a topological invariant independent of the specific triangulation or polyhedral decomposition",
      "D": "The formula $V - E + F = 2$ holds only for the five Platonic solids (regular polyhedra) and fails for all irregular convex polyhedra due to the asymmetry of their faces"
    },
    "correct_answer": "C",
    "difficulty": 5,
    "x": 0.773103,
    "y": 0.634527,
    "z": 0.453937,
    "source_article": "Euler characteristic",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Euler characteristic",
      "topological invariant",
      "homeomorphism",
      "CW complex",
      "2-sphere"
    ]
  },
  {
    "id": "bb88c300a450d373",
    "question_text": "The Riemann Hypothesis concerns the zeros of the Riemann zeta function $\\zeta(s) = \\sum_{n=1}^{\\infty} n^{-s}$. Why is this conjecture considered the most important unsolved problem in mathematics?",
    "options": {
      "A": "It would prove that there are infinitely many prime numbers, which is a statement currently taken as proven (by Euclid's argument) but whose proof relies on an implicit assumption about the completeness of the natural numbers that has been questioned by constructivist mathematicians — the Riemann Hypothesis would resolve this foundational controversy by providing a purely analytic proof that does not depend on proof by contradiction, thereby placing the infinitude of primes on a firmer logical foundation than Euclid's reductio ad absurdum argument allows",
      "B": "It would show that the Riemann zeta function has no zeros at all in the critical strip $0 < \\text{Re}(s) < 1$, which would simplify analytic number theory by eliminating the need to account for zero contributions in contour integral representations of arithmetic functions — if $\\zeta(s)$ were zero-free in the critical strip, the prime number theorem's error term would vanish identically, and the prime counting function $\\pi(x)$ would equal the logarithmic integral $\\text{Li}(x)$ exactly for all sufficiently large $x$",
      "C": "It concerns whether $\\zeta(s)$ converges for all complex numbers $s$ in the entire complex plane, which would extend the function's domain beyond the half-plane $\\text{Re}(s) > 1$ where the Dirichlet series converges absolutely — while analytic continuation already extends $\\zeta(s)$ to all $s \\neq 1$, the Riemann Hypothesis is sometimes described as being about convergence properties, conflating the series representation with the meromorphically continued function",
      "D": "The location of $\\zeta$'s nontrivial zeros (conjectured to all lie on the critical line $\\text{Re}(s) = \\frac{1}{2}$) controls the distribution of prime numbers — RH implies the strongest possible error bound on the Prime Counting Function $\\pi(x)$ relative to the logarithmic integral $\\text{Li}(x)$, and its resolution would settle hundreds of conditional theorems across number theory, random matrix theory, and mathematical physics"
    },
    "correct_answer": "D",
    "difficulty": 5,
    "x": 0.696971,
    "y": 0.604208,
    "z": 0.866113,
    "source_article": "Riemann Hypothesis",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Riemann Hypothesis",
      "Riemann zeta function",
      "prime number distribution",
      "critical line",
      "analytic number theory"
    ]
  },
  {
    "id": "f11197d1ed714fb3",
    "question_text": "A function f is continuous on the closed interval [a, b] and differentiable on the open interval (a, b). The Mean Value Theorem guarantees the existence of at least one point c in (a, b) where f'(c) equals a specific value. What does f'(c) represent geometrically?",
    "options": {
      "A": "The slope of the secant line connecting (a, f(a)) and (b, f(b))",
      "B": "The tangent line at point c is perpendicular to the secant line connecting the endpoints, meaning f'(c) equals the negative reciprocal of the average rate of change over the interval",
      "C": "The maximum value of the derivative on the entire interval [a, b], because the Mean Value Theorem identifies the point where the function changes most rapidly between the two endpoints",
      "D": "The area under the curve divided by the interval length (b − a), representing the average value of the function rather than the average rate of change over the interval"
    },
    "correct_answer": "A",
    "difficulty": 1,
    "x": 0.9804,
    "y": 0.664876,
    "z": 0.644033,
    "source_article": "Mean Value Theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Mean Value Theorem",
      "secant line",
      "average rate of change"
    ]
  },
  {
    "id": "dbb5e4fe60c852da",
    "question_text": "A 3×3 matrix A has eigenvalues 2, 3, and 5. Without computing the matrix explicitly, what is the determinant of A?",
    "options": {
      "A": "The determinant equals 10 because it is the sum of all eigenvalues, following from the fact that the trace of a matrix equals the product of its eigenvalues and the determinant equals their sum",
      "B": "The determinant is 30, because the determinant of a square matrix equals the product of its eigenvalues",
      "C": "The determinant equals the largest eigenvalue (5), since it measures maximum stretching",
      "D": "The determinant cannot be determined from eigenvalues alone — it depends on the eigenvectors too"
    },
    "correct_answer": "B",
    "difficulty": 1,
    "x": 0.791697,
    "y": 0.80738,
    "z": 0.0,
    "source_article": "eigenvalues",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "eigenvalues",
      "determinant",
      "characteristic polynomial"
    ]
  },
  {
    "id": "f34186b9bbbf18ea",
    "question_text": "You flip a fair coin 10 times. Which outcome sequence is more likely: exactly 5 heads and 5 tails, or exactly 10 heads?",
    "options": {
      "A": "Both outcomes are equally likely because every specific sequence of 10 coin flips has the same probability of (1/2)^10, and the number of heads versus tails in a given sequence does not affect its individual probability",
      "B": "Exactly 10 heads is more likely because once you start getting heads, the conditional probability of the next flip being heads increases slightly due to momentum effects in the binomial distribution",
      "C": "5 heads and 5 tails is more likely because there are C(10,5) = 252 distinct arrangements giving that result, versus only 1 arrangement giving 10 heads",
      "D": "Neither can be calculated without knowing whether the flips are independent events"
    },
    "correct_answer": "C",
    "difficulty": 1,
    "x": 0.836038,
    "y": 0.965184,
    "z": 0.672189,
    "source_article": "binomial distribution",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "binomial distribution",
      "combinatorics",
      "probability"
    ]
  },
  {
    "id": "78c291d69b9bfbcf",
    "question_text": "The number 0.999... (with nines repeating infinitely) is compared to the number 1. What is the mathematical relationship between these two expressions?",
    "options": {
      "A": "0.999... is less than 1 by an infinitesimally small positive amount that cannot be expressed as a standard real number but exists as a hyperreal infinitesimal in non-standard analysis frameworks",
      "B": "0.999... approaches 1 as a limit but never actually reaches it, because the decimal expansion is a process that continues forever and no finite number of nines can equal 1",
      "C": "The two expressions are undefined relative to each other because comparing an infinite process to a finite number requires transfinite arithmetic that is not part of standard real analysis",
      "D": "They are exactly equal — 0.999... = 1 in the real number system"
    },
    "correct_answer": "D",
    "difficulty": 1,
    "x": 0.866189,
    "y": 0.701875,
    "z": 0.798478,
    "source_article": "limits",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "limits",
      "real number system",
      "infinite series"
    ]
  },
  {
    "id": "8febab55e759940b",
    "question_text": "A continuous function f maps the closed interval [0, 1] to itself (i.e., f: [0,1] → [0,1]). Must f have a fixed point — a value x where f(x) = x?",
    "options": {
      "A": "Yes — by the Intermediate Value Theorem applied to g(x) = f(x) − x, which satisfies g(0) ≥ 0 and g(1) ≤ 0, guaranteeing a zero of g and therefore a fixed point of f",
      "B": "Only if f is also differentiable, because the IVT requires differentiability on open intervals",
      "C": "No — a continuous function from [0, 1] to [0, 1] can avoid all fixed points by mapping each point sufficiently far from itself, for example by shifting every point by a small constant amount modulo 1 to create a fixed-point-free continuous mapping",
      "D": "Only if f is monotonically increasing, because decreasing functions on [0, 1] can jump over the diagonal y = x without crossing it if the function decreases steeply enough between the endpoints"
    },
    "correct_answer": "A",
    "difficulty": 1,
    "x": 0.98775,
    "y": 0.553266,
    "z": 0.614814,
    "source_article": "Intermediate Value Theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Intermediate Value Theorem",
      "fixed point theorem",
      "continuity"
    ]
  },
  {
    "id": "b3c03dffe82e8cba",
    "question_text": "Two events A and B are independent. You know P(A) = 0.3 and P(B) = 0.5. What is P(A ∪ B)?",
    "options": {
      "A": "0.80, since independence means P(A) + P(B) with no overlap",
      "B": "P(A ∪ B) = 0.65, computed as P(A) + P(B) − P(A)P(B) = 0.3 + 0.5 − 0.15",
      "C": "0.50, because the union equals the larger event's probability",
      "D": "P(A ∪ B) cannot be computed without knowing whether A and B are mutually exclusive, because the inclusion-exclusion formula P(A) + P(B) − P(A ∩ B) requires knowing the joint probability which independence alone does not determine"
    },
    "correct_answer": "B",
    "difficulty": 1,
    "x": 0.869539,
    "y": 0.942925,
    "z": 0.45863,
    "source_article": "independence",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "independence",
      "inclusion-exclusion",
      "probability"
    ]
  },
  {
    "id": "6c0db75e5e9d7cc3",
    "question_text": "A linear transformation T: R³ → R³ has a 2-dimensional null space (kernel). What is the dimension of the image (range) of T?",
    "options": {
      "A": "The image dimension is 2, because the rank must equal the nullity for any linear transformation between spaces of the same dimension, by a symmetry property of the rank-nullity theorem",
      "B": "The image dimension cannot be determined without knowing the specific matrix representation of T, because different transformations with the same null space dimension can have different image dimensions depending on their eigenvalue structure",
      "C": "The image dimension is 1, by the rank-nullity theorem: dim(domain) = rank + nullity, so 3 = rank + 2, giving rank = 1",
      "D": "The image dimension is 0, meaning T maps every vector in R³ to the zero vector, because any transformation with a non-trivial kernel must be the zero transformation since the kernel's existence implies the image collapses entirely"
    },
    "correct_answer": "C",
    "difficulty": 2,
    "x": 0.813978,
    "y": 0.637801,
    "z": 0.249069,
    "source_article": "rank-nullity theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "rank-nullity theorem",
      "null space",
      "image",
      "linear transformation"
    ]
  },
  {
    "id": "b5e8c181568daa2d",
    "question_text": "You're computing a Taylor series expansion of sin(x) around x = 0. The series contains only odd powers of x (x, x³, x⁵, ...). Why are there no even-power terms?",
    "options": {
      "A": "Because the even-power coefficients happen to be very small (on the order of 10⁻¹⁵) due to numerical cancellation during the derivation process, so they are conventionally rounded to zero for simplicity in the standard presentation of the series",
      "B": "Because the Taylor series of any periodic function contains only odd powers, since periodicity forces all even-order derivatives at any point to equal zero by a fundamental theorem of Fourier analysis",
      "C": "Because sin(x) only converges as a Taylor series for odd-degree polynomial approximations, and including even-power terms would cause the series to diverge for all nonzero values of x",
      "D": "Because sin(x) is an odd function — sin(−x) = −sin(x) — which forces all even-order derivatives at x = 0 to equal zero, eliminating the even-power coefficients from the expansion"
    },
    "correct_answer": "D",
    "difficulty": 2,
    "x": 0.837915,
    "y": 0.688082,
    "z": 0.511909,
    "source_article": "Taylor series",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Taylor series",
      "odd functions",
      "symmetry"
    ]
  },
  {
    "id": "29add4cc1a938769",
    "question_text": "A fair six-sided die is rolled repeatedly until a 6 appears. What is the expected number of rolls needed?",
    "options": {
      "A": "The expected number of rolls is 6, because the geometric distribution with success probability p = 1/6 has expected value 1/p = 6",
      "B": "3, the median of the uniform distribution on {1,...,6} representing central tendency",
      "C": "The expected number grows without bound (it is infinite) because there is always a nonzero probability that the die never lands on 6, which makes the expectation integral diverge when computed over the unbounded sample space of all possible trial sequences",
      "D": "The expected number is 3.5, computed as the average of 1 and 6, since the minimum possible rolls is 1 (first roll is a 6) and the maximum is 6 (guaranteed to see a 6 within 6 rolls of a fair die by the pigeonhole principle)"
    },
    "correct_answer": "A",
    "difficulty": 2,
    "x": 0.874743,
    "y": 0.952839,
    "z": 0.639852,
    "source_article": "geometric distribution",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "geometric distribution",
      "expected value",
      "probability"
    ]
  },
  {
    "id": "2d7bdcb4be081ca7",
    "question_text": "A real-valued function f is differentiable at a point x₀ and f'(x₀) = 0. Does this guarantee that x₀ is a local extremum (maximum or minimum)?",
    "options": {
      "A": "Yes — any point where the derivative equals zero must be either a local maximum or local minimum, because the tangent line is horizontal and the function must curve either upward or downward away from this critical point by the continuity of the derivative function",
      "B": "No — f'(x₀) = 0 is necessary but not sufficient for a local extremum; the point could be an inflection point like x₀ = 0 for f(x) = x³, where the derivative vanishes but the function changes from concave to convex without achieving a local extremum",
      "C": "Yes, provided the function is continuous on an interval containing x₀, because Fermat's theorem states that interior critical points of continuous functions on closed intervals are always local extrema of the function",
      "D": "The question is ill-posed because a derivative of exactly zero cannot occur at an isolated point — the derivative must equal zero on an entire open interval surrounding x₀ by the completeness property of the real numbers and the continuity of differentiable functions"
    },
    "correct_answer": "B",
    "difficulty": 2,
    "x": 0.940775,
    "y": 0.638297,
    "z": 0.478429,
    "source_article": "critical points",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "critical points",
      "inflection points",
      "necessary vs sufficient conditions"
    ]
  },
  {
    "id": "42cfd0085c5ec228",
    "question_text": "A convergent series Σaₙ has all positive terms. Does the rearranged series (same terms in a different order) necessarily converge to the same sum?",
    "options": {
      "A": "No — Riemann's rearrangement theorem says any convergent series can be rearranged to any value",
      "B": "Only if the rearrangement preserves the relative ordering of terms with magnitude above 1 and terms with magnitude below 1, because large terms dominate the convergence behavior and reordering them changes the partial sums enough to alter the limit",
      "C": "Yes — a convergent series of positive terms converges absolutely (since |aₙ| = aₙ), and absolutely convergent series produce the same sum under any rearrangement",
      "D": "It depends on convergence rate — rapidly convergent series are invariant while slow ones are not"
    },
    "correct_answer": "C",
    "difficulty": 2,
    "x": 0.859542,
    "y": 0.635382,
    "z": 0.732966,
    "source_article": "absolute convergence",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "absolute convergence",
      "Riemann rearrangement theorem",
      "series"
    ]
  },
  {
    "id": "fc4cb1b6aa517718",
    "question_text": "Two vectors u and v in R³ are orthogonal. You compute their cross product u × v. What is the relationship between the magnitude |u × v| and the magnitudes |u| and |v|?",
    "options": {
      "A": "|u × v| = |u| + |v|, because the cross product of orthogonal vectors produces a vector whose magnitude equals the sum of the input magnitudes by the parallelogram identity extended to three dimensions via the triangle inequality for orthogonal components",
      "B": "|u||v|sin(0°) = 0, since orthogonal vectors are anti-parallel making the sine factor zero",
      "C": "|u × v| = 0 whenever both vectors lie in the same coordinate plane, because the cross product only produces nonzero results when the two input vectors have components in all three coordinate directions simultaneously",
      "D": "|u × v| = |u||v|, because the cross product formula gives |u||v|sin(θ), and orthogonality means θ = 90° so sin(90°) = 1"
    },
    "correct_answer": "D",
    "difficulty": 2,
    "x": 0.806582,
    "y": 0.755403,
    "z": 0.197055,
    "source_article": "cross product",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "cross product",
      "orthogonality",
      "vector magnitude"
    ]
  },
  {
    "id": "0f9e91a5de9e4adb",
    "question_text": "The Fundamental Theorem of Algebra states that every non-constant polynomial with complex coefficients has at least one complex root. What crucial property of the complex numbers makes this theorem true, that the real numbers lack?",
    "options": {
      "A": "The complex numbers are algebraically closed — every polynomial equation of degree n ≥ 1 has exactly n roots (counted with multiplicity) in C, a completeness property that R lacks since polynomials like x² + 1 have no real roots",
      "B": "The complex numbers form a totally ordered field allowing < and > comparisons, which enables the Intermediate Value Theorem to locate roots",
      "C": "The complex numbers have finite cardinality matching the number of polynomial equations, creating a natural bijection between polynomials and root sets",
      "D": "The complex numbers support division by zero via the extended complex plane, eliminating the only obstruction to polynomial factorization"
    },
    "correct_answer": "A",
    "difficulty": 3,
    "x": 0.751722,
    "y": 0.583578,
    "z": 0.597168,
    "source_article": "algebraic closure",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "algebraic closure",
      "Fundamental Theorem of Algebra",
      "field extensions"
    ]
  },
  {
    "id": "372f2b9b771a9aa6",
    "question_text": "Gödel's First Incompleteness Theorem applies to formal systems satisfying certain conditions. Which statement correctly describes its core implication?",
    "options": {
      "A": "Every mathematical statement is either provably true or provably false within standard set theory, because ZFC (Zermelo-Fraenkel with Choice) was specifically designed after Gödel's work to be a complete system that avoids the incompleteness phenomenon",
      "B": "Any consistent formal system capable of expressing basic arithmetic contains true statements that cannot be proved within that system — the system is necessarily incomplete",
      "C": "Mathematical truths are subjective and culturally determined, since no logical system establishes objective facts",
      "D": "Arithmetic is inconsistent — some statements are simultaneously provably true and false, revealing a foundational contradiction"
    },
    "correct_answer": "B",
    "difficulty": 3,
    "x": 0.803678,
    "y": 0.616562,
    "z": 0.698243,
    "source_article": "Gödel's incompleteness theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Gödel's incompleteness theorem",
      "formal systems",
      "consistency vs completeness"
    ]
  },
  {
    "id": "fd9da6d4981b47ae",
    "question_text": "You sample n independent observations from a population with finite mean μ and finite variance σ². As n increases, the distribution of the sample mean X̄ approaches a normal distribution. What is the minimum requirement on the population distribution for this convergence to hold?",
    "options": {
      "A": "The population itself must already be normally distributed, because the Central Limit Theorem is actually a statement about preserving normality through averaging — non-normal populations produce sample means with non-normal limiting distributions that depend on the original population's shape",
      "B": "The population must have a symmetric distribution, because skewed populations produce sample means that remain skewed regardless of sample size, and the Central Limit Theorem's convergence to normality only occurs when the underlying distribution has exactly zero skewness",
      "C": "No distributional shape requirement beyond having finite mean and variance — the Central Limit Theorem guarantees convergence to normality for the sample mean regardless of the population's distribution shape, whether skewed, multimodal, discrete, or otherwise",
      "D": "The population must be continuous (not discrete), because discrete distributions produce sample means that take on only rational values and therefore cannot converge to the continuous normal distribution in the distributional convergence sense"
    },
    "correct_answer": "C",
    "difficulty": 3,
    "x": 0.879417,
    "y": 0.88381,
    "z": 0.798461,
    "source_article": "Central Limit Theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Central Limit Theorem",
      "convergence in distribution",
      "sample mean"
    ]
  },
  {
    "id": "7638f371b2e0f1ae",
    "question_text": "A group G has order 15 (exactly 15 elements). What can you conclude about the structure of G using the Sylow theorems?",
    "options": {
      "A": "G must be non-abelian because 15 has two distinct odd prime factors (3 and 5), and groups whose order is a product of two distinct odd primes always have non-trivial non-commuting elements that make the group non-abelian by a corollary of Sylow's theorems",
      "B": "G could have multiple non-isomorphic structures — there exist both abelian and non-abelian groups of order 15, and additional information about the generators and relations is needed to determine which structure G possesses",
      "C": "G is isomorphic to S₃ × Z₅, because the symmetric group S₃ is the unique group of order 6 and combining it with Z₅ via direct product is the only way to construct a group whose order equals the product of 3 and 5",
      "D": "G has both a unique subgroup of order 3 and a unique subgroup of order 5, and since these subgroups together generate a group isomorphic to Z₁₅, the only possibility for G is the cyclic group of order 15 — making G necessarily abelian and cyclic"
    },
    "correct_answer": "D",
    "difficulty": 3,
    "x": 0.664631,
    "y": 0.670716,
    "z": 0.410226,
    "source_article": "Sylow theorems",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Sylow theorems",
      "group classification",
      "cyclic groups"
    ]
  },
  {
    "id": "39a19976e76d3aef",
    "question_text": "A topological space X is compact. You have a sequence of nested, non-empty closed subsets C₁ ⊇ C₂ ⊇ C₃ ⊇ ... in X. Must the intersection ∩Cₙ be non-empty?",
    "options": {
      "A": "Yes — compactness is precisely the property that guarantees the finite intersection property extends to arbitrary intersections of nested closed sets, ensuring ∩Cₙ ≠ ∅",
      "B": "No — consider the nested intervals (0, 1/n] in R, which are non-empty closed subsets with empty intersection, demonstrating that compactness is insufficient to prevent nested closed sets from having vacuous intersection",
      "C": "Only if each Cₙ is also connected — disconnected closed sets can have empty nested intersection",
      "D": "Only in metric spaces — the triangle inequality is needed for the convergence argument"
    },
    "correct_answer": "A",
    "difficulty": 3,
    "x": 0.890279,
    "y": 0.567531,
    "z": 0.529225,
    "source_article": "compactness",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "compactness",
      "finite intersection property",
      "nested closed sets"
    ]
  },
  {
    "id": "fdfa23f58a5a7f40",
    "question_text": "The Banach fixed-point theorem guarantees that a contraction mapping on a complete metric space has a unique fixed point. What happens if you remove the completeness requirement — can the conclusion still hold?",
    "options": {
      "A": "Completeness is irrelevant — the contraction condition alone forces the fixed point to exist, and completeness was only a historical artifact of the 1922 proof",
      "B": "Completeness is essential — without it, the iterative sequence generated by the contraction can converge to a limit point that lies outside the space, meaning no fixed point exists within the domain despite the sequence being Cauchy",
      "C": "Removing completeness still guarantees existence but not uniqueness — incomplete spaces can have multiple fixed points depending on the starting point",
      "D": "Without completeness, the contraction becomes expansive in some regions due to metric distortion from missing limit points"
    },
    "correct_answer": "B",
    "difficulty": 3,
    "x": 0.931763,
    "y": 0.51,
    "z": 0.720047,
    "source_article": "Banach fixed-point theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Banach fixed-point theorem",
      "completeness",
      "contraction mapping"
    ]
  },
  {
    "id": "287a269cdb5d25d2",
    "question_text": "In the RSA cryptosystem, the security depends on the difficulty of factoring large numbers. Specifically, given the public key (n, e) where n = pq for large primes p, q, why does knowing the factorization of n break the system?",
    "options": {
      "A": "Knowing p and q reveals the encryption exponent e directly, because e is always chosen as the smaller of the two primes and is only disguised by the public posting of their product n as a decoy to mislead attackers into attempting factorization",
      "B": "Knowing p and q allows direct decryption by dividing the ciphertext by n, because RSA encryption is simply multiplication by n, and decryption is the corresponding division — factoring reveals the divisors needed for this operation",
      "C": "Factoring n into p and q allows computing Euler's totient φ(n) = (p−1)(q−1), from which the private decryption exponent d can be efficiently calculated as the modular inverse of e modulo φ(n) using the extended Euclidean algorithm",
      "D": "The factorization provides the secret initialization vector needed to seed the pseudorandom number generator that RSA uses internally to scramble plaintext bits before the modular exponentiation step, and without this seed the scrambling cannot be reversed"
    },
    "correct_answer": "C",
    "difficulty": 4,
    "x": 0.62118,
    "y": 0.78463,
    "z": 0.630963,
    "source_article": "RSA cryptosystem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "RSA cryptosystem",
      "Euler's totient function",
      "modular arithmetic"
    ]
  },
  {
    "id": "565578c85174dd78",
    "question_text": "A random variable X follows a Poisson distribution with parameter λ. As λ → ∞, what distribution does the standardized variable (X − λ)/√λ approach?",
    "options": {
      "A": "A uniform distribution on [−√λ, √λ], since the Poisson spreads mass evenly as λ increases",
      "B": "It diverges and does not converge to any distribution, since the Poisson's support grows unboundedly as λ increases",
      "C": "An exponential distribution with rate 1, because the Poisson process has exponential inter-arrival times",
      "D": "It approaches the standard normal distribution N(0, 1), as a consequence of the Central Limit Theorem applied to the Poisson as a sum of λ independent Poisson(1) random variables"
    },
    "correct_answer": "D",
    "difficulty": 4,
    "x": 0.878435,
    "y": 0.906645,
    "z": 0.733807,
    "source_article": "Poisson distribution",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Poisson distribution",
      "Central Limit Theorem",
      "normal approximation"
    ]
  },
  {
    "id": "aa96da19994a3fb8",
    "question_text": "A smooth manifold M has Euler characteristic χ(M) = 0. By the Poincaré-Hopf theorem, what does this imply about vector fields on M?",
    "options": {
      "A": "There exists a nowhere-vanishing smooth vector field on M, because the Poincaré-Hopf theorem states that the sum of indices of zeros of any vector field equals χ(M), and χ(M) = 0 permits a vector field with no zeros at all",
      "B": "M must be non-orientable, because orientable manifolds always have nonzero Euler characteristic by a topological obstruction arising from the orientation class in the top cohomology group of the manifold, making χ = 0 impossible for orientable surfaces",
      "C": "Every smooth vector field on M must vanish at every point — a zero Euler characteristic means the manifold has trivial tangent bundle and cannot support any nonzero tangent vectors at any point anywhere on the surface of the manifold",
      "D": "M admits exactly two topologically distinct smooth vector fields (up to homotopy), with all other vector fields being continuously deformable into one of these two canonical forms by gradient flow along the manifold's intrinsic metric"
    },
    "correct_answer": "A",
    "difficulty": 4,
    "x": 0.815062,
    "y": 0.597738,
    "z": 0.367404,
    "source_article": "Poincaré-Hopf theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Poincaré-Hopf theorem",
      "Euler characteristic",
      "vector fields"
    ]
  },
  {
    "id": "f3dfb50e32b24a87",
    "question_text": "The p-adic numbers Q_p extend the rational numbers using a non-Archimedean absolute value. In Q_5 (5-adic numbers), which of the following is true about the series 1 + 5 + 5² + 5³ + ...?",
    "options": {
      "A": "The series diverges in Q_5 just as it diverges in R, because geometric series with ratio greater than 1 cannot converge in any number system by the Archimedean principle, which is a universal property of all metric completions of Q",
      "B": "The series converges in Q_5 to −1/4, because |5|_5 = 1/5 < 1, making this a convergent geometric series with sum 1/(1−5) = −1/4 in the 5-adic metric",
      "C": "The series represents 5-adic infinity, a formal element adjoined to Q_5 analogous to ∞ in the extended real numbers, that serves as the identity element for 5-adic multiplication in the completed number field",
      "D": "The series converges to 0 in Q_5, because successive terms 5ⁿ become 5-adically smaller so rapidly that they contribute nothing to the total sum, collapsing the series to its first term's residue class modulo 5"
    },
    "correct_answer": "B",
    "difficulty": 4,
    "x": 0.757941,
    "y": 0.639286,
    "z": 0.715128,
    "source_article": "p-adic numbers",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "p-adic numbers",
      "non-Archimedean absolute value",
      "geometric series"
    ]
  },
  {
    "id": "717ea0f4aefb7700",
    "question_text": "A measure space (X, Σ, μ) satisfies μ(X) = 1 (it's a probability space). A sequence of measurable functions fₙ converges to f almost everywhere. Does fₙ necessarily converge to f in L¹ (i.e., does ∫|fₙ − f|dμ → 0)?",
    "options": {
      "A": "Yes — on a finite measure space, a.e. convergence always implies L¹ convergence by the monotone convergence theorem",
      "B": "Yes, provided the measure space is complete, since completeness ensures all null-set modifications are measurable",
      "C": "No — a.e. convergence does not imply L¹ convergence, even on a probability space, because the functions can develop 'escaping mass' (e.g., fₙ = n·1_{[0,1/n]} converges to 0 a.e. but ∫|fₙ|dμ = 1 for all n)",
      "D": "Undecidable within ZFC because the relationship between pointwise and integral convergence depends on the Continuum Hypothesis"
    },
    "correct_answer": "C",
    "difficulty": 4,
    "x": 0.931675,
    "y": 0.674004,
    "z": 0.904641,
    "source_article": "measure theory",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "measure theory",
      "L1 convergence",
      "almost everywhere convergence"
    ]
  },
  {
    "id": "4319791106027cd1",
    "question_text": "The Riemann zeta function ζ(s) = Σn⁻ˢ converges for Re(s) > 1 and extends to a meromorphic function on all of C. What is the value of ζ(−1), and what does it represent in the context of regularization?",
    "options": {
      "A": "ζ(−1) = ∞, which simply confirms that the series 1 + 2 + 3 + 4 + ... diverges and has no meaningful finite value under any mathematical framework whatsoever, including analytic continuation or any other regularization method ever developed",
      "B": "ζ(−1) = 0, because the zeta function has trivial zeros at all negative odd integers, and −1 is the first such zero encountered when extending the function to the left half-plane",
      "C": "ζ(−1) = 1, computed by Abel summation of the series 1 + 2 + 3 + 4 + ... using the exponential regularization method, which assigns each term a convergence factor and evaluates the result at the regularization parameter equal to zero",
      "D": "ζ(−1) = −1/12, obtained through analytic continuation — while the series 1 + 2 + 3 + ... diverges, the unique meromorphic extension of ζ assigns the value −1/12 at s = −1, which appears in string theory and the Casimir effect"
    },
    "correct_answer": "D",
    "difficulty": 4,
    "x": 0.774804,
    "y": 0.571989,
    "z": 0.842984,
    "source_article": "Riemann zeta function",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Riemann zeta function",
      "analytic continuation",
      "regularization"
    ]
  },
  {
    "id": "4d06891350af4180",
    "question_text": "The Axiom of Choice (AC) is independent of ZF set theory. Which of the following mathematical statements is equivalent to AC?",
    "options": {
      "A": "Every vector space has a basis (a Hamel basis), which requires choosing basis vectors from potentially uncountable collections of linearly independent sets without any explicit selection rule guiding the choices",
      "B": "Every continuous function on a compact set is uniformly continuous — this requires AC to select δ-neighborhoods from covering families",
      "C": "The real numbers are uncountable — Cantor's diagonalization requires AC to make infinitely many digit-selection choices",
      "D": "Every bounded monotone sequence of real numbers converges, because the Axiom of Choice is needed to select the limit point from the set of accumulation points in the monotone convergence argument"
    },
    "correct_answer": "A",
    "difficulty": 5,
    "x": 0.796505,
    "y": 0.604803,
    "z": 0.569739,
    "source_article": "Axiom of Choice",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Axiom of Choice",
      "Hamel basis",
      "ZF set theory"
    ]
  },
  {
    "id": "0cb50585346077da",
    "question_text": "Fermat's Last Theorem states that xⁿ + yⁿ = zⁿ has no positive integer solutions for n ≥ 3. Andrew Wiles' 1995 proof established this by proving a special case of which broader conjecture?",
    "options": {
      "A": "The Riemann Hypothesis for elliptic curve L-functions, showing that all non-trivial zeros of these L-functions lie on the critical line Re(s) = 1/2, which implies the non-existence of integer solutions to Fermat's equation through a deep connection between zero distributions and Diophantine equations",
      "B": "The Taniyama-Shimura-Weil conjecture (modularity theorem) — that every rational elliptic curve is modular, meaning it corresponds to a modular form. Combined with Ribet's theorem showing Frey's curve from a hypothetical Fermat solution cannot be modular, this yields a contradiction",
      "C": "The Birch and Swinnerton-Dyer conjecture, relating elliptic curve rank to L-function behavior at s = 1",
      "D": "The Langlands Program's functoriality conjecture for GL(2) automorphic representations, proving that every automorphic representation of GL(2) over Q arises from a geometric Galois representation, which excludes representations attached to Fermat solution curves"
    },
    "correct_answer": "B",
    "difficulty": 5,
    "x": 0.640228,
    "y": 0.584468,
    "z": 0.875093,
    "source_article": "Fermat's Last Theorem",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Fermat's Last Theorem",
      "modularity theorem",
      "elliptic curves"
    ]
  },
  {
    "id": "f7da64d7061f7419",
    "question_text": "Lebesgue's decomposition theorem states that any σ-finite measure ν on a measurable space can be uniquely decomposed with respect to another σ-finite measure μ. What are the two components?",
    "options": {
      "A": "A purely atomic measure plus a diffuse non-atomic measure, determined solely by ν's internal structure",
      "B": "ν splits into a finite measure and an infinite measure, separating the bounded and unbounded contributions to the total mass of ν across the measurable space so that integration against ν can be handled as a finite integral plus an improper integral extending to infinity",
      "C": "ν splits into a component absolutely continuous with respect to μ (possessing a Radon-Nikodym derivative dν/dμ) and a component singular with respect to μ (supported on a set of μ-measure zero)",
      "D": "A positive part and a negative part (Jordan decomposition), measuring where ν exceeds or falls below μ"
    },
    "correct_answer": "C",
    "difficulty": 5,
    "x": 0.870665,
    "y": 0.666214,
    "z": 0.698303,
    "source_article": "Lebesgue decomposition",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Lebesgue decomposition",
      "absolute continuity",
      "singular measures"
    ]
  },
  {
    "id": "3eed733b71493308",
    "question_text": "The Continuum Hypothesis (CH) asserts that there is no set whose cardinality lies strictly between that of the integers and the real numbers. What is its status within standard mathematics?",
    "options": {
      "A": "CH was proven false by Cohen in 1963 using forcing, which constructed an explicit set with cardinality between ℵ₀ and 2^ℵ₀",
      "B": "CH was proven true by Gödel in 1940 using the constructible universe L, which showed no intermediate cardinalities exist",
      "C": "CH remains open — neither consistency nor independence has been established, and it is one of the seven Millennium Prize Problems",
      "D": "CH is independent of ZFC — Gödel (1940) showed CH is consistent with ZFC (cannot be disproved), and Cohen (1963) showed ¬CH is also consistent with ZFC (cannot be proved), making CH undecidable within standard set theory"
    },
    "correct_answer": "D",
    "difficulty": 5,
    "x": 0.80073,
    "y": 0.577026,
    "z": 0.839808,
    "source_article": "Continuum Hypothesis",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Continuum Hypothesis",
      "independence",
      "forcing",
      "constructible universe"
    ]
  },
  {
    "id": "d9eda7f99cc7b5b1",
    "question_text": "The Langlands program proposes deep connections between number theory and representation theory. At its core, what kind of correspondence does it predict?",
    "options": {
      "A": "A correspondence between Galois representations (encoding arithmetic symmetries of number fields) and automorphic forms (highly symmetric analytic functions), linking the algebraic world of field extensions to the analytic world of harmonic analysis on reductive groups",
      "B": "A correspondence between prime numbers and eigenvalues of the Laplacian on hyperbolic manifolds, predicting that the nth prime equals the nth eigenvalue of the Laplacian on the modular surface up to an explicit error term bounded by the Riemann Hypothesis",
      "C": "A correspondence between finite simple groups and modular forms, predicting that every sporadic simple group arises as the automorphism group of a unique modular form of specific weight and level determined by the group's order",
      "D": "A correspondence between polynomial solutions over finite fields and Riemann zeta zeros, unifying the Weil conjectures with the Riemann Hypothesis"
    },
    "correct_answer": "A",
    "difficulty": 5,
    "x": 0.631032,
    "y": 0.646588,
    "z": 0.86869,
    "source_article": "Langlands program",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "Langlands program",
      "Galois representations",
      "automorphic forms"
    ]
  },
  {
    "id": "a4fa32a4bf445190",
    "question_text": "The abc conjecture (proved by Mochizuki, though contested) relates the prime factorization of three coprime positive integers a + b = c. If proven, it would imply which of the following major consequences?",
    "options": {
      "A": "It would prove the Riemann Hypothesis by establishing a direct equivalence between the distribution of prime factors in abc triples and the zeros of the Riemann zeta function on the critical strip",
      "B": "It would provide a new, short proof of Fermat's Last Theorem for all sufficiently large exponents, because the abc conjecture directly bounds the size of solutions to xⁿ + yⁿ = zⁿ, forcing n to be bounded — and combining this with existing computer verifications for small n resolves the full theorem",
      "C": "It would resolve the twin prime conjecture by showing that the gap between consecutive primes is bounded by a constant determined by the abc ratio, connecting the additive structure of integers to the distribution of prime gaps",
      "D": "It would prove that every even number greater than 2 is the sum of two primes (Goldbach's conjecture), because the abc conjecture controls how prime factors interact in additive equations of three integers"
    },
    "correct_answer": "B",
    "difficulty": 5,
    "x": 0.639009,
    "y": 0.646929,
    "z": 0.776525,
    "source_article": "abc conjecture",
    "domain_ids": [
      "mathematics"
    ],
    "concepts_tested": [
      "abc conjecture",
      "Fermat's Last Theorem",
      "Diophantine equations"
    ]
  }
]