{
  "domain": "probability-statistics",
  "parent_domain": "mathematics",
  "total_concepts": 50,
  "distribution": { "L1": 13, "L2": 13, "L3": 12, "L4": 12 },
  "concepts": {
    "L1": [
      {"concept": "probability", "wikipedia_article": "Probability", "brief_rationale": "The likelihood that an event will occur, expressed as a number between 0 and 1; the most foundational concept in the entire field."},
      {"concept": "mean", "wikipedia_article": "Mean", "brief_rationale": "The arithmetic average of a set of numbers; the most commonly recognized summary statistic, familiar from everyday life."},
      {"concept": "median", "wikipedia_article": "Median", "brief_rationale": "The middle value in an ordered dataset; universally taught alongside mean as a measure of central tendency."},
      {"concept": "mode", "wikipedia_article": "Mode (statistics)", "brief_rationale": "The most frequently occurring value in a dataset; introduced in every introductory statistics course as the third measure of center."},
      {"concept": "variance", "wikipedia_article": "Variance", "brief_rationale": "Average squared deviation from the mean measuring spread; universally taught as the foundational measure of dispersion."},
      {"concept": "standard deviation", "wikipedia_article": "Standard deviation", "brief_rationale": "Square root of variance measuring spread in original units; the most widely recognized measure of variability in data."},
      {"concept": "histogram", "wikipedia_article": "Histogram", "brief_rationale": "Bar chart displaying frequency distribution of data; universally used to visualize the shape of a dataset."},
      {"concept": "normal distribution", "wikipedia_article": "Normal distribution", "brief_rationale": "The bell-shaped probability distribution; the most famous and widely applied distribution in all of statistics."},
      {"concept": "random variable", "wikipedia_article": "Random variable", "brief_rationale": "A variable whose value is determined by a random process; the central object connecting probability to statistics."},
      {"concept": "sample", "wikipedia_article": "Sampling (statistics)", "brief_rationale": "A subset of a population used to draw inferences; foundational concept distinguishing descriptive from inferential statistics."},
      {"concept": "correlation", "wikipedia_article": "Correlation", "brief_rationale": "A measure of the linear relationship between two variables; widely recognized and frequently reported in scientific and popular literature."},
      {"concept": "outlier", "wikipedia_article": "Outlier", "brief_rationale": "A data point that differs markedly from other observations; universally taught as a concern in data analysis and summary statistics."},
      {"concept": "hypothesis testing", "wikipedia_article": "Statistical hypothesis test", "brief_rationale": "A procedure for deciding whether data support a claim about a population; the conceptual framework behind most applied statistical analysis."}
    ],
    "L2": [
      {"concept": "Bayes' theorem", "wikipedia_article": "Bayes' theorem", "brief_rationale": "Named rule relating conditional probabilities via prior and likelihood; specific fundamental result taught in every probability course."},
      {"concept": "p-value", "wikipedia_article": "P-value", "brief_rationale": "The probability of obtaining results at least as extreme as observed under the null hypothesis; specific named quantity central to hypothesis testing."},
      {"concept": "confidence interval", "wikipedia_article": "Confidence interval", "brief_rationale": "A range of values estimated to contain a population parameter with a given probability; specific named inferential tool universally taught in introductory statistics."},
      {"concept": "central limit theorem", "wikipedia_article": "Central limit theorem", "brief_rationale": "Named theorem stating that sample means converge to a normal distribution as sample size grows; the key theoretical result justifying normal-based inference."},
      {"concept": "law of large numbers", "wikipedia_article": "Law of large numbers", "brief_rationale": "Named theorem stating that sample averages converge to the population mean with increasing sample size; foundational named result in probability theory."},
      {"concept": "binomial distribution", "wikipedia_article": "Binomial distribution", "brief_rationale": "Distribution of the number of successes in n independent Bernoulli trials; specific named distribution universally introduced in introductory probability."},
      {"concept": "Poisson distribution", "wikipedia_article": "Poisson distribution", "brief_rationale": "Distribution modeling counts of rare events in a fixed interval; specific named distribution widely applied in science and engineering."},
      {"concept": "t-test", "wikipedia_article": "Student's t-test", "brief_rationale": "Named hypothesis test for comparing means using the t-distribution; specific named procedure the most commonly applied statistical test."},
      {"concept": "chi-squared test", "wikipedia_article": "Chi-squared test", "brief_rationale": "Named test for independence or goodness of fit using the chi-squared distribution; specific named procedure universally taught in introductory statistics."},
      {"concept": "linear regression", "wikipedia_article": "Linear regression", "brief_rationale": "Model fitting a linear relationship between a response and one or more predictors; specific named method the most widely applied statistical model."},
      {"concept": "expected value", "wikipedia_article": "Expected value", "brief_rationale": "The probability-weighted average of all possible values of a random variable; specific named quantity fundamental to probability theory and decision making."},
      {"concept": "conditional probability", "wikipedia_article": "Conditional probability", "brief_rationale": "The probability of an event given that another event has occurred; specific technical concept underlying Bayes' theorem and probabilistic reasoning."},
      {"concept": "null hypothesis", "wikipedia_article": "Null hypothesis", "brief_rationale": "The default claim of no effect or no difference that hypothesis tests attempt to reject; specific named concept structuring all of frequentist inference."}
    ],
    "L3": [
      {"concept": "maximum likelihood estimation", "wikipedia_article": "Maximum likelihood estimation", "brief_rationale": "Method of estimating parameters by maximizing the likelihood function; requires working knowledge of how probability models are fit to data and why the estimator has good properties."},
      {"concept": "Markov chain", "wikipedia_article": "Markov chain", "brief_rationale": "Stochastic process where future states depend only on the current state; requires working knowledge of transition matrices, stationarity, and ergodicity."},
      {"concept": "ANOVA", "wikipedia_article": "Analysis of variance", "brief_rationale": "Method for comparing means across multiple groups by partitioning variance; requires working knowledge of F-statistics, sum-of-squares decomposition, and model assumptions."},
      {"concept": "moment generating function", "wikipedia_article": "Moment-generating function", "brief_rationale": "Function whose derivatives at zero yield the moments of a distribution; requires working knowledge of how it uniquely characterizes distributions and simplifies sums of independent variables."},
      {"concept": "sufficient statistic", "wikipedia_article": "Sufficient statistic", "brief_rationale": "A statistic that captures all information in the data relevant to estimating a parameter; requires working knowledge of the Fisher-Neyman factorization theorem and its implications."},
      {"concept": "bootstrap", "wikipedia_article": "Bootstrapping (statistics)", "brief_rationale": "Resampling method for estimating the sampling distribution of a statistic; requires working knowledge of how resampling with replacement approximates variability without distributional assumptions."},
      {"concept": "Bayesian inference", "wikipedia_article": "Bayesian inference", "brief_rationale": "Statistical framework updating prior beliefs with observed data via Bayes' theorem to form a posterior distribution; requires working knowledge of prior choice, likelihood specification, and posterior computation."},
      {"concept": "type I and type II errors", "wikipedia_article": "Type I and type II errors", "brief_rationale": "False positive (rejecting a true null) and false negative (failing to reject a false null) errors; requires working knowledge of their trade-off, significance level, and statistical power."},
      {"concept": "logistic regression", "wikipedia_article": "Logistic regression", "brief_rationale": "Regression model for binary outcomes using the logistic function; requires working knowledge of log-odds, maximum likelihood fitting, and interpretation of coefficients."},
      {"concept": "probability density function", "wikipedia_article": "Probability density function", "brief_rationale": "Function describing the relative likelihood of a continuous random variable taking a given value; requires working knowledge of how it relates to cumulative distributions and how probabilities are computed as integrals."},
      {"concept": "covariance", "wikipedia_article": "Covariance", "brief_rationale": "Measure of the joint variability of two random variables; requires working knowledge of how it differs from correlation, how it is computed, and its role in the covariance matrix."},
      {"concept": "law of total probability", "wikipedia_article": "Law of total probability", "brief_rationale": "Expresses the probability of an event by conditioning on a partition of the sample space; requires working knowledge of conditional probability and how it underlies Bayesian computations."}
    ],
    "L4": [
      {"concept": "Cramér-Rao bound", "wikipedia_article": "Cramér–Rao bound", "brief_rationale": "Lower bound on the variance of any unbiased estimator in terms of the Fisher information; requires deep knowledge of efficiency, score functions, and the information inequality."},
      {"concept": "Kolmogorov axioms", "wikipedia_article": "Probability axioms", "brief_rationale": "The formal axiomatic foundation of probability theory via measure on a sigma-algebra; requires deep knowledge of how rigorous probability is built from measure theory."},
      {"concept": "martingale", "wikipedia_article": "Martingale (probability theory)", "brief_rationale": "Stochastic process where the expected future value equals the current value; requires deep knowledge of filtrations, optional stopping, and applications in finance and gambling theory."},
      {"concept": "exponential family", "wikipedia_article": "Exponential family", "brief_rationale": "Broad parametric family of distributions sharing a common log-partition function form; requires deep knowledge of sufficient statistics, natural parameters, and how it unifies GLMs and Bayesian conjugacy."},
      {"concept": "Gaussian process", "wikipedia_article": "Gaussian process", "brief_rationale": "Stochastic process where any finite collection of points follows a multivariate normal distribution; requires deep knowledge of kernel functions, covariance structure, and its use in spatial statistics and machine learning."},
      {"concept": "Rao-Blackwell theorem", "wikipedia_article": "Rao–Blackwell theorem", "brief_rationale": "Guarantees that conditioning an unbiased estimator on a sufficient statistic yields a uniformly better estimator; requires deep knowledge of conditional expectation, sufficiency, and the theory of uniformly minimum-variance unbiased estimators."},
      {"concept": "Neyman-Pearson lemma", "wikipedia_article": "Neyman–Pearson lemma", "brief_rationale": "Establishes that the likelihood ratio test is the most powerful test for simple hypotheses at a given significance level; requires deep knowledge of power functions, uniformly most powerful tests, and their limits."},
      {"concept": "copula", "wikipedia_article": "Copula (statistics)", "brief_rationale": "Function linking multivariate joint distributions to their marginals via Sklar's theorem; requires deep knowledge of dependence structures beyond linear correlation and applications in risk modeling."},
      {"concept": "Dirichlet process", "wikipedia_article": "Dirichlet process", "brief_rationale": "A stochastic process over distributions used as a nonparametric Bayesian prior; requires deep knowledge of stick-breaking constructions, Chinese restaurant processes, and Bayesian nonparametrics."},
      {"concept": "empirical process theory", "wikipedia_article": "Empirical process", "brief_rationale": "Study of convergence of empirical distribution functions as stochastic processes; requires deep knowledge of Donsker's theorem, uniform convergence, and Vapnik-Chervonenkis complexity theory."},
      {"concept": "Fisher information", "wikipedia_article": "Fisher information", "brief_rationale": "Measure of the amount of information a random variable carries about an unknown parameter via the expected squared score; requires deep knowledge of its role in the Cramér-Rao bound, asymptotic theory, and information geometry."},
      {"concept": "extreme value theory", "wikipedia_article": "Extreme value theory", "brief_rationale": "Study of the limiting distributions of maxima and minima of random variables via the Gumbel, Fréchet, and Weibull families; requires deep knowledge of the Fisher-Tippett-Gnedenko theorem and applications in risk and reliability analysis."}
    ]
  }
}
